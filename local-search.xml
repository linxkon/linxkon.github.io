<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>大型语言模型LLM训练流程详解</title>
    <link href="/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%B7%A5%E4%BD%9C%E6%B5%81.html"/>
    <url>/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%B7%A5%E4%BD%9C%E6%B5%81.html</url>
    
    <content type="html"><![CDATA[<h2 id="更新内容">更新内容</h2><p>这里是近期(2024年8月1日)更新的LLaMA3.1的模型后训练（Post-training）策略和流程</p><blockquote><p>在预训练的基础上，通过几轮后训练对模型进行微调，使其更好地与人类反馈对齐。</p><p>每轮后训练包括监督微调（SFT）和直接偏好优化（DPO），后者使用了人工注释和合成的数据样本。</p></blockquote><figure><img src="/images/llama3模型架构/llm训练流程.png" alt="LLM pipline" /><figcaption aria-hidden="true">LLM pipline</figcaption></figure><h4 id="提示收集">1.提示收集</h4><ul><li><strong>CollectedPrompts（收集的提示）</strong>：开始于收集各种输入提示。</li></ul><h4 id="响应生成">2. 响应生成</h4><ul><li><strong>K Generations perPrompt（每个提示生成K个响应）</strong>：每个提示生成多个响应（K个），以供后续选择和优化。</li></ul><h4 id="响应筛选">3. 响应筛选</h4><ul><li>Rejection Sampling（拒绝采样）<ul><li>使用奖励模型对生成的响应进行评分</li><li>通过拒绝采样来选择质量较高的响应</li><li>有助于筛选出最优的生成结果</li></ul></li></ul><h4 id="奖励模型">4. 奖励模型</h4><p>在预训练检查点的基础上训练奖励模型（Reward Model,RM），利用人类标注的偏好数据进行训练，主要目标是根据偏好数据进行排序和选择。</p><ul><li>奖励模型使用（选择的、被拒绝的）响应对进行训练，此外，还可以通过对选择的响应进行编辑以创建第三种“编辑响应”。</li><li>将提示和多个响应连接为单行进行训练，响应随机打乱，以提高训练效率。</li></ul><h4 id="监督微调">5. 监督微调</h4><p>使用奖励模型对人类注释的提示进行拒绝采样，再结合合成数据进行监督微调。微调时使用交叉熵损失，采用的学习率和训练步数在实验中取得了良好的效果。</p><ul><li><strong>SFTData（监督微调数据）</strong>：从拒绝采样中选出的高质量数据</li><li><strong>Specialized Per-CapabilityData（专门化的每项能力数据）</strong>：<ul><li>这些数据专注于特定能力的提升，比如推理、编码、事实性、多语言支持、工具使用、长上下文理解以及精准指令执行等。</li></ul></li><li>SFT Model（监督微调模型）<ul><li>利用SFT数据进行监督微调训练</li><li>提高模型在特定任务上的表现</li><li>使用<strong>Specialized Per-capability SFTdata</strong>，针对特定能力进行微调</li></ul></li></ul><p>使用交叉熵损失对目标标记进行训练，并对提示标记进行损失掩码。</p><p>大模型采用1e-5的学习率，训练步数为8500至9000步。</p><h4 id="直接偏好优化">6. 直接偏好优化</h4><p>DPO是在人类偏好数据上对齐模型的进一步优化步骤，旨在提高模型生成结果的满意度。</p><p>通过调整DPO的超参数（如学习率和正则化项）优化模型表现。使用DPO进行训练时，采用1e-5的学习率，并设定超参数β。</p><ul><li>Final DPO Model（最终直接偏好优化模型）<ul><li>在SFT模型基础上进行直接偏好优化（DPO）训练</li><li>进一步对齐模型的输出与人类偏好</li></ul></li></ul><h4 id="模型迭代">7. 模型迭代</h4><ul><li>Best models from previous rounds（来自前几轮的最佳模型）<ul><li>每轮训练后，选择表现最好的模型进入下一轮训练</li></ul></li></ul><h1 id="llm经典训练流程">LLM经典训练流程</h1><h2 id="数据准备和预处理">1. 数据准备和预处理</h2><ul><li>大规模数据收集（网络爬虫、数据库购买等）</li><li>数据清洗和过滤（去重、去噪、内容审核等）</li><li>数据格式化和标准化</li><li>数据增强（如回译、同义词替换等）</li></ul><h2 id="预训练pretraining">2. 预训练（Pretraining）</h2><ul><li><strong>数据集</strong>：来自互联网的原始数据，包含数万亿个单词，质量较低但数量庞大</li><li><strong>算法</strong>：语言模型，通过预测下一个token进行训练（涉及其他自监督学习任务，如maskedlanguage modeling）</li><li><strong>模型</strong>：基础模型（Basemodel），需要数千个GPU进行数月的大规模分布式训练</li><li><strong>示例</strong>：GPT、LLaMA、PaLM等</li><li><strong>备注</strong>：可以部署这个模型，过程涉及模型检查点保存和验证</li></ul><blockquote><p>以下阶段统称后训练</p></blockquote><h2 id="监督微调supervised-finetuning">3. 监督微调（SupervisedFinetuning）</h2><ul><li><strong>数据集</strong>：由承包商编写的理想助手响应（包括提示和响应对），数量在1万到10万对之间，质量较高</li><li><strong>特点</strong>：<ul><li>数据集创建是关键挑战，需要精心设计提示和回答，以涵盖各种场景和任务</li><li>可能使用其他语言模型生成部分数据，然后人工筛选</li><li>可能引入特定领域的数据，以增强模型在某些领域的能力</li></ul></li><li><strong>算法</strong>：语言模型，通过预测下一个token进行训练</li><li><strong>模型</strong>：SFT模型（Supervised FinetuningModel），从基础模型初始化，需要1到100个GPU，训练时间为数天</li><li><strong>示例</strong>：Vicuna-13B</li><li><strong>备注</strong>：可以部署这个模型</li></ul><h2 id="奖励模型reward-modeling">4. 奖励模型（Reward Modeling）</h2><ul><li><strong>数据集</strong>：构建人类偏好数据集，由承包商编写的<strong>比较数据</strong>，数量在10万到100万之间，质量较高</li></ul><blockquote><p>比较对（pairwisecomparisons）形式，即对于两个输出，标注出哪一个更符合人类偏好</p><table><thead><tr class="header"><th>输入</th><th>输出1</th><th>输出2</th><th>人类偏好</th></tr></thead><tbody><tr class="odd"><td>用户：天气怎么样？</td><td>答：今天晴天，温度25度。</td><td>答：今天天气不错，适合出门。</td><td>输出1</td></tr><tr class="even"><td>用户：今天天气如何？</td><td>答：温度大约20度，适合户外活动。</td><td>答：今天天气挺好的。</td><td>输出1</td></tr></tbody></table></blockquote><ul><li><strong>算法</strong>：<strong>二元分类</strong>或其它<strong>排序评分</strong>机制，通过预测一致性奖励来进行训练</li><li><strong>模型</strong>：RM模型（RewardModel），从SFT模型初始化，需要1到100个GPU，训练时间为数天</li><li><strong>备注</strong>：<strong>奖励模型可以独立部署</strong>，<strong>用于评估模型输出的质量</strong>。</li></ul><h2 id="强化学习reinforcement-learning">5. 强化学习（ReinforcementLearning）</h2><ul><li><strong>数据集</strong>：由承包商编写的提示数据，数量在1万到10万之间，质量较高</li></ul><blockquote><table><thead><tr class="header"><th>输入</th><th>目标输出</th></tr></thead><tbody><tr class="odd"><td>用户：天气怎么样？</td><td>答：今天晴天，气温在25度左右，非常适合户外活动。</td></tr><tr class="even"><td>用户：今天天气如何？</td><td>答：今天天气不错，气温大约20度，适合散步。</td></tr></tbody></table></blockquote><ul><li><p><strong>模型</strong>：<strong>RL模型</strong>（ReinforcementLearningModel），从SFT模型初始化并<strong>使用奖励模型</strong>，需要1到100个GPU，训练时间为数天</p></li><li><p><strong>算法</strong>：强化学习，通过生成最大化奖励的token进行训练</p></li></ul><blockquote><p>常用强化学习算法包括Proximal PolicyOptimization（PPO）等，使用奖励模型（RM）来提供反馈。</p><p>当模型生成的输出获得较高的奖励分数时，调整参数以增加生成此类输出的概率。</p><p>当模型生成的输出获得较低的奖励分数时，调整参数以减少生成此类输出的概率。</p></blockquote><ul><li><strong>示例</strong>：ChatGPT和Claude</li><li><strong>备注</strong>：可以部署这个模型，训练时监控和防止模型退化</li></ul><h2 id="领域适应domain-adaptation">6. 领域适应（Domain Adaptation）</h2><ul><li><strong>数据集</strong>：来自源领域和目标领域的数据，源领域数据较为丰富，目标领域数据稀缺或分布不同，数量因领域而异</li></ul><blockquote><table><thead><tr class="header"><th>输入</th><th>目标输出</th></tr></thead><tbody><tr class="odd"><td>源领域：猫的图片</td><td>猫（分类标签）</td></tr><tr class="even"><td>目标领域：新环境中的猫的图片</td><td>猫（分类标签），需要模型适应目标领域的视觉特征变化</td></tr></tbody></table></blockquote><ul><li><strong>模型</strong>：<strong>领域适应模型</strong>（DomainAdaptationModel），通常使用迁移学习技术，将预训练模型在源领域的知识迁移到目标领域。可使用1到10个GPU，训练时间从数小时到数天不等，具体取决于数据规模和复杂度。</li><li><strong>算法</strong>：使用<strong>对抗性训练</strong>（如DANN：Domain-AdversarialNeural Networks）或<strong>重加权方法</strong>（如TCA：TransferComponent Analysis）来最小化源领域和目标领域的分布差异</li></ul><blockquote><p>领域适应通常涉及在源领域预训练模型，然后在目标领域进行微调或通过对抗性损失调整模型，使其在目标领域上表现良好。</p><p>主要思想是通过<strong>对抗性训练</strong>使模型对源领域和目标领域的数据分布差异不敏感。</p><p>通过减少源领域和目标领域特征空间的分布差异，提高模型在目标领域的性能。</p></blockquote><h2 id="多任务学习multi-task-learning">7. 多任务学习（Multi-taskLearning）</h2><p>主要内容:设计多种下游任务 , 联合训练模型以提高泛化能力</p><ul><li><strong>数据集</strong>：多任务学习需要来自多个相关任务的数据集，各任务数据量可根据实际情况调整，通常任务间有某种程度的相关性</li></ul><blockquote><table><thead><tr class="header"><th>输入</th><th>目标输出</th></tr></thead><tbody><tr class="odd"><td>任务1：语法纠正</td><td>正确的句子（语言修正）</td></tr><tr class="even"><td>任务2：情感分析</td><td>情感标签（正面、负面、中性）</td></tr><tr class="odd"><td>任务3：机器翻译</td><td>目标语言翻译（英语翻译为法语）</td></tr></tbody></table></blockquote><ul><li><strong>模型</strong>：<strong>多任务学习模型</strong>（Multi-taskLearningModel），通过共享表示学习多个任务。可用1到100个GPU，训练时间因任务和数据量而异，从数小时到数天不等。</li><li><strong>算法</strong>：使用<strong>共享参数架构</strong>（如共享编码器-解码器）或<strong>任务特定头</strong>，在多个相关任务间共享知识和表示</li></ul><blockquote><p>多任务学习通过共享网络的部分结构来共同训练多个任务。</p><p>共享部分捕获任务间的通用特征，而每个任务也有其特定的参数以捕获专门特性。</p><p>这种方法有助于利用相关任务的信息来增强模型的泛化能力和性能。</p></blockquote><ul><li><strong>示例</strong>：QWEN的多任务学习应用，包括问答、文本分类和实体识别等任务</li><li><strong>备注</strong>：多任务学习模型需注意任务间的权衡与平衡，可能需要调整不同任务的损失函数权重</li></ul><h2 id="多模态扩展如果适用">8. 多模态扩展（如果适用）</h2><ul><li><strong>数据集</strong>：构建多模态数据集，包括文本、图像、音频和视频等模态，规模可达数十亿样本，数据多样性高，标注质量优良。</li></ul><blockquote><p>数据集包含多模态的配对样本，例如文本与图像的对齐关系、音频与视频的关联信息等，数据应覆盖多种场景和领域，以支持模型的广泛应用。</p></blockquote><ul><li><strong>模型</strong>：多模态大模型（如CLIP、DALL-E），基于Transformer架构，支持多模态信息的联合学习和表征，训练时需高性能计算资源。</li></ul><blockquote><p>模型能够处理和融合来自多种模态的信息，使用跨模态对齐机制学习不同模态之间的关系。初始模型可能需要在大规模数据上进行预训练，并通过微调适应特定任务。</p></blockquote><ul><li><strong>算法</strong>：使用<strong>跨模态对齐</strong>算法，如<strong>对比学习</strong>和<strong>自监督学习</strong>，通过优化不同模态表示之间的一致性来提高模型性能。</li></ul><blockquote><p>对比学习可以用于学习文本和图像的共同表示空间，通过最小化相似模态的距离和最大化不相似模态的距离，实现模态对齐和信息融合。</p></blockquote><ul><li><strong>备注</strong>：多模态模型需要大量计算资源，训练时应注意数据隐私和伦理问题，未来发展方向包括提高模型的泛化能力和降低计算成本。</li></ul><h2 id="模型压缩和优化">9. 模型压缩和优化</h2><ul><li>知识蒸馏（Knowledge Distillation）</li><li>模型量化（Quantization）</li><li>模型剪枝（Pruning）</li><li>模型结构搜索（Neural Architecture Search）</li></ul><h2 id="安全性和伦理性强化">10. 安全性和伦理性强化</h2><ul><li>偏见检测和缓解</li><li>有害内容过滤训练</li><li>隐私保护机制实现（如联邦学习）</li></ul><h2 id="模型评估和基准测试">11. 模型评估和基准测试</h2><ul><li>在各种NLP任务上进行评估</li><li>与其他模型比较性能</li><li>进行人类评估</li></ul><h2 id="部署准备">12. 部署准备</h2><ul><li>模型服务化（如ONNX转换、TensorRT优化等）</li><li>API设计和实现</li><li>性能优化（如推理加速）</li></ul><h2 id="持续学习和更新">13. 持续学习和更新</h2><ul><li>收集用户反馈</li><li>增量训练或定期重训练</li><li>A/B测试新版本</li></ul><h2 id="模型解释性和可视化">14. 模型解释性和可视化</h2><ul><li>注意力可视化</li><li>决策树提取</li><li>概念激活向量分析</li></ul><h2 id="额外说明">额外说明</h2><h4 id="流程说明">流程说明</h4><blockquote><ul><li>整个流程可能是迭代的，而不是严格的线性过程。例如，可能在RL后再进行SFT。</li><li>多模态模型（如GPT-4）的训练可能涉及更复杂的流程和数据处理。</li></ul></blockquote><h4id="大模型对齐large-language-model-alignment与rlhf"><strong>大模型对齐</strong>(LargeLanguage Model Alignment)与RLHF</h4><p>大模型对齐指的是在预训练的基础上，进一步将大模型的输出与任务场景和人类的价值观相统一，大模型对齐分为SFT，RLHF两个阶段,<strong>RLHF</strong>（ReinforcementLearning from HumanFeedback）指的是人类反馈强化学习的方法，它一般涵盖奖励模型和强化学习两个步骤。<img src="/images/llama3模型架构/SFT与RLHF.jpg" alt="SFT与RLHF" /></p><p><strong>监督微调（SFT）</strong></p><p><strong>定义</strong>：在新任务的小规模标注数据集上，使用有监督学习的方法对预训练模型进行微调，以使其适应新任务。</p><p><strong>步骤</strong>：加载预训练模型 → 准备新任务的数据集 →调整模型输出层 → 在新任务数据集上训练模型。</p><p><strong>应用</strong>：适用于那些有明确标注数据集的任务，如文本分类、命名实体识别等。</p><p><strong>基于人类反馈的强化学习微调（RLHF)</strong></p><p><strong>定义</strong>：在SFT的基础上，通过强化学习和人类反馈来进一步微调模型，使其输出更加符合人类的偏好或期望。</p><p><strong>步骤</strong>：首先进行SFT → 收集人类反馈数据 → 训练奖励模型→ 使用奖励模型指导强化学习过程来微调模型。</p><p><strong>应用</strong>：适用于那些需要高度人类判断或创造力的任务，如对话生成、文本摘要等。</p>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>大模型</tag>
      
      <tag>笔记整理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLaMA 3.1 模型架构技术解析及代码实现</title>
    <link href="/lamma3.1%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84.html"/>
    <url>/lamma3.1%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84.html</url>
    
    <content type="html"><![CDATA[<figure><img src="/images/llama3模型架构/image-20240725101545036.png"alt="image-20240725101545036" /><figcaption aria-hidden="true">image-20240725101545036</figcaption></figure><p>LLaMA3.1的模型结构如上图所示，它代表了目前主流的大型语言模型架构，也被称为DenseLLM。它应用了经典Transformer的Decoder部分并加以改造。与之相对的是混合专家模型（Mixture ofExperts，MOE）。MOE模型的主要特点是：将前馈网络（FFN）模块中的单一SwiGLU替换为个并行的SwiGLU模块，每个模块被称为"专家"。增加了一个路由网络，用于为每个输入token选择最合适的"专家"。</p><blockquote><p><strong>小课堂: Dense LLM与 MOE LLM</strong></p><p>Dense LLM（密集大语言模型）：</p><ul><li>这是传统的LLM结构，如GPT系列、LLaMA等。</li><li>所有的参数在每次推理时都会被激活和使用。</li><li>模型结构相对简单，每个层的每个神经元都参与计算。</li></ul><p>MOE结构LLM（Mixture of Experts，专家混合模型）：</p><ul><li>这是一种更复杂的模型结构，如Google的Switch Transformer。</li><li>模型包含多个"专家"子网络（experts）和一个路由机制。</li><li>在处理每个输入时，只激活部分专家，而不是全部参数。</li></ul></blockquote><h3 id="llama-3.1的模型架构的8个技术点一览">LLaMA3.1的模型架构的8个技术点一览</h3><ol type="1"><li><p><strong>Transformer Block × L</strong>：这个模块表示整个Transformer 由多个重复的 Transformer 块组成，这里的 (L) 指的是Transformer 块的层数。</p></li><li><p><strong>TokenEmbedding</strong>：输入的词（token）被嵌入到一个高维向量空间中，作为Transformer 的输入。</p></li><li><p><strong>RMSNorm</strong>：每个 Transformer 块使用 RMSNorm（RootMean Square Layer Normalization）来进行正则化。它与传统的 LayerNorm不同，RMSNorm 使用的是均方根来进行归一化操作。</p></li><li><p><strong>Pre-Norm</strong>：正则化的位置是在主计算路径之前，这种做法可以提高模型的稳定性和收敛速度。</p></li><li><p><strong>Grouped Query Attention(GQA)</strong>：这个模块表示使用了一种称为“分组查询注意力”的自注意力机制。GQA是一种改进的注意力机制，通过对查询进行分组，可以提高模型的效率和性能。</p></li><li><p><strong>ROPE（Rotary PositionalEncoding）</strong>：一种位置编码机制，用于在模型中注入位置信息。ROPE通过旋转变换为位置提供相对位置信息，使模型可以更好地理解序列中的位置关系。</p></li><li><p><strong>SwiGLU</strong>：这是 Feed-Forward Network (FFN)的结构，SwiGLU 是一种使用 Gate LinearUnits（GLU）的变体，通过引入非线性激活函数来增强模型的表达能力。</p></li><li><p><strong>Skip Connection</strong>：在 Transformer中，使用跳跃连接（SkipConnection）来促进梯度流动和模型训练的稳定性。</p></li></ol><p>LLaMA 3.1的架构结合了最新的正则化、注意力机制和位置编码技术，旨在提高 Transformer模型的效率和性能。</p><h2 id="一.-transformer-block-l">一. Transformer Block× L</h2><p>TransformerBlock是模型构成的基本单元,它基本可以分为两部分构成:自注意层和前馈全连接层(FFN),通过将以上Transformer单元组合L次,即可得到LLaMA3.1的整体架构,L即layers的具体数值与模型的参数量有关.</p><figure><img src="/images/llama3模型架构/image-20240725103022368.png"alt="image-20240725103022368" /><figcaption aria-hidden="true">image-20240725103022368</figcaption></figure><p>不同参数量模型的详细参数如下</p><table><thead><tr class="header"><th></th><th style="text-align: right;">8B</th><th style="text-align: right;">70B</th><th style="text-align: right;">405B</th></tr></thead><tbody><tr class="odd"><td>Layers</td><td style="text-align: right;">32</td><td style="text-align: right;">80</td><td style="text-align: right;">126</td></tr><tr class="even"><td>Model Dimension</td><td style="text-align: right;">4,096</td><td style="text-align: right;">8192</td><td style="text-align: right;">16,384</td></tr><tr class="odd"><td>FFN Dimension</td><td style="text-align: right;">6,144</td><td style="text-align: right;">12,288</td><td style="text-align: right;">20,480</td></tr><tr class="even"><td>Attention Heads</td><td style="text-align: right;">32</td><td style="text-align: right;">64</td><td style="text-align: right;">128</td></tr><tr class="odd"><td>Key/Value Heads</td><td style="text-align: right;">8</td><td style="text-align: right;">8</td><td style="text-align: right;">8</td></tr><tr class="even"><td>Peak Learning Rate</td><td style="text-align: right;">3 × 10⁻⁴</td><td style="text-align: right;">1.5 × 10⁻⁴</td><td style="text-align: right;">8 × 10⁻⁵</td></tr><tr class="odd"><td>Activation Function</td><td style="text-align: right;">SwiGLU</td><td style="text-align: right;">SwiGLU</td><td style="text-align: right;">SwiGLU</td></tr><tr class="even"><td>Vocabulary Size</td><td style="text-align: right;">128,000</td><td style="text-align: right;">128,000</td><td style="text-align: right;">128,000</td></tr><tr class="odd"><td>Positional Embeddings</td><td style="text-align: right;">RoPE (θ = 500,000)</td><td style="text-align: right;">RoPE (θ = 500,000)</td><td style="text-align: right;">RoPE (θ = 500,000)</td></tr></tbody></table><h2 id="二.-token-embedding">二. Token Embedding</h2><p>在 LLaMA模型中，<strong>Token Embedding</strong>是第二个关键模块。其主要功能是将输入的词（token）转换为高维向量，以便后续的Transformer层可以有效地处理这些数据。具体来说,模型首先从词汇表中获取输入词的索引,然后利用嵌入矩阵将每个词映射到一个唯一的高维向量。这个过程将离散的词语转化为连续的向量表示,能够捕捉词语的语义和上下文信息。</p><p>TokenEmbedding的设计有几个重要优势。首先,它能够有效地捕捉和表示词语的语义信息,使模型更好地理解词语之间的关系。其次,将词语转换为向量表示降低了输入数据的复杂度,便于后续计算。最后,这种设计增强了模型的表达能力,使其能够学习和处理复杂的语言模式和结构,从而在各种自然语言处理任务中表现出色。</p><p>TokenEmbedding在NLP领域已经是主流的技术手段,pytroch中也已经封装好它的实现:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br>vocab_size = <span class="hljs-number">10000</span>  <span class="hljs-comment"># 词汇表大小</span><br>embedding_dim = <span class="hljs-number">256</span>  <span class="hljs-comment"># 嵌入向量的维度</span><br><br>embedding_layer = nn.Embedding(vocab_size, embedding_dim)<br><br><span class="hljs-comment"># 假设我们有一个批次的输入序列</span><br>input_ids = torch.LongTensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br><br><span class="hljs-comment"># 通过Embedding层获取嵌入向量</span><br>embedded = embedding_layer(input_ids)<br><br><span class="hljs-built_in">print</span>(embedded.shape)  <span class="hljs-comment"># 输出：torch.Size([2, 4, 256])</span><br></code></pre></td></tr></table></figure><h2 id="三-.-rmsnorm">三 . RMSNorm</h2><ol type="1"><li>基本原理: RMSNorm使用均方根(Root MeanSquare)来对神经网络中的隐藏状态进行归一化。这种方法旨在稳定深度网络中的激活值分布,有助于<strong>加速训练过程并提高模型性能</strong>。</li><li>计算过程:</li></ol><ul><li>计算输入向量x的均方根值</li><li>用这个均方根值来归一化输入向量</li><li>应用可学习的缩放参数g</li></ul><p>数学表达式:RMSNorm(x) = x / RMS(x) * g 其中RMS(x) =sqrt(mean(x^2))</p><ol type="1"><li>与LayerNorm的区别:</li></ol><ul><li>LayerNorm使用均值和方差进行归一化</li><li>RMSNorm只使用均方根,计算更简单</li><li>RMSNorm不需要减去均值,保留了原始信号的一些属性</li></ul><ol type="1"><li>优势:</li></ol><ul><li>计算效率更高,尤其是在大规模模型中</li><li>在某些任务中表现优于LayerNorm</li><li>有助于缓解梯度消失/爆炸问题</li></ul><h4 id="rmsnorm实现">RMSNorm实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, num_heads</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.attention = nn.MultiheadAttention(dim, num_heads)<br>        self.feed_forward = nn.Sequential(<br>            nn.Linear(dim, <span class="hljs-number">4</span> * dim),<br>            nn.GELU(),<br>            nn.Linear(<span class="hljs-number">4</span> * dim, dim)<br>        )<br>        self.norm1 = RMSNorm(dim)<br>        self.norm2 = RMSNorm(dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 自注意力</span><br>        attn_output, _ = self.attention(x, x, x)<br>        x = x + attn_output<br>        x = self.norm1(x)<br><br>        <span class="hljs-comment"># 前馈网络</span><br>        ff_output = self.feed_forward(x)<br>        x = x + ff_output<br>        x = self.norm2(x)<br><br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h4 id="rmsnorm调用">RMSNorm调用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, num_heads</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.attention = nn.MultiheadAttention(dim, num_heads)<br>        self.feed_forward = nn.Sequential(<br>            nn.Linear(dim, <span class="hljs-number">4</span> * dim),<br>            nn.GELU(),<br>            nn.Linear(<span class="hljs-number">4</span> * dim, dim)<br>        )<br>        self.norm1 = RMSNorm(dim)<br>        self.norm2 = RMSNorm(dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 自注意力</span><br>        attn_output, _ = self.attention(x, x, x)<br>        x = x + attn_output<br>        x = self.norm1(x)<br><br>        <span class="hljs-comment"># 前馈网络</span><br>        ff_output = self.feed_forward(x)<br>        x = x + ff_output<br>        x = self.norm2(x)<br><br>        <span class="hljs-keyword">return</span> x<br>    <br><span class="hljs-comment"># 创建一个使用RMSNorm的Transformer块</span><br>block = TransformerBlock(dim=<span class="hljs-number">512</span>, num_heads=<span class="hljs-number">8</span>)<br><br><span class="hljs-comment"># 创建一个随机输入张量</span><br>x = torch.randn(<span class="hljs-number">32</span>, <span class="hljs-number">10</span>, <span class="hljs-number">512</span>)  <span class="hljs-comment"># [batch_size, seq_len, dim]</span><br><br><span class="hljs-comment"># 前向传播</span><br>output = block(x)<br><br><span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># 应该输出 torch.Size([32, 10, 512])</span><br></code></pre></td></tr></table></figure><blockquote><p>注意事项：</p><ol type="1"><li><code>eps</code> 参数用于数值稳定性，防止除以零。</li><li>RMSNorm 的权重参数 <code>self.weight</code>是可学习的，在训练过程中会被优化。</li><li>在实际应用中，您可能需要根据具体需求调整 RMSNorm的实现，例如考虑不同的维度或批处理情况。</li><li>某些PyTorch版本可能已经包含了RMSNorm的实现，您可以检查最新的文档或考虑使用第三方库（如<code>transformers</code>库）中的实现。</li><li>在使用RMSNorm时，可能需要调整学习率或其他超参数，因为它可能会影响模型的训练动态。</li></ol></blockquote><h2 id="四-.-gqa分组查询注意力机制">四 . GQA(分组查询注意力机制)</h2><ol type="1"><li><p>背景：传统的自注意力机制在处理长序列时会面临计算复杂度和内存消耗的问题。随着模型规模的增大，这些问题变得更加突出。</p></li><li><p>GQA的基本思想：将查询（Query）向量分成多个组，每组共享相同的键（Key）和值（Value）矩阵。这种方法可以在保持模型表达能力的同时，显著减少参数数量和计算复杂度。</p></li><li><p>工作原理：</p><ul><li>将查询向量分成G个组。</li><li>每个组使用独立的查询权重矩阵。</li><li>所有组共享相同的键和值权重矩阵。</li><li>对每个组单独计算注意力分数和输出。</li><li>最后将所有组的输出合并。</li></ul></li><li><p>优势：</p><ul><li>参数效率：减少了模型的参数数量，特别是在键和值矩阵上。</li><li>计算效率：降低了注意力计算的复杂度。</li><li>内存效率：减少了中间结果的存储需求。</li><li>可扩展性：使得模型更容易扩展到更大的规模。</li></ul></li><li><p>与其他注意力变体的比较：</p><ul><li>相比于多头注意力（Multi-HeadAttention），GQA在保持类似性能的同时，具有更高的参数和计算效率。</li><li>相比于稀疏注意力机制，GQA更容易实现和优化。</li></ul></li><li><p>潜在局限性：</p><ul><li><p>可能会略微降低模型的表达能力，尤其是在处理需要精细区分的任务时。</p></li><li><p>分组数量的选择可能会影响模型性能，需要仔细调优。</p><p>总的来说，GQA是一种在效率和性能之间取得良好平衡的注意力机制，为大型语言模型的发展提供了重要支持。它的出现标志着注意力机制设计正朝着更高效、更可扩展的方向发展。</p><h4 id="gqa的定义">GQA的定义</h4></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GroupedQueryAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, num_heads, num_groups</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">assert</span> num_heads % num_groups == <span class="hljs-number">0</span>, <span class="hljs-string">&quot;num_heads must be divisible by num_groups&quot;</span><br>        <br>        self.dim = dim<br>        self.num_heads = num_heads<br>        self.num_groups = num_groups<br>        self.head_dim = dim // num_heads<br>        <br>        self.q_proj = nn.Linear(dim, dim)<br>        self.k_proj = nn.Linear(dim, dim // num_groups)<br>        self.v_proj = nn.Linear(dim, dim // num_groups)<br>        self.out_proj = nn.Linear(dim, dim)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        batch_size, seq_len, _ = x.shape<br>        <br>        <span class="hljs-comment"># Project inputs</span><br>        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)<br>        k = self.k_proj(x).view(batch_size, seq_len, self.num_groups, self.head_dim)<br>        v = self.v_proj(x).view(batch_size, seq_len, self.num_groups, self.head_dim)<br>        <br>        <span class="hljs-comment"># Transpose for attention computation</span><br>        q = q.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        k = k.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        v = v.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        <br>        <span class="hljs-comment"># Compute attention scores</span><br>        attn_weights = torch.matmul(q, k.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)) / (self.head_dim ** <span class="hljs-number">0.5</span>)<br>        attn_weights = F.softmax(attn_weights, dim=-<span class="hljs-number">1</span>)<br>        <br>        <span class="hljs-comment"># Apply attention to values</span><br>        out = torch.matmul(attn_weights, v)<br>        <br>        <span class="hljs-comment"># Reshape and project output</span><br>        out = out.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(batch_size, seq_len, self.dim)<br>        out = self.out_proj(out)<br>        <br>        <span class="hljs-keyword">return</span> out<br><br><span class="hljs-comment"># 使用示例</span><br>dim = <span class="hljs-number">512</span><br>num_heads = <span class="hljs-number">8</span><br>num_groups = <span class="hljs-number">2</span><br>batch_size = <span class="hljs-number">32</span><br>seq_len = <span class="hljs-number">100</span><br><br>gqa = GroupedQueryAttention(dim, num_heads, num_groups)<br>x = torch.randn(batch_size, seq_len, dim)<br>output = gqa(x)<br><span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># 应该输出 torch.Size([32, 100, 512])</span><br></code></pre></td></tr></table></figure><h4 id="gqa的调用">GQA的调用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, num_heads, num_groups, ffn_dim</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.attention = GroupedQueryAttention(dim, num_heads, num_groups)<br>        self.ffn = nn.Sequential(<br>            nn.Linear(dim, ffn_dim),<br>            nn.ReLU(),<br>            nn.Linear(ffn_dim, dim)<br>        )<br>        self.norm1 = nn.LayerNorm(dim)<br>        self.norm2 = nn.LayerNorm(dim)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x + self.attention(self.norm1(x))<br>        x = x + self.ffn(self.norm2(x))<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><blockquote><p>确保 <code>num_heads</code> 能被 <code>num_groups</code> 整除。</p><p>这个实现假设输入的形状是<code>(batch_size, sequence_length, embedding_dimension)</code>。</p><p><code>k_proj</code> 和 <code>v_proj</code>的输出维度是原始维度除以组数，这反映了 GQA 中键和值的共享特性。</p><p>在实际应用中，你可能需要根据具体需求调整实现，比如添加dropout、层归一化等。</p><p>这个实现没有考虑掩码（mask）。如果你需要处理可变长度的序列，你需要添加掩码支持。</p></blockquote></li></ol><h2 id="五-.-rope">五 . ROPE</h2><p>ROPE（Rotary PositionalEmbedding）是一种位置编码技术，旨在为Transformer模型注入相对位置信息。传统的Transformer模型使用位置编码来弥补自注意力机制在处理序列数据时缺乏位置信息的不足。ROPE通过旋转变换提供了一种更灵活和有效的方式来编码位置信息。以下是对ROPE的详细介绍：</p><ol type="1"><li><strong>背景</strong></li></ol><p>在自然语言处理中，序列中的位置信息是非常重要的。自注意力机制虽然能够捕获序列中元素之间的依赖关系，但本身不具备序列顺序的知识。因此，位置信息需要通过某种方式注入到模型中。传统的解决方案是使用固定的或可学习的位置编码。</p><ol start="2" type="1"><li><strong>传统位置编码的缺陷</strong></li></ol><p>传统的位置编码方法主要有两种：</p><ul><li><p><strong>固定位置编码</strong>：例如正弦和余弦函数生成的位置编码，这种方法将绝对位置信息注入到输入中。</p></li><li><p><strong>可学习的位置编码</strong>：这种方法使得位置编码可以在训练过程中进行学习和调整。</p></li></ul><p>这两种方法都有一定的局限性，特别是在处理非常长的序列时，传统位置编码可能不够灵活，无法有效地捕获相对位置信息。</p><ol start="3" type="1"><li><strong>ROPE的核心思想</strong></li></ol><p>ROPE采用了旋转变换来表示位置信息，核心思想是通过旋转将位置信息嵌入到特征向量中。这种方法能够直接在向量空间中表示相对位置关系，而不是绝对位置。</p><ul><li><p><strong>旋转变换</strong>：对于每个输入向量，ROPE使用一个旋转矩阵对其进行变换。具体来说，如果一个向量被表示为复数或二维向量对（实部和虚部），那么它可以通过复数乘法进行旋转。</p></li><li><p><strong>相对位置编码</strong>：通过旋转，相对位置信息自然地嵌入到向量中，而无需显式表示。这使得模型可以更好地捕获序列中元素的相对顺序和关系。</p></li></ul><ol start="4" type="1"><li><strong>数学原理</strong></li></ol><p>假设有一个输入向量 ( x )，其在位置 ( p ) 的旋转编码可以表示为：</p><p>[ (x, p) = x R(p) ]</p><p>其中，( R(p) ) 是一个旋转矩阵或复数旋转算子，表示为：</p>[ R(p) = (<span class="math display">\[\begin{array}{cc} \cos(\theta_p) &amp;-\sin(\theta_p) \\ \sin(\theta_p) &amp; \cos(\theta_p)\end{array}\]</span><p>) ]</p><p>或者在复数形式下：</p><p>[ R(p) = e^{i_p} ]</p><p>这里，( _p ) 是与位置 ( p ) 相关的旋转角度，通常与位置线性相关。</p><ol start="5" type="1"><li><strong>优势</strong></li></ol><ul><li><p><strong>相对位置信息</strong>：ROPE可以自然地表示相对位置信息，而不是仅仅依赖绝对位置信息，这对长序列处理尤为有利。</p></li><li><p><strong>无缝集成</strong>：ROPE可以与现有的Transformer架构无缝集成，不需要对模型结构进行重大修改。</p></li><li><p><strong>计算效率</strong>：旋转变换是一种简单而高效的操作，计算成本低。</p></li></ul><p><strong>6. 应用场景</strong></p><p>ROPE在处理长文本和其他需要捕获复杂相对位置信息的任务中表现优异，特别是在语言模型、翻译和序列预测任务中具有显著优势。</p><p>通过使用ROPE，模型可以更好地理解和生成自然语言文本，尤其在需要复杂上下文关系建模的场景中表现突出。</p><h2 id="六.-swiglu">六. swiGLU</h2><p><strong>结构</strong>:SwiGLU是对标准FFN的改进。它的主要组成部分包括两个线性变换和一个门控机制。</p><p><strong>公式</strong>: SwiGLU的基本公式可以表示为: SwiGLU(x) =swish(xW) ⊙ (xV)其中,x是输入,W和V是权重矩阵,swish是激活函数,⊙表示逐元素相乘。</p><p><strong>Swish激活函数</strong>:SwiGLU使用Swish作为激活函数,而不是传统的ReLU。Swish函数定义为f(x) = x *sigmoid(βx),其中β是一个可学习的参数。</p><p><strong>优势</strong>:</p><ul><li>增强非线性:SwiGLU通过引入更复杂的非线性变换,提高了模型的表达能力。</li><li>改善梯度流: Swish函数的平滑特性有助于更好的梯度传播。</li><li>自适应门控: 门控机制允许模型动态调整信息流。</li></ul><p><strong>应用</strong>:SwiGLU在多个大型语言模型中得到应用,如PaLM和GPT-4,显著提升了模型性能。</p><p><strong>计算效率</strong>:尽管SwiGLU的计算复杂度略高于标准FFN,但其性能提升通常可以抵消这一成本。</p><p><strong>与其他变体的比较</strong>:相比于GLU或GeGLU等其他变体,SwiGLU在多项任务中表现更为出色。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#创建SwiGLU类</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SwiGLU</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_features, hidden_features=<span class="hljs-literal">None</span>, out_features=<span class="hljs-literal">None</span>, bias=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        out_features = out_features <span class="hljs-keyword">or</span> in_features<br>        hidden_features = hidden_features <span class="hljs-keyword">or</span> in_features<br>        self.w1 = nn.Linear(in_features, hidden_features, bias=bias)<br>        self.w2 = nn.Linear(in_features, hidden_features, bias=bias)<br>        self.w3 = nn.Linear(hidden_features, out_features, bias=bias)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x1 = self.w1(x)<br>        x2 = self.w2(x)<br>        x1 = F.silu(x1)  <span class="hljs-comment"># SiLU is equivalent to Swish with beta=1</span><br>        out = x1 * x2<br>        out = self.w3(out)<br>        <span class="hljs-keyword">return</span> out<br><br><span class="hljs-comment"># 使用示例</span><br>in_features = <span class="hljs-number">512</span><br>hidden_features = <span class="hljs-number">2048</span><br>out_features = <span class="hljs-number">512</span><br><br>swiglu = SwiGLU(in_features, hidden_features, out_features)<br><br><span class="hljs-comment"># 假设我们有一个输入张量</span><br>input_tensor = torch.randn(<span class="hljs-number">32</span>, <span class="hljs-number">512</span>)  <span class="hljs-comment"># batch_size=32, sequence_length=512</span><br><br>output = swiglu(input_tensor)<br><span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># 应该输出 torch.Size([32, 512])</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#模型的调用</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.swiglu = SwiGLU(<span class="hljs-number">512</span>, <span class="hljs-number">2048</span>, <span class="hljs-number">512</span>)<br>        <span class="hljs-comment"># 其他层...</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.swiglu(x)<br>        <span class="hljs-comment"># 其他操作...</span><br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p>全文完</p><p>更详细的实现过程见<ahref="https://linxkon.github.io/从零实现llama3.html">从头开始实现llama3- AI·你所爱 (linxkon.github.io)</a></p>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型架构</tag>
      
      <tag>LLaMA</tag>
      
      <tag>知识总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>谁是最强大模型--权威大模型榜单整理</title>
    <link href="/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%92%E8%A1%8C%E6%A6%9C.html"/>
    <url>/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%92%E8%A1%8C%E6%A6%9C.html</url>
    
    <content type="html"><![CDATA[<p>大模型的发展日新月异,那到底哪个模型更强呢,不同模型又有哪些各自擅长的领域呢?这里整理几个比较权威的LLM评测榜单和数据集供诸君参考.</p><span id="more"></span><h3 id="lmsys-chatbot-arena"><ahref="https://chat.lmsys.org/?leaderboard">LMSYS Chatbot Arena</a></h3><ul><li>LMSYS Chatbot Arena是一个众包的开放平台，用于大语言模型（LLM）的评估。收集了超过 1,000,000次人类成对比较，使用 Bradley-Terry 模型对 LLM 进行排名，并以 Elo评分展示模型的评级。</li></ul><p>https://chat.lmsys.org/?leaderboard</p><h3 id="opencompass"><ahref="https://rank.opencompass.org.cn/home">OpenCompass</a></h3><ul><li>OpenCompass是一个开源项目,提供丰富的算法和功能支持，能够帮助社区更便捷地对NLP模型的性能进行公平全面的评估。</li></ul><p><ahref="https://www.modelscope.cn/studios/opencompass/CompassArena">司南评测</a>：国产版LMSYSChatbot Arena</p><p><ahref="https://www.modelscope.cn/studios/opencompass/CompassArena/summary?fullScreen=1">CompassArena司南大模型竞技场 · 创空间 (modelscope.cn)</a></p><p><ahref="https://rank.opencompass.org.cn/leaderboard-llm/?m=24-05">OpenCompass司南- 评测榜单</a></p><blockquote><p>OC是国产的，榜单上经常有不知是真是假的”惊喜“。</p></blockquote><h2 id="openllmleaderboard"><ahref="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard">OpenLLMLeaderboard</a></h2><p>Open LLMLeaderboard是最大的大模型和数据集社区HuggingFace推出的开源大模型排行榜单，基于EleutherAl Language Model Evaluation Harness EleutherAl语言模型评估框架）封装。由于社区在发布了大量的大型语言模型（LLM）和聊天机器人之后，往往伴随着对其性能的夸大宣传，很难过滤出开源社区取得的真正进展以及目前的最先进模型。因此，HuggingFace使用EleutherAl语言模型评估框架对模型进行四个关键基准测试评估。这是一个统一的框架，用于在大量不同的评估任务上测试生成式语言模型。</p><h3 id="mmlu"><ahref="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu">MMLU</a></h3><ul><li><strong>MMLU</strong> ： 全称Massive Multitask LanguageUnderstanding，是一种针对大模型的<strong>语言理解能力的测评</strong>，是目前最著名的大模型语义理解测评之一，由UCBerkeley大学的研究人员在2020年9月推出。该测试涵盖57项任务，包括初等数学、美国历史、计算机科学、法律等。任务涵盖的知识很广泛，语言是英文，用以评测大模型基本的知识覆盖范围和理解能力。</li></ul><p>https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu</p><h3 id="c-eval"><ahref="https://cevalbenchmark.com/static/leaderboard_zh.html">C-Eval</a></h3><ul><li><strong>C-Eval</strong> ： C-Eval是一个全面的中文基础模型评估套件。由上海交通大学、清华大学和匹兹堡大学研究人员在2023年5月份联合推出，它包含了13948个多项选择题，涵盖了52个不同的学科和四个难度级别。用以<strong>评测大模型中文理解能力</strong>。</li></ul><p>https://cevalbenchmark.com/static/leaderboard.html</p><h3 id="gsm8k">GSM8K</h3><ul><li><strong>GSM8K</strong> ：OpenAI发布的大模型数学推理能力评测基准，涵盖了8500个中学水平的高质量数学题数据集。数据集比之前的数学文字题数据集规模更大，语言更具多样性，题目也更具挑战性。该项测试在2021年10月份发布，至今仍然是非常困难的一种测试基准.</li></ul><p>https://paperswithcode.com/sota/arithmetic-reasoning-on-gsm8k</p><h3 id="agi-eval">AGI Eval</h3><ul><li><strong>AGI Eval</strong> ：微软发布的大模型基础能力评测基准，在2023年4月推出，主要评测大模型在人类认知和解决问题的一般能力，涵盖全球20种面向普通人类考生的官方、公共和高标准录取和资格考试，包含中英文数据。因此，该测试更加倾向于<strong>人类考试结果</strong>，涵盖了中英文，论文地址：https://arxiv.org/abs/2304.06364</li></ul><h3 id="lmsys榜单">LMSYS榜单</h3><iframe aria-hidden="true" tabindex="-1" src="about:blank" style="box-sizing: border-box; border: 0px; display: block; vertical-align: middle; top: 0px; left: 0px; width: 1146.4px; height: 62.2px; overflow: hidden; opacity: 0; pointer-events: none; z-index: -1;"></iframe><table><thead><tr class="header"><th>🤖 Model</th><th>⭐ Arena Elo</th><th>📈 MT-bench</th><th>📚 MMLU</th><th>Organization</th><th>License</th></tr></thead><tbody><tr class="odd"><td><ahref="https://openai.com/index/hello-gpt-4o/">GPT-4o-2024-05-13</a></td><td>1287</td><td></td><td>88.7</td><td>OpenAI</td><td>Proprietary</td></tr><tr class="even"><td><ahref="https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4">GPT-4-Turbo-2024-04-09</a></td><td>1252</td><td></td><td></td><td>OpenAI</td><td>Proprietary</td></tr><tr class="odd"><td><ahref="https://openai.com/blog/new-models-and-developer-products-announced-at-devday">GPT-4-1106-preview</a></td><td>1250</td><td>9.32</td><td></td><td>OpenAI</td><td>Proprietary</td></tr><tr class="even"><td><ahref="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">Gemini1.5 Pro API-0409-Preview</a></td><td>1248</td><td></td><td>81.9</td><td>Google</td><td>Proprietary</td></tr><tr class="odd"><td><a href="https://www.anthropic.com/news/claude-3-family">Claude 3Opus</a></td><td>1246</td><td></td><td>86.8</td><td>Anthropic</td><td>Proprietary</td></tr><tr class="even"><td><ahref="https://openai.com/blog/new-models-and-developer-products-announced-at-devday">GPT-4-0125-preview</a></td><td>1244</td><td></td><td></td><td>OpenAI</td><td>Proprietary</td></tr><tr class="odd"><td><a href="https://www.01.ai/">Yi-Large-preview</a></td><td>1236</td><td></td><td></td><td>01 AI</td><td>Proprietary</td></tr><tr class="even"><td><a href="https://bard.google.com/">Bard (Gemini Pro)</a></td><td>1208</td><td></td><td></td><td>Google</td><td>Proprietary</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>排行榜</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RAG加分神器:embedding与rerank</title>
    <link href="/RAG%E5%8A%A0%E5%88%86%E7%A5%9E%E5%99%A8embedding%E4%B8%8Ererank.html"/>
    <url>/RAG%E5%8A%A0%E5%88%86%E7%A5%9E%E5%99%A8embedding%E4%B8%8Ererank.html</url>
    
    <content type="html"><![CDATA[<p>基于 Retrieval Augmented Generation (<strong>RAG</strong>)技术的效果取决于两个关键因素:</p><ol type="1"><li>文本嵌入及语义提取的性能:<ul><li>这个环节负责将输入文本转换为有意义的语义表示向量。</li><li>嵌入算法的准确性和鲁棒性直接影响后续的搜索和排序效果。</li></ul></li><li>重排序模块的性能:<ul><li>这个环节负责根据语义相似度对检索到的相关文本进行排序。</li><li>排序算法的效果直接决定了包含正确答案的文本是否能够排在前列。</li></ul></li></ol><p>总的来说, RAG模型的整体性能高低取决于上述两个关键环节的表现。只有当语义提取和重排序两者均达到较高水平,RAG模型才能发挥出应有的优势,为用户提供准确可靠的信息检索和生成服务。各自使用的环节如下：</p><p>​ <imgsrc="/images/RAG中的embedding与rerank/2052730-20240629105924854-837516240.png"alt="img" /></p><p>1、文本embedding的提取：理论上讲，任何transformer架构的encoder部分都可用于生成token的embedding，然后采用合适的pooling方式把整个setence中所有token的embedding融合成一个embedding。截止目前，哪个现成的LLM的encoder更适合提取整段句子的embedding了？</p><p>　　　要想效果好，以下是必要条件：</p><ul><li>模型不能太小，否则对训练预料的“”消化、承载“”能力不够，无法精准理解语义；模型也不能太大，否则过于耗费计算资源，同时还需要大量训练预料，否则会欠拟合（模型参数大小和所需token数详见scalinglaw）！</li><li>训练预料要足够，涵盖各行业、各领域；也要涵盖各种不同的类型、风格的文本(中英文、说明文、议论文、陈述文、小说、散文、诗歌)等</li><li>最好能提供微调的接口，利于用户使用自己特定领域的数据</li></ul><p>　　截止目前，业界公认效果比较好的就是moka-ai/m3e了！以下是官方的介绍：</p><ul><li>Moka，此模型由 MokaAI 训练，开源和评测，训练脚本使用 <ahref="https://github.com/wangyuxinwhy/uniem/blob/main/scripts/train_m3e.py">uniem</a>，评测 BenchMark 使用 <ahref="https://github.com/wangyuxinwhy/uniem/tree/main/mteb-zh">MTEB-zh</a></li><li>Massive，此模型通过千万级 (2200w+)的中文<strong>句对</strong>数据集进行训练</li><li>Mixed，此模型支持中英双语的<strong>同质文本相似度计算，异质文本检索</strong>等功能，未来还会支持代码检索</li></ul><p>　　<strong>最核心的还是训练数据</strong>了，如下：</p><ul><li>中文训练集，M3E在大规模句对数据集上的训练，包含中文百科，金融，医疗，法律，新闻，学术等多个领域共计2200W 句对样本，数据集详见 <ahref="https://huggingface.co/moka-ai/m3e-base#M3E数据集">M3E数据集</a></li><li>英文训练集，M3E 使用 MEDI 145W 英文三元组数据集进行训练，数据集详见<ahref="https://drive.google.com/file/d/1vZ5c2oJNonGOvXzppNg5mHz24O6jcc52/view">MEDI数据集</a>，此数据集由 <ahref="https://github.com/HKUNLP/instructor-embedding">instructorteam</a> 提供</li><li>指令数据集，M3E 使用了 300W + 的指令微调数据集，这使得 M3E对文本编码的时候可以遵从指令，这部分的工作主要被启发于 <ahref="https://github.com/HKUNLP/instructor-embedding">instructor-embedding</a>（这点很牛逼，<strong>同样的sentence，可以根据不同的instruct生成不同的embedding，充分理解语义，比普通的bert模型强多了</strong>）</li></ul><p>　　基础模型，还是基于bert架构：</p><ul><li>基础模型，M3E 使用 hfl 实验室的 <ahref="https://huggingface.co/hfl/chinese-roberta-wwm-ext">Roberta</a>系列模型进行训练，目前提供 small 、base和large三个版本；<strong>只要是embedding，就离不开bert架构！</strong></li></ul><p>　　最终的效果就是：ALL INONE，不仅支持<strong>同质句子相似度判断</strong>，还支持<strong>异质文本检索</strong>，只需要一个模型就可以覆盖全部的应用场景，各个指标对比如下：</p><p>​ <imgsrc="/images/RAG中的embedding与rerank/2052730-20240628225842866-1015035741.png"alt="img" />　　</p><p>　　看着还是很牛逼的！ M3E的配置文件1_Pooling/config.json，有pooling的方式和embedding的dimension：这里可以看出M3E默认采用的是每个token取均值的pooling方式！</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;word_embedding_dimension&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">768</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pooling_mode_cls_token&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pooling_mode_mean_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pooling_mode_max_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;pooling_mode_mean_sqrt_len_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>　　2、rerank： 经过第一步使用cosin余弦相似度从密集向量数据库 +keyword search（稀疏向量召回）初步召回topK相似度的文本，按理来说就可以让LLM根据用户的query +召回的context生成最终答案了，还要这个rerank干啥了？实际操作时，还是会发现一些问题：包含正确答案的文本在context中的排名可能并不靠前。比如query= “清华大学在哪座城市？”。正确答案肯定是“北京”啦！但实际召回的context中包含北京的文本不一定排在前面，可能在中间甚至后面，给最后一个LLM输入的context会很大，直接导致LLM需要处理很长的文本，推理效率低不说，还容易出错，核心问题还是在于：初步召回的context还是有进一步压缩提炼的空间！造成这种现象的原因是啥了？</p><p>　　利用cosin求两个向量的相似度，本质是看两个向量的距离。<strong>比如“北京”、“上海”、“深圳”这些都是中国的一线大城市，这3个词的embedding的cosin会很近，所以使用cosin召回的时候也可能把“上海”、“深圳”这些不是正确答案的sentence召回，所以要用tf-idf这类稀疏向量补充召回部分向量，整个过程称为hybrid search。经过hybirdsearch后，召回的context变多，给最后一步的LLM生成最终答案带来了麻烦，所以需要进一步从context中继续提炼，优中选优</strong>！比如初步召回20条，需要通过rerank选择更接近的3~5条，这个过程就是rerank！整个流程图示如下：</p><figure><imgsrc="/images/RAG中的embedding与rerank/2052730-20240629173627392-1724851624.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>　确定要做rerank后，怎么做才能达到既定的目的？要想明白这个问题，还要回到最初的动机：<strong>cosin计算的是两个向量的距离，只考虑语义相似，不考虑字面符号是否一致；而稀疏检索tf-idf只考虑字面的符号，不考虑语义</strong>，怎么整合这两种retrieve的优势，摒弃其劣势了？这就需要用到传统NLP常见的手段了：classifier！</p><p>​ <imgsrc="/images/RAG中的embedding与rerank/2052730-20240629190955087-450259949.png"alt="img" /></p><p>　如上图右边所示：两个sentence先进入同一个bert，lm_head用一个二分类来判断这两个sentence是否匹配！右边这种classifier判断是否匹配比左边这种cosin判断是否相似更准确，原因又是啥了？两个sentence首尾拼接进入bert后：</p><ul><li>先要计算attention计算token之间的相似度，再进入FFN<strong>生成非线性特征</strong>，更利于lm_head的分类</li><li>两个sentence的特征能<strong>两两组合交互生成新的维度特征</strong>，捕捉复杂的细节关系</li><li>cosin相似度的计算是基于整个sentence的embedding，但这种embeeding<strong>涉及到pooling，这个过程会有一定的信息丢失，造成精度下降</strong></li></ul><p>　 上面两个角度是从特征维度考虑的，从模型维度看，还有以下优点：</p><ul><li>cosin是没有参数可调节的，但classifier可以<strong>通过调节参数，让模型的目标函数主动适配特定的任务和数据分布。具体到这里，可以让模型生成的答案主动适配query；可以简单理解为answer对query的1v1有针对性的VIP服务！</strong></li></ul><p>　　当然，既然classifier的准确性提高了，为啥不从一开始就用这种classifier来召回生成context了？还用cosin计算相似度干嘛了？这里就是计算量的问题了！<strong>cosin的计算量远比classifier小，并且可以事先离线计算embedding存入向量数据库，所以适合第一步从大量数据中初步召回数十条；classifier精准度高，但计算量大，适合从初步召回的数十条context中进一步精选出几条包含或最接正确答案的context</strong>；</p><p>　　原理搞清楚了，接下来看代码：</p><p>　　getitem方法要对query、pos、neg三个不同的答案按照一定的逻辑配对，后续的loss才知道是0还是1；</p><figure><imgsrc="/images/RAG中的embedding与rerank/2052730-20240629230203323-1507745790.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>　看看吧：loss用的是常规的crossentropy；classifier也是常规的SequenceClassifierOutput，没啥特别的！</p><figure><imgsrc="/images/RAG中的embedding与rerank/2052730-20240629230348085-1080851308.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>总结：</p><p>1、RAG整个流程有3个地方涉及到LLM：<strong>文本embedding、rerank和根据context生成最终的答案</strong>2、moka官方的建议：</p><ul><li>使用场景主要是中文，少量英文的情况，建议使用 m3e 系列的模型</li><li>多语言使用场景，并且不介意数据隐私的话，我建议使用 openaitext-embedding-ada-002</li><li>代码检索场景，推荐使用 openai text-embedding-ada-002</li><li>文本检索场景，请使用具备文本检索能力的模型，只在 Sentence 2 Sentence上训练的文本嵌入模型，没有办法完成文本检索任务</li></ul><p>3、 FlagEmbedding也有 Embedding Model: <ahref="https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/visual">Visualized-BGE</a>,<ahref="https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3">BGE-M3</a>,<ahref="https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_embedder">LLMEmbedder</a>, <ahref="https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/baai_general_embedding">BGEEmbedding</a>，感兴趣的小伙伴也可以尝试一下！</p><figure><imgsrc="/images/RAG中的embedding与rerank/2052730-20240630171649397-1130484406.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>4、RAG整个流程中关键节点和涉及到的现成包列举如下：<strong>不同节点可以根据用户需求和实际情况选择，节点之间的选择可以排列组合</strong>！</p><figure><imgsrc="/images/RAG中的embedding与rerank/2052730-20240701172423551-368104928.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>参考：</p><p>1、https://huggingface.co/moka-ai/m3e-basehttps://github.com/wangyingdong/m3e-base</p><p>2、https://github.com/coffeebean6/retrieval_augmented_generation</p><p>3、https://blog.csdn.net/lovechris00/article/details/138378828</p><p>4、https://github.com/wangyuxinwhy/uniem/blob/main/examples/finetune.ipynb</p><p>5、https://www.bilibili.com/video/BV1h142197Fm/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=241a5bcb1c13e6828e519dd1f78f35b2https://techdiylife.github.io/blog/blog.html?category1=c02&amp;blogid=0047如何选择embedding模型</p><p>6、https://huggingface.co/spaces/mteb/leaderboard Massive TextEmbedding Benchmark (MTEB) Leaderboard</p><figure><imgsrc="/images/RAG中的embedding与rerank/2052730-20240701090619852-2066428401.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>7、https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzg3NDIyMzI0Mw==&amp;action=getalbum&amp;album_id=3377833073308024836RAG实战</p><p>8、https://www.pinecone.io/learn/series/rag/rerankers/https://www.bilibili.com/video/BV1r1421R77Y/?spm_id_from=333.788.recommend_more_video.2&amp;vd_source=241a5bcb1c13e6828e519dd1f78f35b2为什么要用rerank</p><p>9、https://qanything.ai/docs/architecture embedding和rerank测评https://github.com/netease-youdao/BCEmbedding/blob/master/Docs/EvaluationSummary/embedding_eval_summary.mdhttps://github.com/netease-youdao/BCEmbedding/blob/master/Docs/EvaluationSummary/reranker_eval_summary.md</p><figure><imgsrc="/images/RAG中的embedding与rerank/2052730-20240702233033921-228329500.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>RAG</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ollama部署常见问题解答</title>
    <link href="/ollama%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97.html"/>
    <url>/ollama%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97.html</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文将分为以下章节对 Ollama 进行介绍：</p><ol type="1"><li>Ollama 基本介绍，它的作用是什么</li><li>Ollama 软件安装、一些常用的系统参数设置</li><li>Ollama 管理本地已有大模型（包括终端对话界面）</li><li>Ollama 导入模型到本地的三种方式：直接从 Ollama 远程仓库拉取、通过GGUF 模型权重文件导入到本地、通过 safetensors模型权限文件导入到本地</li><li>基于 WebUI 部署 Ollama 可视化对话界面</li><li>Ollama 客户端 API 应用，包括 Python API 和 Java API 接口应用</li></ol></blockquote><h2 id="ollama-是什么它与-llama-有什么关系">Ollama 是什么，它与 Llama有什么关系？</h2><p><strong>Ollama</strong>官网：https://ollama.com/，官方网站的介绍就一句话：<strong>Getup and running with large language models.</strong>（开始使用大语言模型。）</p><p><strong>Ollama</strong>是一个开源的LLM（大型语言模型）服务工具，用于简化在本地运行大语言模型、降低使用大语言模型的门槛，使得大模型的开发者、研究人员和爱好者能够在本地环境快速实验、管理和部署最新大语言模型，包括如<strong>Qwen2</strong>、<strong>Llama3</strong>、<strong>Phi3</strong>、<strong>Gemma2</strong>等开源的大型语言模型。</p><p><strong>Ollama</strong>支持的大语言模型列表，可通过搜索模型名称查看：https://ollama.com/library</p><p><strong>Ollama</strong>官方 GitHub 源代码仓库：<ahref="https://github.com/ollama/ollama">https://github.com/ollama/ollama/</a></p><p><strong>Llama</strong>是 Meta公司开源的备受欢迎的一个通用大语言模型，和其他大模型一样，<strong>Llama</strong>可以通过<strong>Ollama</strong>进行管理部署和推理等。</p><p>因此，<code>Ollama</code>与<code>Llama</code>的关系：<code>Llama</code>是大语言模型，而<code>Ollama</code>是大语言模型（不限于<code>Llama</code>模型）便捷的管理和运维工具，它们只是名字后面部分恰巧相同而已！</p><figure><img src="/images/ollama/01.png" alt="Ollama官网" /><figcaption aria-hidden="true">Ollama官网</figcaption></figure><h2 id="ollama-安装和常用系统参数设置">Ollama安装和常用系统参数设置</h2><p>在官网首页，我们可以直接下载<strong>Ollama</strong>安装程序（支持Windows/MacOS/Linux）：https://ollama.com/</p><p><strong>Ollama</strong>的安装过程，与安装其他普通软件并没有什么两样，安装完成之后，有几个常用的系统<strong>环境变量</strong>参数建议进行设置：</p><ol type="1"><li><strong>OLLAMA_MODELS</strong>：模型文件存放目录，默认目录为当前用户目录（Windows目录：<code>C:\Users%username%.ollama\models</code>，MacOS目录：<code>~/.ollama/models</code>，Linux目录：<code>/usr/share/ollama/.ollama/models</code>），如果是 Windows系统<strong>建议修改</strong>（如：D:），避免 C 盘空间吃紧</li><li><strong>OLLAMA_HOST</strong>：Ollama服务监听的网络地址，默认为<strong>127.0.0.1</strong>，如果允许其他电脑访问Ollama（如：局域网中的其他电脑），<strong>建议设置</strong>成<strong>0.0.0.0</strong>，从而允许其他网络访问</li><li><strong>OLLAMA_PORT</strong>：Ollama服务监听的默认端口，默认为<strong>11434</strong>，如果端口有冲突，可以修改设置成其他端口（如：<strong>8080</strong>等）</li><li><strong>OLLAMA_ORIGINS</strong>：HTTP客户端请求来源，半角逗号分隔列表，若本地使用无严格要求，可以设置成星号，代表不受限制</li><li><strong>OLLAMA_KEEP_ALIVE</strong>：大模型加载到内存中后的存活时间，默认为<strong>5m</strong>即5 分钟（如：纯数字如 300 代表 300 秒，0代表处理请求响应后立即卸载模型，任何负数则表示一直存活）；我们可设置成<strong>24h</strong>，即模型在内存中保持24 小时，提高访问速度</li><li><strong>OLLAMA_NUM_PARALLEL</strong>：请求处理并发数量，默认为<strong>1</strong>，即单并发串行处理请求，可根据实际情况进行调整</li><li><strong>OLLAMA_MAX_QUEUE</strong>：请求队列长度，默认值为<strong>512</strong>，可以根据情况设置，超过队列长度请求被抛弃</li><li><strong>OLLAMA_DEBUG</strong>：输出 Debug日志标识，应用研发阶段可以设置成<strong>1</strong>，即输出详细日志信息，便于排查问题</li><li><strong>OLLAMA_MAX_LOADED_MODELS</strong>：最多同时加载到内存中模型的数量，默认为<strong>1</strong>，即只能有1 个模型在内存中</li></ol><h2 id="ollama-管理本地已有大模型">Ollama 管理本地已有大模型</h2><p>【展示本地大模型列表：<code>ollama list</code>】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama list</span><br>NAME            ID              SIZE    MODIFIED<br>gemma2:9b       c19987e1e6e2    5.4 GB  7 days ago<br>qwen2:7b        e0d4e1163c58    4.4 GB  10 days ago<br></code></pre></td></tr></table></figure><p>可以看到，本地有 2个大模型，它们的名称（<strong>NAME</strong>）分别为<strong>gemma2:9b</strong>和<strong>qwen2:7b</strong>。</p><p>【删除单个本地大模型：<code>ollama rm 本地模型名称</code>】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama <span class="hljs-built_in">rm</span> gemma2:9b</span><br>deleted &#x27;gemma2:9b&#x27;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama list</span><br>NAME            ID              SIZE    MODIFIED<br>qwen2:7b        e0d4e1163c58    4.4 GB  10 days ago<br></code></pre></td></tr></table></figure><p>通过<code>rm</code>命令删除了<strong>gemma2:9b</strong>大模型之后，再次通过<code>list</code>命令查看，本地只有<strong>qwen2:7b</strong>一个大模型了。</p><p>【设置模型下载目录：<code>ollama run 本地模型名</code>】</p><blockquote><p>模型默认存储地址为:</p><p>macOS: ~/.ollama/models Linux: /usr/share/ollama/.ollama/models#作为系统服务启动时 Linux: /home/<username>/.ollama/models#当前用户启动时 Windows: C:&lt;username&gt;.ollama</p></blockquote><blockquote><p><strong>Windows用户</strong></p><ol type="1"><li>设置 OLLAMA_MODELS</li></ol><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-comment"># 只设置当前用户</span><br>setx OLLAMA_MODELS <span class="hljs-string">&quot;D:\ollama_model&quot;</span> <br><span class="hljs-comment"># 为所有用户设置</span><br>setx OLLAMA_MODELS <span class="hljs-string">&quot;D:\ollama_model&quot;</span> <span class="hljs-string">/M</span><br><br>TEXT<br></code></pre></td></tr></table></figure><ol type="1"><li>重启终端（setx命令在Windows中设置环境变量时，这个变量的更改只会在新打开的命令提示符窗口或终端会话中生效。）</li><li>重启ollama服务</li></ol><p><strong>Linux一般用户</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 打开下面文件</span><br>nano ~/.bashrc<br><span class="hljs-comment"># 添加设置</span><br><span class="hljs-built_in">export</span> <span class="hljs-attribute">OLLAMA_MODELS</span>=<span class="hljs-string">&quot;/path/to/ollama_model&quot;</span><br><br>TEXT<br></code></pre></td></tr></table></figure><ol type="1"><li>重启终端</li><li>重启ollama服务： ollama serve</li></ol><p>或者直接使用： OLLAMA_MODELS="/path/to/ollama_model" ollama serve启动服务</p><p><strong>Liunx root 服务模式</strong>在服务文件中设置环境变量，并且要为新的目录设置ollama用户的读写权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 打开服务文件</span><br>sudo nano /etc/systemd/system/ollama.service<br><span class="hljs-comment"># 在文件中Service字段后添加</span><br>[Service]<br>Environment=<span class="hljs-string">&quot;OLLAMA_MODELS=/home/xxx/ollama/models&quot;</span><br>Environment=<span class="hljs-string">&quot;http_proxy=xxxxxx&quot;</span><br><br><span class="hljs-comment"># 设置目录访问权限 (根据反馈做了些调整)</span><br>sudo <span class="hljs-built_in">chown</span> ollama:ollama /home/xxx/ollama<br>sudo <span class="hljs-built_in">chmod</span> u+w /home/xxx/ollama<br>sudo <span class="hljs-built_in">chown</span> ollama:ollama /home/xxx/ollama/models<br>sudo <span class="hljs-built_in">chmod</span> u+w /home/xxx/ollama/models<br><br><span class="hljs-comment"># 重启服务</span><br>sudo systemctl daemon-reload<br>sudo systemctl restart ollama.service<br><br><span class="hljs-comment"># 确认状态</span><br>sudo systemctl status ollama.service<br><br>TEXT<br></code></pre></td></tr></table></figure><p>注：有小伙伴反馈，修改模型存储目录时，如果只设置/home/xxx/ollama/models 目录的权限会出现 mkdir没有权限的错误。所以，建议对目录 /home/xxx/ollama/models 和/home/xxx/ollama 都为ollama用户赋予读写权限（2024)</p></blockquote><p>【启动本地模型：<code>ollama run 本地模型名</code>】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama run qwen2:0.5b</span><br><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span><br></code></pre></td></tr></table></figure><p>启动成功之后，就可以通过终端对话界面进行对话了（本命令下面也会讲到，其他详细暂且忽略）</p><p>【查看本地运行中模型列表：<code>ollama ps</code>】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama ps</span><br>NAME            ID              SIZE    PROCESSOR       UNTIL<br>qwen2:0.5b      6f48b936a09f    693 MB  100% CPU        4 minutes from now<br></code></pre></td></tr></table></figure><p>通过<code>ps</code>命名可以看到，本地<strong>qwen2:0.5b</strong>大模型正在运行中。</p><p>【复制本地大模型：<code>ollama cp 本地存在的模型名 新复制模型名</code>】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama <span class="hljs-built_in">cp</span> qwen2:0.5b Qwen2-0.5B</span><br>copied &#x27;qwen2:0.5b&#x27; to &#x27;Qwen2-0.5B&#x27;<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama list</span><br>NAME                    ID              SIZE    MODIFIED<br>Qwen2-0.5B:latest       6f48b936a09f    352 MB  4 seconds ago<br>qwen2:0.5b              6f48b936a09f    352 MB  29 minutes ago<br>qwen2:7b                e0d4e1163c58    4.4 GB  10 days ago<br></code></pre></td></tr></table></figure><p>上面<code>cp</code>命令，把本地<strong>qwen2:0.5b</strong>复制了一份，新模型名为<strong>Qwen2-0.5B</strong></p><p>下面介绍三种通过 Ollama 下载到本地大模型方式：</p><ol type="1"><li>方式一：直接通过 Ollama远程仓库下载，这是最直接的方式，也是最推荐、最常用的方式</li><li>方式二：如果已经有 GGUF 模型权重文件了，不想重新下载，也可以通过Ollama 把该文件直接导入到本地（不推荐、不常用）</li><li>方式三：如果已经有 safetensors模型权重文件，也不想重新下载，也可以通过 Ollama把该文件直接导入到本地（不推荐、不常用）</li></ol><h2 id="方式一ollama-从远程仓库下载大模型到本地">方式一：Ollama从远程仓库下载大模型到本地</h2><p>【下载或者更新本地大模型：<code>ollama pull 本地/远程仓库模型名称</code>】</p><p>本<code>pull</code>命令从 Ollama远程仓库完整下载或增量更新模型文件，模型名称<strong>格式</strong>为：<strong>模型名称:参数规格</strong>；如<code>ollama pull qwen2:0.5b</code>则代表从 Ollama仓库下载<strong>qwen2</strong>大模型的<strong>0.5b</strong>参数规格大模型文件到本地磁盘：</p><figure><img src="/images/ollama/02.png" alt="Qwen2模型列表" /><figcaption aria-hidden="true">Qwen2模型列表</figcaption></figure><p>如果参数规格标记为<code>latest</code>则代表为默认参数规格，下载时<strong>可以</strong>不用指定，如<strong>Qwen2</strong>的<strong>7b</strong>被标记为<code>latest</code>，则<code>ollama pull qwen2</code>和<code>ollama pull qwen2:7b</code>这2个命令的意义是一样的，都下载的为<strong>7b</strong>参数规格模型。为了保证后续维护方便、避免误操作等，<strong>建议</strong>不管是否为默认参数规格，我们下载命令中均明确参数规格。</p><p>值得一提的是，今天开始<strong>GLM4</strong>支持 Ollama部署和推理，特意列出它的下载命令：<code>ollama pull glm4:9b</code>（和其他模型相比，其实并没有特殊支出）。需要注意的是：Ollama最低版本为<strong>0.2.0</strong>才能支持<strong>GLM4</strong>大模型！</p><figure><img src="/images/ollama/03.png" alt="GLM4模型列表" /><figcaption aria-hidden="true">GLM4模型列表</figcaption></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama pull qwen2:0.5b</span><br>pulling manifest<br>pulling manifest<br>pulling manifest<br>pulling manifest<br>pulling manifest<br>pulling 8de95da68dc4... 100% ▕████████████████████████▏ 352 MB<br>pulling 62fbfd9ed093... 100% ▕████████████████████████▏  182 B<br>pulling c156170b718e... 100% ▕████████████████████████▏  11 KB<br>pulling f02dd72bb242... 100% ▕████████████████████████▏   59 B<br>pulling 2184ab82477b... 100% ▕████████████████████████▏  488 B<br>verifying sha256 digest<br>writing manifest<br>removing any unused layers<br>success<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama list</span><br>NAME            ID              SIZE    MODIFIED<br>qwen2:0.5b      6f48b936a09f    352 MB  9 minutes ago<br>qwen2:7b        e0d4e1163c58    4.4 GB  10 days ago<br></code></pre></td></tr></table></figure><p>若本地不存在大模型，则<strong>下载</strong>完整模型文件到本地磁盘；若本地磁盘存在该大模型，则<strong>增量</strong>下载大模型更新文件到本地磁盘。</p><p>从上面最后的<code>list</code>命令结果可以看到，本地存在了<strong>qwen2:0.5b</strong>这个名称的大模型。</p><p>【下载且运行本地大模型：<code>ollama run 本地/远程仓库模型名称</code>】</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama run qwen2:0.5b</span><br><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">&gt;&gt;</span><br></code></pre></td></tr></table></figure><p>若本地不存在大模型，则<strong>下载</strong>完整模型文件到本地磁盘（类似于<code>pull</code>命令），然后<strong>启动</strong>大模型；若本地存在大模型，则直接启动（不进行更新）。</p><p>启动成功后，默认为终端对客界面：</p><figure><img src="/images/ollama/04.png" alt="Ollama终端对话界面" /><figcaption aria-hidden="true">Ollama终端对话界面</figcaption></figure><ol type="1"><li>若需要输入多行文本，需要用<strong>三引号</strong>包裹，如：<code>"""这里是多行文本"""</code></li><li><code>/clear</code>清除对话上下文信息</li><li><code>/bye</code>则退出对话窗口</li><li><code>/set parameter num_ctx 4096</code>可设置窗口大小为 4096 个Token，也可以通过请求设置，如：<code>curl &lt;http://localhost:11434/api/generate&gt; -d '&#123; "model": "qwen2:7b", "prompt": "Why is the sky blue?", "options": &#123; "num_ctx": 4096 &#125;&#125;'</code></li><li><code>/show info</code>可以查看当前模型详情： ，</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">&gt;&gt;&gt; /show info<br>  Model<br>        arch                    qwen2<br>        parameters              494.03M<br>        quantization            Q4_0<br>        context length          32768<br>        embedding length        896<br> <br>  Parameters<br>        stop    &quot;&lt;|im_start|&gt;&quot;<br>        stop    &quot;&lt;|im_end|&gt;&quot;<br> <br>  License<br>        Apache License<br>        Version 2.0, January 2004<br></code></pre></td></tr></table></figure><h2 id="方式二ollama-导入-gguf-模型文件到本地磁盘">方式二：Ollama 导入GGUF 模型文件到本地磁盘</h2><p>若我们已经从 HF 或者 ModeScope 下载了 GGUF文件（文件名为：<strong>Meta-Llama-3-8B-Instruct.Q4_K_M.gguf</strong>），在我们存放<code>Llama3-8B</code>的GGUF模型文件目录中，创建一个文件名为<code>Modelfile</code>的文件，该文件的内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">FROM ./Meta-Llama-3-8B-Instruct.Q4_K_M.gguf<br></code></pre></td></tr></table></figure><p>然后，打开终端，执行命令导入模型文件：<code>ollama create 模型名称 -f ./Modelfile</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama create Llama-3-8B -f ./Modelfile</span><br>transferring model data<br>using existing layer sha256:647a2b64cbcdbe670432d0502ebb2592b36dd364d51a9ef7a1387b7a4365781f<br>creating new layer sha256:459d7c837b2bd7f895a15b0a5213846912693beedaf0257fbba2a508bc1c88d9<br>writing manifest<br>success<br></code></pre></td></tr></table></figure><p>导入成功之后，我们就可以通过<code>list</code>命名，看到名为<strong>Llama-3-8B</strong>的本地模型了，后续可以和其他模型一样进行管理了。</p><h2id="方式三ollama-导入-safetensors-模型文件到到本地磁盘">方式三：Ollama导入 safetensors 模型文件到到本地磁盘</h2><p>官方操作文档：https://ollama.fan/getting-started/import/#importing-pytorch-safetensors</p><p>若我们已经从 HF 或者 ModeScope 下载了 safetensors文件（文件目录为：<strong>Mistral-7B</strong>），</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">git lfs install<br> <br>git clone https://www.modelscope.cn/rubraAI/Mistral-7B-Instruct-v0.3.git Mistral-7B<br></code></pre></td></tr></table></figure><p>然后，我们转换模型（结果：<code>Mistral-7B-v0.3.bin</code>）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python llm/llama.cpp/convert.py ./Mistral-7B --outtype f16 --outfile Mistral-7B-v0.3.bin<br></code></pre></td></tr></table></figure><p>接下来，进行量化量化：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">llm/llama.cpp/quantize Mistral-7B-v0.3.bin Mistral-7B-v0.3_Q4.bin q4_0<br></code></pre></td></tr></table></figure><p>最后，通过 Ollama导入到本地磁盘，创建<code>Modelfile</code>模型文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">FROM Mistral-7B-v0.3_Q4.bin<br></code></pre></td></tr></table></figure><p>执行导入命令，导入模型文件：<code>ollama create 模型名称 -f ./Modelfile</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">ollama create Mistral-7B-v0.3 -f ./Modelfile</span><br>transferring model data<br>using existing layer sha256:647a2b64cbcdbe670432d0502ebb2592b36dd364d51a9ef7a1387b7a4365781f<br>creating new layer sha256:459d7c837b2bd7f895a15b0a5213846912693beedaf0257fbba2a508bc1c88d9<br>writing manifest<br>success<br></code></pre></td></tr></table></figure><p>导入成功之后，我们就可以通过<code>list</code>命名，看到名为<strong>Mistral-7B-v0.3</strong>的本地模型了，后续可以和其他模型一样进行管理了。</p><h2 id="基于-webui-部署-ollama-可视化对话界面">基于 WebUI 部署 Ollama可视化对话界面</h2><p><strong>Ollama</strong>自带控制台对话界面体验总归是不太好，接下来部署Web 可视化聊天界面：</p><ol type="1"><li>下载并安装 Node.js 工具：https://nodejs.org/zh-cn</li><li>下载<code>ollama-webui</code>工程代码：<code>git clone https://github.com/ollama-webui/ollama-webui-lite ollama-webui</code></li><li>切换<code>ollama-webui</code>代码的目录：<code>cd ollama-webui</code></li><li>设置 Node.js工具包镜像源（下载提速）：<code>npm config set registry http://mirrors.cloud.tencent.com/npm/</code></li><li>安装 Node.js 依赖的工具包：<code>npm install</code></li><li>最后，启动 Web 可视化界面：<code>npm run dev</code></li></ol><figure><img src="/images/ollama/05.jpg" alt="Ollam WebUI启动成功" /><figcaption aria-hidden="true">Ollam WebUI启动成功</figcaption></figure><p>如果看到以上输出，代表 Web 可视化界面已经成功了！</p><p>浏览器打开 Web 可视化界面：http://localhost:3000/</p><figure><img src="/images/ollama/06.png" alt="Ollam WebUI对话界面" /><figcaption aria-hidden="true">Ollam WebUI对话界面</figcaption></figure><h2 id="ollama-客户端http-访问服务">Ollama 客户端：HTTP 访问服务</h2><p>Ollama 默认提供了<code>generate</code>和<code>chat</code>这 2个原始的 API 接口，使用方式如下：</p><ol type="1"><li><code>generate</code>接口的使用样例：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">curl http://localhost:11434/api/generate -d &quot;&#123;<br>  &#x27;model&#x27;: &#x27;qwen:0.5b&#x27;,<br>  &#x27;prompt&#x27;: &#x27;为什么天空是蓝色的？&#x27;<br>&#125;&quot;<br></code></pre></td></tr></table></figure><ol type="1"><li><code>chat</code>接口的使用样例：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">curl http://localhost:11434/api/chat -d &#x27;&#123;<br>  &quot;model&quot;: &quot;qwen:7b&quot;,<br>  &quot;messages&quot;: [<br>    &#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;为什么天空是蓝色的？&quot; &#125;<br>  ]<br>&#125;&#x27;<br></code></pre></td></tr></table></figure><p>接下来的<strong>Python</strong>和<strong>Java</strong>客户端应用，都是对这2 个接口的封装。</p><h2 id="ollama-客户端python-api-应用">Ollama 客户端：Python API应用</h2><p>我们把 Ollama 集成到 Python 应用中，只需要以下简单 2 步即可：</p><p><strong>第一步</strong>，安装 Python 依赖包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install ollama<br></code></pre></td></tr></table></figure><p><strong>第二步</strong>，使用 Ollama接口，<code>stream=True</code>代表按照流式输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> ollama<br> <br><span class="hljs-comment"># 流式输出</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">api_generate</span>(<span class="hljs-params">text:<span class="hljs-built_in">str</span></span>):<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;提问：<span class="hljs-subst">&#123;text&#125;</span>&#x27;</span>)<br> <br>  stream = ollama.generate(<br>    stream=<span class="hljs-literal">True</span>,<br>    model=<span class="hljs-string">&#x27;qwen:7b&#x27;</span>,<br>    prompt=text,<br>    )<br> <br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-----------------------------------------&#x27;</span>)<br>  <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> stream:<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> chunk[<span class="hljs-string">&#x27;done&#x27;</span>]:<br>      <span class="hljs-built_in">print</span>(chunk[<span class="hljs-string">&#x27;response&#x27;</span>], end=<span class="hljs-string">&#x27;&#x27;</span>, flush=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>      <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>      <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-----------------------------------------&#x27;</span>)<br>      <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;总耗时：<span class="hljs-subst">&#123;chunk[<span class="hljs-string">&#x27;total_duration&#x27;</span>]&#125;</span>&#x27;</span>)<br>      <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-----------------------------------------&#x27;</span>)<br> <br> <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>  <span class="hljs-comment"># 流式输出</span><br>  api_generate(text=<span class="hljs-string">&#x27;天空为什么是蓝色的？&#x27;</span>)<br> <br>  <span class="hljs-comment"># 非流式输出</span><br>  content = ollama.generate(model=<span class="hljs-string">&#x27;qwen:0.5b&#x27;</span>, prompt=<span class="hljs-string">&#x27;天空为什么是蓝色的？&#x27;</span>)<br>  <span class="hljs-built_in">print</span>(content)<br></code></pre></td></tr></table></figure><h2 id="ollama-客户端java-api-应用springboot-应用">Ollama 客户端：JavaAPI 应用（SpringBoot 应用）</h2><p>我们也可以把 Ollama 集成到 SpringBoot 应用中，只需要以下简单 3步即可：</p><p><strong>第一步</strong>，在总<code>pom.xml</code>中新增 SpringBootStarter 依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>io.springboot.ai<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-ai-ollama-spring-boot-starter<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><p><strong>第二步</strong>，在 SpringBoot配置文件<code>application.properties</code>中增加 Ollama 配置信息：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">server.port</span>=<span class="hljs-string">8088</span><br><span class="hljs-attr">spring.application.name</span>=<span class="hljs-string">NTopicBootX</span><br><span class="hljs-attr">spring.ai.ollama.base-url</span>=<span class="hljs-string">http://localhost:11434</span><br><span class="hljs-attr">spring.ai.ollama.chat.options.model</span>=<span class="hljs-string">qwen:0.5b</span><br></code></pre></td></tr></table></figure><p>配置文件指定了 Ollama API地址和端口，同时指定了默认模型<strong>qwen:0.5b</strong>（注意：模型需要在本地已经存在）</p><p><strong>第三步</strong>，使用<code>OllamaChatClient</code>进行文字生成或者对话：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> org.springframework.ai.chat.ChatResponse;<br><span class="hljs-keyword">import</span> org.springframework.ai.chat.prompt.Prompt;<br><span class="hljs-keyword">import</span> org.springframework.ai.ollama.OllamaChatClient;<br><span class="hljs-keyword">import</span> org.springframework.ai.ollama.api.OllamaOptions;<br><span class="hljs-keyword">import</span> org.springframework.beans.factory.annotation.Autowired;<br><span class="hljs-keyword">import</span> org.springframework.beans.factory.annotation.Qualifier;<br><span class="hljs-keyword">import</span> org.springframework.web.bind.annotation.GetMapping;<br><span class="hljs-keyword">import</span> org.springframework.web.bind.annotation.RequestParam;<br><span class="hljs-keyword">import</span> org.springframework.web.bind.annotation.RestController;<br> <br><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">OllamaClientController</span> &#123;<br> <br>    <span class="hljs-meta">@Autowired</span><br>    <span class="hljs-meta">@Qualifier(&quot;ollamaChatClient&quot;)</span><br>    <span class="hljs-keyword">private</span> OllamaChatClient ollamaChatClient;<br> <br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * http://localhost:8088/ollama/chat/v1?msg=天空为什么是蓝色的？</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@GetMapping(&quot;/ollama/chat/v1&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">ollamaChat</span><span class="hljs-params">(<span class="hljs-meta">@RequestParam</span> String msg)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">this</span>.ollamaChatClient.call(msg);<br>    &#125;<br> <br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * http://localhost:8088/ollama/chat/v2?msg=人为什么要不断的追求卓越？</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@GetMapping(&quot;/ollama/chat/v2&quot;)</span><br>    <span class="hljs-keyword">public</span> Object <span class="hljs-title function_">ollamaChatV2</span><span class="hljs-params">(<span class="hljs-meta">@RequestParam</span> String msg)</span> &#123;<br>        <span class="hljs-type">Prompt</span> <span class="hljs-variable">prompt</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Prompt</span>(msg);<br>        <span class="hljs-type">ChatResponse</span> <span class="hljs-variable">chatResponse</span> <span class="hljs-operator">=</span> ollamaChatClient.call(prompt);<br>        <span class="hljs-keyword">return</span> chatResponse;<br>    &#125;<br> <br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * http://localhost:8088/ollama/chat/v3?msg=你认为的文章如何？</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@GetMapping(&quot;/ollama/chat/v3&quot;)</span><br>    <span class="hljs-keyword">public</span> Object <span class="hljs-title function_">ollamaChatV3</span><span class="hljs-params">(<span class="hljs-meta">@RequestParam</span> String msg)</span> &#123;<br>        <span class="hljs-type">Prompt</span> <span class="hljs-variable">prompt</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Prompt</span>(<br>                msg,<br>                OllamaOptions.create()<br>                        .withModel(<span class="hljs-string">&quot;qwen:0.5b&quot;</span>)<br>                        .withTemperature(<span class="hljs-number">0.4F</span>));<br>        <span class="hljs-type">ChatResponse</span> <span class="hljs-variable">chatResponse</span> <span class="hljs-operator">=</span> ollamaChatClient.call(prompt);<br>        <span class="hljs-keyword">return</span> chatResponse.getResult().getOutput().getContent();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>以上是 Java客户端的简单样例，我们可以通过<code>OllamaChatClient</code>访问 Ollama接口，既可以使用默认大模型，也可以在参数指定模型名称！</p><h2 id="ollama部署常见问题解答">Ollama部署常见问题解答</h2><h3 id="如何修改下载模型的默认存放目录">1如何修改下载模型的默认存放目录？</h3><p><strong>Windows用户</strong></p><ol type="1"><li>设置 OLLAMA_MODELS</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text"># 只设置当前用户<br>setx OLLAMA_MODELS &quot;D:\ollama_model&quot; <br># 为所有用户设置<br>setx OLLAMA_MODELS &quot;D:\ollama_model&quot; /M<br></code></pre></td></tr></table></figure><ol type="1"><li>重启终端（setx命令在Windows中设置环境变量时，这个变量的更改只会在新打开的命令提示符窗口或终端会话中生效。）</li><li>重启ollama服务</li></ol><p><strong>Linux一般用户</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text"># 打开下面文件<br>nano ~/.bashrc<br># 添加设置<br>export OLLAMA_MODELS=&quot;/path/to/ollama_model&quot;<br></code></pre></td></tr></table></figure><ol type="1"><li>重启终端</li><li>重启ollama服务： ollama serve</li></ol><p>或者直接使用： OLLAMA_MODELS="/path/to/ollama_model" ollama serve启动服务</p><p><strong>Liunx root 服务模式</strong>在服务文件中设置环境变量，并且要为新的目录设置ollama用户的读写权限</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs text"># 打开服务文件<br>sudo nano /etc/systemd/system/ollama.service<br># 在文件中Service字段后添加<br>[Service]<br>Environment=&quot;OLLAMA_MODELS=/home/xxx/ollama/models&quot;<br>Environment=&quot;http_proxy=xxxxxx&quot;<br><br># 设置目录访问权限 (根据反馈做了些调整)<br>sudo chown ollama:ollama /home/xxx/ollama<br>sudo chmod u+w /home/xxx/ollama<br>sudo chown ollama:ollama /home/xxx/ollama/models<br>sudo chmod u+w /home/xxx/ollama/models<br><br># 重启服务<br>sudo systemctl daemon-reload<br>sudo systemctl restart ollama.service<br><br># 确认状态<br>sudo systemctl status ollama.service<br></code></pre></td></tr></table></figure><p>注：有小伙伴反馈，修改模型存储目录时，如果只设置/home/xxx/ollama/models 目录的权限会出现 mkdir没有权限的错误。所以，建议对目录 /home/xxx/ollama/models 和/home/xxx/ollama 都为ollama用户赋予读写权限（2024.04.28）。</p><h3 id="ollama下载的模型与huggingface上的模型有什么区别">2ollama下载的模型与huggingface上的模型有什么区别？</h3><p>通常情况下，Qwen 模型的表示方法为 <code>Qwen1.5-4B-Chat</code>。在Ollama 中，<code>Qwen</code> 指代的是与 Hugging Face 上的<code>qwen1_5-4B-Chat-q4_0.gguf</code> 模型相对应的版本，这是一个经过 4位量化处理的模型。</p><p><strong>ollama提供的qwen模型：默认为4B，4bit量化模型，大小为2.3G</strong></p><h3 id="什么是modelfile-它的作用是什么">3 什么是Modelfile？它的作用是什么？</h3><p>在创建自定义模型时，需要一个配置文件来指定模型推理相关的设置。</p><p>这个文件仅在创建自定义模型过程中是必需的。若需修改模型推理的参数，必须重新创建模型，可以通过在<code>modelfile</code> 中调整参数来实现。</p><h3 id="自定义模型如何-create-自定义模型基于gguf格式">4 自定义模型：如何create 自定义模型（基于GGUF格式）？</h3><p>制作自定义模型的过程如下（GGUF格式），以qwen1.5 0.5B模型为例：</p><ol type="1"><li>下载模型 qwen1_5-0_5b-chat-q4_0.gguf</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">wget https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat-GGUF/resolve/main/qwen1_5-0_5b-chat-q4_0.gguf<br></code></pre></td></tr></table></figure><ol type="1"><li>准备modelfile文件</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs text">#FROM qwen1_5-0_5b-chat-q4_0.gguf<br>FROM ./qwen1_5-0_5b-chat-q4_0.gguf<br><br># set the temperature to 1 [higher is more creative, lower is more coherent]<br>PARAMETER temperature 0.7<br>PARAMETER top_p 0.8<br>PARAMETER repeat_penalty 1.05<br>PARAMETER top_k 20<br><br>TEMPLATE &quot;&quot;&quot;&#123;&#123; if and .First .System &#125;&#125;&lt;|im_start|&gt;system<br>&#123;&#123; .System &#125;&#125;&lt;|im_end|&gt;<br>&#123;&#123; end &#125;&#125;&lt;|im_start|&gt;user<br>&#123;&#123; .Prompt &#125;&#125;&lt;|im_end|&gt;<br>&lt;|im_start|&gt;assistant<br>&#123;&#123; .Response &#125;&#125;&quot;&quot;&quot;<br><br># set the system message<br>SYSTEM &quot;&quot;&quot;<br>You are a helpful assistant.<br>&quot;&quot;&quot;<br></code></pre></td></tr></table></figure><ol type="1"><li>创建模型</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">ollama create qwen0_5b -f Modelfile<br></code></pre></td></tr></table></figure><h3 id="自定义模型模型创建后去了哪里">5自定义模型：模型创建后去了哪里？</h3><p>模型被创建后，会被存放在以下位置： 模型文本被存储在：<code>/home/&lt;username&gt;/.ollama/models/blobs</code>配置文件位于：<code>/home/&lt;username&gt;/.ollama/models/manifests/registry.ollama.ai/library/qwen0_5b/latest</code></p><h3 id="如何重新修改模型的-temperature-等参数">6 如何重新修改模型的temperature 等参数？</h3><p>模型被创建后，修改temperature等参数，需要重新create模型。</p><p>通过以下命令可以查看一个模型的 modelfile 设置</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs text">$ ollama show --modelfile qwen0_5b<br># Modelfile generated by &quot;ollama show&quot;<br># To build a new Modelfile based on this one, replace the FROM line with:<br># FROM qwen0_5b:latest<br><br>FROM /home/&lt;username&gt;/.ollama/models/blobs/sha256:46a9de8316739892e2721fdc49f8353155e4c1bcfa0b17867cb590d2dfdf1d99<br>TEMPLATE &quot;&quot;&quot;&#123;&#123; if and .First .System &#125;&#125;&lt;|im_start|&gt;system<br>&#123;&#123; .System &#125;&#125;&lt;|im_end|&gt;<br>&#123;&#123; end &#125;&#125;&lt;|im_start|&gt;user<br>&#123;&#123; .Prompt &#125;&#125;&lt;|im_end|&gt;<br>&lt;|im_start|&gt;assistant<br>&#123;&#123; .Response &#125;&#125;&quot;&quot;&quot;<br>SYSTEM &quot;&quot;&quot;<br>You are a helpful assistant.<br>&quot;&quot;&quot;<br>PARAMETER repeat_penalty 1.05<br>PARAMETER temperature 0.7<br>PARAMETER top_k 20<br>PARAMETER top_p 0.8<br></code></pre></td></tr></table></figure><p>可以看到这些数据都被存放到了/home//.ollama/models/blobs/sha256:46a9de8316739892e2721fdc49f8353155e4c1bcfa0b17867cb590d2dfdf1d99文件中（此文件是二进制文件）。通过重新create模型，可以修改里面的参数。</p><h3 id="如何导入-pytorchsafetensors-格式的模型">7 如何导入PyTorch，Safetensors 格式的模型？</h3><p>ollama只支持GGUF格式的模型进行导入。对于pytorch和safetensors的模型，需要转换为gguf格式之后再导入。具体步骤，请参考：https://github.com/ollama/ollama/blob/main/docs/import.md</p><h3 id="是否可以链接webui有什么webui推荐">8是否可以链接WebUI，有什么WebUI推荐？</h3><p>ollama github首页中推荐了多种WebUI和终端访问方法的相关项目。https://github.com/ollama/ollama （Community Integrations部分）</p><p><strong>安装教程：Windows上如何安装Open WebUI</strong> B站：</p><iframe width="560" height="315" src="https://player.bilibili.com/player.html?bvid=BV1Ex421Q723&amp;page=1&amp;autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="box-sizing: border-box; color: rgb(53, 55, 64); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Segoe UI&quot;, Arial, freesans, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"></iframe><p>油管：</p><iframe width="560" height="315" src="https://www.youtube.com/embed/VfeCri0yplc?si=UCoZpuOyyJ-ymjix" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen style="box-sizing: border-box; color: rgb(53, 55, 64); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Segoe UI&quot;, Arial, freesans, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; white-space: normal; background-color: rgb(255, 255, 255); text-decoration-thickness: initial; text-decoration-style: initial; text-decoration-color: initial;"></iframe><p><strong>Linux安装教程请访问：</strong>https://techdiylife.github.io/blog/blog.html?category1=c02&amp;blogid=0036</p><h3 id="如何对ollama进行速度评价">9 如何对ollama进行速度评价？</h3><p>当以普通用户身份启动服务时，可以在终端界面查看推理速度。比如{"function":"print_timings","level":"INFO","line":257,"msg":"prompt evaltime = 25.55 ms / 12 tokens ( 2.13 ms per token, 469.70 tokens persecond)","n_prompt_tokens_processed":12,"n_tokens_second":469.70408642555196,"slot_id":0,"t_prompt_processing":25.548,"t_token":2.129,"task_id":111,"tid":"140543230871296","timestamp":1711096105}</p><p>可以看到有：2.13 ms per token, 469.70 tokens per second</p><p>在Windows或者Linux上以服务启动时，也可以在日志文件中找到这些数据。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text"># Windows<br>C:\Users\&lt;username&gt;\AppData\Local\Ollama\server.log<br>#MacOS<br>cat ~/.ollama/logs/server.log<br># Linux<br>sudo systemctl status ollama.service &gt; xxx.log<br></code></pre></td></tr></table></figure><h3 id="ollama是否可以对模型精度评价">10Ollama是否可以对模型精度评价？</h3><p>在ollama工具中，没有直接的方式来评估模型性能。然而，在<code>llama.cpp</code>中，有提供测试数据集，以及使用Perplexity指标来进行模型评估的示例。</p><p>常见LLM大模型评估方法如下：</p><ul><li><strong>主观评价</strong>：通过人工审查模型的输出，评估其生成内容的质量和相关性。</li><li><strong>测试集评价</strong>：利用特定的测试数据集，对模型性能进行量化评估。这种方法的细节可以参考相关模型的技术报告。</li><li><strong>利用其他模型进行评价</strong>：例如，使用GPT-4对ollama模型的输出结果进行评估，以此来比较不同模型的性能。</li></ul><h3 id="linux系统中以服务模式运行ollama如何查看运行日志">11Linux系统中以服务模式运行ollama，如何查看运行日志？</h3><p>使用以下命令可以查看ollama的日志：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text"># 查看服务日志<br>sudo systemctl status ollama.service<br><br># 查看用户日志<br>sudo journalctl -u ollama<br></code></pre></td></tr></table></figure><h3 id="linux系统中如何卸载ollama">12 Linux系统中如何卸载Ollama？</h3><p>在Windows和MacOS上，卸载ollama的过程与卸载其他软件相同，支持一键卸载。</p><p>而在Linux上，卸载ollama需要执行更多步骤，包括关闭运行中的服务以及删除相关文件。具体操作步骤，请参考官方文档中的“Uninstall”部分：https://github.com/ollama/ollama/blob/main/docs/linux.md</p><h3 id="上网需要使用代理时模型无法下载怎么办">13上网需要使用代理时，模型无法下载怎么办？</h3><p><strong>出现错误：</strong> Error: pull model manifest: Get"https://registry.ollama.ai/v2/library/qwen/manifests/0.5b": dial tcp34.120.132.20:443: i/o timeout</p><p><strong>原因分析：</strong> 代理设置不正确。</p><ol type="1"><li><strong>服务文件中设置环境变量（sudo安装时）</strong>：在以服务启动后，默认以<code>ollama</code>用户的身份运行。可以为ollama.service服务设置环境变量。</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs text"># 打开服务文件<br>sudo nano /etc/systemd/system/ollama.service<br># 在文件中Service字段后添加<br>[Service]<br>Environment=&quot;http_proxy=xxxxxx&quot;<br><br># 重启服务<br>sudo systemctl daemon-reload<br>sudo systemctl restart ollama.service<br><br># 确认状态<br>sudo systemctl status ollama.service<br></code></pre></td></tr></table></figure><ol type="1"><li><strong>以当前用户身份启动服务(一般用户)</strong>：通过为当前用户设置代理，然后以当前用户的身份启动服务。这要求当前用户具有启动该服务所需的权限。</li></ol><ul><li><p>方法1：.bashrc中设置</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text"># 在本地账户 .bashrc 文件中加入<br>export HTTP_PROXY=xxxxxxxxxxx<br>export HTTPS_PROXY=xxxxxxxxxxx<br><br># 启动服务<br>ollama serve 启动（不能使用 sudo systemctl start ollama.service）<br></code></pre></td></tr></table></figure></li><li><p>方法2：通过下面的方式启动服务</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">HTTPS_PROXY=xxxxxxxxxxx ollama serve<br></code></pre></td></tr></table></figure></li></ul><p>参考资料：https://github.com/ollama/ollama/issues/1859</p><h3 id="有多个gpu时如何指定使用单张gpu">14有多个GPU时，如何指定使用单张GPU？</h3><p>ollama默认会使用所有它可见的GPU，如果希望限制它只使用其中的某个GPU时，可以在环境变量中设置CUDA_VISIBLE_DEVICES，比如： export CUDA_VISIBLE_DEVICES=0</p><h3 id="ollama是否支持rag">15 ollama是否支持RAG？</h3><p>ollama本身不支持RAG，但是可以结合langchain等工具来实现，比如：https://github.com/ollama/ollama/tree/main/examples/langchain-python-rag-websummary</p><h3 id="补充ollama模型库中instructtext等tag是指什么模型">16补充：Ollama模型库中instruct，text等tag是指什么模型？</h3><p>如下图所示的llama3模型有70b， 8b， instruct， text都分别对应着什么模型呢？</p><figure><imgsrc="data:image/png;charset=utf-8;base64,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"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>可以在模型的说明中找到相关的解释。没有特殊标记的对应着chat版本，也就是经过指令微调的模型。而text版本则对应着base model，也就是预训练模型。</p><figure><imgsrc="data:image/png;charset=utf-8;base64,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"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="补充open-webui-与现有服务端口冲突如何修改端口">17 补充：OpenWebUI 与现有服务端口冲突，如何修改端口？</h3><ul><li>如果是使用docker安装运行，可以在docker命令中修改：</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text">#默认端口为3000<br>docker run -d -p 3000:8080 -e xxxxxxxx<br>#修改为端口3001<br>docker run -d -p 3001:8080 -e xxxxxxxx<br></code></pre></td></tr></table></figure><ul><li>如果是通过代码安装，启动</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">cd ./backend<br>PORT=1234 start.sh #使用端口1234<br></code></pre></td></tr></table></figure><h3 id="补充ollama支持中文名用户名或者目录吗">18补充：Ollama支持中文名用户名，或者目录吗？</h3><p>从0.1.33版开始增加了对中文名目录的支持。https://github.com/ollama/ollama/issues/33670.1.33之前的版本不支持。如果你使用的老版本，请检查：</p><ul><li>你的windows用户名是否为中文名</li><li>ollama的模型存放目录是否包含中文</li></ul><p>如果存在以上情况，可以修改ollama模型默认存放目录。（修改方式参考，问题6）</p><h3 id="补充ollama使用一段时间后为什么会自动停止">19补充：Ollama使用一段时间后，为什么会自动停止？</h3><p>很大的原因是由于资源不足，比如GPU显存不足等。</p><ol type="1"><li>查看ollama的日志看看是否有记录</li><li>尝试较小的模型，比如qwen 0.5B的模型看看是否出现同样的问题。</li></ol><h3id="补充windows上安装完后在终端执行提示-ollama-不是内部或外部命令">20补充：windows上安装完后，在终端执行提示 ollama 不是内部或外部命令</h3><p>【根据群里小伙伴的讨论整理】</p><ol type="1"><li>设置环境变量 PATH： win+r打开运行，输入“controlsystem”-高级系统设置-高级-环境变量-系统变量-编辑Path-新建-确定。</li><li>设置PATH后重新启动ollama服务，在ollama图标上点击右键，以管理员身份启动。启动后，在右下角任务栏中确认是否有ollama的“小羊”图标</li><li>启动终端输入：ollama run qwen确认是否可以运行（如果出错，可以尝试以管理员身份）</li></ol><h3id="补充windows系统提示错误-errorcould-not-connect-to-ollama-app-is-it-running">21补充：Windows系统，提示错误 Error：Could not connect to ollama app， isit running</h3><p>运行 ollama run xxx 出现此错误，说明ollama没有正确启动。可以尝试：</p><ol type="1"><li>关闭ollama程序</li><li>以管理员身份重新启动ollama。</li></ol><h2 id="参考资料">参考资料</h2><ul><li>Docker官网：https://www.docker.com/products/docker-desktop/</li><li>Ollama官网：https://ollama.com/</li><li>Open WebUI Github地址：https://github.com/open-webui/open-webui</li><li>Ollama官方QA：https://github.com/ollama/ollama/blob/main/docs/faq.md</li></ul>]]></content>
    
    
    <categories>
      
      <category>大模型部署</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>人工智能领域常见概念中英文汇编</title>
    <link href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A2%86%E5%9F%9F%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5%E4%B8%AD%E8%8B%B1%E6%96%87%E6%B1%87%E7%BC%96.html"/>
    <url>/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A2%86%E5%9F%9F%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5%E4%B8%AD%E8%8B%B1%E6%96%87%E6%B1%87%E7%BC%96.html</url>
    
    <content type="html"><![CDATA[<h3id="人工智能领域常见概念中英文汇编">人工智能领域常见概念中英文汇编</h3><p>本文动态收入总结AI领域的一些常见英文概念及其对应的中文释义</p><span id="more"></span><h2 id="大模型专栏">大模型专栏:</h2><ol type="1"><li><p><strong>Transformer</strong>：</p><ul><li>一种用于自然语言处理的神经网络架构，通过自注意力机制（self-attention）来处理输入序列。Transformer模型包括编码器和解码器部分，常用于各种NLP任务，如翻译、文本生成等。</li></ul></li><li><p><strong>BERT（Bidirectional Encoder Representations fromTransformers）</strong>：</p><ul><li>一种预训练的Transformer模型，通过双向（上下文）编码来理解文本的上下文关系，广泛应用于问答、分类等任务。</li></ul></li><li><p><strong>GPT（Generative Pre-trained Transformer）</strong>：</p><ul><li>由OpenAI开发的生成式预训练Transformer模型，擅长生成连贯的文本。GPT-3是其著名的版本之一，具有1750亿参数。</li></ul></li><li><p><strong>Fine-tuning（微调）</strong>：</p><ul><li>在预训练模型的基础上，通过在特定任务或数据集上进行进一步训练，使模型更适合特定任务。</li></ul></li><li><p><strong>Zero-shot Learning</strong>：</p><ul><li>模型在没有见过特定任务的情况下，利用其预训练知识直接进行预测。GPT-3展示了强大的零样本学习能力。</li></ul></li><li><p><strong>Few-shot Learning</strong>：</p><ul><li>模型在只见过少量示例的情况下进行学习和预测。通过提供少量示例作为提示，模型可以更好地理解和执行任务。</li></ul></li><li><p><strong>Attention Mechanism（注意力机制）</strong>：</p><ul><li>一种让模型在处理输入序列时关注重要部分的机制，极大地提升了模型的性能。自注意力机制是Transformer的核心组件。</li></ul></li><li><p><strong>Self-Attention（自注意力）</strong>：</p><ul><li>Transformer中的一种机制，通过计算序列中每个元素与其他元素的相关性来生成新的表示。</li></ul></li><li><p><strong>Language Model（语言模型）</strong>：</p><ul><li>预测给定上下文下下一个词的概率模型。语言模型是生成文本和理解文本的基础。</li></ul></li><li><p><strong>Tokenization（分词）</strong>：</p><ul><li>将文本拆分成更小的单元（如单词、子词、字符等），是文本处理的第一步。常用的分词方法包括BPE（Byte-PairEncoding）和WordPiece。</li></ul></li><li><p><strong>Embedding（嵌入）</strong>：</p><ul><li>将离散的文本表示为连续的向量，以捕捉词语之间的语义关系。嵌入向量可以通过模型学习得到，如Word2Vec、GloVe等。</li></ul></li><li><p><strong>Sequence-to-Sequence（序列到序列，Seq2Seq）</strong>：</p><ul><li>一种用于将输入序列转换为输出序列的模型架构，广泛应用于机器翻译、文本摘要等任务。通常由编码器和解码器组成。</li></ul></li><li><p><strong>Beam Search（束搜索）</strong>：</p><ul><li>一种在生成过程中用于寻找最优序列的方法，通过保留多个最优候选序列以提高生成质量。</li></ul></li><li><p><strong>Perplexity（困惑度）</strong>：</p><ul><li>评价语言模型性能的指标，反映模型对测试集的预测能力。困惑度越低，模型性能越好。</li></ul><hr /><h2 id="机器学习领域">机器学习领域</h2></li></ol><h3 id="a">A</h3><p><strong>A/B Testing</strong>（A/B 测试）一种受控的真实实验，用于比较系统或模型的两个变体A和B。</p><p><strong>Activation Function</strong>（激活函数）在人工神经网络的情境中，接受来自上一层的所有输入的加权和并生成输出值来激活下一层的函数。</p><p>Active Learning (Active Learning Strategy)（主动学习/主动学习策略）半监督机器学习的一种特殊情况，在这种情况下，学习代理能够以交互的方式查询数据库（通常是人工标注员），以获取新数据点的标签。</p><p><strong>Algorithm</strong>（算法）一种关于如何解决某一类问题的过程的明确规范，它能够执行计算、处理数据并进行自动推理。</p><p><strong>Annotation</strong>（标注）附加到一条数据之上的元数据，通常由人工标注员提供。</p><p>Area Under the Curve (<strong>AUC</strong>)（曲线下面积）机器学习中用于确定在多个使用的模型中哪个模型具有最高性能的一种方法。</p><p><strong>Artificial Intelligence</strong>（人工智能）机器模拟人类智力和行为做出决策、执行任务的能力。</p><p><strong>Artificial Neural Networks</strong>（人工神经网络）由简单互联单元（称作神经元）的连续层所构成的一种架构，这些单元与非线性激活函数交织在一起，会让人模糊地联想到动物大脑中的神经元。</p><p><strong>Association Rule Learning</strong>（关联规则学习）一种基于规则的机器学习方法，用于发现大型数据集中变量之间的关系。</p><p>Autoencoder（自动解码器）一种人工神经网络，用于以无监督、非线性的方式生成高效的数据表示，通常用于降低维度。</p><p><strong>Automated Speech Recognition</strong>（自动语音识别）计算语言学的一个子领域，主要是关于通过计算机识别和翻译口语的方法。</p><h3 id="b">B</h3><p><strong>Backpropagation</strong> (Backpropagation ThroughTime)（反向传播/基于时间的反向传播）用于训练人工神经网络，进而计算网络权重计算所需梯度的一种方法。</p><p><strong>Batch</strong>（批量）在模型训练的单个梯度更新中使用的示例集。</p><p><strong>Bayes’s Theorem</strong>（贝叶斯定理）统计学家根据可能与某个存在相关的先验条件知识描述某个事件的概率时所用的一个著名定理。</p><p><strong>BERT（Bidirectional Encoder Representations fromTransformers）</strong>：</p><p>一种预训练的Transformer模型，通过双向（上下文）编码来理解文本的上下文关系，广泛应用于问答、分类等任务。</p><p><strong>Bias</strong> (Inductive Bias, ConfirmationBias)（偏差-归纳偏差、确认偏差）归纳偏差：学习者在给定输入条件下预测尚未遇到的输出时所用的假设事项集。确认偏差：以确认自己的信念或假设的方式搜索、解释、赞成和回想信息，而较少关注与之相矛盾的信息的趋势。</p><p><strong>Bias-Variance Tradeoff</strong>（偏差与方差权衡）当数据科学家尝试同时最大程度地减小偏差和方差时所产生的冲突，该冲突不利于监督算法推广到他们的训练集范围之外。</p><p><strong>Boosting</strong>（提升）主要用于减少监督学习中的偏差和方差的一种机器学习集成元算法，以及将弱学习者转化为强学习者的一系列机器学习算法。常见的boosting包括Baggingboosting(随机森林),GBDT(梯度提升树),XGBoost , LightGbm</p><p><strong>Bounding Box</strong>（边界框）完全包含一组点或一个对象的最小（矩形）框。</p><h3 id="c">C</h3><p><strong>Chatbot</strong>（聊天机器人）一种旨在通过对话与人类用户进行交互的计算机程序或 AI。</p><p><strong>Classification</strong>（分类）对映射函数进行从输入变量到离散输出变量的近似处理的任务，或者从广义上来说，是指用于确定特定实例所属的类的某一类机器学习算法。</p><p><strong>Clustering</strong>（聚类）在机器学习中，是指对一组对象进行分组，使得同一组（即集群）中的对象彼此之间的“相似性”高于与其他组中的对象“相似性”的无监督任务。</p><p>Cold-Start（冷启动）由于系统无法针对尚未收集到足够信息的用户或项目推断出任何信息而引起的潜在问题。</p><p>Collaborative Filtering（协作过滤）在推荐系统中使用的一种方法，用于通过收集来自较大用户组的偏好来预测用户的兴趣。</p><p>Computer Vision（计算机视觉）机器学习的领域之一，主要研究如何获得对图像或视频的高级理解。</p><p><strong>Confidence Interval</strong>（置信区间）一种区间估计，可能包含未知总体参数的真实值。该区间与置信水平相关，而置信水平用于量化参数在区间中的置信度。</p><p>Contributor（贡献者） 提供标注服务的人工标注员。</p><p>Convolutional Neural Network (<strong>CNN</strong>)（卷积神经网络）一种深层、前馈人工神经网络类别，通常用于计算机视觉。</p><p>Central Processing Unit (CPU)（中央处理单元）计算机中通过执行指令指定的基本算术、逻辑、控制和输入/输出操作来执行计算机程序的指令的电子电路。</p><p><strong>Cross-Validation</strong> (k-fold Cross-Validation,Leave-p-out Cross-Validation)（交叉验证-k 折交叉验证、留 p 法交叉验证）旨在评估如何将预测模型的结果推广到新数据集的一组流程，包括k折交叉验证及留p法交叉验证。</p><h3 id="d">D</h3><p>Data (Structured Data, Unstructured Data, Dataaugmentation)（数据-结构化数据、非结构化数据、数据增强）所有机器学习和人工智能项目的最基本要素。</p><p>非结构化数据：未经处理的原始数据。文本数据是非结构化数据的完美示例，因为它没有格式化为特定功能。</p><p>结构化数据：以机器学习算法可摄取的方式处理的数据；如果是监督机器学习，则为已标记的、经处理后的数据。</p><p>数据增强：将内外部来源衍生的新信息添加到数据集的过程（一般通过标注来实现）。</p><p><strong>Decision Tree</strong>（决策树）监督机器学习算法的一个类别，在此类算法中，数据会根据给定参数或条件进行迭代拆分。</p><p>Deep Blue（深蓝） 由 IBM开发的国际象棋游戏计算机，作为全球首个在常规时限内同时战胜了国际象棋游戏和国际象棋比赛卫冕世界冠军的计算机国际象棋游戏系统而闻名。</p><p><strong>Deep Learning</strong> (Deep ReinforcementLearning)（深度学习/深度强化学习）与特定任务的算法相反，基于学习数据表示的更广泛的机器学习方法系列。深度学习包括监督学习、半监督学习或无监督学习。</p><p><strong>Dimension</strong>维度（降维、维度灾难） 降维 DimensionalityReduction：通过获取一组主变量来减少所考虑的随机变量数量的过程。另请参见特征选择。</p><p>维度灾难 Curse ofDimensionality：由于维数越多，可用数据量越稀疏这一事实，在高维空间中分析和组织数据时出现的一种现象。</p><h3 id="e">E</h3><p><strong>Embedding</strong> (Word Embedding)（嵌入/词嵌入）某个实例中所含的某个数学结构的另一个实例，例如作为另一个组的子组的组。</p><p>Ensemble Methods（集成方法）在统计和机器学习中，集成方法使用多种学习算法来获得更好的预测性能，而这种性能可以单独从任何组合式学习算法中获得。与统计力学中通常是无限的统计集成不同，机器学习集成仅由一组有限的替代模型组成，但通常允许在这些替代模型之间存在更灵活的结构。</p><p><strong>Entropy</strong>（熵） 随机数据源传达的平均信息量。</p><p><strong>Epoch</strong>（时期）在深度学习模型训练场景中，完整训练数据集的一次训练循环。</p><h3 id="f">F</h3><p><strong>Feature</strong> (Feature Selection, FeatureLearning)（特征-特征选择、特征学习） 用作模型输入的变量。</p><p>Feature Learning（特征学习）旨在自动从原始数据中发现特征检测或分类所需的表示的一组技术。</p><p><strong>False Positive</strong>（误报）由于结果在虚无假设原本不应该存在的情况下拒绝虚无假设而导致的误差。</p><p><strong>False Negative</strong>（漏报）由于结果在虚无假设应该存在的情况下未拒绝虚无假设而导致的误差。</p><p><strong>Feed-Forward (Neural) Networks</strong>（前馈神经网络）一种人工神经网络，其中神经元之间的连接不会向后移动或形成循环。</p><p><strong>F-Score</strong>（F 得分）衡量模型准确性的一个指标，它会考量准确率和召回率来计算得分。更具体地说，F得分是准确率和召回率的调和平均值，该平均值的最大值为1（完美的准确率和召回率），最小值为 0。</p><h3 id="g">G</h3><p><strong>Garbage In, Garbage Out</strong>（垃圾进垃圾出）一项原则，具体说的是：只要输入数据存在缺陷，就会导致误导性的结果并产生无意义的输出，也就是“垃圾”。</p><p>General Data Protection Regulation (GDPR)（通用数据保护条例）欧盟颁布的一部针对欧盟内所有个体的数据保护和隐私法规，旨在控制公民和居民对其个人数据的控制。</p><p><strong>Genetic Algorithm</strong>（遗传算法）基于进化论的一种启发式搜索算法，进化论反映了自然选择的过程，在这个过程中，最能适应环境的个体会被选出生产下一代。</p><p><strong>Generative Adversarial Networks(GANs)</strong>（生成对抗网络）无监督机器学习中使用的一种人工智能算法类别，作为零和游戏框架中相互竞争的两个神经网络的组合予以实施。</p><p>Graphic Processing Unit (GPU)（图形处理单元）一种专用的电子电路，它采用并行处理架构，旨在快速操作和更改内存，以加速图像渲染，从而使其可以同时执行多个计算。</p><p><strong>Ground Truth</strong>（事实真相）通过直接观察（而非推论）获得的一条信息。</p><h3 id="h">H</h3><p><strong>Human-in-the-Loop</strong>（人机协同） 人机协同 (HITL)是人工智能的一个分支，它同时利用人类智能和机器智能来构建机器学习模型。在传统的“人机协同”方法中，人们会参与到一个良性循环，在其中训练、调整和测试特定算法。</p><p><strong>Hyperparameter</strong> (HyperparameterTuning)（超参数/超参数优化）模型外部的一种配置，其值无法从数据中估算出来，数据科学家会在模型训练过程中不断对其进行调整。-手动确定训练特定模型最佳配置的过程。</p><h3 id="i">I</h3><p><strong>ImageNet</strong>（ImageNet数据集）一个庞大的视觉数据集，由1400万个手工标注图像的URL组成，并以两万个不同类别进行组织，旨在用于视觉对象识别研究。</p><p>Image Recognition（图像识别）计算机视觉中用于确定图像是否包含某些特定对象、特征或活动的问题。</p><p><strong>Inference</strong>（推理）通过将经训练的模型运用到新的未标记实例来进行预测的过程。</p><p><strong>Information Retrieval</strong>（信息检索）计算机科学的一个领域，旨在研究在文档中搜索信息、搜索文档本身、搜索描述数据的元数据以及搜索文本、图像或声音数据库的过程。</p><h3 id="l">L</h3><p><strong>Layer (Hidden Layer)</strong>（层/隐藏层）人工神经网络中的一系列神经元，旨在处理一组输入特征，或者从广义上来说，处理这些神经元的输出。</p><p>隐藏层：神经元的一层，其输出连接到其他神经元的输入，因此不能作为网络输出直接实现可视化。</p><p><strong>Learning-to-Learn</strong>（元学习）机器学习领域的一个新方向，主要是研究算法如何通过分析自己的学习过程并对其加以改进来改变其归纳方式。</p><p><strong>Learning-to-Rank</strong>（排序学习）运用机器学习构建信息检索系统的排名模型。</p><p><strong>Learning Rate</strong>（学习率）梯度下降算法在人工神经网络训练阶段的每次迭代中所用的标量值，与梯度相乘得出结果。</p><p><strong>Logit Function</strong>（Logit 函数）在数学中（尤其是在统计学中）使用的 S 型“逻辑”函数的逆函数。</p><p><strong>Long Short-Term Memory Networks</strong>（长短期记忆网络）递归神经网络的一种变体，可用作梯度消失问题的一种解决方案。</p><h3 id="m">M</h3><p>Machine Learning（机器学习）人工智能的一个子领域，通常使用统计技术来赋予计算机“学习”能力，即借助数据来逐步提高特定任务的性能，而无需进行显式编程。</p><p>Machine Learning Lifecycle Management（机器学习生命周期管理）机器学习系统的 DevOps。</p><p>Machine Translation（机器翻译）计算语言学的一个子领域，主要是研究如何使用软件将文本或语音从一种语言翻译成另一种语言。</p><p>Model（模型）模型是机器学习系统通过训练过程从训练数据中所学到内容的抽象表示。</p><p><strong>Monte Carlo</strong>（蒙特卡洛方法）一种使用重复随机采样生成合成模拟数据的近似方法。</p><p><strong>Multi-Modal Learning</strong>（多模式学习）机器学习的一个子领域，旨在将多模式信号合并到一起进行解释，并构建模型来处理和关联来自多种数据类型的信息。</p><p>Multi-Task Learning（多任务学习）机器学习的一个子领域，同时利用多个任务之间的异同来解决多个任务。</p><h3 id="n">N</h3><p>Naive Bayes（朴素贝叶斯）基于贝叶斯定理并在特征之间具有很强的独立性假设的一系列简单概率分类器。</p><p>Named Entity Recognition（命名实体识别）信息提取的一个子任务，旨在将文本中的命名实体识别和分类为预定类别，例如名称、位置、词性等。</p><p>Natural Language Processing (NLP)（自然语言处理）人工智能领域之一，主要是研究计算机语言与人类语言之间的交互，尤其是如何处理和分析大量自然语言数据。</p><p>Neural Networks（神经网络） 参见人工神经网络。</p><p>Neuron（神经元）人工神经网络中的一个单元，用以处理多个输入值，以生成单个输出值。</p><p><strong>Node</strong>（节点） 参见神经元。</p><h3 id="o">O</h3><p>Optical Character Recognition（光学字符识别）将打印、手写或键入文本的图像转换为机器友好的文本格式。</p><p><strong>Optimization</strong>（优化）从可用替代方案中（基于某些标准）选择最佳方案。</p><p><strong>Overfitting</strong>（过度拟合）模型在不知情的情况下识别出噪声中的模式并假设这些模式代表了底层结构；模型的生成结果与特定数据集过于接近，因此无法很好地归纳到不可见的观察结果。</p><h3 id="p">P</h3><p>Pattern Recognition（模式识别）机器学习的领域之一，主要专注于数据模式的（监督或无监督）识别。</p><p>Pooling (Max Pooling)（轮询/最大轮询）将卷积层生成的矩阵缩减为较小矩阵的过程。</p><p>Personally Identifiable Information（个人可识别信息）可以单独使用或与某些其他信息结合使用，以识别特定个人的任何信息。</p><p><strong>Precision</strong>（准确率）正确的阳性结果数除以分类器返回的所有样阳性结果数。</p><p><strong>Prediction</strong>（预测）带有输入实例的训练模型的推断输出。</p><p><strong>Preprocessing</strong>（预处理）将原始数据转换为更易理解格式的过程。</p><p>Pre-trained Model（预训练模型）通常已使用另一个数据集进行了初步训练的模型或模型的组成部分。另请参见：转移学习。</p><p>Principal Component Analysis（主组件分析）使用正交变换将一组可能相关变量的观测值转换为一组线性不相关变量（称为主组件）的过程。</p><p>Prior（先前技术）在考虑新证据之前，代表特定数量的先前存在信念的概率分布。</p><h3 id="r">R</h3><p><strong>RAG（Retrieval-AugmentedGeneration，检索增强生成）</strong></p><p>RAG是一种结合信息检索和生成式模型的新方法。RAG的核心思想是通过将检索模块和生成模块结合起来，以提高生成的准确性和信息性。</p><p><strong>Random Forest</strong>（随机森林）一种集成学习方法，其工作原理是在训练时构造大量决策树并输出每个单独树的结果的组合版本（例如均值或众数）。</p><p><strong>Recall</strong>（召回率）所有相关样本中被正确分类为阳性的样本数所占百分比。</p><p>Rectified Linear Unit（整流线性单元）使用整流函数作为激活函数的单元。</p><p><strong>Recurrent Neural Networks</strong>（递归神经网络）人工神经网络的类别之一，其中神经元之间的连接沿着序列形成有向图，使其表现出时序动态时间行为并使用其内部状态（内存）来处理顺序信号。</p><p><strong>Regression</strong> (Linear Regression, LogisticRegression)（回归-线性回归、逻辑回归）一组用于估计变量间关系的统计过程。</p><p>线性回归：一种简单的回归类型，以特征的线性组合作为输入，并输出连续值。</p><p>逻辑回归：一种回归类型，通过将 S型函数运用到线性预测对分类问题中每个可能的离散标签值生成概率。</p><p><strong>Regressor</strong>（回归器）一种特征，即用作模型输入的解释性变量。</p><p><strong>Regularization</strong>（正则化）引入额外信息以防过度拟合的过程。</p><p>Reinforcement Learning（强化学习）机器学习的子领域之一，主要是受人类行为的启发，研究代理应如何在给定的环境中采取行动，以实现累积奖励概念的最大化。</p><p>Reproducibility (crisis of)（可再现性危机）科学领域的一种方法论危机，即学者们发现：许多科学研究的结果很难或不可能在独立研究人员或最初研究人员自己的后续研究中复制或再现。</p><p>Restricted Boltzmann Machines（受限玻尔兹曼机） 受限玻尔兹曼机 (RBM)是一种生成型随机人工神经网络，可以学习其输入集上的概率分布。</p><h3 id="s">S</h3><p><strong>Sora(State of the Art)</strong></p><p>指的是在某一领域内最新、最先进的技术或方法。无论是在科学研究、工程技术还是机器学习中，SOTA都代表了当前公认的最佳成果或最高水平的成就。SOTA方法和技术通常是通过同行评议的学术论文、行业报告或者标准评测中展示的，并被用作衡量其他研究或技术进展的基准。</p><p><strong>Semi-Supervised Learning</strong>（半监督学习）监督学习技术的一个类别，它还可以利用可用的未标记数据进行训练，通常结合使用少量的已标记实例与大量的未标记行。另请参见监督学习和无监督学习。</p><p>Sentiment Analysis 情绪分析使用自然语言处理、文本分析、计算语言学和生物特征识别等功能系统地识别、提取、量化和研究受影响的状态和主观信息。</p><p>Speech Recognition（语音识别） 参见自动语音识别。</p><p>Statistical Distribution（统计分布）在统计学中，经验分布函数是指与样本的经验指标相关的分布函数。该累积分布函数是一个阶跃函数，在n 个数据点中的每个数据点上都跳了 1/n次。它在测量变量的任何指定值处的值都是小于或等于对应指定值的测量变量观察值的分数。</p><p>Supervised Learning（监督学习）一种机器学习任务，主要是指基于示例输入/输出对学习将输入映射到输出的函数。</p><p><strong>Support Vector Machines</strong> (SVM)（支持向量机）由一个单独的超平面正式定义的一种判别分类器类别，对于每个提供的带标记训练数据点，算法都会输出一个对新示例进行分类的最佳超平面。</p><p>Synthetic Data（合成数据）当无法收集足够的实际数据或原始数据不满足特定要求时人工生成的数据。</p><h3 id="t">T</h3><p>TensorFlow（TensorFlow代码库）一种开源代码库，在机器学习社区中非常流行，用于跨一系列任务的数据流编程。它是一个符号数学库，还可用于神经网络等机器学习应用。</p><p><strong>Time Series</strong> (Time Series Data)（时序/时序数据）在特定时间记录并根据它们的出现顺序进行索引处理的一系列数据点。</p><p>Testing (Testing Data)（测试/测试数据）测试是指在监督机器学习情境中，使用保留数据评估模型最终性能的过程。</p><p>测试数据：数据科学家针对模型开发的测试阶段而选择的可用数据的子集。</p><p>Topic Modeling（主题建模）无监督机器学习算法的一种类别，它使用聚类功能在文本数据中查找隐藏的结构并作为一个主题对其进行解释。</p><p>Training Data（训练数据）在监督机器学习情境中，构建可从数据中学习并根据数据进行预测的算法。</p><p>训练数据：数据科学家针对模型开发的训练阶段而选择的可用数据的子集。</p><p>Transfer Learning（转移学习）机器学习的一个领域，其重点在于使用获得的知识来解决特定问题，并将此类知识运用到其他相关问题。</p><p><strong>Turing Test</strong>（图灵测试）由艾伦·图灵开发的一种测试，用于评估机器表现出与人类相同的智能行为的能力。该测试包括人机聊天。如果在测试房间之外见证对话的评估人员不能可靠地区分人类与受测机器，则可以认定该机器已经通过了图灵测试。</p><p>Type I Error（I 类误差） 参见误报。</p><p>Type II Error（II 类误差） 参见漏报。</p><h3 id="u">U</h3><p>Uncertainty（不确定性） 可能包含真实值的一系列值。</p><p><strong>Underfitting</strong>（拟合不足)机器学习算法无法正确捕获数据的底层结构，通常是因为模型不够高级或不适用于当前任务；与过度拟合的涵义相反。</p><p>Unsupervised Learning（无监督学习）机器学习的领域之一，包括对用于描述未标记数据结构的函数进行推断。</p><h3 id="v">V</h3><p><strong>Validation</strong>（验证）使用保留数据评估训练模型性能的过程；与模型性能最终评估的测试阶段相反，验证阶段旨在确定是否需要对模型进行任何迭代修改。</p><p><strong>Vanishing/Exploding Gradients</strong>（消失/爆炸梯度）数据科学家在采用基于梯度的学习方法和反向传播对人工神经网络进行训练时，由于神经网络中接收与误差函数偏导数成比例的更新的权重（考虑到每个训练迭代中的当前权重）而面临的可怕困难和主要障碍。</p><p><strong>Variance</strong>（方差）由于对训练集中小波动的敏感性而引起的误差，该误差按照针对随机变量与其平均值的平方偏差的期望值进行计算。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>基础知识</tag>
      
      <tag>中英文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>高效微调统一框架——LLAMA-FACTORY技术点详解</title>
    <link href="/LLAMA-FACTORY%E6%8A%80%E6%9C%AF%E7%82%B9%E6%A2%B3%E7%90%86.html"/>
    <url>/LLAMA-FACTORY%E6%8A%80%E6%9C%AF%E7%82%B9%E6%A2%B3%E7%90%86.html</url>
    
    <content type="html"><![CDATA[<p>高效的微调对于将大语言模型 (LLM)适应下游任务至关重要。然而，在不同模型上实施这些方法需要付出不小的努力。LLAMA-FACTORY是一个集成一套高效训练方法的统一框架。它允许用户通过内置的Web UI LLAMA-BOARD 灵活地自定义 100 多个 LLM 的微调，无需编码。（本文旨在说明LLAMA-FACTORY引入了NLP领域的哪些训练微调技术及其优势应用领域，项目部署与应用参考官方网址：https://github.com/hiyouga/LLaMA-Factory）<span id="more"></span></p><h3 id="一.-llama-factory简介">一. LLAMA-FACTORY简介</h3><p>LLAMA-FACTORY是一个使 LLM微调任务实现低代码规范化的框架。它通过可扩展的模块统一了各种高效的微调方法，从而能够以最少的资源和高吞吐量对数百种LLM进行微调。此外，它还简化了常用的训练方法，包括<strong>生成式预训练</strong>（Radford，2018）<strong>、监督微调(SFT)</strong>（Wei，2022）、<strong>人类反馈中强化学习(RLHF)</strong>（Ouyang，2022）和<strong>直接偏好优化(DPO)</strong>（Rafailov，2023）。用户可以利用<strong>命令行或 Web界面以最少或无需编码工作量来定制和微调LLM。</strong></p><p>下表是其和现存LLM调优工具的特征比较：</p><figure><img src="/images/llamafactory/image-20240814114808848.png"alt="image-20240814114808848" /><figcaption aria-hidden="true">image-20240814114808848</figcaption></figure><p>LLAMA-FACTORY由三个主要模块组成：模型加载器、数据工作器和训练器。尽量减少这些模块对特定模型和数据集的依赖，使框架能够灵活地扩展到数百个模型和数据集。具体来说，首先建立一个模型注册表，模型加载器可以通过识别精确的层将适配器精确地连接到预训练模型。然后，开发一个数据描述规范，允许数据工作器通过对齐相应的列来收集数据集。此外，提供高效微调方法的即插即用实现，使训练器能够通过替换默认方法激活。允许这些模块在不同的训练方法中重复使用，从而显著降低新方法的集成成本。</p><p>下表是支持的LLM清单：</p><table style="width:100%;"><thead><tr class="header"><th>模型名</th><th>模型大小</th><th>Template</th></tr></thead><tbody><tr class="odd"><td><a href="https://huggingface.co/baichuan-inc">Baichuan 2</a></td><td>7B/13B</td><td>baichuan2</td></tr><tr class="even"><td><a href="https://huggingface.co/bigscience">BLOOM/BLOOMZ</a></td><td>560M/1.1B/1.7B/3B/7.1B/176B</td><td>-</td></tr><tr class="odd"><td><a href="https://huggingface.co/THUDM">ChatGLM3</a></td><td>6B</td><td>chatglm3</td></tr><tr class="even"><td><a href="https://huggingface.co/CohereForAI">Command R</a></td><td>35B/104B</td><td>cohere</td></tr><tr class="odd"><td><a href="https://huggingface.co/deepseek-ai">DeepSeek(Code/MoE)</a></td><td>7B/16B/67B/236B</td><td>deepseek</td></tr><tr class="even"><td><a href="https://huggingface.co/tiiuae">Falcon</a></td><td>7B/11B/40B/180B</td><td>falcon</td></tr><tr class="odd"><td><a href="https://huggingface.co/google">Gemma/Gemma2/CodeGemma</a></td><td>2B/7B/9B/27B</td><td>gemma</td></tr><tr class="even"><td><a href="https://huggingface.co/THUDM">GLM-4</a></td><td>9B</td><td>glm4</td></tr><tr class="odd"><td><ahref="https://huggingface.co/internlm">InternLM2/InternLM2.5</a></td><td>7B/20B</td><td>intern2</td></tr><tr class="even"><td><a href="https://github.com/facebookresearch/llama">Llama</a></td><td>7B/13B/33B/65B</td><td>-</td></tr><tr class="odd"><td><a href="https://huggingface.co/meta-llama">Llama 2</a></td><td>7B/13B/70B</td><td>llama2</td></tr><tr class="even"><td><a href="https://huggingface.co/meta-llama">Llama 3/Llama3.1</a></td><td>8B/70B</td><td>llama3</td></tr><tr class="odd"><td><a href="https://huggingface.co/llava-hf">LLaVA-1.5</a></td><td>7B/13B</td><td>vicuna</td></tr><tr class="even"><td><a href="https://huggingface.co/openbmb">MiniCPM</a></td><td>1B/2B</td><td>cpm</td></tr><tr class="odd"><td><a href="https://huggingface.co/mistralai">Mistral/Mixtral</a></td><td>7B/8x7B/8x22B</td><td>mistral</td></tr><tr class="even"><td><a href="https://huggingface.co/allenai">OLMo</a></td><td>1B/7B</td><td>-</td></tr><tr class="odd"><td><a href="https://huggingface.co/google">PaliGemma</a></td><td>3B</td><td>gemma</td></tr><tr class="even"><td><a href="https://huggingface.co/microsoft">Phi-1.5/Phi-2</a></td><td>1.3B/2.7B</td><td>-</td></tr><tr class="odd"><td><a href="https://huggingface.co/microsoft">Phi-3</a></td><td>4B/7B/14B</td><td>phi</td></tr><tr class="even"><td><a href="https://huggingface.co/Qwen">Qwen/Qwen1.5/Qwen2(Code/Math/MoE)</a></td><td>0.5B/1.5B/4B/7B/14B/32B/72B/110B</td><td>qwen</td></tr><tr class="odd"><td><a href="https://huggingface.co/bigcode">StarCoder 2</a></td><td>3B/7B/15B</td><td>-</td></tr><tr class="even"><td><a href="https://huggingface.co/xverse">XVERSE</a></td><td>7B/13B/65B</td><td>xverse</td></tr><tr class="odd"><td><a href="https://huggingface.co/01-ai">Yi/Yi-1.5</a></td><td>6B/9B/34B</td><td>yi</td></tr><tr class="even"><td><a href="https://huggingface.co/01-ai">Yi-VL</a></td><td>6B/34B</td><td>yi_vl</td></tr><tr class="odd"><td><a href="https://huggingface.co/IEITYuan">Yuan 2</a></td><td>2B/51B/102B</td><td>yuan</td></tr></tbody></table><p>LLAMA-FACTORY 是用PyTorch（Paszke，2019）实现的，并且从开源库中获益良多，例如Transformers（Wolf，2020）、PEFT（Mangrulkar，2022）和 TRL（vonWerra，2020）。在此基础上，提供一个具有更高抽象级的开箱即用框架。此外，用Gradio（Abid，2019）构建 LLAM-ABOARD，无需编码即可微调 LLM。</p><p>高效的 LLM微调技术可分为两大类：专注于优化和面向计算。高效优化技术的主要目标是调整LLM 参数，同时将成本保持在最低水平。另一方面，高效的计算方法则力求减少LLM 中所需计算的时间或空间。LLAMA-FACTORY 中特色功能如下。</p><blockquote><ul><li><strong>多种模型</strong>：LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Yi、Gemma、Baichuan、ChatGLM、Phi等等。</li><li><strong>集成方法</strong>：（增量）预训练、（多模态）指令监督微调、奖励模型训练、PPO训练、DPO 训练、KTO 训练、ORPO 训练等等。</li><li><strong>多种精度</strong>：16 比特全参数微调、冻结微调、LoRA微调和基于 AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ 的 2/3/4/5/6/8 比特 QLoRA微调。</li><li><strong>先进算法</strong>：GaLore、BAdam、Adam-mini、DoRA、LongLoRA、LLaMAPro、Mixture-of-Depths、LoRA+、LoftQ、PiSSA 和 Agent 微调。</li><li><strong>实用技巧</strong>：FlashAttention-2、Unsloth、RoPEscaling、NEFTune 和 rsLoRA。</li><li><strong>实验监控</strong>：LlamaBoard、TensorBoard、Wandb、MLflow等等。</li><li><strong>极速推理</strong>：基于 vLLM 的 OpenAI 风格API、浏览器界面和命令行接口。</li></ul></blockquote><h3 id="二.-特色功能介绍">二. 特色功能介绍</h3><p>LLAMA-FACTORY可以覆盖LLM的预训练和RLHF(人类反馈强化)的完整阶段,以下是详细说明:</p><h4 id="训练方法集成">2.1 训练方法集成</h4><p><strong>1. （增量）预训练 (Pre-training)</strong></p><ul><li><strong>预训练:</strong>预训练是指在大规模文本数据上训练一个语言模型，使其学习通用的语言表示。预训练模型能够捕捉语言的语法、语义和上下文信息，为下游任务提供良好的初始化参数。</li><li><strong>增量预训练:</strong>指在已有的预训练模型基础上，使用新的数据或任务继续训练，以增强模型的性能或使其适应新的领域。增量预训练可以避免从头训练，节省时间和资源。</li></ul><p><strong>2. （多模态）指令监督微调 (Instruction-tunedFine-tuning)</strong></p><ul><li><strong>指令监督微调:</strong>指使用指令-答案对数据对预训练模型进行微调，使其能够遵循指令完成各种任务。指令通常描述了任务目标和输入格式，答案则是期望的输出。</li><li><strong>多模态指令监督微调:</strong>将指令监督微调扩展到多模态领域，例如图像-文本对或视频-文本对，使模型能够理解和处理多模态信息。</li></ul><p><strong>3. 奖励模型训练 (Reward Model Training)</strong></p><p>奖励模型用于评估模型生成的文本质量。在强化学习中，奖励模型为模型提供反馈信号，指导模型学习生成更优质的文本。奖励模型通常通过人工标注数据或根据特定指标进行训练。</p><p><strong>4. PPO 训练 (Proximal Policy Optimization)</strong></p><p>PPO 是一种强化学习算法，用于训练 agent (例如语言模型)在与环境交互的过程中学习最佳策略。PPO算法通过迭代更新策略网络的参数，以最大化累积奖励。</p><p><strong>5. DPO 训练 (Direct Preference Optimization)</strong></p><p>DPO是一种基于偏好的强化学习算法，它直接从人类偏好数据中学习奖励函数，并使用该奖励函数来优化策略。DPO避免了手动设计奖励函数的困难，能够更好地捕捉人类的偏好。</p><p><strong>6. KTO 训练 (Knowledge-aware Training)</strong></p><p>KTO训练是指将知识图谱等外部知识融入到模型训练中，以增强模型的知识理解和推理能力。KTO训练可以帮助模型更好地理解文本中的实体、关系和概念，从而提高模型的性能。</p><p><strong>7. ORPO 训练 (Off-Policy Reward PolicyOptimization)</strong></p><p>ORPO是一种离线强化学习算法，它利用预先收集的数据来训练策略，而不需要与环境进行实时交互。ORPO算法可以有效地利用历史数据，并能够在离线环境中进行策略优化</p><h4 id="llm微调方法集成">2.2 LLM微调方法集成</h4><p>LLAMA-FACTORY支持六种先进<strong>微调方案</strong>和六种<strong>模型训练加速</strong>方案</p><figure><img src="/images/llamafactory/image-20240814115905187.png"alt="image-20240814115905187" /><figcaption aria-hidden="true">image-20240814115905187</figcaption></figure><p><strong>1.冻结调整方法</strong> (Frozen Fine-tuning, Houlsby,2019)**</p><ul><li><strong>核心思想:</strong>只微调模型的一小部分参数，通常是解码器最后几层，而其余参数保持冻结。</li><li><strong>优点:</strong> 简单易实现，计算成本和存储成本低。</li><li><strong>缺点:</strong>限制了模型的表达能力，可能导致性能不如全参数微调。</li></ul><p><strong>2. 梯度低秩投影 (Gradient Low-Rank Projection, GaLoRA, Zhao,2024)</strong></p><ul><li><strong>核心思想:</strong>将梯度投影到低维空间，从而降低梯度更新的维度，节省内存。</li><li><strong>优点:</strong> 允许全参数学习，同时降低内存占用。</li><li><strong>缺点:</strong> 相比LoRA等方法，实现较为复杂。</li></ul><p><strong>3. 低秩自适应 (Low-Rank Adaptation, LoRA, Hu,2022)</strong></p><ul><li><strong>核心思想:</strong>冻结所有预训练权重，并在特定层引入一对可训练的低秩矩阵。这些矩阵捕获微调过程中的关键更新信息。</li><li><strong>优点:</strong>在保持性能的同时，显著降低内存占用和计算成本。</li><li><strong>缺点:</strong>对于某些任务，可能需要仔细调整低秩矩阵的秩。</li></ul><p><strong>4. 量化低秩自适应 (Quantized Low-Rank Adaptation, QLoRA,Dettmers, 2023)</strong></p><ul><li><strong>核心思想:</strong> 将 LoRA与量化技术结合，进一步压缩模型大小，降低内存需求。</li><li><strong>优点:</strong> 在 LoRA的基础上进一步降低内存占用，使得在更小的设备上进行微调成为可能。</li><li><strong>缺点:</strong> 量化可能会导致一定的性能损失。</li></ul><p><strong>5. 权重分解低秩自适应 (Weight Decomposed Low-Rank Adaptation,DoRA, Liu et al., 2024)</strong></p><ul><li><strong>核心思想:</strong> 将预训练权重分解为绝对值和方向分量，只将LoRA 应用于方向分量。</li><li><strong>优点:</strong> 相比LoRA，可以更有效地捕捉权重更新的方向，提升微调效果。</li><li><strong>缺点:</strong> 实现比 LoRA 稍复杂。</li></ul><p><strong>6. LoRA+ (Hayou et al., 2024)</strong></p><ul><li><strong>核心思想:</strong> 针对 LoRA的一些不足进行改进，例如对不同层使用不同的低秩矩阵秩。</li><li><strong>优点:</strong> 在 LoRA的基础上进一步提升性能，并提供更灵活的配置选项。</li><li><strong>缺点:</strong> 相对 LoRA 更复杂，需要更多的调参经验。</li></ul><h4 id="高效训练技术"><strong>2.3 高效训练技术</strong></h4><p>在 LLAMA-FACTORY中，集成了一系列高效的计算技术。常用的技术包括混合精度训练（Micikevicius，2018）和激活检查点（Chen，2016）。从检查注意层的输入输出(IO) 开销中汲取见解，flash attention（Dao，2022年）引入一种硬件友好的方法来增强注意计算。S^2attention（Chen，2024b）解决了在块稀疏注意中扩展上下文的挑战，从而减少了微调长上下文LLM 中的内存使用量。</p><p><strong>混合精度训练 (Mixed Precision Training) (Micikevicius,2018)</strong></p><ul><li><strong>核心思想：</strong> 在训练过程中混合使用 FP32 (单精度浮点数)和 FP16 (半精度浮点数)。</li><li><strong>优势：</strong><ul><li><strong>加速训练：</strong> FP16 计算速度比 FP32快，减少训练时间。</li><li><strong>降低内存占用：</strong> FP16占用内存更少，允许训练更大模型或使用更大批次。</li></ul></li><li><strong>关键技术：</strong> 损失缩放 (loss scaling) 防止梯度下溢(underflow)。</li><li><strong>应用：</strong> 广泛应用于各种深度学习模型训练，尤其在 GPU上训练大型 NLP 模型时效果显著。</li></ul><p><strong>2. 激活检查点 (Activation Checkpointing) (Chen,2016)</strong></p><ul><li><strong>核心思想：</strong>只保存部分激活值，并在反向传播时重新计算未保存的激活值。</li><li><strong>优势：</strong><ul><li><strong>大幅降低内存占用：</strong>避免存储所有中间激活值，特别有利于训练深度网络。</li></ul></li><li><strong>劣势：</strong><ul><li><strong>增加计算开销：</strong>需要重新计算部分激活值，延长训练时间。</li></ul></li><li><strong>应用：</strong>适用于内存受限的情况下训练大型模型，例如训练长序列的 NLP 模型。</li></ul><p><strong>3. Flash Attention 2</strong></p><ul><li><strong>核心思想：</strong>对注意力机制的计算进行优化，使其更加硬件友好，特别针对 GPU。</li><li><strong>优势：</strong><ul><li><strong>加速训练和推理：</strong>通过优化内存访问模式和减少冗余计算，提高计算效率。</li><li><strong>降低内存占用：</strong>更高效地利用内存，允许处理更长的序列。</li></ul></li><li><strong>应用：</strong> 广泛应用于 Transformer模型，显著提升其性能，特别是在长序列任务上。</li></ul><p><strong>4. S^2 Attention (Chen, 2024b)</strong></p><ul><li><strong>核心思想：</strong>一种针对块稀疏注意力的方法，旨在解决扩展上下文长度时内存使用过大的问题。</li><li><strong>优势：</strong><ul><li><strong>降低内存占用：</strong> 允许在微调长上下文 LLM时使用更长的序列，而不会导致内存溢出。</li></ul></li><li><strong>应用：</strong> 主要用于微调大型语言模型(LLM)，使其能够处理更长的上下文信息，例如长文档或对话历史。</li></ul><p><strong>5. Unsloth</strong></p><ul><li><strong>核心思想：</strong> 一种用于优化 Transformer模型训练的库，主要针对长序列任务。</li><li><strong>优势：</strong><ul><li><strong>加速训练：</strong> 通过一系列优化技术，例如 Flash Attention和 S^2 Attention，提高训练速度。</li><li><strong>降低内存占用：</strong>允许训练更长序列的模型，或使用更大的批次。</li></ul></li><li><strong>应用：</strong> 主要用于训练长序列 Transformer模型，例如用于代码生成或长文本摘要的模型。</li></ul><h3 id="三.-项目框架">三. 项目框架</h3><p><strong>LLAMA-FACTORY 有效地将这些技术组合成一个凝聚的结构，大大提高LLM 微调的效率</strong>。这使得内存占用从混合精度训练期间的18字节/参数（Micikevicius，2018）或 Bfloat16 训练期间的 8 字节/参数（LeScao，2022）减少到 0.6 字节/参数。</p><p><strong>在LLAMA-FACTORY 中， 模型加载器准备了各种用于微调的架构，支持100 多个LLM。</strong>数据工作器通过精心设计的流水线处理来自不同任务的数据，<strong>支持50多个数据集</strong>。训练器统一了有效的微调方法，使这些模型适应不同的任务和数据集，提供四种训练方法。LLAMA-BOARD为上述模块提供了友好的可视化界面，使用户能够以无代码的方式配置和启动单个LLM 微调过程，并实时监控训练状态。如图说明 LLAMA-FACTORY的整体架构。</p><figure><img src="/images/llamafactory/image-20240814122034895.png"alt="image-20240814122034895" /><figcaption aria-hidden="true">image-20240814122034895</figcaption></figure><h4 id="模型加载器有四个组件模型初始化模型补丁模型量化和适配器连接">3.1<strong>模型加载器</strong>有四个组件：<strong>模型初始化、模型补丁、模型量化和适配器连接</strong>。</h4><p><strong>模型初始化</strong>。用 HF Transformers 的 AutoModelAPI（Wolf，2020）来加载模型和初始化参数。为了使框架与不同的模型架构兼容，建立了一个模型注册表来存储每个层的类型，从而更直接地促进高效微调技术的使用。如果token化器的词汇表大小超出了嵌入层的容量，会调整层的大小并使用噪声均值初始化来初始化新参数。为了确定RoPE的缩放因子（Chen，2023），将其取做最大输入序列长度与模型的上下文长度之比。</p><p><strong>模型补丁</strong>。为了启用 flash attention 和 S^2attention，用 monkey patch 来代替模型的前向计算。不过，由于自 HFTransformers 4.34.0 以来就支持 flash attention，用 API 来启用 flashattention。为了防止动态模块过度分区，在 DeepSpeed ZeRO-3 (Rasley et al.,2020) 优化时将混合专家 (MoE) 块设置为叶（Leaf）模块。</p><p><strong>模型量化</strong>。可以通过 bits-and-bytes 库 (Dettmers,2021) 用 LLM.int8 (Dettmers et al., 2022a) 将模型动态量化为 8 位或 4位。对于 4 位量化，用双量化和 4 位普通浮点作为 QLoRA (Dettmers et al.,2023)。还支持训练后量化 (PTQ) 方法量化的模型微调，包括 GPTQ(Frantar，2023)、AWQ (Lin，2023) 和 AQLM(Egiazarian，2024)。请注意，无法直接微调量化权重；因此，量化模型仅与基于适配器的方法兼容。</p><p><strong>适配器附加</strong>。用模型注册表自动识别适当的层来附加适配器。适配器默认附加到一个层的子集以节省内存，但将它们附加到所有线性层可能会产生更好的性能(Dettmers，2023)。 <strong>PEFT</strong> (Mangrulkar et al., 2022)库提供了一种非常方便的方式来连接适配器，例如 LoRA (Hu et al.,2022)、rsLoRA (Kalajdzievski, 2023) 和 DoRA (Liu et al.,2024)。替换后向计算为Unsloth (Han &amp; Han, 2023) 的版本加速LoRA。为了执行人类反馈中强化学习 (RLHF)，在模型上添加了一个V头，这是一个将每个 token的表示映射到标量的线性层。</p><p>精度适应。根据设备的功能处理预训练模型的浮点精度。对于 NVIDIAGPU，如果计算能力为 8.0 或更高，使用 bfloat16 精度。否则，采用float16。对 Ascend NPU 和 AMD GPU 使用 float16，对非 CUDA 设备使用float32。请注意，用 float16 精度加载 bfloat16模型可能会导致溢出问题。在混合精度训练中，将所有可训练参数设置为float32。尽管如此，在 bfloat16 训练中将可训练参数保留为 bfloat16。</p><blockquote><p><strong><code>fp16</code></strong>：</p><ul><li>常用于 GPU（例如 NVIDIA 的 TensorCores）中，以加速深度学习模型的训练。</li><li>在部分硬件中，<code>fp16</code>运算速度比 <code>fp32</code>更快，且内存消耗较少。</li><li>由于尾数部分较长，<code>fp16</code>能在一些需要较高精度的运算中发挥优势。</li></ul><p><strong><code>bf16</code></strong>：</p><ul><li><code>bf16</code> 主要由 Google 推广，特别适用于 TPU（TensorProcessing Unit）。</li><li>因为指数位数较多，<code>bf16</code>在处理较大数值范围时表现优异，同时避免了过度的数值溢出。</li><li>尽管 <code>bf16</code> 的精度比 <code>fp16</code>低，但在深度学习训练中，<code>bf16</code>被认为在保持足够数值范围的同时具有足够的精度，因此非常适合神经网络的训练。</li></ul></blockquote><h4 id="一个数据处理流水线"><strong>3.2</strong><strong>一个数据处理流水线</strong></h4><p><strong>包括数据集加载、数据集对齐、数据集合并和数据集预处理</strong>。它将不同任务的数据集标准化为统一的格式，能够在各种格式的数据集上微调模型。</p><p><strong>数据集加载</strong>。用数据集（Lhoest，2021）库来加载数据，这使用户可以从Hugging Face Hub加载远程数据集或通过脚本或文件读取本地数据集。数据集库显着减少数据处理过程中的内存开销，并加速了用<strong>Arrow</strong>（Apache，2016）的样本查询。默认情况下，整个数据集会下载到本地磁盘。但是，如果数据集太大而无法存储，框架提供<strong>数据集流动对其进行迭代，而无需下载。</strong></p><p><strong>数据集对齐</strong>。为了统一数据集格式，设计了一个数据描述规范来表征数据集的结构。例如，羊驼数据集有三列：指令、输入和输出（Taori，2023）。根据数据描述规范将数据集转换为与各种任务兼容的标准结构。下表显示了一些数据集结构示例。</p><figure><imgsrc="/images/llamafactory/v2-2d56e468d3c0215c3a3876e994b79b4f_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>数据集合并</strong>。统一的数据集结构为合并多个数据集提供了一种有效的方法。对于非流动模式下的数据集，只需在训练期间数据集混洗之前先连接起来。然而，在流动模式下，简单地连接数据集会阻碍数据混洗。因此，提供交替读取不同数据集数据的方法。</p><p><strong>数据集预处理</strong>。LLAMA-FACTORY专为微调文本生成模型而设计，主要用于聊天完成。聊天模板是这些模型中的关键组成部分，因为它与这些模型的指令遵循能力高度相关。因此，提供数十种聊天模板，可以根据模型类型自动选择。用token化器在应用聊天模板后对句子进行编码。默认情况下，仅计算完成的损失，而忽略提示（Taori，2023）。或者，利用序列打包（Krell，2021）来减少训练时间，这在执行生成式预训练时会自动启用。</p><p>设计了一个 <strong>Formatter类</strong>，以便将文本输入稳健地转换为其嵌入 ID。具体来说，提供EmptyFormatter、StringFormatter、FunctionFormatter 和ToolFormatter。此外，LLAMA-FACTORY 支持微调模型以获得函数调用能力。虽然ReAct提示（Yao，2023）是工具使用的流行选择，但它对于嵌套工具参数来说是不够的。优化的工具调用提示如表所示。</p><figure><imgsrc="/images/llamafactory/v2-fab6b975715fa57b67090650f542a809_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>高效训练微调</strong>。将最先进的高效微调方法，包括LoRA+（Hayou，2024）和GaLore（Zhao，2024），集成到训练器中，替换默认组件。这些训练方法独立于训练器，因此可以轻松应用于各种任务。利用Transformers（Wolf，2020）的训练器进行预训练和 SFT，同时采用 TRL（vonWerra，2020）的训练器进行 RLHF 和DPO。利用定制的数据整理器来区分各种训练方法的训练器。为了匹配训练器偏好数据的输入格式，在一个批次中构建2n 个样本，其中前 n 个样本是选定的示例，后 n 个样本是拒绝的示例。</p><p><strong>模型共享RLHF</strong>。允许在消费设备上进行 RLHF 训练是 LLM微调的一个有用属性。然而，这个实现起来很困难，因为 RLHF训练需要四种不同的模型。为了解决这个问题，提出了模型共享 RLHF，使整个RLHF训练只用一个预训练模型即可完成。具体来说，首先用奖励建模的目标函数训练一个适配器和一个V头，让模型计算奖励分数。然后初始化另一个适配器和V头，并用PPO 算法 (Ouyang et al., 2022) 训练它们。在训练过程中，适配器和V头通过PEFT (Mangrulkar et al., 2022) 的 set_adapter 和 disable_adapter API动态切换，允许预训练模型同时用作策略、价值、参考和奖励模型。</p><p><strong>分布式训练</strong>。将上述训练器与<strong>DeepSpeed</strong> (Rasley et al., 2020)结合进行分布式训练。利用 DeepSpeed ZeRO优化器，可以通过分区或卸载进一步减少内存消耗。</p><p><strong>加速推理</strong>。在推理期间，重用数据工作器的聊天模板来构建模型输入。支持使用HF Transformers（Wolf，2020 年）和vLLM（Kwon，2023）对模型输出进行采样，这两者都支持流解码。此外，还实现一个OpenAI 风格的 API，该 API 利用异步 LLM 引擎和 vLLM 的pagedattention来提供高吞吐量的并发推理服务，从而促进微调的 LLM部署到各种应用程序中。</p><p><strong>综合评估</strong>。纳入多项 LLM评估指标，包括多项选择任务，如 <strong>MMLU</strong>（Hendrycks et al.,2021）、CMMLU（Li et al., 2023a）和 C-Eval（Huang et al.,2023），以及计算文本相似度分数，如 <strong>BLEU-4</strong>（Papineni etal., 2002）和 <strong>ROUGE</strong>（Lin, 2004）。</p><h4 id="可视化界面">3.3 可视化界面</h4><p>LLAMA-BOARD 是一个基于Gradio（Abid，2019）的统一用户界面，允许用户自定义 LLM的微调，而无需编写任何代码。它提供了简化的模型微调和推理服务，使用户能够在实践中轻松利用100 多个 LLM 和 50 多个数据集。LLAMA-BOARD 具有以下显着特点：</p><p><strong>易于配置</strong>。LLAMA-BOARD 允许用户通过Web界面交互自定义微调参数。其为许多参数提供了推荐给大多数用户的默认值，从而简化了配置过程。此外，用户可以在Web UI 上预览数据集以检查其自定义格式。</p><p><strong>可监控的训练</strong>。在训练过程中，训练日志和损失曲线可视化和实时更新，使用户可以监控训练进度。此功能为分析微调过程提供了有价值的见解。</p><p><strong>灵活的评估</strong>。LLAMA-BOARD支持计算数据集上的文本相似度得分，自动评估模型或通过与模型聊天进行人工评估。</p><p><strong>多语言支持</strong>。LLAMA-BOARD提供本地化文件，方便集成新语言呈现界面。目前支持三种语言：英语、俄语和中文，这使得更广泛的用户能够使用LLAMA-BOARD 来微调 LLM。</p><p><strong>训练细节</strong>。采用 10−5 的学习率和 512的tokens批处理大小，使用 8 位 AdamW 优化器（Dettmers，2022b）以 bfloat16精度对这些模型进行微调，并使用激活检查点来减少内存占用。在冻结调整中，仅微调模型的最后3 个解码器层。对于 GaLore，分别将秩和尺度设置为 128 和 2.0。对于 LoRA 和QLoRA，将适配器连接到所有线性层，并将秩和 alpha 分别设置为 128 和256。所有实验均在单个 NVIDIA A100 40GB GPU 上进行。在所有实验中启用flashattention，并在 LoRA 和 QLoRA 实验中启用 Unsloth。</p><h3 id="四.总结">四.总结</h3><p>LLAMA-FACTORY无疑可以规范工作流程,大大增加NLPer的工作效率,下表是其不同微调方法的训练效率对比参考：</p><figure><img src="/images/llamafactory/image-20240814124516886.png"alt="image-20240814124516886" /><figcaption aria-hidden="true">image-20240814124516886</figcaption></figure><figure><img src="/images/llamafactory/image-20240814124604969.png"alt="image-20240814124604969" /><figcaption aria-hidden="true">image-20240814124604969</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>工具框架</tag>
      
      <tag>NLP</tag>
      
      <tag>效率工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从头开始实现llama3</title>
    <link href="/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0llama3.html"/>
    <url>/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0llama3.html</url>
    
    <content type="html"><![CDATA[<p>都说大模型是黑箱玄学，这次让我们打开黑箱，一起来探索它内部的世界。</p><span id="more"></span><p>在这个文件中，我从头开始实现了llama3，一次一个张量和矩阵乘法。另外，我将直接从Meta为 llama3提供的模型文件加载张量，您需要在运行此文件之前下载权重。这是下载权重的官方链接：<ahref="https://llama.meta.com/llama-downloads/">https://llama.meta.com/llama-downloads/</a></p><figure><imgsrc="/images/llama3实现/v2-513855262cb2170c7aa8d1db7e5260ed_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h1 id="分词器tokenizer">1.分词器（tokenizer）</h1><p>我不会实现 bpe tokenizer（但 andrej karpathy 有一个非常干净的实现）他的实现链接：[https://github.com/karpathy/minbpe)</p><figure><img src="/images/llama3实现/karpathyminbpe.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs text">from pathlib import Path<br>import tiktoken<br>from tiktoken.load import load_tiktoken_bpe<br>import torch<br>import json<br>import matplotlib.pyplot as plt<br><br>tokenizer_path = &quot;Meta-Llama-3-8B/tokenizer.model&quot;<br>special_tokens = [<br>            &quot;&lt;|begin_of_text|&gt;&quot;,<br>            &quot;&lt;|end_of_text|&gt;&quot;,<br>            &quot;&lt;|reserved_special_token_0|&gt;&quot;,<br>            &quot;&lt;|reserved_special_token_1|&gt;&quot;,<br>            &quot;&lt;|reserved_special_token_2|&gt;&quot;,<br>            &quot;&lt;|reserved_special_token_3|&gt;&quot;,<br>            &quot;&lt;|start_header_id|&gt;&quot;,<br>            &quot;&lt;|end_header_id|&gt;&quot;,<br>            &quot;&lt;|reserved_special_token_4|&gt;&quot;,<br>            &quot;&lt;|eot_id|&gt;&quot;,  # end of turn<br>        ] + [f&quot;&lt;|reserved_special_token_&#123;i&#125;|&gt;&quot; for i in range(5, 256 - 5)]<br>mergeable_ranks = load_tiktoken_bpe(tokenizer_path)<br>tokenizer = tiktoken.Encoding(<br>    name=Path(tokenizer_path).name,<br>    pat_str=r&quot;(?i:&#x27;s|&#x27;t|&#x27;re|&#x27;ve|&#x27;m|&#x27;ll|&#x27;d)|[^\r\n\p&#123;L&#125;\p&#123;N&#125;]?\p&#123;L&#125;+|\p&#123;N&#125;&#123;1,3&#125;| ?[^\s\p&#123;L&#125;\p&#123;N&#125;]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+&quot;,<br>    mergeable_ranks=mergeable_ranks,<br>    special_tokens=&#123;token: len(mergeable_ranks) + i for i, token in enumerate(special_tokens)&#125;,<br>)<br><br>tokenizer.decode(tokenizer.encode(&quot;hello world!&quot;))<br>&#x27;hello world!&#x27;<br></code></pre></td></tr></table></figure><h1 id="读取模型文件">2.读取模型文件</h1><p>通常，阅读本文取决于模型类的编写方式以及其中的变量名称。但由于我们是从头开始实现 llama3，因此我们将一次读取一个张量文件。</p><figure><imgsrc="/images/llama3实现/v2-c237a044abe6bbdc2556cbe7acf044b3_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs text">model = torch.load(&quot;Meta-Llama-3-8B/consolidated.00.pth&quot;)<br>print(json.dumps(list(model.keys())[:20], indent=4))<br>[<br>    &quot;tok_embeddings.weight&quot;,<br>    &quot;layers.0.attention.wq.weight&quot;,<br>    &quot;layers.0.attention.wk.weight&quot;,<br>    &quot;layers.0.attention.wv.weight&quot;,<br>    &quot;layers.0.attention.wo.weight&quot;,<br>    &quot;layers.0.feed_forward.w1.weight&quot;,<br>    &quot;layers.0.feed_forward.w3.weight&quot;,<br>    &quot;layers.0.feed_forward.w2.weight&quot;,<br>    &quot;layers.0.attention_norm.weight&quot;,<br>    &quot;layers.0.ffn_norm.weight&quot;,<br>    &quot;layers.1.attention.wq.weight&quot;,<br>    &quot;layers.1.attention.wk.weight&quot;,<br>    &quot;layers.1.attention.wv.weight&quot;,<br>    &quot;layers.1.attention.wo.weight&quot;,<br>    &quot;layers.1.feed_forward.w1.weight&quot;,<br>    &quot;layers.1.feed_forward.w3.weight&quot;,<br>    &quot;layers.1.feed_forward.w2.weight&quot;,<br>    &quot;layers.1.attention_norm.weight&quot;,<br>    &quot;layers.1.ffn_norm.weight&quot;,<br>    &quot;layers.2.attention.wq.weight&quot;<br>]<br>with open(&quot;Meta-Llama-3-8B/params.json&quot;, &quot;r&quot;) as f:<br>    config = json.load(f)<br>config<br>&#123;&#x27;dim&#x27;: 4096,<br> &#x27;n_layers&#x27;: 32,<br> &#x27;n_heads&#x27;: 32,<br> &#x27;n_kv_heads&#x27;: 8,<br> &#x27;vocab_size&#x27;: 128256,<br> &#x27;multiple_of&#x27;: 1024,<br> &#x27;ffn_dim_multiplier&#x27;: 1.3,<br> &#x27;norm_eps&#x27;: 1e-05,<br> &#x27;rope_theta&#x27;: 500000.0&#125;<br></code></pre></td></tr></table></figure><h2id="我们使用此配置来推断有关模型的详细信息例如">我们使用此配置来推断有关模型的详细信息，例如</h2><ol type="1"><li>该模型有 32 个transformer layers</li><li>每个多头注意力块有 32 个头</li><li>词汇大小等等</li></ol><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs text">dim = config[&quot;dim&quot;]<br>n_layers = config[&quot;n_layers&quot;]<br>n_heads = config[&quot;n_heads&quot;]<br>n_kv_heads = config[&quot;n_kv_heads&quot;]<br>vocab_size = config[&quot;vocab_size&quot;]<br>multiple_of = config[&quot;multiple_of&quot;]<br>ffn_dim_multiplier = config[&quot;ffn_dim_multiplier&quot;]<br>norm_eps = config[&quot;norm_eps&quot;]<br>rope_theta = torch.tensor(config[&quot;rope_theta&quot;])<br></code></pre></td></tr></table></figure><h2 id="将文本转换为标记tokens">将文本转换为标记（tokens）</h2><p>这里我们使用 tiktoken （我认为是一个 openai 库）作为 tokenizer</p><figure><imgsrc="/images/llama3实现/v2-1acdee68e45fc5503592b79e34c18258_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">prompt = &quot;the answer to the ultimate question of life, the universe, and everything is &quot;<br>tokens = [128000] + tokenizer.encode(prompt)<br>print(tokens)<br>tokens = torch.tensor(tokens)<br>prompt_split_as_tokens = [tokenizer.decode([token.item()]) for token in tokens]<br>print(prompt_split_as_tokens)<br>[128000, 1820, 4320, 311, 279, 17139, 3488, 315, 2324, 11, 279, 15861, 11, 323, 4395, 374, 220]<br>[&#x27;&lt;|begin_of_text|&gt;&#x27;, &#x27;the&#x27;, &#x27; answer&#x27;, &#x27; to&#x27;, &#x27; the&#x27;, &#x27; ultimate&#x27;, &#x27; question&#x27;, &#x27; of&#x27;, &#x27; life&#x27;, &#x27;,&#x27;, &#x27; the&#x27;, &#x27; universe&#x27;, &#x27;,&#x27;, &#x27; and&#x27;, &#x27; everything&#x27;, &#x27; is&#x27;, &#x27; &#x27;]<br></code></pre></td></tr></table></figure><h2 id="将标记转换为嵌入embedding">将标记转换为嵌入（embedding）</h2><p>抱歉，但无论如何，这是代码库中我使用内置神经网络模块的唯一部分，因此我们的[17x1] 标记现在是 [17x4096]，即长度为 4096 的 17 个嵌入（每个标记一个）注意：跟踪形状，它让你更容易理解一切</p><figure><imgsrc="/images/llama3实现/v2-a4436330430517444590607a5af4bfcf_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">embedding_layer = torch.nn.Embedding(vocab_size, dim)<br>embedding_layer.weight.data.copy_(model[&quot;tok_embeddings.weight&quot;])<br>token_embeddings_unnormalized = embedding_layer(tokens).to(torch.bfloat16)<br>token_embeddings_unnormalized.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h2 id="然后我们使用-rms-归一化对嵌入进行归一化">然后我们使用 rms归一化对嵌入进行归一化</h2><p>请注意，在这一步之后，形状不会改变，这些值只是需要记住的标准化内容，我们需要一个norm_eps（来自配置），因为我们不想意外地将rms设置为0并除以0，这里是公式：</p><figure><imgsrc="/images/llama3实现/v2-645012127903f431f8f9f5f9dd506e66_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text"># def rms_norm(tensor, norm_weights):<br>#     rms = (tensor.pow(2).mean(-1, keepdim=True) + norm_eps)**0.5<br>#     return tensor * (norm_weights / rms)<br>def rms_norm(tensor, norm_weights):<br>    return (tensor * torch.rsqrt(tensor.pow(2).mean(-1, keepdim=True) + norm_eps)) * norm_weights<br></code></pre></td></tr></table></figure><h1 id="构建transformer的第一层">3.构建transformer的第一层</h1><h2 id="正常化">正常化</h2><p>无论如何，你会看到我从模型字典访问layer.0（这是第一层），所以在标准化之后我们的形状仍然[17x4096]与嵌入相同但标准化</p><figure><imgsrc="/images/llama3实现/v2-979811529314dc783cb499cf2ca93ece_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">token_embeddings = rms_norm(token_embeddings_unnormalized, model[&quot;layers.0.attention_norm.weight&quot;])<br>token_embeddings.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h2 id="从头开始实施注意力">从头开始实施注意力</h2><p>让我们加载transformer第一层的注意力头</p><figure><imgsrc="/images/llama3实现/v2-3a86ff1392e4ff420bdd9e65b3ce4d6d_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>&gt; 当我们从模型加载查询、键、值和输出向量时，我们注意到形状为[4096x4096]、[1024x4096]、[1024x4096]、[4096x4096] &gt;乍一看这很奇怪，因为理想情况下我们想要每个 q ,k,v 和 o 分别代表每个头&gt;代码的作者将它们捆绑在一起，因为它很容易，有助于并行化注意力头乘法。&gt; 我要打开所有东西...</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs text">print(<br>    model[&quot;layers.0.attention.wq.weight&quot;].shape,<br>    model[&quot;layers.0.attention.wk.weight&quot;].shape,<br>    model[&quot;layers.0.attention.wv.weight&quot;].shape,<br>    model[&quot;layers.0.attention.wo.weight&quot;].shape<br>)<br>torch.Size([4096, 4096]) torch.Size([1024, 4096]) torch.Size([1024, 4096]) torch.Size([4096, 4096])<br></code></pre></td></tr></table></figure><h2 id="展开查询">展开查询</h2><p>在下一节中，我们将从多个注意力头中解开查询，生成的形状为[32x128x4096]，其中 32 是 llama3 中注意力头的数量，128是查询向量的大小，4096 是令牌嵌入的大小</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">q_layer0 = model[&quot;layers.0.attention.wq.weight&quot;]<br>head_dim = q_layer0.shape[0] // n_heads<br>q_layer0 = q_layer0.view(n_heads, head_dim, dim)<br>q_layer0.shape<br>torch.Size([32, 128, 4096])<br></code></pre></td></tr></table></figure><h2 id="我要实现第一层的第一个头">我要实现第一层的第一个头</h2><p>这里我访问第一层的查询权重矩阵第一个头，这个查询权重矩阵的大小是[128x4096]</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">q_layer0_head0 = q_layer0[0]<br>q_layer0_head0.shape<br>torch.Size([128, 4096])<br></code></pre></td></tr></table></figure><h2id="我们现在将查询权重与令牌嵌入相乘以接收令牌的查询">我们现在将查询权重与令牌嵌入相乘，以接收令牌的查询</h2><p>在这里你可以看到结果的形状是 [17x128]，这是因为我们有 17个标记，每个标记都有一个 128 长度的查询。</p><figure><imgsrc="/images/llama3实现/v2-b946f4191582804b9e03e0b3c2f0003d_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">q_per_token = torch.matmul(token_embeddings, q_layer0_head0.T)<br>q_per_token.shape<br>torch.Size([17, 128])<br></code></pre></td></tr></table></figure><h2 id="定位编码">定位编码</h2><p>我们现在处于这样一个阶段：提示中的每个标记都有一个查询向量，但如果你仔细想想——单独的查询向量不知道提示中的位置。查询：“生命、宇宙和一切的终极问题的答案是”在我们的提示中我们已经使用了“the”三次，我们需要所有 3个“the”标记的查询向量具有不同的查询向量（每个大小[1x128]）基于它们在查询中的位置。我们使用RoPE（旋转位置嵌入）执行这些旋转。</p><h2 id="rope">RoPE</h2><p>观看此视频（这就是我观看的）以理解数学。 <ahref="https://www.youtube.com/watch%3Fv%3Do29P0Kpobz0%26t%3D530s">https://www.youtube.com/watch?v=o29P0Kpobz0&amp;t=530s</a></p><figure><imgsrc="/images/llama3实现/v2-f49af1e8f64b0ce2eb5961232523607b_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">q_per_token_split_into_pairs = q_per_token.float().view(q_per_token.shape[0], -1, 2)<br>q_per_token_split_into_pairs.shape<br>torch.Size([17, 64, 2])<br></code></pre></td></tr></table></figure><p>在上面的步骤中，我们将查询向量分成对，我们对每对应用旋转角度偏移！我们现在有一个大小为 [17x64x2] 的向量，这是针对提示中的每个标记将 128个长度的查询分为 64 对！这 64 对中的每一对都将旋转 m*(theta)，其中 m是我们旋转查询的标记的位置！</p><figure><imgsrc="/images/llama3实现/v2-79322d3dcc6c412772c7389e8c4ed8b9_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h2 id="使用复数的点积来旋转向量">使用复数的点积来旋转向量</h2><figure><imgsrc="/images/llama3实现/v2-58f0207e09f6c337fd2177a8e109a02c_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs text">zero_to_one_split_into_64_parts = torch.tensor(range(64))/64<br>zero_to_one_split_into_64_parts<br>tensor([0.0000, 0.0156, 0.0312, 0.0469, 0.0625, 0.0781, 0.0938, 0.1094, 0.1250,<br>        0.1406, 0.1562, 0.1719, 0.1875, 0.2031, 0.2188, 0.2344, 0.2500, 0.2656,<br>        0.2812, 0.2969, 0.3125, 0.3281, 0.3438, 0.3594, 0.3750, 0.3906, 0.4062,<br>        0.4219, 0.4375, 0.4531, 0.4688, 0.4844, 0.5000, 0.5156, 0.5312, 0.5469,<br>        0.5625, 0.5781, 0.5938, 0.6094, 0.6250, 0.6406, 0.6562, 0.6719, 0.6875,<br>        0.7031, 0.7188, 0.7344, 0.7500, 0.7656, 0.7812, 0.7969, 0.8125, 0.8281,<br>        0.8438, 0.8594, 0.8750, 0.8906, 0.9062, 0.9219, 0.9375, 0.9531, 0.9688,<br>        0.9844])<br>freqs = 1.0 / (rope_theta ** zero_to_one_split_into_64_parts)<br>freqs<br>tensor([1.0000e+00, 8.1462e-01, 6.6360e-01, 5.4058e-01, 4.4037e-01, 3.5873e-01,<br>        2.9223e-01, 2.3805e-01, 1.9392e-01, 1.5797e-01, 1.2869e-01, 1.0483e-01,<br>        8.5397e-02, 6.9566e-02, 5.6670e-02, 4.6164e-02, 3.7606e-02, 3.0635e-02,<br>        2.4955e-02, 2.0329e-02, 1.6560e-02, 1.3490e-02, 1.0990e-02, 8.9523e-03,<br>        7.2927e-03, 5.9407e-03, 4.8394e-03, 3.9423e-03, 3.2114e-03, 2.6161e-03,<br>        2.1311e-03, 1.7360e-03, 1.4142e-03, 1.1520e-03, 9.3847e-04, 7.6450e-04,<br>        6.2277e-04, 5.0732e-04, 4.1327e-04, 3.3666e-04, 2.7425e-04, 2.2341e-04,<br>        1.8199e-04, 1.4825e-04, 1.2077e-04, 9.8381e-05, 8.0143e-05, 6.5286e-05,<br>        5.3183e-05, 4.3324e-05, 3.5292e-05, 2.8750e-05, 2.3420e-05, 1.9078e-05,<br>        1.5542e-05, 1.2660e-05, 1.0313e-05, 8.4015e-06, 6.8440e-06, 5.5752e-06,<br>        4.5417e-06, 3.6997e-06, 3.0139e-06, 2.4551e-06])<br>freqs_for_each_token = torch.outer(torch.arange(17), freqs)<br>freqs_cis = torch.polar(torch.ones_like(freqs_for_each_token), freqs_for_each_token)<br>freqs_cis.shape<br><br># viewing tjhe third row of freqs_cis<br>value = freqs_cis[3]<br>plt.figure()<br>for i, element in enumerate(value[:17]):<br>    plt.plot([0, element.real], [0, element.imag], color=&#x27;blue&#x27;, linewidth=1, label=f&quot;Index: &#123;i&#125;&quot;)<br>    plt.annotate(f&quot;&#123;i&#125;&quot;, xy=(element.real, element.imag), color=&#x27;red&#x27;)<br>plt.xlabel(&#x27;Real&#x27;)<br>plt.ylabel(&#x27;Imaginary&#x27;)<br>plt.title(&#x27;Plot of one row of freqs_cis&#x27;)<br>plt.show()<br></code></pre></td></tr></table></figure><figure><imgsrc="/images/llama3实现/v2-3b27398a4bea72f1f64f3115faf516ae_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h2id="现在我们对每个标记token的查询元素都有一个复数角度变化向量">现在我们对每个标记（token）的查询元素都有一个复数（角度变化向量）</h2><p>我们可以将查询（我们分成对的查询）转换为复数，然后进行点积以根据位置诚实旋转查询，这想想就很美好:)</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">q_per_token_as_complex_numbers = torch.view_as_complex(q_per_token_split_into_pairs)<br>q_per_token_as_complex_numbers.shape<br>torch.Size([17, 64])<br>q_per_token_as_complex_numbers_rotated = q_per_token_as_complex_numbers * freqs_cis<br>q_per_token_as_complex_numbers_rotated.shape<br>torch.Size([17, 64])<br></code></pre></td></tr></table></figure><h2 id="得到旋转向量后">得到旋转向量后</h2><p>我们可以通过再次将复数视为实数来返回成对的查询</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">q_per_token_split_into_pairs_rotated = torch.view_as_real(q_per_token_as_complex_numbers_rotated)<br>q_per_token_split_into_pairs_rotated.shape<br>torch.Size([17, 64, 2])<br></code></pre></td></tr></table></figure><p>旋转的对现在被合并，我们现在有一个新的查询向量（旋转查询向量），其形状为[17x128]，其中 17 是标记的数量，128 是查询向量的暗度</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">q_per_token_rotated = q_per_token_split_into_pairs_rotated.view(q_per_token.shape)<br>q_per_token_rotated.shape<br>torch.Size([17, 128])<br></code></pre></td></tr></table></figure><h2 id="键几乎与查询相同">键（几乎与查询相同）</h2><figure><imgsrc="/images/llama3实现/v2-c997910e27f5cebae65b38a6b46d5b85_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我太懒了，所以我不会对键进行数学计算，你需要记住的唯一事情是： &gt;键也生成维度 128 的键向量 &gt; 键的权重数量只有1/4查询，这是因为键的权重一次在 4 个头之间共享，为了减少需要的计算数量&gt; 键也会旋转以添加位置信息，就像查询一样，原因相同</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs text">k_layer0 = model[&quot;layers.0.attention.wk.weight&quot;]<br>k_layer0 = k_layer0.view(n_kv_heads, k_layer0.shape[0] // n_kv_heads, dim)<br>k_layer0.shape<br>torch.Size([8, 128, 4096])<br>k_layer0_head0 = k_layer0[0]<br>k_layer0_head0.shape<br>torch.Size([128, 4096])<br>k_per_token = torch.matmul(token_embeddings, k_layer0_head0.T)<br>k_per_token.shape<br>torch.Size([17, 128])<br>k_per_token_split_into_pairs = k_per_token.float().view(k_per_token.shape[0], -1, 2)<br>k_per_token_split_into_pairs.shape<br>torch.Size([17, 64, 2])<br>k_per_token_as_complex_numbers = torch.view_as_complex(k_per_token_split_into_pairs)<br>k_per_token_as_complex_numbers.shape<br>torch.Size([17, 64])<br>k_per_token_split_into_pairs_rotated = torch.view_as_real(k_per_token_as_complex_numbers * freqs_cis)<br>k_per_token_split_into_pairs_rotated.shape<br>torch.Size([17, 64, 2])<br>k_per_token_rotated = k_per_token_split_into_pairs_rotated.view(k_per_token.shape)<br>k_per_token_rotated.shape<br>torch.Size([17, 128])<br></code></pre></td></tr></table></figure><h2id="在此阶段现在每个标记都有查询和键的旋转值">在此阶段，现在每个标记都有查询和键的旋转值。</h2><figure><imgsrc="/images/llama3实现/v2-b3bacaeb87eba8b665968d1c4e06ad28_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>现在每个查询和键的形状都是 [17x128]。</p><h1id="在下一步中我们将乘以查询和关键矩阵">4.在下一步中，我们将乘以查询和关键矩阵</h1><p>这样做将为我们提供一个将每个标记相互映射的分数，该分数描述了每个标记的查询与每个标记的密钥的相关程度。这是自我注意力:) 注意力分数矩阵 (qk_per_token) 的形状是 [17x17]，其中 17是提示中的标记数量</p><figure><imgsrc="/images/llama3实现/v2-e4b38700f8f38d052ddc34bb770077d3_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">qk_per_token = torch.matmul(q_per_token_rotated, k_per_token_rotated.T)/(head_dim)**0.5<br>qk_per_token.shape<br>torch.Size([17, 17])<br></code></pre></td></tr></table></figure><h2 id="我们现在必须屏蔽查询关键分数">我们现在必须屏蔽查询关键分数</h2><p>在 llama3 的训练过程中，未来的 token qk分数被屏蔽。为什么？因为在训练期间我们只学习使用过去的标记来预测标记。因此，在推理过程中，我们将未来的标记设置为零。</p><figure><imgsrc="/images/llama3实现/v2-32b947acb627e83f1be3cfaf7bcea213_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs text">def display_qk_heatmap(qk_per_token):<br>    _, ax = plt.subplots()<br>    im = ax.imshow(qk_per_token.to(float).detach(), cmap=&#x27;viridis&#x27;)<br>    ax.set_xticks(range(len(prompt_split_as_tokens)))<br>    ax.set_yticks(range(len(prompt_split_as_tokens)))<br>    ax.set_xticklabels(prompt_split_as_tokens)<br>    ax.set_yticklabels(prompt_split_as_tokens)<br>    ax.figure.colorbar(im, ax=ax)<br>    <br>display_qk_heatmap(qk_per_token)<br></code></pre></td></tr></table></figure><figure><imgsrc="/images/llama3实现/v2-7200e3d7069abc5a550654c2e2c0635a_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs text">mask = torch.full((len(tokens), len(tokens)), float(&quot;-inf&quot;), device=tokens.device)<br>mask = torch.triu(mask, diagonal=1)<br>mask<br>tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],<br>        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])<br>qk_per_token_after_masking = qk_per_token + mask<br>display_qk_heatmap(qk_per_token_after_masking)<br></code></pre></td></tr></table></figure><figure><imgsrc="/images/llama3实现/v2-9d128697d492aac646b8458d83c59a86_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure><imgsrc="/images/llama3实现/v2-f023e1085ebbe8e6b882d54ca7a4e147_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1).to(torch.bfloat16)<br>display_qk_heatmap(qk_per_token_after_masking_after_softmax)<br></code></pre></td></tr></table></figure><figure><imgsrc="/images/llama3实现/v2-af163b0bde4ab6ddc644d5d30a3dea53_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h2 id="值values注意力几乎结束">值（values）（注意力几乎结束）</h2><figure><imgsrc="/images/llama3实现/v2-f636fe202c7a600487771fb278566cc9_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>这些分数（0-1）用于确定每个标记使用了多少值矩阵&gt;就像键一样，值权重也每4个注意力头共享（以节省计算）&gt;因此，值的形状下面的权重矩阵是[8x128x4096]</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text">v_layer0 = model[&quot;layers.0.attention.wv.weight&quot;]<br>v_layer0 = v_layer0.view(n_kv_heads, v_layer0.shape[0] // n_kv_heads, dim)<br>v_layer0.shape<br>torch.Size([8, 128, 4096])<br></code></pre></td></tr></table></figure><p>下面给出第一层第一头值权重矩阵</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">v_layer0_head0 = v_layer0[0]<br>v_layer0_head0.shape<br>torch.Size([128, 4096])<br></code></pre></td></tr></table></figure><h2 id="值向量value-vectors">值向量（value vectors）</h2><figure><imgsrc="/images/llama3实现/v2-4f9bf9fa8cb5ec2f7f338049e98df276_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我们现在使用值权重来获取每个标记的注意力值，其大小为 [17x128]，其中17 是提示中标记的数量，128 是每个标记的值向量的暗度</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">v_per_token = torch.matmul(token_embeddings, v_layer0_head0.T)<br>v_per_token.shape<br>torch.Size([17, 128])<br></code></pre></td></tr></table></figure><h1 id="注意力">5.注意力</h1><figure><imgsrc="/images/llama3实现/v2-c022102b0ca593356099825ddc0cb312_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>与每个标记的值相乘后得到的注意力向量的形状为 [17*128]</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)<br>qkv_attention.shape<br>torch.Size([17, 128])<br></code></pre></td></tr></table></figure><h2 id="多头注意力">多头注意力</h2><p>我们现在有了第一层和第一个头的注意力值，现在我将运行一个循环并执行与上面的单元完全相同的数学运算，但对于第一层中的每个头</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs text">qkv_attention_store = []<br><br>for head in range(n_heads):<br>    q_layer0_head = q_layer0[head]<br>    k_layer0_head = k_layer0[head//4] # key weights are shared across 4 heads<br>    v_layer0_head = v_layer0[head//4] # value weights are shared across 4 heads<br>    q_per_token = torch.matmul(token_embeddings, q_layer0_head.T)<br>    k_per_token = torch.matmul(token_embeddings, k_layer0_head.T)<br>    v_per_token = torch.matmul(token_embeddings, v_layer0_head.T)<br><br>    q_per_token_split_into_pairs = q_per_token.float().view(q_per_token.shape[0], -1, 2)<br>    q_per_token_as_complex_numbers = torch.view_as_complex(q_per_token_split_into_pairs)<br>    q_per_token_split_into_pairs_rotated = torch.view_as_real(q_per_token_as_complex_numbers * freqs_cis[:len(tokens)])<br>    q_per_token_rotated = q_per_token_split_into_pairs_rotated.view(q_per_token.shape)<br><br>    k_per_token_split_into_pairs = k_per_token.float().view(k_per_token.shape[0], -1, 2)<br>    k_per_token_as_complex_numbers = torch.view_as_complex(k_per_token_split_into_pairs)<br>    k_per_token_split_into_pairs_rotated = torch.view_as_real(k_per_token_as_complex_numbers * freqs_cis[:len(tokens)])<br>    k_per_token_rotated = k_per_token_split_into_pairs_rotated.view(k_per_token.shape)<br><br>    qk_per_token = torch.matmul(q_per_token_rotated, k_per_token_rotated.T)/(128)**0.5<br>    mask = torch.full((len(tokens), len(tokens)), float(&quot;-inf&quot;), device=tokens.device)<br>    mask = torch.triu(mask, diagonal=1)<br>    qk_per_token_after_masking = qk_per_token + mask<br>    qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1).to(torch.bfloat16)<br>    qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)<br>    qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)<br>    qkv_attention_store.append(qkv_attention)<br><br>len(qkv_attention_store)<br>32<br></code></pre></td></tr></table></figure><figure><imgsrc="/images/llama3实现/v2-8031063609f976093e7b47ba068f359d_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我们现在有了第一层所有 32 个头的 qkv_attention矩阵，接下来我将把所有注意力分数合并到一个大小为 [17x4096] 的大矩阵中，我们即将结束:)</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">stacked_qkv_attention = torch.cat(qkv_attention_store, dim=-1)<br>stacked_qkv_attention.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h1 id="权重矩阵最后步骤之一">6.权重矩阵，最后步骤之一</h1><figure><imgsrc="/images/llama3实现/v2-076def42e5c789cd9e63170716ed7fea_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>对于第 0 层注意力要做的最后一件事是乘以</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">w_layer0 = model[&quot;layers.0.attention.wo.weight&quot;]<br>w_layer0.shape<br>torch.Size([4096, 4096])<br></code></pre></td></tr></table></figure><h2id="这是一个简单的线性层所以我们只需-matmul">这是一个简单的线性层，所以我们只需matmul</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">embedding_delta = torch.matmul(stacked_qkv_attention, w_layer0.T)<br>embedding_delta.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><figure><imgsrc="/images/llama3实现/v2-e3f7584e47bc523b3f1711d74d64534e_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我们现在在注意力之后嵌入值发生了变化，这应该添加到原始令牌嵌入中</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">embedding_after_edit = token_embeddings_unnormalized + embedding_delta<br>embedding_after_edit.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h1id="我们进行标准化然后通过嵌入增量运行前馈神经网络">7.我们进行标准化，然后通过嵌入增量运行前馈神经网络</h1><figure><imgsrc="/images/llama3实现/v2-bab8f207f6096fe5f7f0b4908e20a202_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">embedding_after_edit_normalized = rms_norm(embedding_after_edit, model[&quot;layers.0.ffn_norm.weight&quot;])<br>embedding_after_edit_normalized.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h2 id="加载-ff-权重并实现前馈网络">加载 ff 权重并实现前馈网络</h2><figure><imgsrc="/images/llama3实现/v2-c632ca45a493952c3ba94901629df5e5_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>在 llama3 中，他们使用了 SwiGLU前馈网络，这种网络架构非常擅长在模型需要时添加非线性。 如今在 llms中使用这种前馈网络架构是相当标准的</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">w1 = model[&quot;layers.0.feed_forward.w1.weight&quot;]<br>w2 = model[&quot;layers.0.feed_forward.w2.weight&quot;]<br>w3 = model[&quot;layers.0.feed_forward.w3.weight&quot;]<br>output_after_feedforward = torch.matmul(torch.functional.F.silu(torch.matmul(embedding_after_edit_normalized, w1.T)) * torch.matmul(embedding_after_edit_normalized, w3.T), w2.T)<br>output_after_feedforward.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h2id="我们终于在第一层之后为每个令牌有了新编辑的嵌入">我们终于在第一层之后为每个令牌有了新编辑的嵌入</h2><p>在我们完成之前还需要 31 层（一个 for 循环），您可以想象这个编辑后的嵌入包含有关第一层上提出的所有查询的信息，现在每一层都会对所提出的问题编码越来越复杂的查询，直到我们有一个嵌入知道我们需要的下一个令牌的所有信息。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">layer_0_embedding = embedding_after_edit+output_after_feedforward<br>layer_0_embedding.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h2 id="天哪一切都同时发生">天哪，一切都同时发生</h2><figure><imgsrc="/images/llama3实现/v2-9abf6da09122332cf71f63526ec24dd9_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>是的，就是这样。我们之前为每一层所做的一切都是一次性完成的。</p><p>祝阅读愉快:)</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs text">final_embedding = token_embeddings_unnormalized<br>for layer in range(n_layers):<br>    qkv_attention_store = []<br>    layer_embedding_norm = rms_norm(final_embedding, model[f&quot;layers.&#123;layer&#125;.attention_norm.weight&quot;])<br>    q_layer = model[f&quot;layers.&#123;layer&#125;.attention.wq.weight&quot;]<br>    q_layer = q_layer.view(n_heads, q_layer.shape[0] // n_heads, dim)<br>    k_layer = model[f&quot;layers.&#123;layer&#125;.attention.wk.weight&quot;]<br>    k_layer = k_layer.view(n_kv_heads, k_layer.shape[0] // n_kv_heads, dim)<br>    v_layer = model[f&quot;layers.&#123;layer&#125;.attention.wv.weight&quot;]<br>    v_layer = v_layer.view(n_kv_heads, v_layer.shape[0] // n_kv_heads, dim)<br>    w_layer = model[f&quot;layers.&#123;layer&#125;.attention.wo.weight&quot;]<br>    for head in range(n_heads):<br>        q_layer_head = q_layer[head]<br>        k_layer_head = k_layer[head//4]<br>        v_layer_head = v_layer[head//4]<br>        q_per_token = torch.matmul(layer_embedding_norm, q_layer_head.T)<br>        k_per_token = torch.matmul(layer_embedding_norm, k_layer_head.T)<br>        v_per_token = torch.matmul(layer_embedding_norm, v_layer_head.T)<br>        q_per_token_split_into_pairs = q_per_token.float().view(q_per_token.shape[0], -1, 2)<br>        q_per_token_as_complex_numbers = torch.view_as_complex(q_per_token_split_into_pairs)<br>        q_per_token_split_into_pairs_rotated = torch.view_as_real(q_per_token_as_complex_numbers * freqs_cis)<br>        q_per_token_rotated = q_per_token_split_into_pairs_rotated.view(q_per_token.shape)<br>        k_per_token_split_into_pairs = k_per_token.float().view(k_per_token.shape[0], -1, 2)<br>        k_per_token_as_complex_numbers = torch.view_as_complex(k_per_token_split_into_pairs)<br>        k_per_token_split_into_pairs_rotated = torch.view_as_real(k_per_token_as_complex_numbers * freqs_cis)<br>        k_per_token_rotated = k_per_token_split_into_pairs_rotated.view(k_per_token.shape)<br>        qk_per_token = torch.matmul(q_per_token_rotated, k_per_token_rotated.T)/(128)**0.5<br>        mask = torch.full((len(token_embeddings_unnormalized), len(token_embeddings_unnormalized)), float(&quot;-inf&quot;))<br>        mask = torch.triu(mask, diagonal=1)<br>        qk_per_token_after_masking = qk_per_token + mask<br>        qk_per_token_after_masking_after_softmax = torch.nn.functional.softmax(qk_per_token_after_masking, dim=1).to(torch.bfloat16)<br>        qkv_attention = torch.matmul(qk_per_token_after_masking_after_softmax, v_per_token)<br>        qkv_attention_store.append(qkv_attention)<br><br>    stacked_qkv_attention = torch.cat(qkv_attention_store, dim=-1)<br>    w_layer = model[f&quot;layers.&#123;layer&#125;.attention.wo.weight&quot;]<br>    embedding_delta = torch.matmul(stacked_qkv_attention, w_layer.T)<br>    embedding_after_edit = final_embedding + embedding_delta<br>    embedding_after_edit_normalized = rms_norm(embedding_after_edit, model[f&quot;layers.&#123;layer&#125;.ffn_norm.weight&quot;])<br>    w1 = model[f&quot;layers.&#123;layer&#125;.feed_forward.w1.weight&quot;]<br>    w2 = model[f&quot;layers.&#123;layer&#125;.feed_forward.w2.weight&quot;]<br>    w3 = model[f&quot;layers.&#123;layer&#125;.feed_forward.w3.weight&quot;]<br>    output_after_feedforward = torch.matmul(torch.functional.F.silu(torch.matmul(embedding_after_edit_normalized, w1.T)) * torch.matmul(embedding_after_edit_normalized, w3.T), w2.T)<br>    final_embedding = embedding_after_edit+output_after_feedforward<br></code></pre></td></tr></table></figure><h1id="我们现在有了最终的嵌入模型可以对下一个标记做出的最佳猜测">8.我们现在有了最终的嵌入，模型可以对下一个标记做出的最佳猜测</h1><p>嵌入的形状与常规令牌嵌入 [17x4096] 相同，其中 17 是令牌数量，4096是嵌入暗淡</p><figure><imgsrc="/images/llama3实现/v2-5b3c042a93c2a044a82e2e64f84d3065_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">final_embedding = rms_norm(final_embedding, model[&quot;norm.weight&quot;])<br>final_embedding.shape<br>torch.Size([17, 4096])<br></code></pre></td></tr></table></figure><h2id="最后让我们将嵌入解码到令牌值中">最后，让我们将嵌入解码到令牌值中</h2><figure><imgsrc="/images/llama3实现/v2-6e7276c4975ec431052164c8c49b946a_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我们将使用输出解码器将最终的嵌入转换为令牌</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">model[&quot;output.weight&quot;].shape<br>torch.Size([128256, 4096])<br></code></pre></td></tr></table></figure><h2id="我们使用最后一个标记的嵌入来预测下一个值">我们使用最后一个标记的嵌入来预测下一个值</h2><p>希望在我们的例子中，42 :) 注意：42是“生命、宇宙和一切的终极问题的答案”的答案，根据《银河系漫游指南》一书，大多数现代llms 都会回答这里有 42，这应该验证我们的整个代码！祝我好运 ：）</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">logits = torch.matmul(final_embedding[-1], model[&quot;output.weight&quot;].T)<br>logits.shape<br>torch.Size([128256])<br></code></pre></td></tr></table></figure><h2id="模型预测令牌编号-2983-作为下一个令牌这是-42-的令牌编号吗">模型预测令牌编号2983 作为下一个令牌，这是 42 的令牌编号吗？</h2><p>我正在向您宣传，这是代码的最后一个单元格，希望您玩得开心:)</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">next_token = torch.argmax(logits, dim=-1)<br>next_token<br>tensor(2983)<br></code></pre></td></tr></table></figure><h2 id="lets-go">Let's go</h2><figure><imgsrc="/images/llama3实现/v2-e436800962c747e6de871c364891ae90_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">tokenizer.decode([next_token.item()])<br>#输出&#x27;42&#x27;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>原理</tag>
      
      <tag>nlp</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大模型训练Guidelines</title>
    <link href="/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83Guidelines.html"/>
    <url>/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83Guidelines.html</url>
    
    <content type="html"><![CDATA[<p>根据scaling law，模型越大，高质量数据越多，效果越好。</p><p>但还有一个很直观的情况，随着预训练样本的质量不断提升，训练手段的优化。新的模型，往往效果能轻松反超参数量两倍于它的模型。</p><span id="more"></span><h2 id="背景">1 背景</h2><p>根据scaling law，模型越大，高质量数据越多，效果越好。</p><p>但还有一个很直观的情况，随着预训练样本的质量不断提升，训练手段的优化。新的模型，往往效果能轻松反超参数量两倍于它的模型。</p><p>例如，最新出的minicpm，微信内部评测效果也是非常棒的。跟规模相对接近的2b、7b模型比，得分比qwen2b高，和qwen7b比有的高有的低。</p><p>这个是minicpm的详细技术文档。</p><p>[https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a]</p><p>这说明，现有参数量情况下，哪怕是2B尺度，也并没有得到充分训练。</p><h2 id="样本">2 样本</h2><h3 id="样本构成">2.1 样本构成</h3><p>大家已经达成一些基础的共识。</p><p>如中英混合比例大家都大差不差。</p><p>逻辑推理比较强的样本，像代码，数学。这种就是模型越大，混合的比例反而可以越高。</p><p>跟SFT是类似的，越大的模型，越聪明的模型，需要的SFT数据就越少。同理，越大的模型，越聪明，复杂样本混合比例就可以越高。</p><h3 id="样本质量">2.2 样本质量</h3><h3 id="基本清洗">2.1.1 基本清洗</h3><p>导致ppl崩掉的，都要清洗掉，政治敏感数据清洗，去重等，肯定是一个很长的pipeline。</p><p>大家比较一致的结论是，天工开源的那份预训练数据，是一个比较好的满足基础清洗要求的数据。</p><h3 id="进阶清洗">2.1.2 进阶清洗</h3><p>大家都不太方便展开，但可以透露的信息。</p><p>跟SFT一样，产出各种各样的label来刻画数据，有的公司实习生就优化几个label。</p><p>不过随着优化的往后拓展，这些label的投入产出比越来越难以评估。</p><h3 id="phi式的生成synthetic数据">2.1.3 PHI式的生成(synthetic)数据</h3><p>预训练清洗的pipeline搭建，对于开源团队，小公司来讲，成本其实还是蛮高的。</p><p>所以，基于开源数据，做一些聚类的topic。然后基于这些topic，丢到更大的模型，来构建一批高质量的数据，是一个反而比较低成本的方案。</p><h3 id="买数据">2.1.4 买数据</h3><p>嗯，这次大模型，除了李一舟。卖数据的公司，也是真的赚到钱了。</p><h3 id="不同训练阶段的训练样本">2.3 不同训练阶段的训练样本</h3><p>经过讨论，发现有三种方案。</p><h3 id="末期高质量样本minicpm">2.3.1 末期高质量样本（minicpm)</h3><p>快速收敛阶段和平稳阶段，都采用普通样本。</p><p>退火阶段，混入高质量样本来做教科书式的学习。</p><h3 id="初期高质量样本">2.3.2 初期高质量样本</h3><p>快速收敛阶段，以高质量样本为主，让模型快速收敛。</p><p>平稳阶段，逐步调整比例，增加更多的普通样本。</p><p>退火阶段，跟平稳阶段一致</p><h3 id="全程高质量样本phil方式">2.3.3全程高质量样本（PHIL方式）</h3><p>全程都是高质量样本</p><p><strong>这里大家讨论的蛮激烈的，有这么几点。</strong></p><p>第一，初期就加入高质量样本，初期收敛的更快。但高质量样本少，不断的重复学习高质量样本，会不会导致过拟合？但反方认为，人类的本质上就是复读机，特别对于小模型，不断的重复学习，好像也没太大问题。</p><p>第二，初期学习高质量样本，会不会导致初期模型的初始化，局限在特定的区域，后面的普通样本学了之后，也不一定能很好的跳出来，会不会影响泛化？但反方认为，末期加入高质量样本，反而会不会因为最后加入高质量样本，导致泛化能力受损，集中在高质量样本的领域？</p><p>第三，PHIL方式，大家很快达成一致，PHIL就是探索小模型能不能在特定领域达到SOTA。好处，特定榜单/领域效果会特别好。坏处，模型泛化能力会很差（但PHIL从来没说要做世界模型。</p><h3 id="小模型样本的极限在哪">2.4 小模型样本的极限在哪？</h3><p>到底喂了多少tokens，小模型参数才算是充分得到训练？</p><p>当天讨论，并没有一个很好的结论。</p><p>最近YI-9B的公开技术文档，做了一个有趣的尝试。把每层的输入和输出算cos，来评估模型是否训练的非常充分。</p><p>但内部讨论后，发现这种尝试有一个巨大的遗漏点。</p><p>前段时间，我们做longcontext调研，也是把每层也都单独做了一个分析。结论是，如果模型深度足够的话，有些层其实区分度是在降低的，相当于几层做了一层做的事情。</p><p>以及，另外一个可能，小模型每一层cos都小，有可能每一层在干不同的事，或者每一层都会注意到新的东西。大模型某些层cos大，有可能是因为句子太简单，大模型对结果更加肯定，靠后的层的功能没有被激活。</p><p>感觉这种评估方式，仍旧有一定的优化空间，也期待业内能公开更多好用的评估方式。</p><h2 id="训练">3 训练</h2><h3 id="tokenizer">3.1 tokenizer</h3><p>小模型过大的tokenizer的确是一种浪费。很多小模型有大tokenizer，一个潜在的可能性，作者人力不足，直接是把大模型的tokenizer拿来复用了。</p><h3 id="阶段">3.2 阶段</h3><p>现在大家预训练分成三个阶段。</p><p>快速收敛阶段，稳定阶段，<strong>退火阶段(minicpm比较显式的提出这个阶段）</strong></p><h3 id="为什么要分阶段">3.2.1 为什么要分阶段</h3><p>这个阶段来自于大家对loss曲线的观察，发现loss曲线的收敛就是这么一个特点。</p><p>然后，大家发现不同的loss曲线阶段，做一些针对性样本和参数的调整，能带来更好的效果，于是就这么分了。</p><h3 id="不同阶段学的是什么东西">3.2.2 不同阶段学的是什么东西？</h3><p>首先，我们现在的评估手段还是比较粗糙的，假如有了更细的评估手段，可能能观测到更多有趣的东西。</p><p>例如之前俊林做过关于涌现的分享，涌现从指标观测来看，就是突然出现的。但当把指标细化后，可以发现这个涌现好像也没那么突然，这个可以参考<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2310.03262">https://arxiv.org/abs/2310.03262</a>把原本离散的准确率在1e-5级别的时候的值估计出来了。</p><p>但反方这里又有不同的观点，我们用物理学的一个理论来解释涌现。</p><p>我们可以把涌现替换成相变来聊一聊它和指标突变的辩证关系：当我们谈论相变时，我们指的是物质从一种状态转变为另一种状态的过程，比如水从液态变成固态的过程（冰冻）或者从液态变成气态的过程（蒸发）。而指标突变通常指的是某种性质或者物理量在某个条件下突然发生明显的变化，比如在某个温度或者压力下，某种物质的导电性、磁性或者其他性质突然发生变化。</p><p>相变与指标突变之间存在着密切的关系，因为相变往往伴随着物质性质的突变。当物质经历相变时，它的一些性质会突然改变，这些性质就是我们所说的指标。举个例子，当水温降到0摄氏度以下时，水会由液态变成固态，这就是相变，同时水的密度也会突然增加，导致它的体积变小，这就是指标突变。</p><p>虽然相变往往伴随着物质性质的指标突破，但是不意味着不突变就不是相变，指标的突变不是相变的重点，相变的重点在于从一个状态/性质，变成另外一个状态/性质，这两种状态有着很不一样的差别。</p><p>尽管可以使用一些技巧方法来构造一些看起来特别平滑的指标来反对大模型涌现这个词汇，但是不可否认的事实是，在不同的尺寸变化或者数据量、计算量变化之后，人们可以非常明显地感知到大模型表现的巨大差异，这就是一个相变的结果，就像是炼制一门18连环刃的法器，从第一把的炼制到第18把，从个数的指标上来说是非常平滑的，但是从威力上来说，18把可以构建一个法阵，极大地增加了武器的威力，与之前不可同日而语。</p><h3 id="batch-size">3.3 batch size</h3><p>老调重弹的问题。</p><p>2020年，transformer出来后，当时大家就碰到这么一个问题。模型太大了，用尽可能能塞进内存的batchsize去train模型，来提升速度。</p><p>很快，大家发现batch size有个trade off。</p><p>batchsize过小，波动会比较大，不太容易收敛。但这种波峰，也有助于跳出局部最优，模型更容易有更好的泛化能力。</p><p>batchsize变大，步数整体变少，训练的步数更少，本来就波动就小，步数也少，同样本的情况下，你收敛的会更慢。</p><p>2020年其实有人就研究，如何用大batchsize，更快的训练的同时，也能收敛的更好。一个解决思路是优化了优化器，例如谷歌当年出的LAMB，就把batchsize从512扩充到了6w，收敛效果也不错。</p><h3 id="lr-scheduler">3.4 LR scheduler</h3><p>机器学习的目标，都是为了收敛loss，让学习的target和我们预测的target的loss尽可能低。</p><p>学习的过程，就是基于样本，分批（batchsize）丢进去。根据过去，现在学习的效果，来决定参数更新的方向和大小。</p><p>batch size这里是很清晰的。比较纠结的点是，优化器和LRscheduler这俩好像边界不是很清晰。</p><h3 id="lr-scheduler是什么">3.4.1 LR scheduler是什么</h3><p>假如我们要下山，山脚就是我们的目标，learningrate就是我们每一步要走多远。如果速度太快，可能开到山脚后，发现刹不住车，还会往山上多开一会，于是这样反复在目标处来回震荡。如果太小的话，到山脚的速度又太慢了。</p><p>现在主流的就是cosine，初期warmup learning rate线性增长，然后learningrate就是以余弦函数的周期方式周期性变换。</p><h3 id="优化器做什么">3.4.2 优化器做什么？</h3><p>优化器核心要解决的问题，初期怎么更好的学，那些地方要加速学，那些地方容易陷入局部最优，要如何跳出来。</p><p>现在的主流做法都是基于历史的反馈。</p><p>类似于爬山，某个地方你发现爬的很慢，那么就加下油门。有的地方你发现是下坡路，跑的贼快，那就就要松下油门，免得油门太快，直接从主路跑出去了。</p><p>从momentum，到adagrad，再到adam，这两年还有人在各种折腾。</p><h3 id="优化器和lr-scheduler如何协同工作">3.4.3 优化器和LRscheduler如何协同工作？</h3><p>问题就来了，LR scheduler决定了learningrate的大小。优化器也会根据历史情况来自动调整。</p><p>这俩会不会冲突？</p><p>优化器的优点刚刚说了，但它的缺点就是无论优化器怎么说的高大上，它本质上还规则，是大家基于调参经验，或者一些假设，定的规则。</p><p>规则就很难完美适配所有任务，事实上2020年左右，大家就发现不同的任务上不同的优化器效果是不同的。例如当年的炼丹经验，计算机视觉优先使用SGD(withMomentum)，NLP（特别是用Transformer）优先使用Adam，现在CV都上transformer了，那么就又切到了AdamW。</p><p>除此之外，还有一个learning ratedecay的问题，但这个偏经验，并不一定完全solid！</p><p>用CIFAR或者ImageNet跑一跑常见的模型，就会发现，最后如果不把learningrate降低下去，loss很难收敛到一个很小的数字。</p><p>SGD和Adam的收敛性证明也都是要求learningrate最后会降到足够低的。但自适应优化器的学习率不会在训练中自动降到很低。</p><p>现在大模型预训练，大家其实最关注的就是这个loss的收敛效果。</p><p>这个时候，LRschedule的出现就是一个比较好的补充，能够补足优化器的一些问题。</p><p>所以，你可以理解为，现在我们没有一个完美的油门，所以搞了俩油门，互相辅助。</p><p>优化器是个老司机的油门，好用，但人类的经验是有局限性的，很容易陷入局部最优跑不出来。</p><p>LR schedule像是一个全局的油门，定期更新，帮助老司机跳出局部最优。</p><h3 id="w-s-d的讨论和优化方案">3.4.4 W-S-D的讨论和优化方案</h3><p>minicpm提出了W-S-D LR scheduler，但stable阶段高learningrate，相当于把调节油门的压力全给到优化器了。</p><p>但S-D的确也有很多好处，例如我想train到什么时候就train到什么时候。</p><p>这里提出了一个解决思路，W-S-D是不是可以改成，warm-cosine-stable-decay，cosine占据训练阶段大头，甚至多个余弦波段，余弦波段多了，如上文所说，是不是能更好的跳出局部最优？</p><p>快要结束训练的时候，把cosine的learningrate给升上去，走一段stable+decay。</p><h3 id="退火加sft-和面">3.5 退火加sft &amp;“和面”</h3><p>前段时间，业界流行一个说法，你发现某块效果差，在预训练最后阶段补充一些类似的数据，效果就会蹭蹭的往上涨。</p><p>简称，和面——水多了加面，面多了加水。</p><p>刚开始，大家都很鄙视这种行为，觉得这种行为不就是刷榜么？</p><p>但现在我们来探讨这块的合理性，minicpm可以算是更进一步的“作弊”了，如果按照之前的观点。他都直接把sft数据混入了预训练数据里面，更加明目张胆的“刷榜”。</p><p>我个人觉得这里可以用两个角度去理解:</p><p>角度一，模型学习的训练动态角度，在退火的时候loss下降较stable和正常的cosine都要快，证明这里的学习效率在提升(最聪明的时候?)，而此时在这一刻使用高质量数据来喂给模型,可以尽可能发挥高质量数据的作用;</p><p>角度二， SFT数据较正常的文本数据，我猜测会更偏向于benchmark一些，因为SFT很多都是"QA型"结构的数据,对于模型认识bechmark有一定的改善。</p><p>之前预训练完毕后，直接上SFT数据，语料分布差距很大，其实天然是不太好的。这种作弊的行为，只要控制样本比例得当，反而能保证后面通用对其的一致性。</p><h2 id="再看scaling-law"><strong>4 再看scaling law</strong></h2><p>随着一些common sense的建立，scalinglaw的指导意义的确是在不断下降的。</p><p>举个例子，假如我有300张卡，我要train多大的模型？</p><p>计算方式，往往就变成，我大致知道训练1T-2Ttokens效果往往就不错了，这个模型两个月后我想赶一个发布会。那么就来反推，1T的tokens训练2个月，300张卡能train多大的。</p><p>但我们回到2020年，当大部分人都在基于bert做各种魔改的时候。</p><p>OpenAI发现了这么一个规律。数据，训练，参数一直增长下去，好像loss的确是在不断的下降哎？</p><p>于是，他们拿着这个paper去问微软的CTO，你想不想看看这个loss下降到一定程度会发生什么？</p><p>会发生什么？</p><p>chatgpt就出来了</p><blockquote><p>转载自:<ahref="https://zhuanlan.zhihu.com/p/686664720">如何从零开始训练大模型（minicpm分享&amp;讨论）- 知乎 (zhihu.com)</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>模型训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于多模态信息抽取的菜品知识图谱构建</title>
    <link href="/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E7%9A%84%E8%8F%9C%E5%93%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA.html"/>
    <url>/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%A8%A1%E6%80%81%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%E7%9A%84%E8%8F%9C%E5%93%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景">1. 背景</h2><p>中国有句古话：“民以食为天”。对食物的分析和理解，特别是识别菜肴的食材，在健康管理、卡路里计算、烹饪艺术、食物搜索等领域具有重要意义。但是，算法技术尽管在目标检测[1]-[3]、通用场景理解[4][5]和跨模态检索[6]-[8]方面取得了很大进展，却没有在食物相关的场景中取得好的表现，尤其是对烹饪菜肴的相关场景。其核心原因是缺乏细粒度食材的基准，这已经成为该领域发展的瓶颈。</p><p>以往的研究主要集中在食物层面的表征学习，如Food2K上的食物识别[9]-[12]，UNIMIB2016上的食物检测[13]-[15]。然而，这些方法忽视了菜肴中的食材组成，也不理解食材之间的上下文关系。相比之下，一系列的方法[16]-[18]运用Recipe1M的“食谱-图像”对，实现了跨模态的食谱检索[16]。</p><p>然而，由于缺乏食材边界框的标注，这种类型的研究只能通过三元组建模出整个食物图像和食谱文本之间的关联[16],[19],[20]。这种限制导致图像区域与食物的一系列食材之间存在模糊的匹配关系，产生虚假相关性[21]。综上，目前迫切需要一个细粒度的食材级基准，促进复杂的食品场景理解算法的发展，并支持细粒度的任务，如食材检测和跨模态食材检索。</p><p>在本研究中提出对于中餐进行理解这一新任务，旨在捕捉中餐图像中食材之间的语义关系，并建立了有关中国菜品理解的新基准。我们大致设定了中餐理解的两个任务：食材检测和食材检索。对于食材检测，目标是确定图像中特定食材的存在并提供精确的定位。对于食材检索，目标是探索不同食材组合与食品图像之间的细粒度对应关系。对中餐的理解扩展了食品相关任务的范围，在食品领域开辟了更广泛的应用。同时，食材的多样外观和它们错综复杂的语境关系，对中餐的理解提出了一个更大的难题。</p><p>为了进行中餐理解这一新任务，我们需要构建一个包含食材粒度标注的数据集。然而，由于中餐种类繁多、风格独特，因此在食材标注上面临着巨大的挑战。构建含中餐食材的细粒度跨模态数据集主要有三个难点。</p><ul><li>首先，相同的食材有不同的名称。图1.1(a)说明了这种情况：“圣女果”和“小番茄”都是广泛使用的食材名称，它们是同一食材的不同名称，这样的情况使得我们需要花费更多的精力来清除数据集中的模糊标签以及其他噪声。</li><li>其次，同一植物类食材之间的图像存在细微差异，如“青菜”和“油菜”，“香菇”和“冬菇”，如图1.1(b)所示。这些情况对标注人员来说是相当具有挑战性的，他们需要从文本部分获得一些提示。此外，对于下游任务来说，基于视觉特征来区分它们也是相当具有挑战性的。</li><li>第三，由于烹饪方法的原因，中国菜肴的食材通常分散在图像中。如图1.1©所示，碎片化食材通常缺乏清晰的轮廓边界。此外，从图1.1(d)中可以看出，食品图像中的主要食材往往占据显著区域，这不可避免地削弱了辅助食材的语义信息。这使得在提取食材特征的同时，对辅助食材之间的上下文关系进行建模成为一个关键问题。</li></ul><p>为了应对上述挑战并促进对中餐理解的研究，我们开发了一个名为CMIngre(Cross-Modal Ingredient-level Dataset)的跨模态食材级数据集。该数据集旨在通过提供对食材及其关系的有价值的见解来增强对中国烹饪的理解。该数据集由来自三个不同来源的8,001张图像组成，即菜肴，食谱和用户生成内容（UGC）。该数据集包含429种不同的中国食材和95,290种食材边界框。</p><p>为了对广泛的食材进行全面的语义分类，我们根据中华人民共和国健康行业标准对食品食材数据表达的规定[23]，将其划分为更高级的层次。这些层次关系也可以作为先验信息，以促进在后续研究中探索不同食材之间的上下文关系。此外，我们评估了传统的基于CNN的检测算法和基于Transformer的预训练模型在CMIngre上食材检测任务的性能。我们还提出了食材检索任务的基线方法，该方法捕获单个食材的语义信息以及各种食材组合之间的关系，并进一步采用pooling策略来研究跨模态图像-食材之间的匹配关系。在CMIngre数据集上进行的深入实验评估证实了我们提出的方法在提高食材检测和检索性能方面的有效性。</p><p>本文的贡献可以概括为以下几点：</p><ul><li>本文提出了一种新的基于“图像-文本”对的中餐理解任务，该任务扩展了细粒度对象检测和检索的范围，对中餐烹饪领域的理解提供进一步的帮助。</li><li>为了支持对中餐理解的研究，我们建立了一个名为CMIngre的跨模态食材级别的数据集，该数据集由来自三个不同来源的8,001组图像食材组成，涵盖了429种不同的中国食材和95,290个边界框。</li><li>我们评估了不同的目标检测算法在CMIngre数据集上的性能，并提出了跨模态食材检索任务的基线方法。</li><li>我们在CMIngre上对两个食材级的食品理解任务进行了广泛的实验，以评估我们提出的方法的有效性。</li></ul><figure><imgsrc="/images/多模态菜品知识图谱/dd53a1be4fec67da55f36181dbfb54e42732851.png"alt="图1.1 菜品中不同尺寸的食材" /><figcaption aria-hidden="true">图1.1 菜品中不同尺寸的食材</figcaption></figure><p>图1.1 菜品中不同尺寸的食材</p><h2 id="数据集">2. 数据集</h2><p>在本节中，我们将讨论如何构造CMIngre数据集。我们将在第一部分中介绍我们如何收集和标注数据。在第二部分中，我们对数据进行了后处理，提升原始数据的质量。在第三部分中进行了CMIngre数据集的统计和分析。</p><h3 id="数据收集和标注">2.1 数据收集和标注</h3><p>数据收集：为了收集全面的食物图像，我们探索了三种类型的图像-文本对：</p><ul><li><strong>菜肴图片</strong>：如图2.1第二行所示，这一类别包括与其名称配对的菜肴图像。与其他类型相比，这种类型的文本提供了最简洁的描述。</li><li><strong>菜谱图片</strong>：如图2.1第三行所示，这些数据由菜谱图像和详细的食谱文本组成。这些图像的质量更高，并且比其他两个类别的图像描述的信息更丰富。</li><li><strong>用户UGC图片</strong>：如图2.1的最后一行所示，这种类型数据主要包含用户拍摄的图像及其附带的评论。由于用户生成的内容缺乏约束限制，图像和文本描述经常包含与食物无关的元素，例如餐厅氛围或餐具。为了将该数据集细化为专注于食物，我们使用菜肴名称识别算法[45]来识别带有菜肴名称的文本。具体来说，我们会选择评论中包含三个以上菜名的照片，减少与食物无关的内容。</li></ul><p>这三种类型的数据在线上平台很流行，并且提供了食品相关数据的多样化表示。我们总共收集了11,300个图像-文本对用于标注。</p><figure><imgsrc="/images/多模态菜品知识图谱/aef25b66918705bd9b80d3eca4f5875e2420771.png"alt="图2.1 不同数据来源的图像-文本对，其中UGC表示用户生成的内容" /><figcaption aria-hidden="true">图2.1不同数据来源的图像-文本对，其中UGC表示用户生成的内容</figcaption></figure><p>图2.1 不同数据来源的图像-文本对，其中UGC表示用户生成的内容</p><p><strong>数据标注</strong>：这里将详细介绍收集到的“图像-文本”对的标注过程。我们首先雇佣了8名母语为中文的工作人员，分别对文字描述和图片进行标注。然后，使用另外两名工作人员进行双重检查过程。</p><ol type="1"><li><strong>文字描述标注</strong>：标注人员的任务是识别文本描述中提到的所有食材。该标注的结果如图2.1第三列所示。</li><li><strong>图片标注</strong>：如图2.1最后一列所示，图像标注遵循两个关键原则：1）要求标注人员标注文本中提到的和图像中可见的食材。2)文本中没有提及但在图像中可以识别的食材也需要标注。在这个过程中，标注人员遇到了几个挑战：1）一个图像包含相同食材的多个实例。在这种情况下，标注人员需要用多个边界框标注所有实例。但是，如果同一食材的多个实例紧密聚集在一起，则可以将它们分组在一个边界框中。2)多种食材被其他食材覆盖。在这种情况下，标注人员需要标注出所有可识别的部分。本质上，食材中任何可以被辨别和识别的部分都应该被标注。</li></ol><p>经过标注过程后，最终的数据集包含11,300个图像-文本对，用4,492个不同的食材标签和199,853个边界框进行了标注。</p><h3 id="标注数据后处理">2.2 标注数据后处理</h3><p>由于缺乏对标注人员关于每个图像的边界框的大小和数量的限制，最终的标注结果中存在边界框大小的显著变化和相当多的冗余边界框。为了解决这个问题，我们分别对图像和文本进行了进一步的后处理。</p><ul><li><strong>图像标注清洗</strong>：为了提高数据集中边界框的质量，我们基于两个关键策略实现了清理过程：1)边界框融合：我们通过将相同标签（重叠，相互包含或临近）合并到单个边界框中来解决冗余边界框的问题。具体来说，融合是基于边界框的面积，计算每个边界框内的像素数。如果融合前后的面积比大于一个特定的阈值，我们将这些边界框整合成一个新的边界框。这个阈值的设置是一个关键问题。我们注意到，过高的阈值将使融合策略无效，而过低的阈值将导致可能包含多种食材的过大的边界框。因此，我们根据经验将其设置为0.6作为平衡。2)较小边界框移除：我们通过两个过程来移除数据集中的小边界框。首先，为了去除只有小框的图像，我们去除所有框的总面积小于整个图像面积3%的图像-文本对。其次，如果图像中有超过三个相同类别的边界框，我们只保留面积至少为该类别中最大边界框面积0.8倍的边界框。在这些清理步骤之后，我们的精细化数据集包含8,001个图像-文本对，共有95,290个边界框。</li><li><strong>文本标注清洗</strong>：为了改进数据集中的食材标注，我们实现了两个步骤：1)为了保留足够的数据用于训练和测试，我们删除出现在少于五张图像中的食材。由于原始数据集中存在显著的长尾问题，这一步使得食材标签总数减少到510。2)在这510种食材中，我们发现了不同名称指代同一种食材的情况，例如“松花蛋-皮蛋”。为了解决这个问题，我们利用中华人民共和国健康行业标准[23]中的食物成分数据表达规范，对目前510种食材进行比较和组合。具体而言，两个标注人员最初将510个食材中的每一个分类到分层本体的适当叶节点中。随后，另一个标注人员在同一父节点下审查并合并具有相同语义的食材。合并操作进一步将食材标签减少到429个。</li></ul><p>综上所述，清理后的数据集包括8,001张图像，95,290个边界框和429个食材标签。</p><h3 id="数据统计和分析">2.3 数据统计和分析</h3><p>在CMIngre中，有1,719对来自菜肴的图像-文本，2,330对来自食谱，3,952对来自UGC。如2.1所述，UGC的图像质量比菜肴和食谱的图像质量差，这给我们在接下来的食物理解任务中处理低质量数据带来了更多的工作量，因为UGC覆盖了近一半的数据集。</p><p>数据集中每个食材上的图像数量如图2.2所示，少量食材在我们的数据集中出现了很多次。例如，“葱–scallion”在1,961张图片中出现次数最多，约占图片总数的24.51%。此外，有138种食材出现在不到10张图片中。例如，只有5张图片包含“西柚–grapefruit”，8张图片包含“桃–Peach”。图2.3显示了我们数据集中每个食材的边界框数量。如图2.3所示，每种食材对应的边界框数量分布与图2.2中包含该食材的图像数量分布大致相似，均为长尾。为了说明边界框尺寸的差异，图2.4给出了不同尺寸边界框的比例。我们观察到小尺寸的边界框（面积比在0.0025~0.01之间）的比例最大。同时，有超过50%的边界框的面积比小于0.01，说明数据集中有很多小物体。</p><p>表2.1显示了与食品相关数据集的统计比较。我们可以看到，现有的食品相关数据集主要集中在食品识别任务上，其目的是识别图像内的食品类别。很少有数据集为食物边界框提供标注，这是由于它们的目标是定位整个菜肴，而不是各种类型的食材。相比之下，Recipe1M为每个食物图像提供食材标注。然而，由于缺乏对这些细粒度食材的位置标注，它们只能隐式地建模整个食物图像与相应食材之间的关联，从而限制了模型的性能。因此，我们引入了CMIngre，旨在通过食材检测和检索任务增强对中餐的理解。</p><figure><imgsrc="/images/多模态菜品知识图谱/6686e3666e5a045b1b04ac6b5b958a33119886.png"alt="表2.1 现有食品相关数据集之间的统计比较" /><figcaption aria-hidden="true">表2.1现有食品相关数据集之间的统计比较</figcaption></figure><p>表2.1 现有食品相关数据集之间的统计比较</p><p>最后，我们将CMIngre数据集与广泛使用的目标检测数据集COCO进行了比较分析。在图2.5中，横轴表示每张图像中标签种类的数量（在CMIngre中标签为食材，在COCO中标签为物体）纵轴表示每种图像的比例。很明显，CMIngre图像通常包含更多的对象(在我们的例子中是食材)。具体来说，CMIngre中包含三个以上标签的图像的占比高于MSCOCO数据集。这一趋势在边界框的数量上也很明显。如图2.6所示，与MSCOCO相比，我们的数据集中超过5个边界框的图像比例更大。综上所述，CMIngre中的图像比其他现有数据集具有更丰富的语义和更密集的边界框，这对图像理解提出了更艰巨的挑战。</p><p><imgsrc="/images/多模态菜品知识图谱/e96069a314798d41b37604cdc7ed3824281434.png"alt="img" /><imgsrc="/images/多模态菜品知识图谱/7e8e6ccc79fd44fed414298f41e00d50151768.png"alt="img" /></p><h2 id="方法">3. 方法</h2><p>在本研究中，我们引入了两项从食材层面理解中国菜食材的任务，即食材检测（任务1）和跨模态食材检索（任务2）。任务1的重点是识别食材并在图像中标注准确的位置信息，任务2旨在研究图像与食材组成之间的复杂关系。对于任务1，我们使用现有目标检测模型在CMIngre数据集上进行微调，构建有关中国菜品理解的新基准；对于任务2，我们在现有跨模态检索方法的基础上，提出了一些创新性的做法，填补了有关中国菜品食材粒度理解的空白。</p><h3 id="食材检测">3.1 食材检测</h3><p>与传统的目标检测数据集相比，CMIngre数据集具有极其详细的食材分类和密集的边界框注释，因此直接利用现存的目标检测算法进行拟合是一件非常具有挑战的事情。直接对现有的大规模目标检测模型[1]在原始边界框注释上进行微调的效果并不让人满意，因此我们采用融合和过滤策略来缓解边界框密集和尺寸较小带来的问题。</p><p>具体而言，我们首先按照融合前后的边界框面积百分比不低于阈值τ的规则，对同一类别的多个边界框进行融合，在实验中这个阈值被设置为0.6。接下来，我们对融合后的边界框进行排序，并将边界框的三个最大区域保留为真值。此外，我们将食材树层级结构的最低级标签都转换为第三级标签，例如“紫菜”和“海带”都融合为“藻类”，“冬笋”和“酸笋”都融合为“笋”，这样可以避免模型无法识别同一分支中高度相似的类别的问题。根据这种转换，类别总数从429减少到67个。在这种设置下，我们使用如下的两种不同的基线方法进行实验。</p><h4 id="基于cnn的方法faster-r-cnn47和yolo-v548">3.1.1基于CNN的方法：Faster R-CNN[47]和YOLO v5[48]</h4><p>FasterR-CNN是一种经典的基于卷积神经网络（CNN）的两阶段目标检测框架。在第一阶段，FasterR-CNN利用CNN提取输入图像的特征映射，然后利用区域提名网络（RPN）生成候选目标区域。在第二阶段，基于候选目标区域，利用图像区域边界框回归以及区域食材识别两个约束进行网络参数的整体更新。相比之下，YOLO（YouOnly Look Once）是一种单阶段目标检测算法，以其速度和效率而闻名。与FasterR-CNN不同，YOLO在一次评估中处理整个图像，同时预测多个对象的分类概率和边界框。</p><h4 id="dino1">3.1.2 DINO[1]</h4><p>DINO（DETR with Improved deNoising anchOrboxes）是一个融合对比降噪训练（contrastive way for denoisingtraining），混合查询选择锚点初始化（mixed query selection method foranchr initialization），前向两次预测（look forward twice scheme for boxprediction）的端到端Transformer框架。相比于FasterR-CNN，DINO是一个参数量更大且更高效的目标检测模型。</p><p><strong>评估方案</strong>：使用平均精度（AP）来评估基线模型的检测性能。对于FasterR-CNN，YOLO和DINO，分别评估了不同IoU阈值（0.5、0.75和0.5:0.95）下的标准平均精度结果。</p><h3 id="跨模态食材检索">3.2 跨模态食材检索</h3><figure><imgsrc="/images/多模态菜品知识图谱/89a8ee55deb718feb238d0be52e4852c1386828.png"alt="图3.1 中餐理解框架" /><figcaption aria-hidden="true">图3.1 中餐理解框架</figcaption></figure><p>图3.1 中餐理解框架</p><figure><imgsrc="/images/多模态菜品知识图谱/53475fc70475afca34e5e945ffb37bf480410.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>如图所示，使用两个独立的特征提取器提取图像特征和食材特征。然后，应用对比约束以端到端的方式来缩小匹配的图像和食材之间的嵌入距离。考虑到食材检测能够学习不同图像区域中食材的语义嵌入，我们进一步研究了两阶段的检索模型的有效性，该模型首先使用食材检测算法提取区域特征，然后使用区域特征和食材来训练一个联合嵌入模型。</p><h4 id="方法1-端到端训练">3.2.1 方法1-端到端训练</h4><p>在端到端设置中，我们首先将食品图像和食材组合投影到公共的嵌入空间中，然后使用对比损失来约束跨模态特征对齐。对于图像编码器，受视觉-语言Transformer在各种下游任务中取得成功的启发，我们采用预训练的[49]-[51]CLIPViTB/16作为图像特征提取器对图像特征进行编码，然后利用线性全连接层将原始图像特征投影到公共的嵌入空间中：</p><figure><imgsrc="/images/多模态菜品知识图谱/9f1da74698d2dd9238ab2706e95ec2d9372688.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h4 id="方法2-二阶段训练">3.2.2 方法2-二阶段训练</h4><p>与图像编码器直接提取的全局图像特征相比，从食材检测模型中提取的局部特征包含了特定的食材语义信息，为跨模态食材检索提供了更有利的初始化状态。为了利用这一优势，我们首先使用食材检测模型提取<imgsrc="/images/多模态菜品知识图谱/005A.pngV=2.7.png"alt="img" />𝑍个区域特征。然后，我们提出了一个自适应式池化策略来自动融合多区域特征和多食材特征。</p><figure><imgsrc="/images/多模态菜品知识图谱/74792747bd89855ec9bba298d43ecca0442698.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h2 id="实验">4. 实验</h2><h3 id="算法实现细节">4.1 算法实现细节</h3><p>CMIngre数据集在本次实验中被随机划分为6,001个训练样本，1,000个验证样本和1,000个测试样本。所有的实验都使用了PyTorch框架，在2张NVIDIAGTX 3090 GPU上进行实验。</p><ul><li><strong>食材检测</strong>：对于FasterR-CNN框架，与方法[47],[54]保持一致，利用ResNet-101作为特征提取器，设置batchsize为2，学习率为0.001，并利用SGD优化器进行端到端检测优化。对于YOLO算法，遵循官方报告[48]使用yolov5x6进行检测实验。对于DINO框架，与官方设置[1]保持一致，然后选用VisionTransformer作为特征提取器fine-tune整个模型。</li><li><strong>跨模态食材检索</strong>：选用Adam优化器训练整个模型并且设置batchsize为128，最终映射层维度为1024。对于双层自注意力编码机制，选用包含有2层、4个头部的Transformer作为每层编码器，并且设置隐藏层维度为512。对于图像食材区域特征预提取，在FasterR-CNN框架中提取36个维度为2048的区域特征，在DINO框架中提取128个维度为256的区域特征。为了增加模型泛化能力，随机消去20%的图像区域，并且设置位置编码向量维度<imgsrc="/images/多模态菜品知识图谱/0064.pngV=2.7.png" alt="img" /><imgsrc="/images/多模态菜品知识图谱/0032.pngV=2.7.png"alt="img" />𝑑2为32。</li></ul><h3 id="实验结果">4.2 实验结果</h3><h4 id="食材检测-1">4.2.1 食材检测</h4><p>为了验证现有的检测框架在CMIngre食材数据集上的有效性，我们利用基于CNN以及基于Transformer的端到端框架。实验结果如表4.1所示，可以发现YOLOv5，FasterR-CNN和DINO在CMIngre数据集上性能一般。这一结果表明，目前的目标检测方法为明确的目标边界而设计，很难直接检测到自由形式的食材。这也表明，在食品相关领域开发更多细粒度食材理解算法仍有很大的性能提升空间。与FasterR-CNN相比，DINO在不同的IoU阈值下的检测性能更好，这说明大规模预训练模型在食物领域依然存在着较强的理解能力。</p><p>此外，为了验证微调目标检测模型实验的有效性，我们找到了CMIngre数据集和MSCOCO数据集中的七个公共类别：蛋糕、西兰花、苹果、胡萝卜、橙子、香蕉、甜甜圈。接下来，我们选取CMIngre数据集中包含这七类食材的数据，对预训练模型和使用CMIngre中数据微调后的模型进行了对比验证。表4.2展示了FasterR-CNN和DINO在CMIngre数据集中公共7类食材上的检测结果。与FasterR-CNN相比，预训练的DINO和微调后的DINO都表现出了更优的性能，突出了大规模预训练模型的泛化能力。此外，在CMIngre数据集上对DINO进行微调后，模型对常见类别的检测性能有了很大的提高。具体而言，微调后的DINO在7个公共类别上AP50:95、AP50和AP75方面分别比预训练的DINO提高了18.3%、25.2%和21%，这证明了在CMIngre数据集上进行模型调优的有效性。</p><figure><imgsrc="/images/多模态菜品知识图谱/4407f64a5e96256eb6e48f2e4b17e85185838.png"alt="表4.1 CMIngre和MS COCO的检测结果(%)，“()”表示检测方法在MS COCO和CMIngre上的性能差异" /><figcaption aria-hidden="true">表4.1 CMIngre和MSCOCO的检测结果(%)，“()”表示检测方法在MSCOCO和CMIngre上的性能差异</figcaption></figure><p>表4.1 CMIngre和MS COCO的检测结果(%)，“()”表示检测方法在MSCOCO和CMIngre上的性能差异</p><figure><imgsrc="/images/多模态菜品知识图谱/0fec187d7661ec4c8385100caae817e357503.png"alt="表4.2 Faster R-CNN和DINO在MS COCO和CMIngre的共有类别上的检测性能" /><figcaption aria-hidden="true">表4.2 Faster R-CNN和DINO在MSCOCO和CMIngre的共有类别上的检测性能</figcaption></figure><p>表4.2 Faster R-CNN和DINO在MS COCO和CMIngre的共有类别上的检测性能</p><h4 id="跨模态食材检索-1">4.2.2 跨模态食材检索</h4><p>在这一节中，我们重新实现了几个图像backbone（ResNet-50, ViT B/16和CLIPViTB/16）和食材backbone（分层Transformer和分层LSTM）进行性能对比。此外，还进行了两阶段实验设置，验证了食材对象和跨模态食材检索相结合的有效性。实验结果如表4.3所示，其中APS表示自适应池化策略。最后，在表4.4中，我们重新实现了两种最先进的跨模式食谱检索方法（TFood[19]和VLPCook[56]），来比较我们提出的CMIngre和Recipe1M[32]。</p><figure><imgsrc="/images/多模态菜品知识图谱/19bbec3e32611fcc829815de76a90193148394.png"alt="表4.3 CMIngre中跨模态食材检索性能" /><figcaption aria-hidden="true">表4.3CMIngre中跨模态食材检索性能</figcaption></figure><p>表4.3 CMIngre中跨模态食材检索性能</p><p>结果表明，ResNet+H-LSTM的性能并不令人满意。我们认为这是因为卷积神经网络的接受域有限，ResNet-50只能捕获整体图像的粗粒度语义，而忽略了细粒度的食材特征。这个结果突出了在跨模态食材检索中对于图像进行细粒度分析的重要性。通过利用Transformer中的自注意力机制对不同食材之间的语义关联进行建模，ResNet+H-Transformer增强了食材组合的表现力，从而提高了检索性能。</p><p>具体来说，在图像到食材的设置中，medR从62.0降低到40.0。当使用视觉Transformer[58]作为图像backbone时，检索性能显著提升。这证明了视觉Transformer通过利用不同图像区域之间的关系来提取细粒度食材表示的能力。受视觉-语言基础模型在各种下游任务中获得成功的启发，我们采用CLIP[49]作为图像backbone进行实验，与其他端到端设置相比，CLIP具有最佳的检索性能。这些实验结果表明，当采用更深和更先进的backbone时，检索性能得到了一致的改善。</p><p>除此之外，我们还探索了结合食材检测和跨模态食材检索的两阶段模型的检索性能。首先，我们使用FasterR-CNN和DINO提取固定长度的区域特征。然后，引入自适应池化策略（APS）来融合多区域特征。如表4.3所示，在所有的评估指标中，两阶段的方法明显优于端到端的方法，这表明当前的图像编码器很难直接从图像中提取细粒度食材的判别特征。</p><p>在这种情况下，更有效的方法是下训练一个专门针对食材图像的检测模型，然后使用经过训练的检测模型提取的细粒度食材特征进行检索任务。此外，可以观察到，与FasterR-CNN相比，使用DINO的区域特征可以进一步提高检索性能。这表明食材检索模型的性能提升可以同步体现在跨模态食材检索中。</p><figure><imgsrc="/images/多模态菜品知识图谱/a5eb867bcd290cd13fa8465c0d214f5b148369.png"alt="表4.4 CMIngre和Recipe 1M的跨模态检索性能" /><figcaption aria-hidden="true">表4.4 CMIngre和Recipe1M的跨模态检索性能</figcaption></figure><p>表4.4 CMIngre和Recipe 1M的跨模态检索性能</p><p>为了进一步将所提出数据集与其他跨模态食品检索数据集的复杂性进行对比，我们在Recipe1M中重新实现了两种最先进的方法[32]，并对比了这些方法在CMIngre数据集上的检索性能。根据表4.4所示，CMIngre数据集上的检索效率大约是Recipe1M上的一半，这一显著差异凸显了中国食材面临的更大挑战。具体来说，Recipe1M提供了一套全面的食谱细节（包括配料、标题和说明），它丰富了图像和食谱之间的上下文关系，从而促进了跨模态检索。相比之下，CMIngre数据集仅局限于食材信息，这对有效的跨模态检索提出了更大的挑战。值得注意的是，我们的两阶段方法明显优于这些对比方法，这进一步凸显了两阶段方法的优势，即训练食材检测方法提取细粒度食材特征可以显著增强图像的表示能力。</p><h3 id="可视化">4.3 可视化</h3><p>我们从三种类型的数据（菜名，菜谱，用户生成内容）中随机采样一个查询样本，执行跨模态检索任务，并可视化该查询样本的Top-5检索结果。如图4.1所示，查询图像所对应的正确食材组合成功的以最高相似度出现在第一个检索结果中，验证了我们图像搜索食材的有效性。此外，我们观察到查询样本和Top-5检索结果有着一定程度上的关联，例如在菜谱（recipe）查询图像的检索结果中，Top-5的食材组合都包含有鸡蛋和蔬菜（油菜、蔬菜、西兰花），并且第一个检索结果和第二个检索结果仅仅是“蔬菜”和“油菜”的细微区别，这说明我们的方法可以有效挖掘到图像和食材间的匹配关系。</p><p>如图4.2所示，上述相同的现象也出现在三类查询食材的Top-5检索结果中。我们也在图4.3中可视化了一些最佳匹配失败的案例，发现当图像中所包含的食材不能被清晰认知时，模型会倾向于给出一个相似的具体食材。例如在菜品名称查询图像中，其中的一个绿色食材由于无法被清晰的辨识所以被标注为更高级的“蔬菜”标签。然而当模型执行跨模态检索时，会更倾向于将其认知为更细粒度“芥菜”和“秋葵”而不是“蔬菜”。另外一个观察是相比于最佳匹配案例，错误案例中Top-5检索结果的相似度往往倾向于更低且更平均，表示出了模型很难分辨菜品图像中模糊食材的具体分类。</p><figure><imgsrc="/images/多模态菜品知识图谱/184b91f3216c3bed2a309b5853a7dd2d2366226.png"alt="图4.1 使用图像检索食材组合，三种不同来源查询图的top-5检索结果" /><figcaption aria-hidden="true">图4.1使用图像检索食材组合，三种不同来源查询图的top-5检索结果</figcaption></figure><p>图4.1 使用图像检索食材组合，三种不同来源查询图的top-5检索结果</p><figure><imgsrc="/images/多模态菜品知识图谱/0febdbdddaf8395ce79b0bb3a16093003343169.png"alt="图4.2 使用食材组合检索图像，三种不同来源查询食材组合的top-5检索结果" /><figcaption aria-hidden="true">图4.2使用食材组合检索图像，三种不同来源查询食材组合的top-5检索结果</figcaption></figure><p>图4.2使用食材组合检索图像，三种不同来源查询食材组合的top-5检索结果</p><figure><imgsrc="/images/多模态菜品知识图谱/849cbef9cc773900f058023d5384f87f2610481.png"alt="图4.3 三种不同来源查询图像最佳匹配失败示例" /><figcaption aria-hidden="true">图4.3三种不同来源查询图像最佳匹配失败示例</figcaption></figure><p>图4.3 三种不同来源查询图像最佳匹配失败示例</p><p>此外，按照[59]中描述的方法，我们可视化了单个食材的匹配下降分数（MDS）。具体来说，我们将单个食材的MDS定义为当从食材组合中删除特定食材时，图像与其相应食材组合之间的相似性变化。如图4.4所示，具有明显视觉特征的食材往往具有更高的MDS。例如，在第一张图像中，删除“米”导致了0.1216的相似度显著下降，这个下降明显高于土豆、胡萝卜、肉。另一个值得注意的是，具有模糊视觉外观的食材会对跨模态检索产生负面影响。例如，在第三张图中，由于煮熟的青菜缺乏鲜明的视觉特征，导致图像与缺乏青菜的食材组合匹配相似度增加。</p><figure><imgsrc="/images/多模态菜品知识图谱/1d5bd8c955d2e8e2965dd11a49ef10b31047450.png"alt="图4.4 单个食材在CMIngre上的MDS。MDS最高的食材用红色表示，MDS为负的食材用蓝色表示" /><figcaption aria-hidden="true">图4.4单个食材在CMIngre上的MDS。MDS最高的食材用红色表示，MDS为负的食材用蓝色表示</figcaption></figure><p>图4.4单个食材在CMIngre上的MDS。MDS最高的食材用红色表示，MDS为负的食材用蓝色表示</p><h2 id="业务应用">5. 业务应用</h2><p>菜品作为餐饮业务的最基本单元，在供给策略运营、用户需求洞察、业务经营分析等场景都必要依赖。2020年至2021年，到餐研发团队基于业务菜品数据，进行了标准统一和知识融合，整体菜品知识准确率达到94.51%、覆盖率达到87.01%。但在局部视角，部分菜品知识属性受限于获取信源单一、挖掘技术难度大等原因导致知识覆盖不足，例如烧烤/火锅品类准确率仅63.6%，食材属性覆盖率67.5%，口味属性覆盖率11.9%，影响支持业务精细化、智能化的运营需求。</p><p>为了提升菜品知识的覆盖，我们提出一套构建多模态知识图谱的流程，分别从文本和图像两个模态获取菜品知识。</p><figure><imgsrc="/images/多模态菜品知识图谱/3e93bf767e50422921304edc20581dd7392993.png"alt="图5.1 多模态知识图谱构建流程" /><figcaption aria-hidden="true">图5.1 多模态知识图谱构建流程</figcaption></figure><p>图5.1 多模态知识图谱构建流程</p><p>对于文本模态，使用命名实体识别提取文本中的食材、口味、口感、菜系、烹饪方法；对于图像模态，使用目标检测提取图像中的食材信息和对应区域对文本信息进行补充。在对单个图像-文本对构建多模态知识图谱对基础上，通过相同食材、口味等信息对不同的图像-文本对进行关联，进而构建完整的菜品多模态知识图谱，从而提升菜品知识覆盖率。</p><h2 id="结论">6. 结论</h2><p>在本研究中，我们将重点放在中餐食材理解上，它扩展了细粒度对象检测和检索的范围，在中餐领域提供了更广泛的应用。为了支持新任务的研究，我们设计了第一个跨模态食材级数据集CMIngre，该数据集由来自菜肴、食谱和UGC三种不同来源的8,001对图像食材组成，涵盖了429种不同的中国食材和超过95,290个边界框。我们在CMIngre数据集上评估了不同目标检测算法的有效性，表明开发更高级的细粒度食材检测算法仍然有足够的性能提升空间。此外，在CMIngre上进行的广泛的跨模态食材检索实验验证了我们提出的基线的有效性。此外，我们希望这个基准可以激发更多新颖的细粒度食材理解算法的发展，从而促进食品相关领域的进步。</p><p>利用以上技术能力，在多模态数据集上建设菜品知识图谱。对比文本单模态(知识准确率95%、覆盖率达到80%)，通过在评测数据上进行验证，该项目提升菜品知识图谱的属性知识的质量，知识准确率96.52%、覆盖率达到87.01%。将菜品知识图谱的能力应用于相同商品识别的业务场景，通过提供商品理解的关键信息，识别的错误率从20.38%降低至2.3%，提升美团精细化运营的效率。</p>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>多模态</tag>
      
      <tag>论文解读</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【B站】大模型之路-从分治法至端到端,再到存算训一体</title>
    <link href="/B%E7%AB%99_%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E4%B9%8B%E8%B7%AF--%E4%BB%8E%E5%88%86%E6%B2%BB%E6%B3%95%E8%87%B3%E7%AB%AF%E5%88%B0%E7%AB%AF,%E5%86%8D%E5%88%B0%E5%AD%98%E7%AE%97%E8%AE%AD%E4%B8%80%E4%BD%93.html"/>
    <url>/B%E7%AB%99_%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E4%B9%8B%E8%B7%AF--%E4%BB%8E%E5%88%86%E6%B2%BB%E6%B3%95%E8%87%B3%E7%AB%AF%E5%88%B0%E7%AB%AF,%E5%86%8D%E5%88%B0%E5%AD%98%E7%AE%97%E8%AE%AD%E4%B8%80%E4%BD%93.html</url>
    
    <content type="html"><![CDATA[<h1id="大模型发展之路--从分治法至端到端再到存算训一体">大模型发展之路--从分治法至端到端,再到存算训一体</h1><p>安克创新CEO阳萌对人工智能过去、现在和未来的思考。他认为大模型和transformer只是阶段性的算法实现,未来一定是仿生算法的大趋势。他还谈到了分治法作为经典的范式有其明显的局限,而端到端的方案是人类理性解决问题的必经之路。他指出,人工智能领域的范式每五到十年就会出现一个全新的范式,存算一体已经成为业界新宠。</p><span id="more"></span><iframe src="//player.bilibili.com/player.html?isOutside=true&amp;aid=1954475860&amp;bvid=BV1gC41177xR&amp;cid=1538517104&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe><h3id="人工智能领域的发展历程和未来趋势以及斯蒂文杨萌对于人工智能的看法和建议">人工智能领域的发展历程和未来趋势,以及斯蒂文杨萌对于人工智能的看法和建议。</h3><p>00:01大模型解决不了英伟达的难题</p><p>00:45人工智能的发展历程</p><p>03:16人工智能领域的范式转变</p><h3id="分治法在人工智能领域的应用并探讨了端到端算法和分支法的优缺点">分治法在人工智能领域的应用,并探讨了端到端算法和分支法的优缺点。</h3><p>04:38分治法和端到端学习：分治法是一种解决问题的方法，而端到端学习则是一种新兴的方法。</p><p>05:53分治法可以帮助解决自然语言处理和自动驾驶等领域的问题。</p><p>08:29柔性连接和人类智能：人类的智能具有柔性连接的特点，而机器智能需要更多的研究来实现这样的特性。</p><h3id="搜索算法工程师使用分治法进行搜索并探讨了算法硬件和数据在人工智能中的重要性">搜索算法工程师使用分治法进行搜索,并探讨了算法、硬件和数据在人工智能中的重要性。</h3><p>09:04分治法在搜索引擎中的应用</p><p>12:05GPU和transformer算法的关系</p><p>13:10特斯拉和英伟达在自动驾驶领域的竞争</p><h3id="gpu芯片的结构和工作原理以及现代大模型在训练和推理端的不同应用">GPU芯片的结构和工作原理,以及现代大模型在训练和推理端的不同应用。</h3><p>13:28GPU是封装的芯片，其中包括运算核心和内存。在运算过程中，参数存在两边的内存中。</p><p>14:12大模型的训练需要多卡参与，而推理是将参数从内存中搬运到计算中心进行计算。</p><p>16:38Transformer模型不是一段一段地解决问题的，而是通过整体的参数进行端到端的解决问题。</p><h3id="gpu的发展趋势和优势并提出了人类应该借鉴大脑的运行方式来设计未来的芯片">GPU的发展趋势和优势,并提出了人类应该借鉴大脑的运行方式来设计未来的芯片。</h3><p>17:53计算性能与模型发展问题</p><p>21:35GPU的不足与大脑的差异</p><p>22:04适合大脑的计算芯片与内存位置</p><h3id="存算一体的概念以及如何实现存算一体的芯片并探讨了其在未来ai发展中的潜力">存算一体的概念,以及如何实现存算一体的芯片,并探讨了其在未来AI发展中的潜力。</h3><p>22:10存算一体芯片可以实现大模型的算法，节省能耗，是未来AI硬件的发展趋势。</p><p>25:32存算一体芯片可以应用在智能家居、智能音箱等场景中。</p><p>26:31安克创新正在研发存算一体芯片，并已经取得了一些成果。</p><h3id="算法和硬件之间的关系以及未来可能的发展趋势同时探讨了人工智能可能带来的影响">算法和硬件之间的关系，以及未来可能的发展趋势，同时探讨了人工智能可能带来的影响。</h3><p>26:44下一代算法：下一代算法可能会是一种一边学习一边进化的算法。</p>]]></content>
    
    
    <categories>
      
      <category>B站</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>大模型</tag>
      
      <tag>视频分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一首歌的时间部署本地Llama3大模型</title>
    <link href="/%E4%B8%80%E9%A6%96%E6%AD%8C%E7%9A%84%E6%97%B6%E9%97%B4-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%93%E5%B1%9Ellama3%E5%A4%A7%E6%A8%A1%E5%9E%8B.html"/>
    <url>/%E4%B8%80%E9%A6%96%E6%AD%8C%E7%9A%84%E6%97%B6%E9%97%B4-%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%93%E5%B1%9Ellama3%E5%A4%A7%E6%A8%A1%E5%9E%8B.html</url>
    
    <content type="html"><![CDATA[<p>LLaMA3真的是相当相当炸裂啊！远超过去的体验！看数据Llama3-8B超过Mistra-7BMMLU10分；70B超过Claude3Sonet3分。这是一个惊人的成绩，一个开源模型超过闭源模型这样多。我只能说Meta是真正的OpenAI。自从它从Meta这个邪路上转正后，在OpenAI的路上一骑绝尘了！不废话，动手来给自己的电脑部署下吧。 <span id="more"></span></p><h2 id="有什么硬件要求"><strong>有什么硬件要求</strong></h2><p>N卡独占，起步4G显存，建议8G＋。纯CPU也能跑，如果你不嫌慢的话。</p><h2 id="安装lm-studio"><strong>1. 安装LM studio</strong></h2><p>就这个软件(<a href="https://lmstudio.ai/">LM Studio - Discover,download, and run local LLMs</a>)</p><figure><imgsrc="/images/本地部署Llama3大模型/v2-3a61b06246c57b88fcd83f17062c10df_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>安装成功，打开后应该出现如下界面</p><figure><img src="/images/本地部署Llama3大模型/image-20240514080559847.png"alt="image-20240514080559847" /><figcaption aria-hidden="true">image-20240514080559847</figcaption></figure><h2 id="选择llama3-8b模型"><strong>2. 选择llama3-8B模型</strong></h2><p>我们直接搜索llama 3-8B，找到该模型</p><figure><img src="/images/本地部署Llama3大模型/image-20240514081038674.png"alt="image-20240514081038674" /><figcaption aria-hidden="true">image-20240514081038674</figcaption></figure><p>当然我们也可以选择其他模型，模型选择的重要因素是大小，也就是参数量。模型参数量一般写在名字上，比如Dolphin 2.6 Mistral 7b – DPO Laser就是7B大小，也就是70亿参数。根据自己的电脑内存和显存容量选（CPU运行就看内存，GPU运行就看显存，混合运行就两个加起来），我电脑是8G显存，用的7B模型。</p><p>然后就是模型指标，现在huggingface上有成百上千个LLM，可以根据benchmark的成绩选，排名网页在此：<ahref="https://link.zhihu.com/?target=https%3A//huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">OpenLLM Leaderboard - a Hugging Face Space by HuggingFaceH4</a> 。</p><p>还有就是模型特性，比如是否经过审查，适合于什么类型的工作等。</p><h2 id="下载gguf文件"><strong>3. 下载gguf文件</strong></h2><h3 id="在lm-studio内部下载需要配置网络"><strong>1. 在LMStudio内部下载，需要配置网络</strong></h3><p>如果有国际互联网连接就可以直接下载。如果没有见下一步。</p><h3 id="在huggingface下载并转移到lm-studio中"><strong>2.在huggingface下载并转移到LM Studio中</strong></h3><h3 id="下载"><strong>1. 下载</strong></h3><p>手动将网址复制到浏览器下载。</p><figure><img src="/images/本地部署Llama3大模型/image-20240514081632465.png"alt="image-20240514081632465" /><figcaption aria-hidden="true">image-20240514081632465</figcaption></figure><h3 id="移动下载的gguf文件到lm-studio识别的位置"><strong>2.移动下载的gguf文件到LM studio识别的位置</strong></h3><figure><img src="/images/本地部署Llama3大模型/image-20240514081756888.png"alt="image-20240514081756888" /><figcaption aria-hidden="true">image-20240514081756888</figcaption></figure><p>打开My models,找到gguf文件位置，然后在系统文件管理器中管理好你下载的gguf文件路径，格式为models/A/B/xxx.gguf。再重启LMstudio就能看到它。</p><h2 id="运行"><strong>4. 运行</strong></h2><h3 id="cpu运行"><strong>1.CPU运行</strong></h3><p>同GPU运行，但不用改settings 中的 GPU 参数。</p><h3 id="gpu运行"><strong>2.GPU运行</strong></h3><figure><img src="/images/本地部署Llama3大模型/image-20240514082144052.png"alt="image-20240514082144052" /><figcaption aria-hidden="true">image-20240514082144052</figcaption></figure><p>然后点击窗口上方的Select a model toload，加载上一步下载的模型就可以了。任务管理器中可以监视显存占用。</p><p>如果成功加载到显卡，就可以在下方与其对话了。</p><figure><img src="/images/本地部署Llama3大模型/image-20240514082345176.png"alt="image-20240514082345176" /><figcaption aria-hidden="true">image-20240514082345176</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>categories</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>项目部署</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>院士讲人工智能与智能计算的发展</title>
    <link href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%9A%84%E5%8F%91%E5%B1%95-%E5%A5%BD%E6%96%87%E5%88%86%E4%BA%AB.html"/>
    <url>/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%9A%84%E5%8F%91%E5%B1%95-%E5%A5%BD%E6%96%87%E5%88%86%E4%BA%AB.html</url>
    
    <content type="html"><![CDATA[<h1 id="人工智能与智能计算的发展">人工智能与智能计算的发展</h1><p>这是孙凝晖院士给正国级、副国级讲课的万字长稿,全面深入地梳理了人工智能行业的发展情况,行文高屋建瓴,见微知著,读完收获良多,在此与诸位分享。</p><span id="more"></span><p>人工智能领域近年来正在迎来一场由生成式人工智能大模型引领的爆发式发展。2022年11月30日，OpenAI公司推出一款人工智能对话聊天机器人ChatGPT，其出色的自然语言生成能力引起了全世界范围的广泛关注，2个月突破1亿用户，国内外随即掀起了一场大模型浪潮，Gemini、文心一言、Copilot、LLaMA、SAM、SORA等各种大模型如雨后春笋般涌现，2022年也被誉为大模型元年。</p><p>当前信息时代正加快进入智能计算的发展阶段，人工智能技术上的突破层出不穷，逐渐深入地赋能千行百业，推动人工智能与数据要素成为新质生产力的典型代表。习近平总书记指出，把新一代人工智能作为推动科技跨越发展、产业优化升级、生产力整体跃升的驱动力量，努力实现高质量发展。党的十八大以来，以习近平同志为核心的党中央高度重视智能经济发展，促进人工智能和实体经济深度融合，为高质量发展注入强劲动力。</p><h3 id="一计算技术发展简介"><strong>一、计算技术发展简介</strong></h3><p>计算技术的发展历史大致可分为四个阶段，算盘的出现标志着人类进入第一代——机械计算时代，第二代——电子计算的标志是出现电子器件与电子计算机，互联网的出现使我们进入第三代——网络计算，当前人类社会正在进入第四阶段——智能计算。</p><p>早期的计算装置是手动辅助计算装置和半自动计算装置，人类计算工具的历史是从公元1200年的中国算盘开始，随后出现了纳皮尔筹（1612年）和滚轮式加法器（1642年），到1672年第一台自动完成四则运算的计算装置——步进计算器诞生了。</p><p>机械计算时期已经出现了现代计算机的一些基本概念。查尔斯∙巴贝奇（CharlesBabbage）提出了差分机（1822年）与分析机（1834年）的设计构想，支持自动机械计算。这一时期，编程与程序的概念基本形成，编程的概念起源于雅卡尔提花机，通过打孔卡片控制印花图案，最终演变为通过计算指令的形式来存储所有数学计算步骤；人类历史的第一个程序员是诗人拜伦之女艾达（Ada），她为巴贝奇差分机编写了一组求解伯努利数列的计算指令，这套指令也是人类历史上第一套计算机算法程序，它将硬件和软件分离，第一次出现程序的概念。</p><p>直到在二十世纪上半叶，出现了布尔代数(数学)、图灵机(计算模型)、冯诺依曼体系结构(架构)、晶体管(器件)这四个现代计算技术的科学基础。其中，布尔代数用来描述程序和硬件如CPU的底层逻辑；图灵机是一种通用的计算模型，将复杂任务转化为自动计算、不需人工干预的自动化过程；冯诺依曼体系结构提出了构造计算机的三个基本原则：采用二进制逻辑、程序存储执行、以及计算机由运算器、控制器、存储器、输入设备、输出设备这五个基本单元组成；晶体管是构成基本的逻辑电路和存储电路的半导体器件，是建造现代计算机之塔的“砖块”。基于以上科学基础，计算技术得以高速发展，形成规模庞大的产业。</p><p>从1946年世界上第一台电子计算机ENIAC诞生到二十一世纪的今天，已经形成了五类成功的平台型计算系统。当前各领域各种类型的应用，都可以由这五类平台型计算装置支撑。<strong>第一类</strong>是高性能计算平台，解决了国家核心部门的科学与工程计算问题；<strong>第二类</strong>是企业计算平台，又称服务器，用于企业级的数据管理、事务处理，当前像百度、阿里和腾讯这些互联网公司的计算平台都属于这一类；<strong>第三类</strong>是个人电脑平台，以桌面应用的形式出现，人们通过桌面应用与个人电脑交互；<strong>第四类</strong>是智能手机，主要特点是移动便携，手机通过网络连接数据中心，以互联网应用为主，它们分布式地部署在数据中心和手机终端；<strong>第五类</strong>是嵌入式计算机，嵌入到工业装备和军事设备，通过实时的控制，保障在确定时间内完成特定任务。这五类装置几乎覆盖了我们信息社会的方方面面，长期以来人们追求的以智能计算应用为中心的第六类平台型计算系统尚未形成。</p><h4id="现代计算技术的发展大致可以划分为三个时代"><strong>现代计算技术的发展大致可以划分为三个时代。</strong></h4><h4id="it1.0又称电子计算时代1950-1970"><strong>IT1.0又称电子计算时代（1950-1970）</strong></h4><p>基本特征是以“机”为中心。计算技术的基本架构形成，随着集成电路工艺的进步，基本计算单元的尺度快速微缩，晶体管密度、计算性能和可靠性不断提升，计算机在科学工程计算、企业数据处理中得到了广泛应用。</p><h4id="it2.0又称网络计算时代1980-2020"><strong>IT2.0又称网络计算时代（1980-2020）</strong></h4><p>以“人”为中心。互联网将人使用的终端与后台的数据中心连接，互联网应用通过智能终端与人进行交互。以亚马逊等为代表的互联网公司提出了云计算的思想，将后台的算力封装成一个公共服务租借给第三方用户，形成了云计算与大数据产业。</p><h4id="it3.0又称智能计算时代"><strong>IT3.0又称智能计算时代</strong></h4><p>始于2020年，与IT2.0相比增加了“物”的概念，即物理世界的各种端侧设备，被数字化、网络化和智能化，实现“人-机-物”三元融合。智能计算时代，除了互联网以外，还有数据基础设施，支撑各类终端通过端边云实现万物互联，终端、物端、边缘、云都嵌入AI，提供与ChatGPT类似的大模型智能服务，最终实现有计算的地方就有AI智能。智能计算带来了巨量的数据、人工智能算法的突破和对算力的爆发性需求。</p><h3 id="二智能计算发展简介"><strong>二、智能计算发展简介</strong></h3><p>智能计算包括人工智能技术与它的计算载体，大致历经了四个阶段，分别为通用计算装置、逻辑推理专家系统、深度学习计算系统、大模型计算系统。</p><p><strong>智能计算的起点是通用自动计算装置（1946年）。</strong></p><p>艾伦·图灵（Alan Turing）和冯·诺依曼（John vonNeumann）等科学家，一开始都希望能够模拟人脑处理知识的过程，发明像人脑一样思考的机器，虽未能实现，但却解决了计算的自动化问题。通用自动计算装置的出现，也推动了1956年人工智能（AI）概念的诞生，此后所有人工智能技术的发展都是建立在新一代计算设备与更强的计算能力之上的。</p><p><strong>智能计算发展的第二阶段是逻辑推理专家系统（1990年）。</strong></p><p>E.A.费根鲍姆（Edward AlbertFeigenbaum）等符号智能学派的科学家以逻辑和推理能力自动化为主要目标，提出了能够将知识符号进行逻辑推理的专家系统。人的先验知识以知识符号的形式进入计算机，使计算机能够在特定领域辅助人类进行一定的逻辑判断和决策，但专家系统严重依赖于手工生成的知识库或规则库。这类专家系统的典型代表是日本的五代机和我国863计划支持的306智能计算机主题，日本在逻辑专家系统中采取专用计算平台和Prolog这样的知识推理语言完成应用级推理任务；我国采取了与日本不同的技术路线，以通用计算平台为基础，将智能任务变成人工智能算法，将硬件和系统软件都接入通用计算平台，并催生了曙光、汉王、科大讯飞等一批骨干企业。</p><p>符号计算系统的局限性在于其爆炸的计算时空复杂度，即符号计算系统只能解决线性增长问题，对于高维复杂空间问题是无法求解的，从而限制了能够处理问题的大小。同时因为符号计算系统是基于知识规则建立的，我们又无法对所有的常识用穷举法来进行枚举，它的应用范围就受到了很大的限制。随着第二次AI寒冬的到来，第一代智能计算机逐渐退出历史舞台。</p><p><strong>直到2014年左右，智能计算进阶到第三阶段——深度学习计算系统。</strong></p><p>以杰弗里·辛顿（GeoffreyHinton）等为代表的连接智能学派，以学习能力自动化为目标，发明了深度学习等新AI算法。通过深度神经元网络的自动学习，大幅提升了模型统计归纳的能力，在模式识别①等应用效果上取得了巨大突破，某些场景的识别精度甚至超越了人类。以人脸识别为例，整个神经网络的训练过程相当于一个网络参数调整的过程，将大量的经过标注的人脸图片数据输入神经网络，然后进行网络间参数调整，让神经网络输出的结果的概率无限逼近真实结果。神经网络输出真实情况的概率越大，参数就越大，从而将知识和规则编码到网络参数中，这样只要数据足够多，就可以对各种大量的常识进行学习，通用性得到极大的提升。连接智能的应用更加广泛，包括语音识别、人脸识别、自动驾驶等。在计算载体方面，中国科学院计算技术研究所2013年提出了国际首个深度学习处理器架构，国际知名的硬件厂商英伟达（NVIDIA）持续发布了多款性能领先的通用GPU芯片，都是深度学习计算系统的典型代表。</p><p><strong>智能计算发展的第四阶段是大模型计算系统（2020年）。</strong></p><p>在人工智能大模型技术的推动下，智能计算迈向新的高度。2020年，AI从“小模型+判别式”转向“大模型+生成式”，从传统的人脸识别、目标检测、文本分类，升级到如今的文本生成、3D数字人生成、图像生成、语音生成、视频生成。大语言模型在对话系统领域的一个典型应用是OpenAI公司的ChatGPT，它采用预训练基座大语言模型GPT-3，引入3000亿单词的训练语料，相当于互联网上所有英语文字的总和。其基本原理是：通过给它一个输入，让它预测下一个单词来训练模型，通过大量训练提升预测精确度，最终达到向它询问一个问题，大模型产生一个答案，与人即时对话。在基座大模型的基础上，再给它一些提示词进行有监督的指令微调，通过人类的&lt;指令，回复&gt;对逐渐让模型学会如何与人进行多轮对话；最后，通过人为设计和自动生成的奖励函数来进行强化学习迭代，逐步实现大模型与人类价值观的对齐。</p><blockquote><p>大模型的特点是以“大”取胜，其中有三层含义</p><p><strong>（1）参数大</strong>，GPT-3就有1700亿个参数；</p><p><strong>（2）训练数据大</strong>，ChatGPT大约用了3000亿个单词，570GB训练数据；</p><p><strong>（3）算力需求大</strong>，GPT-3大约用了上万块V100GPU进行训练。为满足大模型对智能算力爆炸式增加的需求，国内外都在大规模建设耗资巨大的新型智算中心，英伟达公司也推出了采用256个H100芯片，150TB海量GPU内存等构成的大模型智能计算系统。</p></blockquote><h3id="三大模型的出现带来了三个变革">三、<strong>大模型的出现带来了三个变革</strong></h3><p><strong>一是技术上的规模定律</strong>（ScalingLaw），即很多AI模型的精度在参数规模超过某个阈值后模型能力快速提升，其原因在科学界还不是非常清楚，有很大的争议。AI模型的性能与模型参数规模、数据集大小、算力总量三个变量成“对数线性关系”，因此可以通过增大模型的规模来不断提高模型的性能。目前最前沿的大模型GPT-4参数量已经达到了万亿到十万亿量级，并且仍在不断增长中；</p><p><strong>二是产业上算力需求爆炸式增长</strong>，千亿参数规模大模型的训练通常需要在数千乃至数万GPU卡上训练2-3个月时间，急剧增加的算力需求带动相关算力企业超高速发展，英伟达的市值接近两万亿美元，对于芯片企业以前从来没有发生过；</p><p><strong>三是社会上冲击劳动力市场</strong>，北京大学国家发展研究院与智联招聘联合发布的《AI大模型对我国劳动力市场潜在影响研究》报告指出，受影响最大的20个职业中财会、销售、文书位于前列，需要与人打交道并提供服务的体力劳动型工作，如人力资源、行政、后勤等反而相对更安全。</p><h4id="人工智能的技术前沿将朝着以下四个方向发展"><strong>人工智能的技术前沿将朝着以下四个方向发展。</strong></h4><p><strong>第一个前沿方向为多模态大模型。</strong>从人类视角出发，人类智能是天然多模态的，人拥有眼、耳、鼻、舌、身、嘴(语言)，从AI视角出发，视觉，听觉等也都可以建模为token②的序列，可采取与大语言模型相同的方法进行学习，并进一步与语言中的语义进行对齐，实现多模态对齐的智能能力。</p><p><strong>第二个前沿方向为视频生成大模型。</strong>OpenAI于2024年2月15日发布文生视频模型SORA，将视频生成时长从几秒钟大幅提升到一分钟，且在分辨率、画面真实度、时序一致性等方面都有显著提升。SORA的最大意义是它具备了世界模型的基本特征，即人类观察世界并进一步预测世界的能力。世界模型是建立在理解世界的基本物理常识（如，水往低处流等）之上，然后观察并预测下一秒将要发生什么事件。虽然SORA要成为世界模型仍然存在很多问题，但可以认为SORA学会了画面想象力和分钟级未来预测能力，这是世界模型的基础特征。</p><p><strong>第三个前沿方向为具身智能。</strong>具身智能指有身体并支持与物理世界进行交互的智能体，如机器人、无人车等，通过多模态大模型处理多种传感数据输入，由大模型生成运动指令对智能体进行驱动，替代传统基于规则或者数学公式的运动驱动方式，实现虚拟和现实的深度融合。因此，具有具身智能的机器人，可以聚集人工智能的三大流派：以神经网络为代表的连接主义，以知识工程为代表的符号主义和控制论相关的行为主义，三大流派可以同时作用在一个智能体，这预期会带来新的技术突破。</p><p><strong>第四个前沿方向是AI4R(AI forResearch)成为科学发现与技术发明的主要范式。</strong>当前科学发现主要依赖于实验和人脑智慧，由人类进行大胆猜想、小心求证，信息技术无论是计算和数据，都只是起到一些辅助和验证的作用。相较于人类，人工智能在记忆力、高维复杂、全视野、推理深度、猜想等方面具有较大优势，是否能以AI为主进行一些科学发现和技术发明，大幅提升人类科学发现的效率，比如主动发现物理学规律、预测蛋白质结构、设计高性能芯片、高效合成新药等。因为人工智能大模型具有全量数据，具备上帝视角，通过深度学习的能力，可以比人向前看更多步数，如能实现从推断(inference)到推理(reasoning)的跃升，人工智能模型就有潜力具备爱因斯坦一样的想象力和科学猜想能力，极大提升人类科学发现的效率，打破人类的认知边界。这才是真正的颠覆所在。</p><p><strong>最后，通用人工智能③（Artificial GeneralIntelligence，简称AGI）是一个极具挑战的话题，极具争论性。</strong>曾经有一个哲学家和一个神经科学家打赌：25年后（即2023年）科研人员是否能够揭示大脑如何实现意识？当时关于意识有两个流派，一个叫集成信息理论，一个叫全局网络工作空间理论，前者认为意识是由大脑中特定类型神经元连接形成的“结构”，后者指出意识是当信息通过互连网络传播到大脑区域时产生的。2023年，人们通过六个独立实验室进行了对抗性实验，结果与两种理论均不完全匹配，哲学家赢了，神经科学家输了。通过这一场赌约，可以看出人们总是希望人工智能能够了解人类的认知和大脑的奥秘。从物理学的视角看，物理学是对宏观世界有了透彻理解后，从量子物理起步开启了对微观世界的理解。智能世界与物理世界一样，都是具有巨大复杂度的研究对象，AI大模型仍然是通过数据驱动等研究宏观世界的方法，提高机器的智能水平，对智能宏观世界理解并不够，直接到神经系统微观世界寻找答案是困难的。人工智能自诞生以来，一直承载着人类关于智能与意识的种种梦想与幻想，也激励着人们不断探索。</p><h3id="四人工智能的安全风险">四、<strong>人工智能的安全风险</strong></h3><p>人工智能的发展促进了当今世界科技进步的同时，也带来了很多安全风险，要从技术与法规两方面加以应对。</p><h4id="首先是互联网虚假信息泛滥这里列举若干场景"><strong>首先是互联网虚假信息泛滥。</strong>这里列举若干场景：</h4><p><strong>一是数字分身。</strong>AI Yoon是首个使用 DeepFake技术合成的官方“候选人”，这个数字人以韩国国民力量党候选人尹锡悦（YoonSuk-yeol）为原型，借助尹锡悦 20小时的音频和视频片段、以及其专门为研究人员录制的 3000多个句子，由当地一家 DeepFake 技术公司创建了虚拟形象 AIYoon，并在网络上迅速走红。实际上 AI Yoon表达的内容是由竞选团队撰写的，而不是候选人本人。</p><p><strong>二是伪造视频，</strong>尤其是伪造领导人视频引起国际争端，扰乱选举秩序，或引起突发舆情事件，如伪造尼克松宣布第一次登月失败，伪造乌克兰总统泽连斯基宣布“投降”的信息，这些行为导致新闻媒体行业的社会信任衰退。</p><p><strong>三是伪造新闻</strong>，主要通过虚假新闻自动生成牟取非法利益，使用ChatGPT生成热点新闻，赚取流量，截至2023年6月30日全球生成伪造新闻网站已达277个，严重扰乱社会秩序。</p><p><strong>四是换脸变声，用于诈骗。</strong>如由于AI语音模仿了企业高管的声音，一家香港国际企业因此被骗3500万美元。</p><p><strong>五是生成不雅图片，特别是针对公众人物。</strong>如影视明星的色情视频制作，造成不良社会影响。因此，迫切需要发展互联网虚假信息的伪造检测技术。</p><h4id="其次ai大模型面临严重可信问题"><strong>其次，AI大模型面临严重可信问题。</strong></h4><p>这些问题包括：（1）“一本正经胡说八道”的事实性错误；（2）以西方价值观叙事，输出政治偏见和错误言论；（3）易被诱导，输出错误知识和有害内容；（4）数据安全问题加重，大模型成为重要敏感数据的诱捕器，ChatGPT将用户输入纳入训练数据库，用于改善ChatGPT，美方能够利用大模型获得公开渠道覆盖不到的中文语料，掌握我们自己都可能不掌握的“中国知识”。因此，迫切需要发展大模型安全监管技术与自己的可信大模型。</p><h4id="除了技术手段外人工智能安全保障需要相关立法工作"><strong>除了技术手段外，人工智能安全保障需要相关立法工作。</strong></h4><p>2021年科技部发布《新一代人工智能伦理规范》，2022年8月，全国信息安全标准化技术委员会发布《信息安全技术机器学习算法安全评估规范》，2022-2023年，中央网信办先后发布《互联网信息服务算法推荐管理规定》《互联网信息服务深度合成管理规定》《生成式人工智能服务管理办法》等。欧美国家也先后出台法规，2018年5月25日，欧盟出台《通用数据保护条例》，2022年10月4日，美国发布《人工智能权利法案蓝图》，2024年3月13日，欧洲议会通过了欧盟《人工智能法案》。</p><p>我国应加快推进《人工智能法》出台，构建人工智能治理体系，确保人工智能的发展和应用遵循人类共同价值观，促进人机和谐友好；创造有利于人工智能技术研究、开发、应用的政策环境；建立合理披露机制和审计评估机制，理解人工智能机制原理和决策过程；明确人工智能系统的安全责任和问责机制，可追溯责任主体并补救；推动形成公平合理、开放包容的国际人工智能治理规则。</p><h3id="五中国智能计算发展困境">五、<strong>中国智能计算发展困境</strong></h3><p>人工智能技术与智能计算产业处于中美科技竞争的焦点，我国在过去几年虽然取得了很大的成绩，但依然面临诸多发展困境，特别是由美国的科技打压政策带来的困难。</p><h4id="困境一为美国在ai核心能力上长期处于领先地位中国处于跟踪模式"><strong>困境一</strong>为美国在AI核心能力上长期处于领先地位，中国处于跟踪模式。</h4><p>中国在AI高端人才数量、AI基础算法创新、AI底座大模型能力（大语言模型、文生图模型、文生视频模型）、底座大模型训练数据、底座大模型训练算力等，都与美国存在一定的差距，并且这种差距还将持续很长一段时间。</p><h4id="困境二为高端算力产品禁售高端芯片工艺长期被卡"><strong>困境二</strong>为高端算力产品禁售，高端芯片工艺长期被卡。</h4><p>A100，H100，B200等高端智算芯片对华禁售。华为、龙芯、寒武纪、曙光、海光等企业都进入实体清单，它们芯片制造的先进工艺④受限，国内可满足规模量产的工艺节点落后国际先进水平2-3代，核心算力芯片的性能落后国际先进水平2-3代。</p><h4id="困境三为国内智能计算生态孱弱ai开发框架渗透率不足"><strong>困境三</strong>为国内智能计算生态孱弱，AI开发框架渗透率不足。</h4><p>英伟达CUDA⑤(Compute Unified Device Architecture,通用计算设备架构)生态完备，已形成了事实上的垄断。国内生态孱弱，具体表现在：一是研发人员不足，英伟达CUDA生态有近2万人开发，是国内所有智能芯片公司人员总和的20倍；二是开发工具不足，CUDA有550个SDK(SoftwareDevelopment Kit,软件开发工具包)，是国内相关企业的上百倍；三是资金投入不足，英伟达每年投入50亿美元，是国内相关公司的几十倍；四是AI开发框架TensorFlow占据工业类市场，PyTorch占据研究类市场，百度飞桨等国产AI开发框架的开发人员只有国外框架的1/10。更为严重的是国内企业之间山头林立，无法形成合力，从智能应用、开发框架、系统软件、智能芯片，虽然每层都有相关产品，但各层之间没有深度适配，无法形成一个有竞争力的技术体系。</p><h4id="困境四为ai应用于行业时成本门槛居高不下"><strong>困境四</strong>为AI应用于行业时成本、门槛居高不下。</h4><p>当前我国AI应用主要集中在互联网行业和一些国防领域。AI技术推广应用于各行各业时，特别是从互联网行业迁移到非互联网行业，需要进行大量的定制工作，迁移难度大，单次使用成本高。最后，我国在AI领域的人才数量与实际需求相比也明显不足。</p><h3id="六中国如何发展智能计算的道路选择">六、<strong>中国如何发展智能计算的道路选择</strong></h3><p>人工智能发展的道路选择对我国至关重要，关系到发展的可持续性与最终的国际竞争格局。当前人工智能的使用成本十分高昂，微软Copilot套件要支付每月10美元的使用费用，ChatGPT每天消耗50万千瓦时的电力，英伟达B200芯片价格高达3万美元以上。总体来说，我国应发展用得起、安全可信的人工智能技术，消除我国信息贫困人口、并造福“一带一路”国家；低门槛地赋能各行各业，让我国的优势产业保持竞争力，让相对落后的产业能够大幅地缩小差距。</p><h4id="选择一统一技术体系走闭源封闭还是开源开放的道路"><strong>选择一：统一技术体系走闭源封闭，还是开源开放的道路？</strong></h4><p>支撑智能计算产业的是一个相互紧耦合的技术体系，即由一系列技术标准和知识产权将材料、器件、工艺、芯片、整机、系统软件、应用软件等密切联系在一起的技术整体。我国发展智能计算技术体系存在三条道路：</p><p><strong>一是追赶兼容美国主导的A体系</strong>。我国大多数互联网企业走的是GPGPU/CUDA兼容道路，很多芯片领域的创业企业在生态构建上也是尽量与CUDA兼容，这条道路较为现实。由于在算力方面美国对我国工艺和芯片带宽的限制，在算法方面国内生态林立很难形成统一，生态成熟度严重受限，在数据方面中文高质量数据匮乏，这些因素会使得追赶者与领先者的差距很难缩小，一些时候还会进一步拉大。　　</p><p><strong>二是构建专用封闭的B体系。</strong>在军事、气象、司法等专用领域构建企业封闭生态，基于国产成熟工艺生产芯片，相对于底座大模型更加关注特定领域垂直类大模型，训练大模型更多采用领域专有高质量数据等。这条道路易于形成完整可控的技术体系与生态，我国一些大型骨干企业走的是这条道路，它的缺点是封闭，无法凝聚国内大多数力量，也很难实现全球化。　　</p><p><strong>三是全球共建开源开放的C体系。</strong>用开源打破生态垄断，降低企业拥有核心技术的门槛，让每个企业都能低成本地做自己的芯片，形成智能芯片的汪洋大海，满足无处不在的智能需求。用开放形成统一的技术体系，我国企业与全球化力量联合起来共建基于国际标准的统一智能计算软件栈。形成企业竞争前共享机制，共享高质量数据库，共享开源通用底座大模型。对于全球开源生态，我国企业在互联网时代收益良多，我国更多的是使用者，是参与者，在智能时代我国企业在RISC-V⑥+AI开源技术体系上应更多地成为主力贡献者，成为全球化开放共享的主导力量。</p><h4id="选择二拼算法模型还是拼新型基础设施"><strong>选择二：拼算法模型，还是拼新型基础设施？</strong>　　</h4><p>人工智能技术要赋能各行各业，具有典型的长尾效应⑦。我国80%的中小微企业，需要的是低门槛、低价格的智能服务。因此，我国智能计算产业必须建立在新的数据空间基础设施之上，其中关键是我国应率先实现智能要素即数据、算力、算法的全面基础设施化。这项工作可比肩二十世纪初美国信息高速公路计划（即信息基础设施建设）对互联网产业的历史作用。　　</p><p>信息社会最核心的生产力是网络空间(Cyberspace)。网络空间的演进过程是：从机器一元连接构成的计算空间，演进到人机信息二元连接构成的信息空间，再演进到人机物数据三元连接构成的数据空间。从数据空间看，人工智能的本质是数据的百炼成钢，大模型就是对互联网全量数据进行深度加工后的产物。在数字化时代，在互联网上传输的是信息流，是算力对数据进行粗加工后的结构化抽象；在智能时代，在互联网上传输的是智能流，是算力对数据进行深度加工与精炼后的模型化抽象。智能计算的一个核心特征就是用数值计算、数据分析、人工智能等算法，在算力池中加工海量数据件，得到智能模型，再嵌入到信息世界、物理世界的各个过程中。　　</p><p>我国政府已经前瞻性地提前布局了新型基础设施，在世界各国竞争中抢占了先机。</p><p><strong>首先，数据已成为国家战略信息资源。</strong>数据具有资源要素与价值加工两重属性，数据的资源要素属性包括生产、获取、传输、汇聚、流通、交易、权属、资产、安全等各个环节，我国应继续加大力度建设国家数据枢纽与数据流通基础设施。　　</p><p><strong>其次，AI大模型就是数据空间的一类算法基础设施。</strong>以通用大模型为基座，构建大模型研发与应用的基础设施，支撑广大企业研发领域专用大模型，服务于机器人、无人驾驶、可穿戴设备、智能家居、智能安防等行业，覆盖长尾应用。　　</p><p><strong>最后，全国一体化算力网建设在推动算力的基础设施化上发挥了先导作用。</strong>算力基础设施化的中国方案，应在大幅度降低算力使用成本和使用门槛的同时，为最广范围覆盖人群提供高通量、高品质的智能服务。算力基础设施的中国方案需要具备“两低一高”，即在供给侧，大幅度降低算力器件、算力设备、网络连接、数据获取、算法模型调用、电力消耗、运营维护、开发部署的总成本，让广大中小企业都消费得起高品质的算力服务，有积极性开发算力网应用；在消费侧，大幅度降低广大用户的算力使用门槛，面向大众的公共服务必须做到易获取、易使用，像水电一样即开即用，像编写网页一样轻松定制算力服务，开发算力网应用。在服务效率侧，中国的算力服务要实现低熵高通量，其中高通量是指在实现高并发⑧度服务的同时，端到端服务的响应时间可满足率高；低熵是指在高并发负载中出现资源无序竞争的情况下，保障系统通量不急剧下降。保障“算得多”对中国尤其重要。　　</p><h4id="选择三ai着重赋能虚拟经济还是发力实体经济"><strong>选择三：AI+着重赋能虚拟经济，还是发力实体经济？</strong>　　</h4><p>“AI+”的成效是人工智能价值的试金石。次贷危机后，美国制造业增加值占GDP的比重从1950年的28%降低为2021年的11%，美国制造业在全行业就业人数占比从1979年的35%降低为2022年的8%，可见美国更倾向于回报率更高的虚拟经济，轻视投资成本高且经济回报率低的实体经济。中国倾向于实体经济与虚拟经济同步发展，更加重视发展装备制造、新能源汽车、光伏发电、锂电池、高铁、5G等实体经济。　　</p><p>相应地美国AI主要应用于虚拟经济和IT基础工具，AI技术也是“脱实向虚”，自2007年以来硅谷不断炒作虚拟现实（VirtualReality，VR）、元宇宙、区块链、Web3.0、深度学习、AI大模型等，是这个趋势的反映。　　</p><p>我国的优势在实体经济，制造业全球产业门类最齐全，体系最完整，特点是场景多、私有数据多。我国应精选若干行业加大投入，形成可低门槛全行业推广的范式，如选择装备制造业作为延续优势代表性行业，选择医药业作为快速缩短差距的代表性行业。赋能实体经济的技术难点是AI算法与物理机理的融合。</p><p>人工智能技术成功的关键是能否让一个行业或一个产品的成本大幅下降，从而将用户数与产业规模扩大10倍，产生类似于蒸汽机对于纺织业，智能手机对于互联网业的变革效果。</p><p>我国应走出适合自己的人工智能赋能实体经济的高质量发展道路。</p><p><strong>注释：</strong>　　</p><p>①模式识别是指用计算的方法根据样本的特征将样本划分到一定的类别中去，是通过计算机用数学方法来研究模式的自动处理和判读，把环境与客体统称为“模式”。以图像处理与计算机视觉、语音语言信息处理、脑网络组、类脑智能等为主要研究方向。　　</p><p>②Token可翻译为词元，指自然语言处理过程中用来表示单词或短语的符号。token可以是单个字符,也可以是多个字符组成的序列。　　</p><p>③通用人工智能是指拥有与人类相当甚至超过人类智能的人工智能类型。通用人工智能不仅能像人类一样进行感知、理解、学习和推理等基础思维能力，还能在不同领域灵活应用、快速学习和创造性思考。通用人工智能的研究目标是寻求统一的理论框架来解释各种智能现象。　　</p><p>④芯片制造工艺指制造CPU或GPU的制程，即晶体管门电路的尺寸，单位为纳米，目前国际上实现量产的最先进工艺以台积电的3nm为代表。更先进的制造工艺可以使CPU与GPU内部集成更多的晶体管，使处理器具有更多的功能以及更高的性能，面积更小，成本更低等。　　</p><p>⑤CUDA是英伟达公司设计研发一种并行计算平台和编程模型，包含了CUDA指令集架构以及GPU内部的并行计算引擎。开发人员可以使用C语言来为CUDA架构编写程序，所编写出的程序可以在支持CUDA的处理器上以超高性能运行。　　</p><p>⑥RISC-V（发音为“risk-five”）是一个由美国加州大学伯克利分校发起的开放通用指令集架构，相比于其他付费指令集，RISC-V允许任何人免费地使用RISC-V指令集设计、制造和销售芯片和软件。　　</p><p>⑦长尾效应是指那些原来不受到重视的销量小但种类多的产品或服务由于总量巨大，累积起来的总收益超过主流产品的现象。在互联网领域，长尾效应尤为显著。　　</p><p>⑧高并发通常指通过设计保证系统能够同时并行处理很多请求。</p>]]></content>
    
    
    <categories>
      
      <category>阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>人工智能</tag>
      
      <tag>行业发展</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>xinference安装报错踩坑</title>
    <link href="/xinference%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%E5%8F%8A%E6%8A%A5%E9%94%99%E8%B8%A9%E5%9D%91.html"/>
    <url>/xinference%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97%E5%8F%8A%E6%8A%A5%E9%94%99%E8%B8%A9%E5%9D%91.html</url>
    
    <content type="html"><![CDATA[<p>xinference是一款流行度很高的本地模型部署框架，它可以非常方便地赋能本地RAG和Agent的构建，与ollama相比，它自带了webui管理界面，除了TEXT EMBEDDINGLLM之外，它还支持SPEECH2TEXT，TTS，RERANK模型的部署，可谓功能非常强大，但是美中不足的是，它的安装却一波三折，现整理下来供诸君避坑。</p><blockquote><p>建议在linux系统安装，win下推理存在问题</p></blockquote><h3 id="正常安装流程">正常安装流程</h3><h4id="安装xinference库实现模型推理">1.安装xinference库，实现模型推理。</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install &quot;xinference[all]&quot;<br></code></pre></td></tr></table></figure><h4 id="启动xinference">2.启动xinference</h4><p>在安装完相应的环境后，启动xinference以进行模型部署。</p><p>通过命令行执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">xinference-local --host 0.0.0.0 --port 9997<br></code></pre></td></tr></table></figure><p>来启动xinference，启动后访问：IP:9997 即可进入xinference主界面。</p><h3 id="报错及解决方法">报错及解决方法</h3><h4 id="问题1cython">问题1：cython</h4><blockquote><p>Python package installation error: missing Cython dependency</p></blockquote><p>解决：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install cython<br></code></pre></td></tr></table></figure><h4 id="问题2pynini">问题2：pynini</h4><blockquote><p>执行命令后：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> <span class="hljs-string">&quot;xinference[all]&quot;</span><br></code></pre></td></tr></table></figure><p>报错信息：ERROR: Failed to build installable wheels for somepyproject.toml based projects (pynini)</p></blockquote><p>解决：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda install -c conda-forge pynini=2.1.5<br></code></pre></td></tr></table></figure><h4 id="问题3nameerror">问题3:NameError</h4><blockquote><p>NameError: Field name "schema" shadows a BaseModel attribute; use adifferent field name with "alias='schema'".</p></blockquote><p>解决：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install openai==1.39.0<br></code></pre></td></tr></table></figure><h4 id="问题4runtimeerror">问题4：RuntimeError</h4><blockquote><p>RuntimeError: Cluster is not available after multiple attempts</p></blockquote><p>原因：xinference-local --host 0.0.0.0 --port9997中ip地址0.0.0.0无法使用，可能是windows的锅</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">xinference-local --host localhost --port 9997<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
      <tag>推理工具</tag>
      
      <tag>部署</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【B站】从零开始学习大语言模型-Lyi</title>
    <link href="/B%E7%AB%99_%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-Lyi.html"/>
    <url>/B%E7%AB%99_%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-Lyi.html</url>
    
    <content type="html"><![CDATA[<h1 id="从零开始学习大语言模型-lyi">从零开始学习大语言模型-Lyi</h1><p>林亦是我比较喜欢的一个UP，视频讲述了他对深度学习基本范式的回顾和梳理。主要介绍了神经网络模型的结构和训练过程，以及当前流行的大语言模型——基于神经网络的技术。视频指出，构建一个能力强、学习效率高的模型是影响学习效果的关键，也是深度学习研究的核心问题。整个视频围绕着数据和模型展开，梳理了深度学习的核心概念和基本流程。</p><span id="more"></span><iframe src="//player.bilibili.com/player.html?isOutside=true&amp;aid=1750586968&amp;bvid=BV1v4421w7pU&amp;cid=1441154247&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe><h3id="机器学习的概念和分类着重讲解了监督学习和无监督学习以及模型的重要性">机器学习的概念和分类,着重讲解了监督学习和无监督学习,以及模型的重要性。</h3><p>00:01机器学习概念与语言任务</p><p>02:01监督学习与无监督学习</p><p>04:00机器学习模型的构建和选择</p><h3id="模型的概念以及神经网络模型的运作原理包括感知机单元和多层神经网络模型">模型的概念,以及神经网络模型的运作原理,包括感知机单元和多层神经网络模型。</h3><p>04:26模型训练与神经网络结构</p><p>06:40感知机的原理和激活函数</p><p>07:45多层神经网络模型和信息归纳能力</p><h3id="神经网络中的函数导数偏导数损失函数和梯度下降等概念以及如何用反向传播算法优化权重值">神经网络中的函数、导数、偏导数、损失函数和梯度下降等概念,以及如何用反向传播算法优化权重值。</h3><p>08:15每个单元之间的连接是一个权重数值，这些数值可以通过反向传播算法进行优化。</p><p>09:27训练神经网络的流程：训练程序会为每个输入变量随机分配一个权重值，然后通过前向传播和梯度下降算法不断优化权重值，直到损失函数最小化。</p><p>11:08梯度下降算法：通过不断更新权重值，沿着梯度下降的方向最快达到最低损失函数值。</p><h3id="如何使用链式法则解决复杂函数的导数计算问题以及模型训练中的收敛和超参数设置">如何使用链式法则解决复杂函数的导数计算问题,以及模型训练中的收敛和超参数设置。</h3><p>12:22链式法则与模型更新</p><p>15:26深度学习中的残差网络</p><p>15:50梯度消失与跳过连接</p><h3id="残差网络的作用和意义以及机器学习中泛化能力的评估和重要性">残差网络的作用和意义,以及机器学习中泛化能力的评估和重要性。</h3><p>17:05模型遇到从未见过的数据时，能不能整明白。</p><p>19:16大模型的转变：从小型专用模型到大型通用模型的转变。</p><h3id="机器如何理解人类语言的基础知识并提到了接下来将进一步探讨这一话题">机器如何理解人类语言的基础知识,并提到了接下来将进一步探讨这一话题。</h3><p>19:45机器理解人类语言的基础知识</p><p>19:52视频结束及作者告别</p>]]></content>
    
    
    <categories>
      
      <category>B站</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>大模型</tag>
      
      <tag>视频分享</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何知道一个大模型是否可以在自己的显卡上运行呢？</title>
    <link href="/%E5%A6%82%E4%BD%95%E7%9F%A5%E9%81%93%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E5%9C%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E6%98%BE%E5%8D%A1%E4%B8%8A%E8%BF%90%E8%A1%8C%E5%91%A2%EF%BC%9F.html"/>
    <url>/%E5%A6%82%E4%BD%95%E7%9F%A5%E9%81%93%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E5%9C%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E6%98%BE%E5%8D%A1%E4%B8%8A%E8%BF%90%E8%A1%8C%E5%91%A2%EF%BC%9F.html</url>
    
    <content type="html"><![CDATA[<h4 id="经验评估">1.经验评估</h4><ul><li>推理显存估算：7B-float 是 28 GB，7B-BF16 是 14GB，7B-int8 是7GB；其他版本以此类推即可。</li><li>训练的参数类型，只能是 float / BF16</li><li>训练 所需显存 保守估算 是 同参数同类型llm 推理 的 4倍。<ul><li>例子：7B-float 训练 显存：28 * 4 = 112 GB</li></ul></li></ul><table><thead><tr class="header"><th>方法</th><th>bits</th><th>7B</th><th>13B</th><th>30B</th><th>65B</th><th>8*7B</th></tr></thead><tbody><tr class="odd"><td>全参数微调</td><td>16</td><td>160GB</td><td>320GB</td><td>600GB</td><td>1200GB</td><td>900GB</td></tr><tr class="even"><td>Freeze</td><td>16</td><td>20GB</td><td>40GB</td><td>120GB</td><td>240GB</td><td>200GB</td></tr><tr class="odd"><td>LoRA</td><td>16</td><td>16GB</td><td>32GB</td><td>80GB</td><td>160GB</td><td>120GB</td></tr><tr class="even"><td>QLoRA</td><td>8</td><td>10GB</td><td>16GB</td><td>40GB</td><td>80GB</td><td>80GB</td></tr><tr class="odd"><td>QLoRA</td><td>4</td><td>6GB</td><td>12GB</td><td>24GB</td><td>48GB</td><td>32GB</td></tr></tbody></table><h4 id="精确评估">2.精确评估</h4><h5 id="在线评估">2.1 在线评估</h5><p>accelerate estimate-memory 是 huggingface 的 accelerate开发库中提供的一个工具。可网页在线访问</p><p>https://huggingface.co/spaces/hf-accelerate/model-memory-usage选择相应模型进行评估</p><h5 id="本地评估">2.2 本地评估</h5><ul><li>安装 accelerate, transformers</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">pip install accelerate<br>pip install transformers<br></code></pre></td></tr></table></figure><ul><li>使用方法举例</li></ul><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs text"># 基本使用方法<br>accelerate estimate-memory mistralai/Mistral-7B-v0.1<br><br># 只显示指定的数据类型<br>accelerate estimate-memory mistralai/Mistral-7B-v0.1 --dtypes float16<br><br># 指定开发库(针对本地模型，Hub上存储的模型不需要指定)<br>accelerate estimate-memory mistralai/Mistral-7B-v0.1 --dtypes float32 float16 --library_name transformers<br><br># 设置 trust_remote_code=True<br>accelerate estimate-memory Qwen/Qwen1.5-7B #正常<br>accelerate estimate-memory Qwen/Qwen-7B #报错<br>accelerate estimate-memory Qwen/Qwen-7B --trust_remote_code #可以运行<br><br># 其他模型<br>accelerate estimate-memory google/gemma-7b<br>accelerate estimate-memory baichuan-inc/Baichuan2-7B-Base --trust_remote_code<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型</tag>
      
      <tag>部署</tag>
      
      <tag>模型训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM 合成数据生成完整指南</title>
    <link href="/%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97.html"/>
    <url>/%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE%E5%AE%9E%E8%B7%B5%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97.html</url>
    
    <content type="html"><![CDATA[<p>大型语言模型(LLM)是强大的工具，不仅可以生成类似人类的文本，还可以创建高质量的合成数据。这种能力正在改变我们进行AI开发的方式，特别是在现实世界数据稀缺、昂贵或隐私敏感的情况下。在本综合指南中，我们将探索LLM 驱动的合成数据生成，深入探讨其方法、应用和最佳实践。</p><figure><img src="/images/合成数据/image-20240812092339558.png"alt="image-20240812092339558" /><figcaption aria-hidden="true">image-20240812092339558</figcaption></figure><h2 id="使用-llm-进行合成数据生成简介">使用 LLM进行合成数据生成简介</h2><p><ahref="https://www.unite.ai/zh-CN/合成数据生成的创新为特定语言构建基础模型/">综合数据</a>使用 LLM 生成数据涉及利用这些先进的 AI模型来创建模拟真实世界数据的人工数据集。这种方法有几个优点：</p><ol type="1"><li><strong>成本效益</strong>：生成合成数据通常比收集和注释真实世界数据更便宜。</li><li><strong>隐私保护</strong>：可以创建合成数据而不暴露敏感信息。</li><li><strong>可扩展性</strong>：LLM 可以快速生成大量不同的数据。</li><li><strong>定制</strong>：数据可以根据特定用例或场景进行定制。</li></ol><h3id="合成数据训练可以分为以下四个步骤">合成数据训练可以分为以下四个步骤</h3><figure><img src="/images/合成数据/image-20240812092304705.png"alt="image-20240812092304705" /><figcaption aria-hidden="true">image-20240812092304705</figcaption></figure><h4 id="合成数据的生成">1 合成数据的生成</h4><p>常见的合成数据生成实践可以大致分为提示工程和多步骤生成。</p><p>提示工程：LLMs的指令遵循能力使其在生成数据时具有很好的可控性。有效的提示通常包含三个关键元素：任务规范、生成条件和上下文演示，然后用模板将其包裹成自然指令。</p><p>多步骤生成：通过逐步生成数据来增强其多样性和真实性，具体方法根据不同任务和场景进行调整</p><h4 id="合成数据的整理">2 合成数据的整理</h4><p>数据整理：确保生成的数据在逻辑和内容上的一致性和连贯性。生成的数据必须在逻辑和语法上连贯。然而，LLMs固有的幻觉问题和知识分布的长尾效应可能会引入显著的噪声，表现为事实错误、标签错误或无关内容。</p><h4 id="合成数据的评估">3 合成数据的评估</h4><p>数据评估：使用多种评价指标来评估数据质量，如准确性、多样性和相关性。多样性反映了生成数据的变化，包括文本长度、主题或写作风格的差异。这对于生成模拟真实世界数据的样本至关重要，从而防止模型训练或评估过程中的过拟合和偏差。</p><blockquote><p>论文题目：On LLMs-Driven Synthetic Data Generation, Curation, andEvaluation: A Survey</p><p>论文链接：https://arxiv.org/pdf/2406.15126</p></blockquote><p>让我们大概了解使用 LLM 生成合成数据的基本过程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM<br><span class="hljs-comment"># Load a pre-trained LLM</span><br>model_name = <span class="hljs-string">&quot;gpt2-large&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_name)<br>model = AutoModelForCausalLM.from_pretrained(model_name)<br><span class="hljs-comment"># Define a prompt for synthetic data generation</span><br>prompt = <span class="hljs-string">&quot;Generate a customer review for a smartphone:&quot;</span><br><span class="hljs-comment"># Generate synthetic data</span><br>input_ids = tokenizer.encode(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>output = model.generate(input_ids, max_length=<span class="hljs-number">100</span>, num_return_sequences=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># Decode and print the generated text</span><br>synthetic_review = tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(synthetic_review)<br></code></pre></td></tr></table></figure><p>这个简单的例子展示了如何使用 LLM 生成合成客户评论。然而，LLM驱动的合成数据生成的真正威力在于更复杂的技术和应用。</p><figure><img src="/images/合成数据/image-20240812092705811.png"alt="image-20240812092705811" /><figcaption aria-hidden="true">image-20240812092705811</figcaption></figure><h2 id="合成数据生成的高级技术">2. 合成数据生成的高级技术</h2><h3 id="及时工程">2.1 及时工程</h3><p><ahref="https://www.unite.ai/zh-CN/什么是人工智能中的即时工程-为什么它很重要/">即时工程</a>对于指导 LLM生成高质量、相关的合成数据至关重要。通过精心设计提示，我们可以控制生成数据的各个方面，例如样式、内容和格式。</p><p>更复杂的提示示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Generate a detailed customer review for a smartphone with the following characteristics:</span><br><span class="hljs-string">- Brand: &#123;brand&#125;</span><br><span class="hljs-string">- Model: &#123;model&#125;</span><br><span class="hljs-string">- Key features: &#123;features&#125;</span><br><span class="hljs-string">- Rating: &#123;rating&#125;/5 stars</span><br><span class="hljs-string">The review should be between 50-100 words and include both positive and negative aspects.</span><br><span class="hljs-string">Review:</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>brands = [<span class="hljs-string">&quot;Apple&quot;</span>, <span class="hljs-string">&quot;Samsung&quot;</span>, <span class="hljs-string">&quot;Google&quot;</span>, <span class="hljs-string">&quot;OnePlus&quot;</span>]<br>models = [<span class="hljs-string">&quot;iPhone 13 Pro&quot;</span>, <span class="hljs-string">&quot;Galaxy S21&quot;</span>, <span class="hljs-string">&quot;Pixel 6&quot;</span>, <span class="hljs-string">&quot;9 Pro&quot;</span>]<br>features = [<span class="hljs-string">&quot;5G, OLED display, Triple camera&quot;</span>, <span class="hljs-string">&quot;120Hz refresh rate, 8K video&quot;</span>, <span class="hljs-string">&quot;AI-powered camera, 5G&quot;</span>, <span class="hljs-string">&quot;Fast charging, 120Hz display&quot;</span>]<br>ratings = [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>]<br><span class="hljs-comment"># Generate multiple reviews</span><br><span class="hljs-keyword">for</span> brand, model, feature, rating <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(brands, models, features, ratings):<br>    filled_prompt = prompt.<span class="hljs-built_in">format</span>(brand=brand, model=model, features=feature, rating=rating)<br>    input_ids = tokenizer.encode(filled_prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    output = model.generate(input_ids, max_length=<span class="hljs-number">200</span>, num_return_sequences=<span class="hljs-number">1</span>)<br>    synthetic_review = tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Review for <span class="hljs-subst">&#123;brand&#125;</span> <span class="hljs-subst">&#123;model&#125;</span>:\n<span class="hljs-subst">&#123;synthetic_review&#125;</span>\n&quot;</span>)<br></code></pre></td></tr></table></figure><p>这种方法可以生成更加可控、更加多样化的合成数据，以适应特定的场景或产品类型。</p><h3 id="小样本学习">2.2 小样本学习</h3><p>少量学习涉及向 LLM提供所需输出格式和样式的几个示例。此技术可以显著提高生成数据的质量和一致性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">few_shot_prompt = <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Generate a customer support conversation between an agent (A) and a customer (C) about a product issue. Follow this format:</span><br><span class="hljs-string">C: Hello, I&#x27;m having trouble with my new headphones. The right earbud isn&#x27;t working.</span><br><span class="hljs-string">A: I&#x27;m sorry to hear that. Can you tell me which model of headphones you have?</span><br><span class="hljs-string">C: It&#x27;s the SoundMax Pro 3000.</span><br><span class="hljs-string">A: Thank you. Have you tried resetting the headphones by placing them in the charging case for 10 seconds?</span><br><span class="hljs-string">C: Yes, I tried that, but it didn&#x27;t help.</span><br><span class="hljs-string">A: I see. Let&#x27;s try a firmware update. Can you please go to our website and download the latest firmware?</span><br><span class="hljs-string">Now generate a new conversation about a different product issue:</span><br><span class="hljs-string">C: Hi, I just received my new smartwatch, but it won&#x27;t turn on.</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-comment"># Generate the conversation</span><br>input_ids = tokenizer.encode(few_shot_prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>output = model.generate(input_ids, max_length=<span class="hljs-number">500</span>, num_return_sequences=<span class="hljs-number">1</span>)<br>synthetic_conversation = tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(synthetic_conversation)<br></code></pre></td></tr></table></figure><p>这种方法有助于 LLM了解所需的对话结构和风格，从而实现更真实的综合客户支持互动。</p><h3 id="条件生成">2.3 条件生成</h3><p>条件生成允许我们控制生成数据的特定属性。当我们需要创建具有某些受控特征的多样化数据集时，这尤其有用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2LMHeadModel, GPT2Tokenizer<br><span class="hljs-keyword">import</span> torch<br>model = GPT2LMHeadModel.from_pretrained(<span class="hljs-string">&quot;gpt2-medium&quot;</span>)<br>tokenizer = GPT2Tokenizer.from_pretrained(<span class="hljs-string">&quot;gpt2-medium&quot;</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_conditional_text</span>(<span class="hljs-params">prompt, condition, max_length=<span class="hljs-number">100</span></span>):<br>    input_ids = tokenizer.encode(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)<br>    <span class="hljs-comment"># Encode the condition</span><br>    condition_ids = tokenizer.encode(condition, add_special_tokens=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>    <span class="hljs-comment"># Concatenate condition with input_ids</span><br>    input_ids = torch.cat([condition_ids, input_ids], dim=-<span class="hljs-number">1</span>)<br>    attention_mask = torch.cat([torch.ones(condition_ids.shape, dtype=torch.long, device=condition_ids.device), attention_mask], dim=-<span class="hljs-number">1</span>)<br>    output = model.generate(input_ids, attention_mask=attention_mask, max_length=max_length, num_return_sequences=<span class="hljs-number">1</span>, no_repeat_ngram_size=<span class="hljs-number">2</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">50</span>, top_p=<span class="hljs-number">0.95</span>, temperature=<span class="hljs-number">0.7</span>)<br>    <span class="hljs-keyword">return</span> tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># Generate product descriptions with different conditions</span><br>conditions = [<span class="hljs-string">&quot;Luxury&quot;</span>, <span class="hljs-string">&quot;Budget-friendly&quot;</span>, <span class="hljs-string">&quot;Eco-friendly&quot;</span>, <span class="hljs-string">&quot;High-tech&quot;</span>]<br>prompt = <span class="hljs-string">&quot;Describe a backpack:&quot;</span><br><span class="hljs-keyword">for</span> condition <span class="hljs-keyword">in</span> conditions:<br>description = generate_conditional_text(prompt, condition)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;condition&#125;</span> backpack description:\n<span class="hljs-subst">&#123;description&#125;</span>\n&quot;</span>)<br></code></pre></td></tr></table></figure><p>这种技术使我们能够生成多样化的合成数据，同时保持对特定属性的控制，确保生成的数据集涵盖广泛的场景或产品类型。</p><h2 id="llm-生成的合成数据的应用">LLM 生成的合成数据的应用</h2><h3 id="训练数据增强">训练数据增强</h3><p>LLM生成的合成数据最强大的应用之一是增强现有的训练数据集。这在现实世界数据有限或获取成本高昂的情况下尤其有用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><span class="hljs-comment"># Load a small real-world dataset</span><br>real_data = pd.read_csv(<span class="hljs-string">&quot;small_product_reviews.csv&quot;</span>)<br><span class="hljs-comment"># Split the data</span><br>train_data, test_data = train_test_split(real_data, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)<br><span class="hljs-comment"># Initialize the text generation pipeline</span><br>generator = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;gpt2-medium&quot;</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">augment_dataset</span>(<span class="hljs-params">data, num_synthetic_samples</span>):<br>    synthetic_data = []<br>    <span class="hljs-keyword">for</span> _, row <span class="hljs-keyword">in</span> data.iterrows():<br>        prompt = <span class="hljs-string">f&quot;Generate a product review similar to: <span class="hljs-subst">&#123;row[<span class="hljs-string">&#x27;review&#x27;</span>]&#125;</span>\nNew review:&quot;</span><br>        synthetic_review = generator(prompt, max_length=<span class="hljs-number">100</span>, num_return_sequences=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;generated_text&#x27;</span>]<br>        synthetic_data.append(&#123;<span class="hljs-string">&#x27;review&#x27;</span>: synthetic_review,<span class="hljs-string">&#x27;sentiment&#x27;</span>: row[<span class="hljs-string">&#x27;sentiment&#x27;</span>] <span class="hljs-comment"># Assuming the sentiment is preserved&#125;)</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(synthetic_data) &gt;= num_synthetic_samples:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">return</span> pd.DataFrame(synthetic_data)<br><span class="hljs-comment"># Generate synthetic data</span><br>synthetic_train_data = augment_dataset(train_data, num_synthetic_samples=<span class="hljs-built_in">len</span>(train_data))<br><span class="hljs-comment"># Combine real and synthetic data</span><br>augmented_train_data = pd.concat([train_data, synthetic_train_data], ignore_index=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Original training data size: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(train_data)&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Augmented training data size: <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(augmented_train_data)&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>这种方法可以显著增加训练数据集的大小和多样性，从而有可能提高机器学习模型的性能和稳健性。</p><h2 id="挑战和最佳实践">挑战和最佳实践</h2><p>虽然 LLM 驱动的合成数据生成提供了许多好处，但也带来了挑战：</p><ol type="1"><li><strong>质量控制</strong>：确保生成的数据质量高且与您的用例相关。实施严格的验证流程。</li><li><strong>减少偏见</strong>：LLM可以继承并放大其训练数据中存在的偏差。请注意这一点并实施偏差检测和缓解策略。</li><li><strong>多元化</strong>：确保您的合成数据集多样化且能够代表真实世界场景。</li><li><strong>持续一致</strong>：保持生成的数据的一致性，尤其是在创建大型数据集时。</li><li><strong>关于SCIREQ</strong>：要注意道德问题，尤其是在生成模仿敏感或个人信息的合成数据时。</li></ol><p>LLM 驱动的合成数据生成的最佳实践：</p><ol type="1"><li><strong>迭代细化</strong>：根据输出的质量不断改进您的提示和生成技术。</li><li><strong>混合方法</strong>：将 LLM生成的数据与真实世界数据相结合以获得最佳结果。</li><li><strong>验证</strong>：实施强有力的验证流程，以确保生成数据的质量和相关性。</li><li><strong>配套文档</strong>：维护合成数据生成过程的清晰文档，以确保透明度和可重复性。</li><li><strong>道德准则</strong>：制定并遵守合成数据生成和使用的道德准则。</li></ol><h2 id="结论">结论</h2><p>LLM 驱动的合成数据生成是一种强大的技术，它正在改变我们以数据为中心的AI开发方式。通过利用高级语言模型的功能，我们可以创建多样化、高质量的数据集，推动各个领域的创新。随着技术的不断发展，它有望在AI研究和应用程序开发中释放新的可能性，同时解决与数据稀缺和隐私相关的关键挑战。</p><p>随着我们不断前进，以平衡的视角看待合成数据生成至关重要，充分利用其优势，同时注意其局限性和道德影响。通过谨慎实施和不断改进，LLM驱动的合成数据生成有可能加速 AI进步并开辟机器学习和数据科学的新领域。</p>]]></content>
    
    
    <categories>
      
      <category>数据工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>数据工程</tag>
      
      <tag>合成数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>提升模型训练效率的十个Pytorch技巧</title>
    <link href="/%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%88%E7%8E%87%E7%9A%84%E5%8D%81%E4%B8%AAPytorch%E6%8A%80%E5%B7%A7.html"/>
    <url>/%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%88%E7%8E%87%E7%9A%84%E5%8D%81%E4%B8%AAPytorch%E6%8A%80%E5%B7%A7.html</url>
    
    <content type="html"><![CDATA[<blockquote><ol type="1"><li>One cycle学习率策略</li><li>Batch size</li><li>num workers &amp; pin memory</li><li>自动混合精度训练</li><li>torch.backends.cudnn.benchmark</li><li>torch.nn.parallel.DistributedDataParallel</li><li>梯度累加</li><li>梯度裁剪</li><li>BN前卷积层中的bias</li><li>陋习改正</li></ol></blockquote><p>在使用 PyTorch进行深度学习模型训练时，提升训练效率和性能是至关重要的。以下是一些常用的PyTorch 技巧，帮助提升模型训练效率：</p><h3 id="one-cycle-学习率策略">1. One Cycle 学习率策略</h3><p>One Cycle Learning Rate Policy 是一种动态调整学习率的方法，由 LeslieN. Smith提出。其核心思想是在训练的前半部分逐渐增加学习率，然后在后半部分逐渐减小，从而加速收敛并提高模型的泛化能力。OneCycle 策略主要包含以下几个步骤：</p><ul><li><strong>增加阶段</strong>：从一个较小的初始学习率开始，逐步增加到一个较高的最大学习率。</li><li><strong>减小阶段</strong>：从最大学习率开始，逐步减小到一个比初始学习率更小的终止学习率。</li><li><strong>动量调整</strong>：同时调整动量值，在学习率增加时减小动量，在学习率减小时增加动量。</li></ul><figure><img src="/images/torch_acc/image-20240722143759040.png"alt="image-20240722143759040" /><figcaption aria-hidden="true">image-20240722143759040</figcaption></figure><p>使用 One Cycle 学习率策略的好处包括： - 加快收敛速度。 -避免模型陷入局部最优。 - 改善训练的稳定性。</p><p>在 PyTorch 中，可以使用<code>torch.optim.lr_scheduler.OneCycleLR</code> 来实现 One Cycle策略。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># 定义优化器</span><br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.1</span>, momentum=<span class="hljs-number">0.9</span>)<br><br><span class="hljs-comment"># 定义学习率调度器</span><br>scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=<span class="hljs-number">0.1</span>, <br>                                          steps_per_epoch=<span class="hljs-built_in">len</span>(train_loader), epochs=<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_loader:<br>        <span class="hljs-comment"># 正向传播</span><br>        outputs = model(inputs)<br>        loss = criterion(outputs, targets)<br><br>        <span class="hljs-comment"># 反向传播</span><br>        optimizer.zero_grad()<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-comment"># 学习率调度</span><br>        scheduler.step()<br></code></pre></td></tr></table></figure><h3 id="batch-size">2. Batch Size</h3><p>Batch size 是指在一次迭代中传递给模型的样本数量。调整 batch size可以显著影响模型的训练速度和性能：</p><figure><img src="/images/torch_acc/image-20240722143849741.png"alt="image-20240722143849741" /><figcaption aria-hidden="true">image-20240722143849741</figcaption></figure><ul><li><strong>较大 batch size</strong>：<ul><li>提高 GPU 的利用率，因为每次迭代处理更多数据。</li><li>减少更新模型参数的频率，可能会导致收敛速度变慢。</li></ul></li><li><strong>较小 batch size</strong>：<ul><li>提高模型的泛化能力，因为更新更频繁，参数更易于捕捉数据分布的细微变化。</li><li>在内存允许的情况下，可以使用较大的 batch size 来提高训练速度。</li></ul></li></ul><p>在训练中，可以逐步增加 batch size来找到内存和速度之间的平衡。还可以使用 <ahref="https://pytorch-lightning.readthedocs.io/en/stable/guides/speed.html#gradient-accumulation">GradientAccumulation</a> 来模拟较大的 batch size 而不增加显存使用。</p><h3 id="num_workers-pin_memory">3. num_workers &amp; pin_memory</h3><figure><img src="/images/torch_acc/image-20240722145932986.png"alt="image-20240722145932986" /><figcaption aria-hidden="true">image-20240722145932986</figcaption></figure><p><strong>num_workers</strong> 和 <strong>pin_memory</strong> 是<code>DataLoader</code> 中的两个重要参数，它们影响数据加载效率：</p><ul><li><strong>num_workers</strong>：指定数据加载时使用的子进程数量。增大<code>num_workers</code>可以提高数据加载速度，但设置过高可能导致资源竞争或内存不足。<ul><li>对于 CPU 核心较多的机器，可以尝试增大<code>num_workers</code>，通常设置为 CPU 核心数的 2 到 4 倍。</li><li>对于小数据集或 IO 受限的情况，适当的增大 <code>num_workers</code>也可以提升性能。</li></ul></li><li><strong>pin_memory</strong>：如果设置为 True，DataLoader会在将张量转移到 GPU 前将它们锁页到内存中。对于 CUDA后端，这通常可以加快数据转移速度。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_loader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>, <br>                          num_workers=<span class="hljs-number">4</span>, pin_memory=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h3 id="自动混合精度训练">4. 自动混合精度训练</h3><p>自动混合精度（AMP）训练是一种通过使用半精度（FP16）和单精度（FP32）混合计算来加速模型训练的方法。AMP可以有效减少显存使用并提高训练速度，同时通常不会影响模型精度。</p><p>在 PyTorch 中，可以使用 <code>torch.cuda.amp</code>模块来实现自动混合精度训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.cuda.amp <span class="hljs-keyword">import</span> autocast, GradScaler<br><br><span class="hljs-comment"># 初始化 scaler</span><br>scaler = GradScaler()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> inputs, targets <span class="hljs-keyword">in</span> train_loader:<br>        <span class="hljs-comment"># 前向传播</span><br>        <span class="hljs-keyword">with</span> autocast():  <span class="hljs-comment"># 启用混合精度</span><br>            outputs = model(inputs)<br>            loss = criterion(outputs, targets)<br><br>        <span class="hljs-comment"># 反向传播</span><br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># 使用 scaler 缩放梯度</span><br>        scaler.scale(loss).backward()<br>        <span class="hljs-comment"># 更新参数</span><br>        scaler.step(optimizer)<br>        <span class="hljs-comment"># 更新 scaler</span><br>        scaler.update()<br></code></pre></td></tr></table></figure><p><strong>自动混合精度训练的优点：</strong></p><ul><li><strong>内存效率</strong>：减少显存使用，使得可以增大 batchsize。</li><li><strong>速度提升</strong>：在不显著影响模型精度的前提下加速训练。</li></ul><p>注意：使用 AMP 时需要确保梯度不会溢出，并使用 <code>GradScaler</code>来防止数值不稳定性。</p><h3 id="动态调整卷积操作">5. 动态调整卷积操作</h3><ul><li><strong>功能</strong>：<code>torch.backends.cudnn.benchmark</code>是 PyTorch 中一个设置，可以动态调整卷积操作的算法以提高 GPU上的性能。</li><li><strong>工作原理</strong>：在 GPU上进行卷积操作时，有多种算法可供选择。<code>benchmark</code> 会让 cuDNN进行测试，以选择最适合当前卷积层配置（如输入大小、批量大小等）的算法。这对于输入大小固定的场景尤其有用，因为可以显著减少算法选择带来的开销。</li><li><strong>使用建议</strong>：在输入大小不变的情况下开启，可以提升性能。但是如果输入大小会变（比如处理变长序列），不建议开启，因为每次输入改变时都需要重新测试，反而降低性能。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>torch.backends.cudnn.benchmark = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><h3 id="分布式训练模块ddp">6. 分布式训练模块DDP</h3><figure><img src="/images/torch_acc/image-20240722150144297.png"alt="image-20240722150144297" /><figcaption aria-hidden="true">image-20240722150144297</figcaption></figure><ul><li><strong>功能</strong>：<code>DistributedDataParallel</code>（DDP）是PyTorch 中用于分布式训练的模块，允许跨多 GPU和多节点并行地训练模型。</li><li><strong>工作原理</strong>：DDP 将模型复制到多个 GPU 上，每个 GPU上的模型处理一部分数据。各个 GPU之间通过梯度同步机制确保更新的一致性。</li><li><strong>使用建议</strong>：在多 GPU 训练中优先使用 DDP，而不是<code>DataParallel</code>，因为 DDP 的通信开销较小，且更具扩展性。使用DDP 可以充分利用多个 GPU 和节点的计算资源，加快训练过程。</li><li><strong>拓展:</strong>huggingface中的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist<br><br><span class="hljs-comment"># 初始化分布式环境</span><br>dist.init_process_group(backend=<span class="hljs-string">&#x27;nccl&#x27;</span>)<br><br><span class="hljs-comment"># 创建模型</span><br>model = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>).cuda()<br><span class="hljs-comment"># 使用 DistributedDataParallel</span><br>model = nn.parallel.DistributedDataParallel(model)<br></code></pre></td></tr></table></figure><h3 id="梯度累加">7. 梯度累加</h3><ul><li><strong>功能</strong>：梯度累加（GradientAccumulation）是一种技术，可以通过多次反向传播累积梯度，模拟更大批量的训练效果，而不需要增加显存占用。</li><li><strong>工作原理</strong>：将一个大批量划分为多个小批量，每个小批量计算完损失后执行反向传播，但不立即更新权重，而是累积梯度，直到累积一定次数后才执行优化器的<code>step</code> 操作更新模型权重。</li><li><strong>使用建议</strong>：适用于显存不足以支撑大批量训练的情况，通过这种方式可以有效提高模型的泛化能力。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">accumulation_steps = <span class="hljs-number">4</span>  <span class="hljs-comment"># 累积4个小批量</span><br><br>optimizer = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">1e-3</span>)<br>model.train()<br><br><span class="hljs-keyword">for</span> i, (inputs, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>    outputs = model(inputs)<br>    loss = loss_function(outputs, labels)<br>    loss = loss / accumulation_steps  <span class="hljs-comment"># 平均损失</span><br>    loss.backward()  <span class="hljs-comment"># 反向传播</span><br><br>    <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % accumulation_steps == <span class="hljs-number">0</span>:<br>        optimizer.step()  <span class="hljs-comment"># 更新权重</span><br>        optimizer.zero_grad()  <span class="hljs-comment"># 清空梯度</span><br></code></pre></td></tr></table></figure><h3 id="梯度裁剪">8. 梯度裁剪</h3><ul><li><strong>功能</strong>：梯度裁剪（GradientClipping）用于控制梯度的大小，防止梯度爆炸问题。</li><li><strong>工作原理</strong>：在反向传播时对梯度进行裁剪，如果梯度的范数超过预设阈值，则按比例缩小，使得训练更稳定。</li><li><strong>使用建议</strong>：在 RNN或者深度网络中使用，有助于稳定训练过程，尤其是在处理梯度爆炸问题时。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.nn.utils <span class="hljs-keyword">import</span> clip_grad_norm_<br><br>max_norm = <span class="hljs-number">1.0</span>  <span class="hljs-comment"># 设置最大梯度范数</span><br><br><span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> dataloader:<br>    optimizer.zero_grad()<br>    outputs = model(inputs)<br>    loss = loss_function(outputs, labels)<br>    loss.backward()<br>    <br>    clip_grad_norm_(model.parameters(), max_norm)  <span class="hljs-comment"># 梯度裁剪</span><br>    optimizer.step()<br></code></pre></td></tr></table></figure><h3 id="bn-前卷积层中的-bias">9. BN 前卷积层中的 bias</h3><ul><li><strong>功能</strong>：在 BatchNormalization（BN）层前的卷积层中通常不需要使用偏置（bias）项。</li><li><strong>工作原理</strong>：BN层会对每个特征进行标准化并重新添加缩放和偏移参数，因此卷积层的偏置会被BN 层的偏置覆盖，成为冗余。</li><li><strong>使用建议</strong>：在使用 BN的模型中，可以去掉卷积层中的偏置参数，以减少计算量和内存使用，尤其是在较大模型中有显著效果。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 定义卷积和BN层</span><br>conv = nn.Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, bias=<span class="hljs-literal">False</span>)<br>bn = nn.BatchNorm2d(<span class="hljs-number">16</span>)<br></code></pre></td></tr></table></figure><h3id="减少不必要的数据复制和设备之间的数据传输">10.减少不必要的数据复制和设备之间的数据传输</h3><ol type="1"><li><strong>避免频繁使用 <code>torch.cpu()</code> 和<code>torch.cuda()</code></strong>：<ul><li><strong>建议：</strong> 在训练过程中，尽量减少在 CPU 和 GPU之间频繁切换张量。这是因为这种操作涉及大量的数据传输，会显著降低训练速度。</li><li><strong>优化方法：</strong> 尽量将所有计算都放在 GPU上进行，以减少数据在设备之间的传输。</li></ul></li><li><strong>避免使用 <code>torch.tensor()</code></strong>：<ul><li><strong>原因：</strong> <code>torch.tensor()</code>每次调用都会复制数据，导致额外的内存开销。</li><li><strong>替代方法：</strong> 使用<code>torch.as_tensor()</code>，这会共享数据，不会进行复制，从而提高效率。</li></ul></li><li><strong>使用 <code>torch.as_tensor()</code> 和<code>torch.from_numpy()</code></strong>：<ul><li><strong><code>torch.as_tensor()</code>:</strong>直接将已有的数据转化为张量，并且不会进行数据的复制，适合在已有数据需要转换为张量时使用。</li><li><strong><code>torch.from_numpy()</code>:</strong> 可以将 NumPy数组转换为张量，且不会复制数据。这个方法适用于已有数据在 NumPy格式时。</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>pytorch</tag>
      
      <tag>干货总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>生成式模型与判别式模型比较</title>
    <link href="/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%EF%BC%88Generative%20Model%EF%BC%89%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B.html"/>
    <url>/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%EF%BC%88Generative%20Model%EF%BC%89%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B.html</url>
    
    <content type="html"><![CDATA[<p>生成模型和判别模型是机器学习和统计建模中两种主要的模型类型，它们在目标、方法和应用上有显著的区别。以下是生成模型和判别模型的详细比较：</p><h2 id="生成模型generative-model">生成模型（Generative Model）</h2><h3 id="目标">目标</h3><p>生成模型的主要目标是<strong>建模数据的生成过程</strong>，即学习数据的联合分布( P(X, Y) )，其中 ( X ) 是输入数据，( Y ) 是标签或输出。</p><h3 id="方法">方法</h3><ul><li><strong>联合概率分布</strong>：生成模型试图学习输入数据和输出标签之间的联合概率分布( P(X, Y) )。通过这种建模，生成模型可以生成新的数据样本。</li><li><strong>生成新样本</strong>：生成模型可以用于生成与训练数据分布相似的新样本。</li><li><strong>最大似然估计</strong>：通常使用最大似然估计来找到使观察数据概率最大的参数。</li></ul><h3 id="优势">优势</h3><ul><li><strong>数据生成</strong>：生成模型能够生成新数据，非常适用于数据增强和缺失数据填补。</li><li><strong>处理缺失数据</strong>：由于建模了数据的生成过程，生成模型在处理缺失数据时表现良好。</li><li><strong>密度估计</strong>：生成模型可以提供数据的概率密度估计。</li></ul><h3 id="示例">示例</h3><ul><li><strong>高斯混合模型（GMM）</strong>：用于聚类和密度估计。</li><li><strong>朴素贝叶斯</strong>：一种简单的概率分类器。</li><li><strong>隐马尔可夫模型（HMM）</strong>：用于时间序列数据建模。</li><li><strong>生成对抗网络（GAN）</strong>：用于生成逼真的新数据样本。</li><li><strong>变分自编码器（VAE）</strong>：用于生成新样本和数据压缩。</li></ul><h2 id="判别模型discriminative-model">判别模型（DiscriminativeModel）</h2><h3 id="目标-1">目标</h3><p>判别模型的主要目标是<strong>直接学习输入与输出之间的映射关系</strong>，即学习条件分布( P(Y|X) )，通过此分布进行分类或回归。</p><h3 id="方法-1">方法</h3><ul><li><strong>条件概率分布</strong>：判别模型直接对输入数据的条件概率 (P(Y|X) ) 进行建模，而不需要考虑输入数据的生成过程。</li><li><strong>直接预测</strong>：判别模型主要用于直接预测输入数据对应的输出标签。</li><li><strong>优化分类边界</strong>：通过优化某种损失函数（如交叉熵损失）来找到最佳的分类边界。</li></ul><h3 id="优势-1">优势</h3><ul><li><strong>更高的分类精度</strong>：因为判别模型专注于寻找输入和输出之间的最佳分离边界。</li><li><strong>训练效率更高</strong>：通常只需要关心输入到输出的映射，而不需要建模数据的生成过程。</li><li><strong>较少的假设</strong>：对数据的分布假设较少，更适用于复杂任务。</li></ul><h3 id="示例-1">示例</h3><ul><li><strong>逻辑回归</strong>：用于二分类问题。</li><li><strong>支持向量机（SVM）</strong>：用于分类和回归任务。</li><li><strong>决策树和随机森林</strong>：用于分类和回归。</li><li><strong>神经网络（包括深度学习）</strong>：用于多种复杂的学习任务。</li><li><strong>线性回归</strong>：用于回归任务。</li></ul><h2 id="比较总结">比较总结</h2><ul><li><strong>目标</strong>：生成模型关注数据生成过程，判别模型关注输入到输出的映射。</li><li><strong>复杂度</strong>：生成模型通常更复杂，因为需要建模完整的数据分布，而判别模型只需建模条件概率。</li><li><strong>应用场景</strong>：生成模型适用于需要生成新数据或处理不完整数据的任务，而判别模型更适合分类和回归任务。</li></ul><h2 id="联合分布joint-distribution">联合分布（Joint Distribution）</h2><h3 id="定义">定义</h3><p>联合分布描述的是两个或多个随机变量同时发生的概率。对于两个随机变量 (X ) 和 ( Y )，其联合分布表示为 ( P(X, Y) )，它给出了变量 ( X ) 和 ( Y )同时取某些特定值的概率。</p><h3 id="公式">公式</h3><p>如果 ( X ) 和 ( Y )是离散随机变量，则其联合概率质量函数（PMF）为：</p><p>[ P(X = x, Y = y) ]</p><p>如果 ( X ) 和 ( Y )是连续随机变量，则其联合概率密度函数（PDF）为：</p><p>[ f(x, y) ]</p><h3 id="示例-2">示例</h3><p>假设我们有一副扑克牌，我们想要计算抽取一张红色牌且为红心的概率。设 (X ) 是抽取红色牌的事件，( Y ) 是抽取红心的事件，那么联合概率为：</p><p>[ P(X = , Y = ) ]</p><h3 id="特点">特点</h3><ul><li><strong>多维分布</strong>：联合分布用于描述多个随机变量的概率关系，可以是多维的。</li><li><strong>概率总和</strong>：所有可能的组合概率之和等于 1，即 (_x _yP(X = x, Y = y) = 1)。</li><li><strong>对称性</strong>： (P(X, Y) = P(Y, X)) 。</li></ul><h2 id="条件分布conditional-distribution">条件分布（ConditionalDistribution）</h2><h3 id="定义-1">定义</h3><p>条件分布描述的是一个随机变量在给定另一个随机变量已经发生的条件下的概率。对于随机变量( X ) 和 ( Y )，条件分布表示为 ( P(Y | X) )，即在 ( X )取某一特定值的情况下，( Y ) 取某值的概率。</p><h3 id="公式-1">公式</h3><p>条件概率可以通过联合概率来定义：</p><p>[ P(Y = y | X = x) = ]</p><p>在这里，( P(X = x) )。</p><p>对于连续随机变量：</p><p>[ f(y | x) = ]</p><h3 id="示例-3">示例</h3><p>继续上面的扑克牌例子，如果我们已经知道抽取的是红色牌，想计算这张牌为红心的概率，那么：</p><p>[ P(Y = | X = ) ]</p><h3 id="特点-1">特点</h3><ul><li><strong>单向性</strong>：条件分布是单向的，即在一个随机变量已知的条件下，描述另一个随机变量的分布。</li><li><strong>依赖关系</strong>：条件分布反映了随机变量之间的依赖关系。</li><li><strong>归一化</strong>：对所有可能的 ( Y ) 的取值，条件概率的和为1，即 (_y P(Y = y | X = x) = 1)。</li></ul><h2 id="区别总结">区别总结</h2><ul><li><strong>目的不同</strong>：<ul><li><strong>联合分布</strong>用于描述两个或多个随机变量同时发生的情况。</li><li><strong>条件分布</strong>用于描述一个随机变量在已知另一个变量的情况下的概率。</li></ul></li><li><strong>表示方法</strong>：<ul><li><strong>联合分布</strong>： ( P(X, Y) ) 或 ( f(x, y) )。</li><li><strong>条件分布</strong>： ( P(Y | X) ) 或 ( f(y | x) )。</li></ul></li><li><strong>关系</strong>：<ul><li><strong>条件分布</strong>可以通过联合分布和边际分布计算出来。</li><li><strong>联合分布</strong>可以分解为条件分布和边际分布的乘积： ( P(X,Y) = P(Y | X) P(X) )。</li></ul></li><li><strong>应用场景</strong>：<ul><li><strong>联合分布</strong>适用于需要考虑多个随机变量同时作用的情境，如联合概率表。</li><li><strong>条件分布</strong>适用于涉及条件概率的情境，如贝叶斯定理。</li></ul></li></ul><p>了解联合分布和条件分布的区别可以帮助更好地理解数据中的依赖关系和概率特性，以及在机器学习中选择合适的模型和方法。</p>]]></content>
    
    
    <categories>
      
      <category>概念</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>算法</tag>
      
      <tag>模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>用wordcoloud生成超炫酷的词云_内含python源码</title>
    <link href="/%E7%94%A8wordcoloud%E7%94%9F%E6%88%90%E8%B6%85%E7%82%AB%E9%85%B7%E7%9A%84%E8%AF%8D%E4%BA%91-%E5%86%85%E5%90%ABpython%E6%BA%90%E7%A0%81.html"/>
    <url>/%E7%94%A8wordcoloud%E7%94%9F%E6%88%90%E8%B6%85%E7%82%AB%E9%85%B7%E7%9A%84%E8%AF%8D%E4%BA%91-%E5%86%85%E5%90%ABpython%E6%BA%90%E7%A0%81.html</url>
    
    <content type="html"><![CDATA[<p>使用jieba分词，wordcoloud词云可视化</p><span id="more"></span><p><img src="/images/word_cloud/2024年5月10日ai.jpg" /><strong>环境准备</strong> pip 安装jieba库,wordcloud库与scipy库<strong>资料准备</strong></p><ul class="task-list"><li><label><inputtype="checkbox" />用于分词的文本:词频统计_AIjob.csv</label></li><li><label><inputtype="checkbox" />禁止统计词库:stopwords.txt</label></li><li><label><inputtype="checkbox" />自定义分词库:人工智能词汇.txt</label></li><li><label><inputtype="checkbox" />掩膜用的形状图片:mask.jpg</label></li></ul><p>不废话,直接上码 ### 1.用结巴分词,生成字典对象 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> jieba<br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><span class="hljs-keyword">import</span> wordcloud<br><span class="hljs-comment"># 读取文件</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;词频统计_AIjob.csv&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    desc = f.read()<br><br><span class="hljs-comment"># 加载停用词列表</span><br>stop_words = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;stopwords.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>,encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>        stop_words.append(line.strip())<br><br>jieba.load_userdict(<span class="hljs-string">&quot;人工智能词汇.txt&quot;</span>)<br><span class="hljs-comment"># 分词</span><br>words = jieba.cut(desc, cut_all=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># 过滤停用词</span><br>filtered_words = []<br><span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>    <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(word) &gt; <span class="hljs-number">1</span>:<br>        filtered_words.append(word)<br><br><span class="hljs-comment"># 统计词频</span><br>word_counts = Counter(filtered_words)<br><br>w100=word_counts.most_common(<span class="hljs-number">500</span>)<br><span class="hljs-comment"># 使用字典推导将列表转换为字典  </span><br>dict_result = &#123;key: value <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> w100&#125; <br></code></pre></td></tr></table></figure> ###2.用wordcloud 生成词云 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> scipy.ndimage <span class="hljs-keyword">import</span> gaussian_gradient_magnitude<br><span class="hljs-keyword">from</span> wordcloud <span class="hljs-keyword">import</span> WordCloud, ImageColorGenerator<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pic_wordcloud</span>(<span class="hljs-params">dict_result,img_path,out_path</span>):<br><br>    <br>    <span class="hljs-comment"># img_path=r&quot;E:\jupyter\spyder\bosszhipin\词频统计\pic\T1.jpg&quot;</span><br>    <br>    parrot_color = np.array(Image.<span class="hljs-built_in">open</span>(img_path))<br>    <br>    parrot_color = parrot_color[::<span class="hljs-number">3</span>, ::<span class="hljs-number">3</span>]<br>    <br>    <span class="hljs-comment"># create mask  white is &quot;masked out&quot;</span><br>    parrot_mask = parrot_color.copy()<br>    parrot_mask[parrot_mask.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">2</span>) == <span class="hljs-number">0</span>] = <span class="hljs-number">255</span><br>    <br>    <br>    edges = np.mean([gaussian_gradient_magnitude(parrot_color[:, :, i] / <span class="hljs-number">255.</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)], axis=<span class="hljs-number">0</span>)<br>    parrot_mask[edges &gt; <span class="hljs-number">.08</span>] = <span class="hljs-number">255</span><br>    <br>    <br>    <span class="hljs-comment"># acurately but it makes a better picture</span><br>    wc = WordCloud(max_words=<span class="hljs-number">1000</span>, mask=parrot_mask, max_font_size=<span class="hljs-number">40</span>, random_state=<span class="hljs-number">42</span>, font_path=<span class="hljs-string">r&quot;C:\Users\10921\AppData\Local\Microsoft\Windows\Fonts\方正正准黑简体.ttf&quot;</span>,relative_scaling=<span class="hljs-number">0</span>,<br>                   <span class="hljs-comment">#width=1920, height=1080</span><br>                   )<br>    <br>    <span class="hljs-comment"># generate word cloud</span><br>    wc.generate_from_frequencies(dict_result)<br>    <span class="hljs-comment"># plt.imshow(wc)</span><br>    <br>    <span class="hljs-comment"># create coloring from image</span><br>    image_colors = ImageColorGenerator(parrot_color)<br>    wc.recolor(color_func=image_colors)<br>    <span class="hljs-comment"># plt.figure(figsize=(10, 10))</span><br>    <span class="hljs-comment"># plt.imshow(wc, interpolation=&quot;bilinear&quot;)</span><br>    <span class="hljs-comment"># wc.to_file(&quot;parrot_new.png&quot;)</span><br>    wc.to_file(out_path)<br>img_path=<span class="hljs-string">&quot;mask.jpg&quot;</span><br>out_path=<span class="hljs-string">&#x27;output.png&#x27;</span><br>pic_wordcloud(dict_result,img_path,out_path)<br></code></pre></td></tr></table></figure> <imgsrc="/images/word_cloud/2024年5月10日color112.png" /> <imgsrc="/images/word_cloud/2024年5月10日parrot_new.png" /></p>]]></content>
    
    
    
    <tags>
      
      <tag>可视化</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在LLM时代，Bert为什么不香了？</title>
    <link href="/BERT%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E9%A6%99%E4%BA%86.html"/>
    <url>/BERT%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E9%A6%99%E4%BA%86.html</url>
    
    <content type="html"><![CDATA[<p>B<strong>ERT和T5怎么了？关于Transformer编码器、PrefixLM和去噪目标</strong></p><p>那些在五年前就从事<ahref="https://www.zhihu.com/search?q=自然语言处理&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">自然语言处理</a>的人们，现在都在困惑：所有的<ahref="https://www.zhihu.com/search?q=编码器模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">编码器模型</a>（encodermodels）去哪了？如果BERT表现得如此出色，为什么不进行扩展？编码器-解码器模型（encoder-decoders）或仅编码器模型（encoder-onlymodels）到底发生了什么？</p><p>今天，我试图解开这一切，在这个新的<ahref="https://www.zhihu.com/search?q=大模型（LLM）&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">大模型（LLM）</a>时代，希望这篇文章能有所帮助。</p><h2 id="前情回顾">前情回顾</h2><p>在过去几年里，主要有三种主流的模型架构范式。编码器模型（如BERT）、编码器-解码器模型（如T5）和仅解码器模型（如GPT系列）。人们经常对此感到困惑，并对这些分类方式和架构存在许多误解，所以我希望这篇文章能有所帮助。</p><p>首先要真正理解的是，编码器-解码器模型实际上仍然是自回归模型。编码器-解码器模型中的解码器从本质上来说仍然是一个因果解码器。与其预填充解码器模型，不如将一些文本卸载到编码器上，然后通过交叉注意力机制发送给解码器。是的，T5模型也是语言模型！</p><p>这种模型的一个变体是<ahref="https://www.zhihu.com/search?q=前缀语言模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">前缀语言模型</a>或PrefixLM架构，它几乎做同样的事情，只是没有交叉注意力（还有一些其他小细节，如在编码器/解码器之间共享权重，以及没有编码器瓶颈）。PrefixLM有时也被称为<ahref="https://www.zhihu.com/search?q=非因果解码器&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">非因果解码器</a>。简而言之，编码器-解码器、仅解码器模型和PrefixLM之间并没有太大的区别！</p><p>在HyungWon最近的一场精彩讲座中，他解释了这些模型之间的关系，可以在这里查看（需要梯子）</p><p><ahref="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DorDKvo8h71o">StanfordCS25: V4 I Hyung Won Chung ofOpenAIwww.youtube.com/watch?v=orDKvo8h71o</a></p><p>与此同时，像原始BERT这样的仅编码器模型以不同的方式进行去噪（in-place，在掩码标记masktoken之上直接添加分类头），在某种程度上，它们依赖分类"任务"头来在预训练后对基础模型做任何有用的事情。去噪目标后来被T5等模型以"改编风格"采用，使用序列到序列的形式。</p><p>值得注意的是，T5中的去噪并不是一个全新的目标函数（从机器学习的角度来看），而更像是对输入的数据转换。顺便说一下，你也可以用因果解码器训练跨度损坏（spancorruption）目标！</p><p>人们总是认为编码器-解码器模型必须是去噪模型，部分原因是T5模型过于具有代表性。然而，这并不总是正确的。你可以用常规的语言建模任务（<ahref="https://www.zhihu.com/search?q=CLM&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">CLM</a>：causallanguagemodels）来训练编码器-解码器。相反，你也可以用跨度损坏任务来训练因果解码器。正如我之前所说，这主要是一种数据转换。</p><p>同样值得注意的是，一般来说，具有2N参数的编码器-解码器的计算成本与具有N参数的仅解码器模型相同，这给它带来了不同的<ahref="https://www.zhihu.com/search?q=FLOP&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">FLOP</a>与参数数量比。这就像是在输入和目标之间分割的"<ahref="https://www.zhihu.com/search?q=模型稀疏性&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">模型稀疏性</a>"。</p><p>这里没有什么新东西，我也没有提出任何新的观点。这些内容在2019年的T5论文中就已经存在，并在UL2论文中得到了重申。</p><p>现在让我们来谈谈目标函数。</p><h2id="关于去噪目标的思考-不好用吗难以扩展吗太容易了吗">关于去噪目标的思考(不好用吗？难以扩展吗？太容易了吗？)</h2><p>我提到的去噪目标是指任何形式的“跨度损坏（spancorruption）”任务。这有时被称为“填充（infilling）”或“填空（fill in theblank）”。关于如何表达它有很多变体，例如，跨度长度（spanlength）、随机性（<ahref="https://www.zhihu.com/search?q=randomness&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">randomness</a>）、哨兵标记等（sentineltokens）等等。</p><p>虽然 BERT 风格模型中的去噪目标大多是“in-place”的（例如，在<ahref="https://www.zhihu.com/search?q=掩码标记&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">掩码标记</a>之上添加分类头），但稍微现代一点的方法是“T5风格”，即可以由编码器-解码器或仅解码器模型处理的数据转换。在这种数据转换中，掩码标记只是为了模型预测而“移到后面”。</p><p>预训练的主要目标是构建一个有用的内部表示，以便能够以最有效的方式对下游任务进行对齐。内部表示越好，以后使用这些学习到的表示来做任何有用的事情就越容易。简单的下一个词预测“<ahref="https://www.zhihu.com/search?q=因果语言建模&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">因果语言建模</a>”目标被证明在这方面做得很好，并且一直是LLM 革命的基石。现在的问题是去噪目标是否同样好。</p><p>从公开的信息来看，我们知道 T5-11B 即使在对齐/SFT后也能很好地工作（Flan-T5 XXL 的 MMLU 得分超过55，对于这种规模和那个时代的模型来说已经相当不错了）。因此，我们可以得出一些结论，即去噪目标的迁移过程（预训练-&gt; 对齐）在这个规模上运行得相当合理。</p><p>去噪目标很棒，但作为独立目标来说还不够。一个很大的缺点是<strong>由于“损失曝光（lossexposure）”较少的原因</strong>。在去噪目标中，只有少量标记被掩码mask并因此被学习（即在损失中被考虑）。相反，在常规语言建模中，这接近100%。这使得每个 FLOP 的样本效率非常低，这使得去噪目标在基于 FLOP的比较中处于极大的劣势。</p><p>另一个缺点是，去噪目标比常规语言建模更不自然，因为它以一种奇怪的方式重新格式化输入/输出，这使得它们在少样本学习中有点尴尬。（虽然仍然可以调整这些模型在少样本任务上表现得相当不错）。因此，我认为去噪目标应该几乎只用作常规语言建模的补充目标。</p><h2 id="统一时代的早期以及-xberts-灭绝的原因">统一时代的早期以及 <ahref="https://www.zhihu.com/search?q=xBERTs&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">xBERTs</a>灭绝的原因</h2><p>统一时代初期，<ahref="https://www.zhihu.com/search?q=BERT%20类模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">BERT类模型</a>逐渐被淘汰是一个有趣的阶段，如今很少有人提及。这个过程是悄无声息的，这也解释了为什么我们现在看不到任何大型的BERT 模型了。原因主要在于模型的统一和任务/建模范式的转变。BERT风格的模型笨拙，<strong>但 BERT模型真正被淘汰的原因是人们想要一次性完成所有任务，这导致了一种更好的去噪方法——使用<ahref="https://www.zhihu.com/search?q=自回归模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">自回归模型</a>。</strong></p><p>在 2018 年到 2021年期间，存在一个隐性的范式转变，从单任务微调转向大规模<ahref="https://www.zhihu.com/search?q=多任务模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">多任务模型</a>。这逐渐将我们引向了如今看到的统一“SFT”模型，这些模型是通用的、多功能的。<strong>而用BERT来实现这一点非常困难。我认为这与“去噪”本身关系不大。人们只是找到了用另一种模型（例如T5）重新表达<ahref="https://www.zhihu.com/search?q=去噪预训练&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">去噪预训练</a>任务的方法，这使得BERT风格的模型在此时基本上被淘汰了，因为存在一个严格更好的替代方案。</strong></p><p>更具体地说，编码器-解码器和仅解码器模型能够一次表达多个任务，而不需要特定任务的分类头。对于编码器-解码器模型，如果解码器成为了阻碍，研究人员和工程师也开始发现，移除编码器也能达到与BERT 编码器一样好的效果。此外，它还保留了双向注意力机制，使 BERT在小型（通常是生产）规模上比 <ahref="https://www.zhihu.com/search?q=GPT%20模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">GPT模型</a>更具竞争力。</p><h2 id="降噪目标的价值">降噪目标的价值</h2><p><ahref="https://www.zhihu.com/search?q=降噪预训练&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">降噪预训练</a>目标也学习预测下一个词，类似于常规的语言模型。然而，与常规的因果语言模型不同，它对序列应用数据转换，使得模型学习“填补空白”，而不是简单地预测自然出现的从左到右的文本。</p><p>值得注意的是，降噪目标有时也被称为“填充任务（infillingtasks）”，有时与常规的语言建模任务一起混合到预训练中。</p><p>虽然确切的配置和实现细节可能有所不同，但如今的现代大型语言模型可能会在某种程度上使用语言建模和填充的组合。有趣的是，这种LM + 填充的混合似乎在同一时间传播开来（例如，<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2205.05131">UL2</a>、<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2207.14255">FIM</a>、<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.02414">GLM</a>、<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2201.07520">CM3</a>），许多团队都以某种方式带来了这种混合的独特风格。顺便说一句，以这种方式训练的最大公开披露和报告的模型可能是<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2305.10403">PaLM-2</a>。</p><p>同样值得注意的是，预训练任务混合可以按顺序堆叠，并不一定需要同时混合，例如，<ahref="https://www.zhihu.com/search?q=Flan-T5&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">Flan-T5</a>最初在 1T 跨度损坏标记上进行训练，并在 <ahref="https://www.zhihu.com/search?q=flan&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">flan</a>指令微调之前切换到 100B标记的前缀语言建模目标。在某种程度上，这算得上是一种混合降噪/LM目标模型。需要明确的是，前缀语言建模目标（不要与架构混淆）只是在随机确定的分割点处进行因果语言建模，并将其发送到输入端（没有损失和<ahref="https://www.zhihu.com/search?q=非因果掩码&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">非因果掩码</a>）。</p><p>顺便说一句，填充可能起源于代码大型语言模型领域，其中填补空白是编码应用程序更需要的功能。同时，UL2的动机更多的是统一降噪目标和双向大型语言模型擅长处理的任务类别，以及本质上是生成性的任务（例如，摘要或开放式生成）。这种自回归式降噪“向后移动”的一个优点是，它允许模型不仅学习更长的范围依赖关系，而且还隐式地从<ahref="https://www.zhihu.com/search?q=非显式双向注意力&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">非显式双向注意力</a>中获益（因为你已经看到了未来才能填补空白）。</p><p>经验表明，降噪目标学习的表示在某些类型的任务中表现更好，有时效率更高。在<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2210.11399">U-PaLM</a>论文中，我们展示了少量跨度损坏的向上训练如何改变行为并在 BIG-Bench任务集上出现。最重要的是，使用这种目标训练的模型进行微调通常会导致更好的监督微调模型，尤其是在较小规模下。</p><p>在单任务微调方面，你可以看到<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2204.02311">PaLM-162B</a> 模型被一个更小的 <ahref="https://www.zhihu.com/search?q=T5%20模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">T5模型</a>击败。<ahref="https://www.zhihu.com/search?q=双向注意力&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">双向注意力</a>+降噪目标在相对较小的规模上发挥了作用！我相信许多从业人员现在也看到了这种情况，尤其是在生产环境中。</p><h2 id="双向注意力机制如何">双向注意力机制如何？</h2><p>双向注意力机制是语言模型的一个有趣的“归纳偏置（inductivebias）”，它通常与目标函数和主干网络（modelbackbones）混淆。归纳偏置的有用性在不同的计算区域会有所不同，并且可能对不同计算区域的缩放曲线产生不同的影响。也就是说，在更大的规模上，双向注意力机制可能不像在更小的规模上那么重要，或者对不同的任务或模态有不同的影响。例如，<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2407.07726v1">PaliGemma</a>使用了 PrefixLM 架构。</p><p>正如 Hyung Won 在他的<ahref="https://link.zhihu.com/?target=https%3A//x.com/hwchung27/status/1800676312916656592">讲座</a>中指出的那样，PrefixLM模型（具有双向注意力的解码器模型）也存在缓存问题，这是这种架构的内在缺陷。但是，我认为有很多方法可以解决这个问题，但这超出了本文的范围。</p><h2 id="编码器-解码器架构的优缺点">编码器-解码器架构的优缺点</h2><p>编码器-解码器架构相较于单纯的解码器模型，确实有一些优势。首先，编码器一侧不受因果掩码的限制。在一定程度上，你可以尽情使用注意力层，进行激进的池化或任何形式的线性注意力，而无需担心自回归设计限制。这是一种将不太重要的“上下文”卸载到编码器的好方法。你还可以使编码器更小，这也很不错。</p><p>编码器-解码器架构的必要性，一个例子就是 <ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2106.12672">Charformer</a>，它允许我们在编码器上尽情发挥，并减轻字节级模型的速度缺陷。编码器端的创新，可以在不担心因果掩码主要重构的情况下，快速取得成果。</p><p>另一方面，编码器-解码器架构相较于 PrefixLM的一个缺点是，输入和目标必须具有固定的分配预算。例如，如果输入预算为1024 个token，则编码器一侧必须填充到该值，这会导致大量的潜在计算浪费。相反，在PrefixLM 中，输入和目标可以直接串联，从而减轻了这个问题。</p><h2 id="与当下模型的相关性及关键要点">与当下模型的相关性及关键要点</h2><p>在当今的 LLM研究和实践中，能够从架构和预训练的角度理解归纳偏差是至关重要的一点。理解这些基本差异有助于我们推断并不断创新。以下是一些关键要点：</p><ul><li>编码器-解码器模型和仅解码器模型都是自回归模型，它们在实现层面存在差异，并各有优缺点。它们体现了细微的归纳偏差差异。最佳使用方式实际上取决于下游应用场景和应用约束。另一方面，除了大多数LLM 使用场景和一些利基应用场景外，BERT风格的编码器模型通常被认为已经过时。</li><li>去噪目标通常与 CLM相互补充。它们只是在预训练中作为“辅助目标”出现。使用去噪目标训练 CLM通常会有所帮助。虽然这种情况在代码模型中非常常见（例如，代码填充），但对于当今的通用模型来说，在使用CLM 进行预训练时，加入一些去噪目标也并非罕见（但并非强制性）。</li><li>双向注意力在较小规模下效果显著，但在较大规模下通常是可选的。这主要是一种经验性结论。我认为双向注意力是一种归纳偏差的形式，就像对Transformer 模型的许多其他修改一样。</li><li>我们没有看到任何规模化的 <ahref="https://www.zhihu.com/search?q=xBERT%20模型&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3565729240%7D">xBERT模型</a>在运行：BERT 模型被更灵活的去噪（自回归）T5模型所取代。这主要归因于范式统一，人们希望用一个通用模型（而不是特定任务模型）来执行任何任务。与此同时，自回归去噪有时会被作为辅助目标添加到因果语言模型中。</li></ul>]]></content>
    
    
    <categories>
      
      <category>模型架构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
      <tag>架构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>激活函数简明教程</title>
    <link href="/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.html"/>
    <url>/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.html</url>
    
    <content type="html"><![CDATA[<h2 id="一什么是激活函数">一、什么是激活函数？</h2><p>在接触到深度学习（DeepLearning）后，特别是神经网络中，我们会发现在每一层的神经网络输出后都会使用一个函数（比如sigmoid，tanh，Relu等等）对结果进行运算，这个函数就是激活函数（ActivationFunction）。那么为什么需要添加激活函数呢？如果不添加又会产生什么问题呢？</p><span id="more"></span><p>首先，我们知道神经网络模拟了人类神经元的工作机理，<strong>激活函数（ActivationFunction）是一种添加到人工神经网络中的函数，旨在帮助网络学习数据中的复杂模式。在神经元中，输入的input经过一系列加权求和后作用于另一个函数，这个函数就是这里的激活函数</strong>。类似于人类大脑中基于神经元的模型，激活函数最终决定了是否传递信号以及要发射给下一个神经元的内容。在人工神经网络中，一个节点的激活函数定义了该节点在给定的输入或输入集合下的输出。标准的计算机芯片电路可以看作是根据输入得到开（1）或关（0）输出的数字电路激活函数。</p><p>激活函数可以分为<strong>线性激活函数</strong>（线性方程控制输入到输出的映射，如f(x)=x等）以及<strong>非线性激活函数</strong>（非线性方程控制输入到输出的映射，比如Sigmoid、Tanh、ReLU、LReLU、PReLU、Swish等）</p><p><strong>这里来解释下为什么要使用激活函数？</strong></p><blockquote><p>因为神经网络中每一层的输入输出都是一个线性求和的过程，下一层的输出只是承接了上一层输入函数的线性变换，所以如果没有激活函数，那么无论你构造的神经网络多么复杂，有多少层，最后的输出都是输入的线性组合，纯粹的线性组合并不能够解决更为复杂的问题。而引入激活函数之后，我们会发现常见的激活函数都是非线性的，因此也会给神经元引入非线性元素，使得神经网络可以逼近其他的任何非线性函数，这样可以使得神经网络应用到更多非线性模型中。</p></blockquote><p>在神经网络中，神经元的工作原理可以用下图进行表示：</p><figure><img src="/images/激活函数/v2-e6b70a32400c7e5ad7833569175a3ebc.jpg"alt="v2-e6b70a32400c7e5ad7833569175a3ebc" /><figcaptionaria-hidden="true">v2-e6b70a32400c7e5ad7833569175a3ebc</figcaption></figure><p>上述过程的数学可视化过程如下图所示：</p><figure><img src="/images/激活函数/v2-6c7946897995143a9c0991f366c877fc.jpg"alt="v2-6c7946897995143a9c0991f366c877fc" /><figcaptionaria-hidden="true">v2-6c7946897995143a9c0991f366c877fc</figcaption></figure><p>一般来说，在神经元中，激活函数是很重要的一部分，为了增强网络的表示能力和学习能力，神经网络的激活函数都是非线性的，通常具有以下几点性质：</p><ul><li>连续并可导（允许少数点上不可导），可导的激活函数可以直接利用数值优化的方法来学习网络参数；</li><li>激活函数及其导数要尽可能简单一些，太复杂不利于提高网络计算率；</li><li>激活函数的导函数值域要在一个合适的区间内，不能太大也不能太小，否则会影响训练的效率和稳定性。</li></ul><h2 id="二常见的激活函数">二、常见的激活函数</h2><h3 id="sigmoid函数">1. Sigmoid函数</h3><p>Sigmoid函数也叫Logistic函数，用于隐层神经元输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。在特征相差比较复杂或是相差不是特别大时效果比较好。sigmoid是一个十分常见的激活函数，函数的表达式如下：</p><figure><img src="/images/激活函数/02-神经网络基础_11.jpeg"alt="02-神经网络基础_11" /><figcaption aria-hidden="true">02-神经网络基础_11</figcaption></figure><p><strong>在什么情况下适合使用 Sigmoid 激活函数呢？</strong></p><ul><li>Sigmoid 函数的输出范围是 0 到 1。由于输出值限定在 0到1，因此它对每个神经元的输出进行了归一化；</li><li>用于将预测概率作为输出的模型。由于概率的取值范围是 0 到 1，因此Sigmoid 函数非常合适；</li><li>梯度平滑，避免「跳跃」的输出值；</li><li>函数是可微的。这意味着可以找到任意两个点的 sigmoid 曲线的斜率；</li><li>明确的预测，即非常接近 1 或 0。</li></ul><p><strong>Sigmoid 激活函数存在的不足：</strong></p><ul><li><strong>梯度消失</strong>：注意：Sigmoid 函数趋近 0 和 1的时候变化率会变得平坦，也就是说，Sigmoid 的梯度趋近于 0。神经网络使用Sigmoid 激活函数进行反向传播时，输出接近 0 或 1 的神经元其梯度趋近于0。这些神经元叫作饱和神经元。因此，这些神经元的权重不会更新。此外，与此类神经元相连的神经元的权重也更新得很慢。该问题叫作梯度消失。因此，想象一下，如果一个大型神经网络包含Sigmoid神经元，而其中很多个都处于饱和状态，那么该网络无法执行反向传播。</li><li><strong>不以零为中心</strong>：Sigmoid输出不以零为中心的,，输出恒大于0，非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（BiasShift），并进一步使得梯度下降的收敛速度变慢。</li><li><strong>计算成本高昂</strong>：exp()函数与其他非线性激活函数相比，计算成本高昂，计算机运行起来速度较慢。</li></ul><h3 id="tanh双曲正切激活函数">2. Tanh/双曲正切激活函数</h3><p>Tanh 激活函数又叫作双曲正切激活函数（hyperbolic tangent activationfunction）。与 Sigmoid 函数类似，Tanh 函数也使用真值，但 Tanh函数将其压缩至-1 到 1 的区间内。与 Sigmoid 不同，Tanh函数的输出以零为中心，因为区间在-1 到 1 之间。</p><figure><img src="/images/激活函数/02-神经网络基础_15.jpeg"alt="02-神经网络基础_15" /><figcaption aria-hidden="true">02-神经网络基础_15</figcaption></figure><p>我们可以发现Tanh 函数可以看作放大并平移的Logistic 函数，其值域是(−1,1)。Tanh与sigmoid的关系如下：</p><p>𝑡𝑎𝑛ℎ(𝑥)=2𝑠𝑖𝑔𝑚𝑜𝑖𝑑(2𝑥)−1</p><p>tanh 激活函数的图像也是 S 形，作为一个双曲正切函数，tanh 函数和sigmoid 函数的曲线相对相似。但是它比 sigmoid 函数更有一些优势。 你可以将Tanh 函数想象成两个 Sigmoid 函数放在一起。在实践中，Tanh函数的使用优先性高于 Sigmoid函数。负数输入被当作负值，零输入值的映射接近零，正数输入被当作正值：</p><ul><li>当输入较大或较小时，输出几乎是平滑的并且梯度较小，这不利于权重更新。二者的区别在于输出间隔，tanh的输出间隔为 1，并且整个函数以 0 为中心，比 sigmoid 函数更好；</li><li>在 tanh 图中，负输入将被强映射为负，而零输入被映射为接近零。</li></ul><p><strong>tanh存在的不足：</strong></p><ul><li>与sigmoid类似，Tanh函数也会有<strong>梯度消失</strong>的问题，因此在饱和时（x很大或很小时）也会「杀死」梯度。</li></ul><p>注意：在一般的二元分类问题中，tanh 函数用于隐藏层，而 sigmoid函数用于输出层，但这并不是固定的，需要根据特定问题进行调整。</p><h3 id="relu激活函数">3. ReLU激活函数</h3><p>ReLU函数又称为修正线性单元（Rectified LinearUnit），是一种分段线性函数，其弥补了sigmoid函数以及tanh函数的梯度消失问题，在目前的深度神经网络中被广泛使用。ReLU函数本质上是一个斜坡（ramp）函数，公式及函数图像如下：</p><figure><img src="/images/激活函数/image-20240607215744379.png"alt="image-20240607215744379" /><figcaption aria-hidden="true">image-20240607215744379</figcaption></figure><p>ReLU 函数是深度学习中较为流行的一种激活函数，相比于 sigmoid 函数和tanh 函数，它具有如下优点：</p><ul><li>当输入为正时，导数为1，一定程度上改善了梯度消失问题，加速梯度下降的收敛速度；</li><li>计算速度快得多。ReLU 函数中只存在线性关系，因此它的计算速度比sigmoid 和 tanh 更快。</li><li>被认为具有生物学合理性（BiologicalPlausibility）,比如单侧抑制、宽兴奋边界（即兴奋程度可以非常高）</li></ul><p><strong>ReLU函数的不足：</strong></p><ul><li>Dead ReLU 问题。当输入为负时，ReLU完全失效，在正向传播过程中，这不是问题。有些区域很敏感，有些则不敏感。但是在反向传播过程中，如果输入负数，则梯度将完全为零；</li></ul><blockquote><p><strong>【DeadReLU问题】</strong>ReLU神经元在训练时比较容易“死亡”。在训练时，如果参数在一次不恰当的更新后，第一个隐藏层中的某个ReLU神经元在所有的训练数据上都不能被激活，那么这个神经元自身参数的梯度永远都会是0，在以后的训练过程中永远不能被激活。这种现象称为死亡ReLU问题，并且也有可能会发生在其他隐藏层。</p></blockquote><ul><li>不以零为中心：和 Sigmoid 激活函数类似，ReLU函数的输出不以零为中心，ReLU 函数的输出为 0或正数,给后一层的神经网络引入偏置偏移，会影响梯度下降的效率。</li></ul><h3 id="leaky-relu">4. Leaky ReLU</h3><p>为了解决 ReLU 激活函数中的梯度消失问题，当 x &lt; 0 时，我们使用Leaky ReLU——该函数试图修复 dead ReLU 问题。下面我们就来详细了解 LeakyReLU。</p><p>函数表达式以及图像如下：</p><p>LeakyReLU (𝑥)={𝑥 if 𝑥&gt;0𝛾𝑥 if 𝑥≤0=max(0,𝑥)+𝛾min(0,𝑥),</p><p>其中 𝛾 是一个很小的数，如0.1,0.01等等。这里，令 𝛾=0.1 进行展示：</p><figure><imgsrc="/images/激活函数/v2-a942719eba0ee2d65db0a8a030d280ba_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>对于 𝛾&lt;1 ，Leaky ReLU也可以写作：</p><p>LeakyReLU( 𝑥)=max(𝑥,𝛾𝑥)</p><p>相当于是一个比较简单的Maxout单元（Maxout函数会在下面讲解）</p><p><strong>为什么使用Leaky ReLU会比ReLU效果要好呢？</strong></p><ul><li>Leaky ReLU 通过把 x的非常小的线性分量给予负输入（0.01x）来调整负值的零梯度（zerogradients）问题，当 x &lt; 0 时，它得到 0.1的正梯度。该函数一定程度上缓解了 dead ReLU 问题，</li><li>leak 有助于扩大 ReLU 函数的范围，通常 a 的值为 0.01 左右；</li><li>Leaky ReLU 的函数范围是（负无穷到正无穷）</li></ul><p>尽管Leaky ReLU具备 ReLU激活函数的所有特征（如计算高效、快速收敛、在正区域内不会饱和），但并不能完全证明在实际操作中LeakyReLU 总是比 ReLU 更好。</p><h3 id="parametric-relu激活函数">5. Parametric ReLU激活函数</h3><p>Leaky ReLU是在ReLU的基础上针对存在的问题进行的扩展。除此以外也可以从其他角度进行扩展，不让x 乘常数项，而是让 x 乘超参数，这看起来比 Leaky ReLU效果要好，这一种扩展就是 Parametric ReLU，即为带参数的ReLU函数。</p><p>函数表达式为：</p><p>PReLU𝑖⁡(𝑥)={𝑥 if 𝑥&gt;0𝛾𝑖𝑥 if 𝑥≤0=max(0,𝑥)+𝛾𝑖min(0,𝑥),</p><p>其中 𝛾𝑖 是超参数，对应了 𝑥≤0时函数的斜率。这里引入了一个随机的超参数，它可以被学习，可以对它进行反向传播。不同神经元可以有不同的参数，其中的i对应了第i个神经元，这使神经元能够选择负区域最好的梯度，有了这种能力，它们可以变成ReLU 或 Leaky ReLU。</p><p>如果 𝛾𝑖=0 ，那么PReLU 就退化为ReLU；</p><p>如果 𝛾𝑖 为一个很小的常数，则PReLU 可以看作Leaky ReLU;</p><p>PReLU可以允许不同神经元具有不同的参数，也可以一组神经元共享一个参数。</p><p>在很多情况下，最好使用 ReLU，但是你可以使用 Leaky ReLU 或 ParametricReLU 进行实践，看看哪一种方式是否更适合你的问题。</p><h3 id="elu激活函数">6. ELU激活函数</h3><p>ELU（Exponential Linear Unit） 的提出同样也是针对解决ReLU负数部分存在的问题，由Djork等人提出,被证实有较高的噪声鲁棒性。ELU激活函数对𝑥 小于零的情况采用类似指数计算的方式进行输出。与 ReLU 相比，ELU有负值，这会使激活的平均值接近零。均值激活接近于零可以使学习更快，因为它们使梯度更接近自然梯度。函数表达式为</p><p>g(𝑥)=ELU(𝑥)={𝑥,𝑥&gt;0𝛼(e𝑥−1),𝑥⩽0</p><figure><imgsrc="/images/激活函数/v2-605fe7d42badd0d1c38b51f53461834a_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>显然，ELU 具有 ReLU 的所有优点，并且：</p><ul><li>没有 Dead ReLU 问题，输出的平均值接近 0，以 0 为中心；</li><li>ELU通过减少偏置偏移的影响，使正常梯度更接近于单位自然梯度，从而使均值向零加速学习；</li><li>ELU 在较小的输入下会饱和至负值，从而减少前向传播的变异和信息。</li></ul><p>一个小问题是它的<strong>计算强度更高，计算量较大</strong>。与 LeakyReLU 类似，尽管理论上比 ReLU 要好，但目前在实践中没有充分的证据表明 ELU总是比 ReLU 好。</p><h3 id="selu激活函数">7. SeLU激活函数</h3><p><a href="https://arxiv.org/pdf/1706.02515.pdf">Self-NormalizingNeural Networks(SNNs)</a>论文中SNN基于缩放的指数线性单位“SELU”，可诱导自标准化属性（例如方差稳定化），从而避免了梯度的爆炸和消失。SELU函数是给ELU函数乘上系数 𝜆 , 即 𝑆𝐸𝐿𝑈(𝑥)=𝜆⋅𝐸𝐿𝑈(𝑥)</p><p>𝑓(𝑥)=𝜆{𝛼(𝑒𝑥−1)𝑥≤0𝑥𝑥&gt;0</p><p>通过论文中大量的证明，作者给出了 𝜆 和 𝛼 的值：</p><figure><imgsrc="/images/激活函数/v2-dcbf6219ccc4b44e5c8305444311f292_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>SELU函数的特点是：</p><ul><li>它的值有正有负：在整个ReLU的family里里面，除了一开始最原始的ReLU以外都有负值，该函数也贯彻了这个特性；</li><li>有Saturation Region：其他的ReLU他们没有SaturationRegion，但是他有Saturation Region，不过ELU其实也有SaturationRegion，因为SELU就只是ELU乘上一个λ而已;乘上这个λ有什么不同？乘上λ，让它在某些区域的斜率是大于1的，意味着说你进来一个比较小的变化，通过Region以后，他把你的变化放大1.0507700987倍，所以它的input能是会被放大的，而且这是他一个ELU的没有的特色。</li></ul><h3 id="softmax激活函数">8. Softmax激活函数</h3><p>Softmax是用于多类分类问题的激活函数，在多类分类问题中，超过两个类标签则需要类成员关系。对于长度为K 的任意实向量，Softmax 可以将其压缩为长度为K，值在（0，1）范围内，并且向量中元素的总和为 1 的实向量。</p><p>函数表达式如下： 𝑆𝑖=𝑒𝑖∑𝑗𝑒𝑗</p><figure><img src="/images/激活函数/v2-fb6770a27f3667c284f4a3318de98777.jpg"alt="v2-fb6770a27f3667c284f4a3318de98777" /><figcaptionaria-hidden="true">v2-fb6770a27f3667c284f4a3318de98777</figcaption></figure><p>Softmax 与正常的 max 函数不同：max 函数仅输出最大值，但 Softmax确保较小的值具有较小的概率，并且不会直接丢弃。我们可以认为它是 argmax函数的概率版本或「soft」版本。</p><p>Softmax 函数的分母结合了原始输出值的所有因子，这意味着 Softmax函数获得的各种概率彼此相关。</p><p><strong>Softmax 激活函数的不足：</strong></p><ul><li>在零点不可微；</li><li>负输入的梯度为零，这意味着对于该区域的激活，权重不会在反向传播期间更新，因此会产生永不激活的死亡神经元。</li></ul><h3 id="swish激活函数">9. Swish激活函数</h3><p>Swish激活函数又叫作自门控激活函数，它由谷歌的研究者发布，数学表达式为：</p><p>𝜎(𝑥)=𝑥∗𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝛽𝑥)=𝑥𝜎(𝛽𝑥)=𝑥1+𝑒−𝛽𝑥</p><p>𝛽 为可学习的参数或一个固定超参数， 𝜎(𝑥)∈(0,1)可以看做是一种软性的门控机制。</p><p>当 𝜎(𝛽𝑥)接近于1时，门处于“<strong>开</strong>”状态，激活函数的输出近似于x本身；</p><p>当 𝜎(𝛽𝑥)接近于0时，门处于“<strong>关</strong>”状态，激活函数的输出近似于0；</p><p>当 𝛽=0 时，Swish 函数变成线性函数 𝑥/2 ;</p><p>当 𝛽=1 时，Swish 函数在 𝑥&gt;0 时近似线性，在 𝑥&lt;0时近似饱和，同时具有一定的非单调性；</p><p>当 𝛽 趋于正无穷时， 𝜎(𝛽𝑥)函数趋向于离散的0-1函数，Swish函数近似为ReLU函数；</p><p>因此，<strong>Swish 函数可以看作线性函数和ReLU函数之间的非线性插值函数</strong>，<strong>其程度由参数 𝛽控制。</strong></p><figure><img src="/images/激活函数/v2-eac833937a604908f808396a10f2b852.jpg"alt="v2-eac833937a604908f808396a10f2b852" /><figcaptionaria-hidden="true">v2-eac833937a604908f808396a10f2b852</figcaption></figure><h3 id="maxout激活函数">10. Maxout激活函数</h3><p>通常情况下，如果激活函数采用sigmoid函数的话，在前向传播过程中，隐含层节点的输出表达式为：</p><p>ℎ𝑖(𝑥)=sigmoid⁡(𝑥⊤𝑊…𝑖+𝑏𝑖)</p><p>其中，一般情况下，W是2维的，这里表示的i是第i列，...表示的是对应第i列中的所有行。Maxout出现在ICML2013上，作者Goodfellow将maxout和dropout结合后，号称在MNIST,CIFAR-10, CIFAR-100,SVHN这4个数据上都取得了start-of-art的识别率。Sigmoid、ReLU等激活函数的输入是神经元的净输入z，是一个标量，而Maxout单元的输入是上一层神经元的全部原始输出，是一个向量x。这里如果采用maxout函数，表达式如下：</p><p>𝑓𝑖(𝑥)=max𝑗∈[1,𝑘]𝑧𝑖𝑗</p><p>𝑧𝑖𝑗=𝑥𝑇𝑊…𝑖𝑗+𝑏𝑖𝑗,𝑊∈𝑅𝑑×𝑚×𝑘</p><p>这里的W是3维的，尺寸为 d<strong>m</strong>k，其中d表示输入层节点的个数，m表示隐含层节点的个数，k表示每个隐含层节点对应了k个”隐隐含层”节点，这k个”隐隐含层”节点都是线性输出的，而maxout的每个节点就是取这k个”隐隐含层”节点输出值中最大的那个值。因为激发函数中有了max操作，所以整个maxout网络也是一种非线性的变换。因此当我们看到常规结构的神经网络时，如果它使用了maxout激发，则我们头脑中应该自动将这个”隐隐含层”节点加入。</p><p>Maxout激活函数特点：maxout激活函数并不是一个固定的函数，不像Sigmod、Relu、Tanh等函数，是一个固定的函数方程。它是一个可学习的激活函数，因为我们W参数是学习变化的。<strong>Maxout单元不但是净输入到输出的非线性映射，而是整体学习输入到输出之间的非线性映射关系，可以看做任意凸函数的分段线性近似，并且在有限的点上是不可微的：</strong></p><figure><img src="/images/激活函数/v2-2f92ec95045872d70ada6d84aadd063f.jpg"alt="v2-2f92ec95045872d70ada6d84aadd063f" /><figcaptionaria-hidden="true">v2-2f92ec95045872d70ada6d84aadd063f</figcaption></figure><p>优点：Maxout的拟合能力非常强，可以拟合任意的凸函数。Maxout具有ReLU的所有优点，线性、不饱和性。同时没有ReLU的一些缺点。如：神经元的死亡。实验结果表明Maxout与Dropout组合使用可以发挥比较好的效果。</p><p>缺点：从上面的激活函数公式中可以看出，每个神经元中有两组(w,b)参数，那么参数量就增加了一倍，这就导致了整体参数的数量激增。</p><h3 id="softplus激活函数">11. Softplus激活函数</h3><p>Softplus函数是Sigmoid函数原函数,即softplus函数求导的结果就是sigmoid函数。Softplus可以看做是ReLU函数的一个平滑版本，函数表达式如下：</p><p>𝑆𝑜𝑓𝑡𝑝𝑙𝑢𝑠(𝑥)=𝑓(𝑥)=log⁡(1+𝑒𝑥)</p><p>𝑓′(𝑥)=𝑒𝑥1+𝑒𝑥 =11+𝑒−𝑥=𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝑥)</p><figure><img src="/images/激活函数/v2-dd6e5088824750221b753fb0429c35bb.jpg"alt="v2-dd6e5088824750221b753fb0429c35bb" /><figcaptionaria-hidden="true">v2-dd6e5088824750221b753fb0429c35bb</figcaption></figure><p>Softplus函数加了1是为了保证非负性。Softplus可以看作是强制非负校正函数max(0,x)平滑版本。红色的即为ReLU。</p><p>Softplus 函数其导数刚好是Logistic 函数．Softplus函数虽然也具有单侧抑制、宽兴奋边界的特性，却没有稀疏激活性．</p><h2 id="三公式汇总">三、公式汇总</h2><figure><img src="/images/激活函数/image-20240607220141448.png"alt="image-20240607220141448" /><figcaption aria-hidden="true">image-20240607220141448</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>激活函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>神经网络核心知识点梳理--一图了然</title>
    <link href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%A7%A3.html"/>
    <url>/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%A7%A3.html</url>
    
    <content type="html"><![CDATA[<p>基于上篇文章的简单入门，这里重点梳理了一下神经网络的核心知识点，并以图片的方式呈现（点击放大哦~）：</p><figure><img src="/images/神经网络图解/神经网络核心知识图解.png"alt="神经网络核心知识点梳理" /><figcaption aria-hidden="true">神经网络核心知识点梳理</figcaption></figure><h2 id="网络结构">1.网络结构</h2><h3 id="输入层">1.1 输入层</h3><ul><li>1x2矩阵的输入数据X1和X2</li><li>Bias(偏置)项作为额外输入,增强模型表达能力</li></ul><h3 id="隐藏层">1.2 隐藏层</h3><ul><li>6维度的神经元结构</li><li>每个神经元包含加权求和(Σ)和激活函数(f)</li><li><ahref="https://linxkon.github.io/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.html">常用激活函数:</a><ul><li><strong>Sigmoid</strong>: σ(x) = 1 / (1 + e^(-x))</li><li><strong>Tanh</strong>: tanh(x) = (e^x - e^(-x)) / (e^x +e^(-x))</li><li><strong>ReLU</strong>: f(x) = max(0, x)</li><li><strong>Leaky ReLU</strong>: f(x) = max(αx, x), 其中α是小正数</li></ul></li></ul><h3 id="输出层">1.3 输出层</h3><ul><li>1x4矩阵输出,对应4个分类</li><li>使用Softmax函数进行概率映射</li><li>交叉熵损失计算</li></ul><h3 id="权重矩阵">1.4 权重矩阵</h3><ul><li>Wa_i: 2x6维度,连接输入层和隐藏层</li><li>Wb_i: 6x4维度,连接隐藏层和输出层</li></ul><h2 id="训练过程详解">2.训练过程详解</h2><h3 id="前向传播">2.1 前向传播</h3><ul><li>数据从输入层经过加权和激活,传递到输出层</li><li>隐藏层计算: H = f(X * Wa_i + b1)</li><li>输出层计算: Y = softmax(H * Wb_i + b2)</li></ul><h3 id="概率映射">2.2 概率映射</h3><ul><li>Softmax函数: Si = e^zi / Σ(e^zj)</li><li>将神经网络的原始输出转换为概率分布</li><li>确保输出和为1,便于多分类问题的概率解释</li><li>得出概率结果方便下一步概率计算</li></ul><blockquote><p><strong>多分类问题</strong>使用softmax进行概率映射</p><p><strong>二分类问题</strong>用sigmoid进行概率映射</p></blockquote><h3 id="损失计算">2.3 损失计算</h3><p>损失计算可以分为分类损失和回归损失两种,</p><ul><li><p><label><input type="checkbox" /><ahref="https://linxkon.github.io/分类问题与回归问题的损失函数.html">详见本文</a></label></p></li><li><p>多分类交叉熵损失(Cross Entropy Loss): L = -Σ(yi * log(ŷi))其中yi为真实标签,ŷi为预测概率</p></li><li><p>对于二分类问题,可使用二元交叉熵: L = -(y * log(ŷ) + (1-y) *log(1-ŷ))</p></li><li><p>损失函数用于量化模型预测与真实标签的差异,惩罚与真实标签差异大的</p></li></ul><h3 id="反向传播">2.4 反向传播</h3><ul><li>计算损失函数对各层参数的梯度</li><li>使用链式法则逐层计算梯度</li><li>∂L/∂W = ∂L/∂Y * ∂Y/∂Z * ∂Z/∂W 其中Z为激活函数输入,W为权重</li></ul><h3 id="梯度下降">2.5 梯度下降</h3><h5 id="梯度下降相关概念">梯度下降相关概念:</h5><ul><li>正向传播+损失计算得出损失值来之后,我们希望找到损失函数取值最小的<strong>w(权重)</strong></li><li>因损失函数皆为凸函数(碗的形状),即寻找令损失函数的导数为0的w</li><li>并不是所有损失函数都能直接求导找到这个点,所以我们通过反向传播+梯度下降的方式迭代去求该w</li><li>我们知道函数的导数方向(即梯度)是函数增长最快的方向,我们想要得到令损失函数导数为0的w,就要找到损失函数的负梯度方向</li><li>基于以上思路,假设我们当前的w是W_old,我们求此刻损失函数的偏导值,增加符号以得到它的负梯度方向,并乘以系数η控制其前进的步伐大小,得到η * ∂L/∂W,再用W_old- η *∂L/∂W得到W_new,新的w可以让损失函数的取值更小,以此类推,便可以通过多次迭代求得令损失函数取得最小值的w</li></ul><p>综上,梯度下降的公式为:</p><p><strong>W = W - η * ∂L/∂W</strong></p><blockquote><p><strong>W</strong>：表示模型的参数（或权重），这些是我们希望优化的值。</p><p><strong>η</strong>（学习率）：这是一个超参数，控制每次更新步伐的大小。较大的学习率会导致更大的步伐，较小的学习率则会导致较小的步伐。选择合适的学习率非常重要，太大可能导致不稳定的收敛，太小可能导致收敛速度太慢。</p><p><strong>L</strong>（损失函数）：这是我们希望最小化的函数，它衡量了模型预测值与实际值之间的差距。</p><p><strong>∂L/∂W</strong>（损失函数对参数的梯度）：这是损失函数相对于参数的导数，表示了在当前参数值下，损失函数的变化率。通过计算这个梯度，我们可以知道如何调整参数W来减少损失函数的值。</p></blockquote><p><strong>根据梯度下降时batchsize的不同,梯度下降的方法可以划分为</strong></p><blockquote><p><strong>BGD批量梯度下降:</strong>全量样本allin训练,大型数据集基本不可行</p><p><strong>SGD随机梯度下降:</strong>随机抽取单样本放入模型训练,受异常值影响,梯度更新时波动较大,训练时间长</p><p><strong>MiniBatch小批量梯度下降:</strong>根据需求自由定义batchsize,兼具BGD和SGD的优点,收敛相对较快,最为常用</p></blockquote><h4 id="梯度下降优化方法">2.5.2梯度下降优化方法</h4><p>在某些情况下（如线性回归），损失函数是凸函数，找到其导数为零的点可以找到全局最小值。但在更复杂的模型（如深度神经网络）中，损失函数通常是非凸的，导数为零的点不一定是全局最小值,也可能是鞍点(局部最优点)。因此，需要使用适当的优化算法来逼近最优解。</p><h5 id="动量momentum">动量(Momentum):</h5><p>v = γv - η * ∂L/∂W W = W + v γ为动量系数,通常取0.9</p><h5 id="adam优化器">Adam优化器:</h5><p><strong>结合动量和自适应学习率</strong> mt = β1<em>mt-1 +(1-β1)</em>gt vt = β2<em>vt-1 + (1-β2)</em>gt^2 W = W - η * mt /(sqrt(vt) + ε) 其中β1, β2为超参数,通常取0.9和0.999</p><h3 id="正则化技术">2.6 正则化技术</h3><ul><li>L1正则化: 添加|W|项到损失函数,促进稀疏性</li><li>L2正则化: 添加||W||^2项,防止权重过大</li><li>Dropout: 训练时随机"丢弃"一部分神经元,防止过拟合</li><li>批量归一化(Batch Normalization):对每一层的输入进行标准化,加速训练收敛</li></ul><h2 id="高级训练技巧">3.高级训练技巧</h2><h3 id="参数初始化">3.1 参数初始化</h3><ul><li>Xavier初始化: Var(W) = 1/nin</li><li>Kaiming初始化: Var(W) = 2/nin (适用于ReLU激活)</li><li>均匀分布初始化</li><li>正态分布初始化</li><li>固定值初始化</li></ul><h3 id="学习率调整">3.2 学习率调整</h3><ul><li>学习率衰减: η = η0 / (1 + kt)</li><li>周期性学习率调整: Cosine Annealing</li><li>学习率预热(Warm-up): 从小学习率逐步增加到初始学习率</li></ul><h3 id="批量训练策略">3.3 批量训练策略</h3><ul><li>Mini-Batch: 平衡计算效率和梯度估计准确性</li><li>批大小选择: 较大批量可提高并行度,但可能影响泛化性</li></ul><h3 id="进阶优化策略">3.4 进阶优化策略</h3><ul><li>梯度裁剪: 防止梯度爆炸</li><li>学习率自适应: 如Adagrad、RMSprop等算法</li><li>早停(Early Stopping): 监控验证集性能,及时停止训练防止过拟合</li></ul><hr /><p>深入理解神经网络的结构、训练过程和优化技巧,对于构建高效且性能优异的模型至关重要。从基础的前向传播、损失计算,到复杂的优化算法和正则化技术,每个环节都在平衡模型的拟合能力和泛化性能。通过合理运用这些技术,我们可以训练出既能准确拟合训练数据,又具有良好泛化能力的神经网络模型。</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习框架中的动态图与静态图</title>
    <link href="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E5%9B%BE%E4%B8%8E%E9%9D%99%E6%80%81%E5%9B%BE.html"/>
    <url>/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B8%AD%E7%9A%84%E5%8A%A8%E6%80%81%E5%9B%BE%E4%B8%8E%E9%9D%99%E6%80%81%E5%9B%BE.html</url>
    
    <content type="html"><![CDATA[<p>深度学习框架中，动态图（Dynamic Computation Graph）和静态图（StaticComputationGraph）是两种构建和执行计算图的方式。他们一个面向开发,一个面向部署,各有优势。</p><span id="more"></span><h3 id="一.-动态图dynamic-computation-graph">一. 动态图（DynamicComputation Graph）</h3><p>动态图，也称为即时执行模式（EagerExecution），是指在代码运行时即时构建和执行计算图。这种方式的特点是：</p><ol type="1"><li><strong>即时性</strong>：每一行代码在运行时都会立即执行相应的计算操作。</li><li><strong>灵活性</strong>：因为计算图是在运行时动态构建的，修改和调试都非常方便。可以轻松地使用Python的控制流（如条件语句和循环）构建复杂的模型。</li><li><strong>直观性</strong>：代码更加直观和易于理解，便于调试和开发。</li></ol><p>代表性的深度学习框架有： - PyTorch - TensorFlow 2.x 的EagerExecution模式</p><p>示例（PyTorch）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 动态构建和执行计算图</span><br>x = torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], requires_grad=<span class="hljs-literal">True</span>)<br>y = x * <span class="hljs-number">2</span><br>z = y.mean()<br>z.backward()<br><br><span class="hljs-built_in">print</span>(x.grad)  <span class="hljs-comment"># 输出: tensor([0.6667, 0.6667, 0.6667])</span><br></code></pre></td></tr></table></figure><h3 id="二.-静态图static-computation-graph">二. 静态图（StaticComputation Graph）</h3><p>静态图，也称为定义-运行模式（Define-and-Run），是指在代码运行之前，先定义好计算图，然后再执行。这种方式的特点是：</p><ol type="1"><li><strong>高效性</strong>：由于计算图在运行前已经完全定义好，框架可以进行各种优化，提升执行效率和性能。</li><li><strong>可移植性</strong>：静态图可以保存为文件，便于在不同环境中加载和运行。</li><li><strong>可调度性</strong>：在执行前可以进行图的优化和分布式调度，提高资源利用率。</li></ol><p>代表性的深度学习框架有： - TensorFlow 1.x - TensorFlow 2.x 的GraphExecution模式</p><p>示例（TensorFlow 1.x）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br><span class="hljs-comment"># 定义计算图</span><br>x = tf.placeholder(tf.float32, shape=(<span class="hljs-literal">None</span>, <span class="hljs-number">3</span>))<br>y = x * <span class="hljs-number">2</span><br>z = tf.reduce_mean(y)<br><br><span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>    <span class="hljs-comment"># 执行计算图</span><br>    result = sess.run(z, feed_dict=&#123;x: [[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]]&#125;)<br>    <span class="hljs-built_in">print</span>(result)  <span class="hljs-comment"># 输出: 4.0</span><br></code></pre></td></tr></table></figure><h3 id="三.-对比总结">三. 对比总结</h3><ol type="1"><li><strong>开发体验</strong>：<ul><li><strong>动态图</strong>：开发体验更好，调试和代码修改更加方便，适合研究和快速原型开发。</li><li><strong>静态图</strong>：需要先定义完整的计算图，修改和调试相对复杂，但更适合大规模训练和部署。</li></ul></li><li><strong>执行性能</strong>：<ul><li><strong>动态图</strong>：灵活性高，但在大规模训练中，性能可能不如静态图。</li><li><strong>静态图</strong>：由于可以进行多种优化，执行性能通常更高，适合在生产环境中部署。</li></ul></li><li><strong>灵活性</strong>：<ul><li><strong>动态图</strong>：可以动态调整模型结构，支持复杂的控制流。</li><li><strong>静态图</strong>：在定义时就确定了模型结构，灵活性相对较低。</li></ul></li><li><strong>适用场景</strong>：<ul><li><strong>动态图</strong>：适用于研究、开发和模型调试。</li><li><strong>静态图</strong>：适用于模型训练和部署，尤其是在资源受限的环境下。</li></ul></li></ol><p>综合来看，动态图和静态图各有优劣，选择使用哪种方式取决于具体的应用需求和开发环境。在实际项目中，常常会根据不同的阶段和任务需求，灵活选择使用动态图或静态图。</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>概念</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch VS TensorFlow</title>
    <link href="/TensorFlow%20VS%20Pytorch.html"/>
    <url>/TensorFlow%20VS%20Pytorch.html</url>
    
    <content type="html"><![CDATA[<p>TensorFlow和PyTorch是两种流行的深度学习框架，它们各自具有独特的优缺点和优势领域。以下是对它们的比较：<span id="more"></span></p><h3 id="tensorflow">TensorFlow</h3><h4 id="优点">优点</h4><ol type="1"><li><strong>生态系统完善</strong>：TensorFlow提供了丰富的工具和库，如TensorFlowExtended (TFX)用于生产部署，TensorFlowLite用于移动设备，TensorFlow.js用于JavaScript开发等。</li><li><strong>高性能</strong>：通过TensorFlowServing，可以实现高效的模型部署和推理。此外，TensorFlow有XLA（加速线性代数）编译器，可以进一步优化性能。</li><li><strong>跨平台支持</strong>：TensorFlow可以在多种平台上运行，包括CPU、GPU、TPU，且支持分布式计算。</li><li><strong>社区和企业支持</strong>：TensorFlow由Google开发并维护，拥有广泛的社区支持和大量的企业用户。</li></ol><h4 id="缺点">缺点</h4><ol type="1"><li><strong>学习曲线陡峭</strong>：TensorFlow的API较为复杂，新手入门相对困难。</li><li><strong>调试困难</strong>：虽然TensorFlow 2.x版本引入了EagerExecution模式，提升了可调试性，但总体上调试体验仍不如PyTorch。</li></ol><h3 id="优势领域">优势领域</h3><ul><li><strong>生产环境</strong>：TensorFlow的工具链和生态系统使其非常适合于从研究到生产的全流程。</li><li><strong>大规模分布式训练</strong>：TensorFlow在大规模分布式训练方面具有明显优势。</li><li><strong>移动和嵌入式设备</strong>：TensorFlowLite专门优化了在移动和嵌入式设备上的性能。</li></ul><h3 id="pytorch">PyTorch</h3><h4 id="优点-1">优点</h4><ol type="1"><li><strong>易用性</strong>：PyTorch的API设计直观且友好，非常适合研究和实验。动态图计算模式使得代码更加灵活和易于调试。</li><li><strong>调试便捷</strong>：由于PyTorch使用动态图计算模式，开发者可以使用标准的Python调试工具来调试模型。</li><li><strong>动态计算图</strong>：PyTorch的动态计算图机制使得开发者可以在运行时改变模型结构，非常适合于研究和实验。</li><li><strong>社区支持</strong>：PyTorch由Facebook（现Meta）开发，得到广泛的学术界支持，许多研究论文和前沿技术都首先在PyTorch上实现。</li></ol><h4 id="缺点-1">缺点</h4><ol type="1"><li><strong>生态系统相对较小</strong>：相比TensorFlow，PyTorch的工具链和扩展库较少，虽然近年来有显著改进。</li><li><strong>生产部署工具较少</strong>：虽然PyTorch推出了TorchServe等部署工具，但整体上在生产部署方面的支持不如TensorFlow成熟。</li></ol><h3 id="优势领域-1">优势领域</h3><ul><li><strong>研究和实验</strong>：PyTorch因其灵活性和易用性，非常适合学术研究和快速原型开发。</li><li><strong>调试和开发</strong>：由于其动态计算图机制，开发和调试深度学习模型更加便捷。</li><li><strong>计算机视觉和自然语言处理</strong>：很多前沿的计算机视觉和自然语言处理研究和应用首先在PyTorch上实现。</li></ul><h3 id="总结">总结</h3><p>选择TensorFlow还是PyTorch主要取决于具体需求。如果你需要一个强大的生产环境，广泛的工具链支持，尤其是在大规模分布式训练和部署方面，TensorFlow可能是更好的选择。而如果你更关注研究、实验以及开发过程的灵活性和可调试性，PyTorch则可能更适合你。</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>学习框架</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NER与关系抽取任务——关系三元组抽取问题中常用的模型</title>
    <link href="/NER%E4%B8%8E%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9E%8B.html"/>
    <url>/NER%E4%B8%8E%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E4%BB%BB%E5%8A%A1%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9E%8B.html</url>
    
    <content type="html"><![CDATA[<p>文本关系抽取的研究工作本身可以划分为很多类别，根据抽取的文本范围以划分为句子级关系抽取、文档级关系抽取和语料级关系抽取；数据集中样本的多少可以划分为正常关系抽取、少样本关系抽取和零样本关系抽取；根据是否定义关系类别和抽取领域可以划分为限定域关系抽取和开放域关系抽取；本文中的关系抽取方法内容仅关注限定域关系抽取中的句子级关系抽取。</p><p>本文关注的工作主要是<strong>关系三元组抽取（Relational TripleExtraction，RTE）问题</strong>，即从文本中同时抽取两个实体及其对应的关系，三元组可以表示为（ Subject, Relation, Object）或 （Subject, Prodicate, Object），其中Subject 和 Object 为两个实体，也可以分别叫头实体（HeadEntity）和尾实体（Tail Entity）， Relation 和 Prodicate表示关系类别。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-c4c78e902610435cffcaa37c67b2b7ce_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>关系三元组抽取示意图</p><h2 id="一.-rte常见问题">一. RTE常见问题</h2><h2 id="pipeline-joint">1. Pipeline &amp; Joint</h2><ul><li><strong>Pipeline管道模型</strong></li></ul><p>早期，RTE任务被分解成两个独立任务的级联，也就是Pipeline模式：首先是命名实体识别(NamedEntity Recognition,NER)，即提取出文本中所有的实体；然后是关系分类(RelationClassifification, RC)，即预测判断提取的实体之间是否存在某种关系。</p><p>Pipeline模型明显的一个缺点是存在<strong>误差传递问题（ErrorPropagationProblem）</strong>，这是由于实体抽取和关系分类两个模型相互独立，不存在依赖，实体抽取阶段的识别错误、遗漏等误差无法被纠正和改变，会直接传递影响到关系分类阶段的效果。</p><ul><li><strong>Joint联合模型</strong></li></ul><p>不同于Pipeline模型，Joint模型以减少误差传递为目的将实体抽取和关系分类通过一定的方式进行整合，联合学习两个任务，构建端到端的关系抽取模型，当前的Joint模型主要有以下两类：</p><p><strong>①参数共享：</strong>本质上是多任务学习<strong>，</strong>实体识别和关系抽取共享encoder，使用不同的decoder，并构建联合loss训练优化。</p><p><strong>② 联合解码：</strong>这一类也可称为Structuredprediction，将实体识别和关系抽取两个任务映射在统一的框架结构下，进行全局的优化以及联合解码，即解码不存在多步(multi-steps)，而是一步(one-step)完成。</p><ul><li><strong>Pipeline VS Joint</strong></li></ul><p>最早的Pipeline模型存在明显的误差累积问题，为了解决实体和关系两个任务模型独立和误差累计问题，许多研究提出了基于参数共享的联合模型，虽然通过多任务学习和联合优化的方式增加了两个任务的关联，但本质还是multi-steps的模型，仍然没有解决误差传递的问题。另一方面，这些模型还存在一个问题，就是<strong>暴露偏差(ExposureBiasProblem)。</strong>为了解决误差传递和暴露偏差问题，许多研究提出了基于联合解码的联合模型，特别是以TPLinker为代表的一系列Tablefilling方法。</p><blockquote><p>暴露偏差：在训练时使用标注好真实的实体件进行最终的关系提取和推断，而在测试推理时，则需要从头开始识别实体，即上一阶段的实体是由构建的模型预测的并且存在错误和噪声，但训练使用的是标注的正确的，这就造成了训练和推理阶段之间的gap</p></blockquote><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-747e2a30f6c834a4cad109b0048620fd_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>研究从Pipeline到Joint模型，2021年<ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2021.naacl-main.5.pdf">PURE</a>模型的提出打破了许多研究长期认为的联合模型能够更好的捕捉实体和关系间的交互并缓解误差传播问题的观念，在PURE之前大多数研究都关注于联合模型，但是PURE证明了联合模型不一定真的比Pipeline模型性能好。因此，Pipeline和Joint哪个更好肯定要看实际的任务和数据。</p><h2 id="关系重叠">2. 关系重叠</h2><p>关系抽取过程中除了模型本身存在的误差传递和暴露偏差问题外，还面临着文本中复杂的关系重叠问题，文本中的复杂关系重叠可以分为以下三类，许多模型设计来解决以下问题。</p><ul><li><strong>SEO (Single Entity Overlap)：</strong>多个实体与同一实体存在关联关系</li><li><strong>EPO (Entity Pair Overlap)：</strong>同一对实体存在多种关系</li><li><strong>SOO (Subject Object Overlap) :</strong>主体和客体实体重叠</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-e240573cff4cc822b4d3bdf62ae0cf98_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h2 id="二.-rte方法总结">二. RTE方法总结</h2><p>在该部分总结归纳了几个关系抽取的模型范式，关系抽取的算法模型非常多，在这里主要关注最近几年的基于预训练模型的研究工作，本文列举的模型都是一些有代表性的工作，还有的许多相关的研究并未列出。</p><p>现有的关系抽取工作中可以分为抽取式模型和生成式模型，抽取式模型中又可分为Pipeline模型和Joint模型，下面列出的工作是通过各种抽取方法范式归类的，包括基于标注、基于片段、基于填表、基于阅读理解的抽取式方法，以及生成式方法。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-81d35755c4aba16c3c1d04f3267ed52a_720w.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h2 id="基于标注的方法tagging-based-methods">1. 基于标注的方法（Taggingbased methods）</h2><p>基于标注的方法通常使用二分标注序列（binary taggingsequences）来确定实体的起始位置，或者确定实体之间的关系。</p><h3 id="casrel"><strong>1.1 CasRel</strong></h3><p>ETL-Span: <ahref="https://link.zhihu.com/?target=https%3A//ecai2020.eu/papers/615_paper.pdf">JointExtraction of Entities and Relations Based on a Novel DecompositionStrategy</a>, ECAI 2020</p><p>CasRel: <ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2020.acl-main.136/">ANovel Cascade Binary Tagging Framework for Relational TripleExtraction</a>, ACL 2020</p><p>常见的关系抽取模式是先抽取实体，然后在对实体对进行关系分类预测，可表示为𝑓(𝑠,𝑜)→𝑟；<strong>ETL-Span</strong>和<strong>CasRel</strong>两个模型采用了与之不同的模式<strong>：先抽取subject实体，然后在subject基础上同时抽取关系relation及其对应的object实体，即𝑓𝑟(𝑠)→𝑜</strong>。</p><p>下图为CasRel的模型结构图，CasRel抽取三元组的具体流程如下：</p><p><strong>①BERT编码</strong>：将输入的文本经过BERT编码获得文本token序列的隐层表示ℎ∈𝑅𝑛×𝑑 ;</p><p><strong>②Subject标注</strong>：该模块识别输入文本中所有可能的subjects，它利用两个独立的二分类器为每个token分配一个二分标签（0/1）来分别检测subject的开始和结束的位置，其中0和1标签分别表示当前token是否是一个subject的开始或结束的位置；</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-53b1903f87fc2607b3eeadd389663c8c_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>③关系特定的Object标注</strong>：该标注模块能够在subject实体基础上识别object实体及两个实体间的关系，通过为每个关系 𝑟学习特定的二分标注器𝑓𝑟(⋅)来识别subject在特定关系 𝑟下可能对应的object起始位置，即𝑓𝑟(𝑠)→𝑜 ；</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-55105774c9fe336d87dfc05cacd2d3bb_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>其中， 𝑣𝑠𝑢𝑏𝑘 为步骤②提取的subject的向量表示，通过将subject起止范围[𝑝𝑖𝑠𝑡𝑎𝑟𝑡_𝑠,𝑝𝑖𝑒𝑛𝑑_𝑠] 内token表示进行mean pooling得到。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-da635e78251159ffc877c23f223df744_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>CasRel模型结构图</p><p><strong>优点：</strong></p><ul><li><strong>CasRel原论文模型能够解决SEO和EPO三元组重叠问题，SOO问题理论上也是能够解决的</strong>，需要注意修改模型中subject和object的位置关系约束和判断部分代码。</li></ul><p><strong>缺点：</strong></p><ul><li><strong>存在误差传递和暴露偏差问题</strong>，因为CasRel仍然是Pipeline的提取模式，subject提取存在的错误和遗漏直接影响后续的关系预测和object的提取。</li><li><strong>存在关系冗余和计算效率低的问题</strong>，假设有N个关系类别，在获取subject之后，每个subject需要计算每个关系下可能对应的object，需要进行2*N次二分类计算，若关系类别较多，由于许多冗余的关系则会导致过多的计算，影响计算效率。</li><li><strong>训练和测试过程也存在效率低的问题</strong>，在CasRel训练过程中每个文本即使有多个subjects也只随机取样其中的一个subject和其对应的三元组作为一个训练样本，这样训练过程中不能对同一文本中所有三元组进行一次性的学习，而且训练的epoch会很大，论文中作者表示通过充分的训练训练集中每个三元组样本均会被采样学习到；同时在测试过程中由于每个文本中的三元组数目是不固定的，CasRel这种抽取模式下batchsize需要设置为1。</li></ul><h3 id="prgc"><strong>1.2 PRGC</strong></h3><p><ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2021.acl-long.486/">PRGC:Potential Relation and Global Correspondence Based Joint RelationalTriple Extraction</a>, ACL 2021</p><p>PRGC是针对上面提到的CasRel模型和章节3.1中介绍的TPLinker模型存在的问题进行改进的，上面也提到了CasRel由于关系冗余使得很多操作无效，它的subject-object对齐提取机制使其一次只能处理一个subject，实际上效率低并难以部署应用；而TPLinker仍然存在关系冗余和扩展性差的问题，同时TPLinker使用了更复杂的解码部分导致解码的标签稀疏和收敛速度慢。针对这些问题，<strong>PRGC提出一个新的端到端的框架，将三元组联合抽取分解成了三个子任务：关系判断、实体抽取和subject-object对齐</strong>。</p><p>下图为PRGC的模型结构图，PRGC抽取三元组的具体流程如下：</p><p>① <strong>Potential RelationPrediction：</strong>给定一个文本经过BERT编码得到序列表示 ℎ∈𝑅𝑛×𝑑，首先判断预测句子中可能存在的关系集合，这样可以过滤无关的关系，减少计算</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-c36b38e0f0ad797c3bbc0af7f35516b6_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>② <strong>Relation-Specifific SequenceTagging：</strong>判断句子中潜在的关系后，针对每个关系进行两次独立的序列标注操作，分别提取subjects和objects，subjects和object独立提取能够subject和object重叠（*<strong>SOO*</strong>）问题，标注采用的是BIO标注方式；同时在标注过程中对每个token向量加入了关系向量，识别在特定关系下的实体</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-952e5ce83e45b776d02c13aab2f77aee_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>③ <strong>GlobalCorrespondence：</strong>针对某一类关系提取除了句子中所有可能的subjects和objects后，使用一个全局关联矩阵𝑀𝑛×𝑛 来确定正确的subject-object对</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-6470d93a7fe53f670ec13b74c20d1f56_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>上式中 ℎ𝑖𝑠𝑢𝑏 和ℎ𝑗𝑜𝑏𝑗分别为两个第 𝑖 个和第 𝑗个token经过BERT编码的向量表示</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-e2bdd851f1a51a7d8edb39ac628aa033_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>PRGC模型结构图</p><p><strong>优点：</strong></p><ul><li><strong>PRGC模型能够解决SEO、EPO和SOO三元组重叠问题</strong></li><li><strong>模型计算效率以及模型训练测试效率较CasRel模型有了很大的提升</strong>，因为关系判断阶段可以过滤无关的关系，同时提取模式的改变，使得训练测试阶段能够批量进行</li></ul><p><strong>缺点：</strong></p><ul><li><strong>存在误差传递和暴露偏差问题</strong>，因为PRGC也是Pipeline的提取模式，而且解码还是经过了三步，关系判断和实体提取两个部分的错误、遗漏等问题都会导致最终三元组提取的精度。</li></ul><h3 id="birte"><strong>1.3 BiRTE</strong></h3><p>BiTE: <ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2112.04940.pdf">ASimple but Effective Bidirectional Framework for Relational TripleExtraction</a>, WSDM 2022</p><p>BiTE模型是针对CasRel改进的，CasRel将提取过程分为了两步，首先提取所有的subjects，然后同时抽取所有的objects和关系，即无向的抽取模式𝑠𝑢𝑏𝑗𝑒𝑐𝑡→𝑜𝑏𝑗𝑒𝑐𝑡→𝑟𝑒𝑙𝑎𝑡𝑖𝑜𝑛，但是这种模式存在的问题是误差传递，即一个subject抽取失败，那么与这个subject相关联的所有三元组都无法抽取成功。</p><p>BiTE设计了一个双向的提取框架，首先模型从 𝑠𝑢𝑏𝑗𝑒𝑐𝑡→𝑜𝑏𝑗𝑒𝑐𝑡→𝑟𝑒𝑙𝑎𝑡𝑖𝑜𝑛(𝑠2𝑜)和 𝑜𝑏𝑗𝑒𝑐𝑡→𝑠𝑢𝑏𝑗𝑒𝑐𝑡→𝑟𝑒𝑙𝑎𝑡𝑖𝑜𝑛(𝑜2𝑠) 两个方向提取出所有可能的 (𝑠𝑢𝑏𝑗𝑒𝑡,𝑜𝑏𝑗𝑒𝑐𝑡)对，这样两个方向可以相互提升与互补，减少实体抽取的遗漏；然后利用一个biaffine模型为每个(𝑠𝑢𝑏𝑗𝑒𝑡,𝑜𝑏𝑗𝑒𝑐𝑡)对预测分配可能的关系类别。</p><p>下图为BiRTE模型结构图，模型具体的细节不再赘述，可见原论文。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-9ede6b3f96dc880c7920a9c30ca3285c_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>BiTE模型结构图</p><h2 id="基于片段的方法span-based-methods">2. 基于片段的方法（Span basedmethods）</h2><h3 id="spanre"><strong>2.1 SpanRE</strong></h3><ul><li>SpanRE: <ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/P19-1525.pdf">Span-LevelModel for Relation Extraction, ACL 2019</a></li></ul><p>SpanRE中提出了标准的基于片段的抽取方法的流程，一般分为以下4个步骤：</p><p><strong>① 文本所有可能的片段span列举</strong>，若输入文本有个 𝑇tokens，那么存在 𝑁=𝑇(𝑇+1)2 个可能的片段， span 𝑖由片段起始范围内的tokens组成， 即 xi=[xSTART(i),xEND(i)]</p><p><strong>②文本编码生成span的向量表示</strong>；如下公式，SpanRE将span范围内的token向量利用attention加权求和的xi^ ，与span的起始token向量 、xSTART(i)、xEND(i) ，以及span的长度 𝜙(𝑖)进行拼接作为span的表示</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-5fde06492897941db2844a6295251c3e_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>③span实体标签分类预测：</strong>通过一个多分类模块预测每个span是否为实体以及实体类别，提取识别所有的实体</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-37a269a1fda428ee4d05a0c11a035e91_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>④实体关系提取：</strong>对提取的所有span实体两两配对，通过一个多分类模块判断实体对之间是否存在关系以及关系类别</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-ec9f63606a78e4410ffc8e53bc9b1288_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-d08cdc9a98853d9eca1dfdbc2dd29b3a_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="spert"><strong>2.2 SpERT</strong></h3><p>SpERT: <ahref="https://link.zhihu.com/?target=https%3A//ecai2020.eu/papers/1283_paper.pdf">Span-basedJoint Entity and Relation Extraction with Transformer Pre-training, ECAI2020</a></p><p>SpERT模型和上述的SpanRE模型很是相似，基本流程也大致相似，不同点在于：</p><ul><li>SpERT使用了预训练模型BERT作为文本编码器，获得token更强大丰富的向量表征；</li><li>SpERT获取span向量表征方式不同，SpERT学习了一个widthembeddings表征span的长度，将span范围内的token进行maxpooling，与BERT输出的[CLS]token向量以及长度向量进行拼接作为span的向量表示；</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-f3d92520ef9cf6db76687bfe7b72c691_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-6ff139cd0b3d0eebf6dc8e953679ec63_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li>SpERT在span实体分类阶段，过滤了被判断为none标签的span，同时过滤了多于10个tokens的span，因为实际总的片段过多会给模型带来冗余噪声并且影响计算效率，一般会限制span的长度在一个窗口范围𝑤 内；</li><li>最后在对实体对进行关系分类时，SpERT将两个span之间的token向量进行maxpooling获得一个上下文表示 𝑐(𝑠1,𝑠2) ,将其与两个span实体的向量表示进行拼接传入分类器进行关系类别预测</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-022b0ae732b3b26ad99503e89030e86b_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-6d2202d98ce1c4ad88794f2b3a208e72_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="pure"><strong>2.3 PURE</strong></h3><p>PURE: <ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2021.naacl-main.5.pdf">AFrustratingly Easy Approach for Entity and Relation Extraction, ACL2021</a></p><p>不同于上述的两个基于span的模型，PURE是一个纯Pipeline模型，但是算法思想非常简单并且性能很好，超过了很多联合模型</p><p><strong>[PURE提出的思路动机]：</strong>①<strong>联合模型中实体和关系模型使用共享的编码器会影响抽取性能</strong>，因为实体和关系抽取两个任务需要关注捕捉的信息是不同的；②关系抽取模型中<strong>在输入层（即文本编码之前）就融入实体相关信息</strong>（包括实体边界和实体类型）是非常重要的；③<strong>利用跨句的的上下文信息</strong>对提升实体和关系抽取两个任务的性能都非常有用</p><p><strong>PURE模型结构流程：</strong></p><p>针对动机①，PURE使用了Pipeline的抽取框架，分别设计训练实体抽取模型和关系抽取模型。</p><p><strong>[EntityModel]：</strong>采用一个标准的基于span的实体抽取模型，将span起始的token向量[XSTART(i),XEND(i)] 与span宽度特征向量 𝜙(𝑠𝑖) 拼接作为一个span的向量表示,然后传入一个前馈神经网络预测实体类型</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-0df5288fdb62864f22d8b912d6017dc6_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>[RelationModel]：</strong>实体模型将输入文本中的所有实体全部抽取出来，对每一对实体片段&lt;𝑠𝑖,𝑠𝑗&gt; 进行关系类型预测</p><ul><li>关系模型用一个不同的PLM模型重新对文本进行编码，作者认为同一句子中不同的实体对的关系预测需要不同的上下文表示，因此关系模型单独处理预测每一对实体片段</li><li>针对动机②，模型在输入层对文本插入实体标识符（Typedmarkers）来突出文本中subject和object实体的位置和实体类型</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-0ae09d5cc9e5de315f07edeb1e814857_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>下图为在文本中插入typed markers的示例：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-fabda91f0d97bb48b31172918ce0e248_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li>将两个实体span的起始标识符向量拼接，然后传入前馈神经网络进行关系预测</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-0c15ef0e013ae28a0e49d02a6db0cf0c_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>[Effificient BatchComputations]：</strong>论文还提出了一个高效的近似模型，通过较小的牺牲性能换来提高计算效率。原模型由于要插入typedmakers无法实现一次文本编码抽取所有的三元组，论文的提高效率的做法是将所有实体对的typedmakers拼接到文本后面，并对文本建模进行两个改变：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-57249bf335b4f52f4c0860dd2070b4cf_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li>首先，将标识符的positionid与其对应的span的起始和结束的token的poisitionid对应，比如上图的第一个maker [S:PER] 与文本第一个token Bill共享一个position id以及position embedding</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-533497af7c03a53fa82e230b8facfe23_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li>其次，在对拼接了makers的文本建模的attentionlayer做了一些限制，文本tokens只能与文本的tokens进行attention计算，不能与makertokens进行交互，这也是近似模型的主要牺牲所在，即原文不能与makers进行交互计算；而makertokens能够和文本tokens以及所属同一实体对的makers进行attention计算。</li></ul><p>其他与原模型保持一致，将每个实体对对应的makers进行拼接传入前馈神经网络预测关系</p><p><strong>PURE的优缺点：</strong></p><ul><li><strong>优点：</strong>PURE模型是很简单，但性能很好，而且还有能够高效的计算模式，尤其是在输入层引入TypedMakers的做法很简单巧妙，整合实体位置和类型信息。其实在谷歌发表的论文<ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/P19-1279.pdf">Matchingthe Blanks: Distributional Similarity for Relation Learning, ACL2019</a>中也有提到使用Entity Makers的做法，但没融入实体类型。</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-3c0390788da2901a6cddf857e25a072a_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>缺点：</strong>误差传递是Pileline模型的通病，实体识别的错误和遗漏影响后续关系分类性能。</li><li>还有一个是基于span方法的缺点：其实基于span的方法的流程基本是识别所有的实体，再对每个实体对进行关系预测，但是实际使用中这种方法的问题在于，若一个文本中包含多个实体，需要对每个实体对一一进行判断预测，若数据集关系复杂多样或者文本语境复杂，那么针对同一文本对很多对实体进行关系预测会很困难，因为会有很多噪声，关系分类预测模块又很简单，而类似于CasRel这中模型首先会在诸多是中寻找subject，然后再去匹配object，会过滤许多噪声。</li></ul><h2 id="基于填表的方法table-filling-based-methods">3.基于填表的方法（Table filling based methods）</h2><p>基于填表的方法通常为每一个关系维护一个表，这个表中的每一项都用来表示一个tokenpair是否具有此类关系，因此该类方法的关键是准确地填充关系表，然后可以根据填充的关系表提取三元组。</p><p>这种预测实体对在每类关系下的评分方式最早来自于multi-headselection模型，<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1804.07847.pdf">Jointentity recognition and relation extraction as a multi-head selectionproblem, 2018</a></p><h3 id="tplinker">3.1 TPLinker</h3><p><ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2020.coling-main.138.pdf">TPLinker:Single-stage Joint Extraction of Entities and Relations Through TokenPair Linking</a>，ACL 2020</p><p>TPLinker主要是解决暴露偏差和误差累积问题，这是由于现有联合模型在解码时常常分为相互关联的多步，导致的训练和推理阶段不一致，同时上一步的提取误差会传递给下一步，导致最终的提取错误。</p><p>TPLinker是一个联合抽取实体和重叠关系的单步模型（one-stage），不存在任何相互依赖的步骤，因此避免了暴露偏差问题。它将联合抽取问题看做一个token对链接问题（<strong>T</strong>oken<strong>P</strong>air <strong>Link</strong>ingProblem），并提出了一个握手标记方案（handshaking taggingscheme）在每中关系类别下对其实体对的tokens的边界。</p><p><strong>① Handshaking Tagging Scheme</strong></p><p>给定一个长度为 𝑛 的文本，将所有可能的token对列举构建一个 𝑛×𝑛矩阵，对矩阵中每个token对进行链接标注，即填表。TPLinker定义了三种类型的token链接：</p><ul><li><strong>entity head to entitytail（EH-to-ET）</strong>：代表一个实体的开始和结束的token的位置，如下图紫色标签</li><li><strong>subjet head to objecthead（SH-to-OH）</strong>：代表一对subject实体和object实体的开始的token的位置，如下图红色标签</li><li><strong>subject tail to objecttail（ST-to-OT）</strong>：代表一对subject实体和object实体的结束的token的位置，如下图蓝色标签</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-3888c429988418495a212f8358b715dd_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>上图为某个关系的矩阵标注示例图，由于实体的tail token不可能出现在headtoken之前，所以对于矩阵的下三角区域均为零，导致矩阵非常稀疏，浪费了内存。但是又不能直接丢弃下三角区，因为object实体可能出现在对应的subject实体之前，因此论文将下三角区的标签1变为2，填充到上三角区，并丢弃下三角区，如下图所示。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-59d6678b4cda43579cd340d3e3666c28_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>为了方便计算，将上三角区的所有项平铺成一个序列，并用一个map记录每一项在原矩阵中的位置。同时，为了解决同一对实体可能具有多种关系，即EntityPairOverlap问题，对每种关系类型都进行各自的SH-to-OH和ST-to-OT矩阵标注，EH-to-ET标注是所有关系共享的，因为它仅关注整体的实体提取与关系无关，整体结构如下图所示。</p><p>通过这种方式，给定长度为 𝑛 的文本序列，联合抽取任务就被分解成了 2𝑁+1个序列标注子任务， 𝑁 为关系的总数目，每个标注任务需要构建长度为 𝑛2+𝑛2的标签序列，因此整体需要预测标注的标签数为(2𝑁+1)𝑛2+𝑛2</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-6492231ccdd54ba22412f7996cba1809_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>② 模型流程</strong></p><p>TPLinker首先将输入的文本经过BERT模型进行编码获得token表示序列，然后通过以下公式获得一个token对(𝑤𝑖,𝑤𝑗) 的关联特征表示</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-1a86786e13febb25a5e54b5fedc9f3f7_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>通过①中介绍的方式进行handshakingtagging得到所有的标注序列，标注序列中的每个token对的标签通过如下公式预测，最后通过标注的标签序列解码提取所有的三元组</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-27996b2fa836ac6bd16660c5ed7700a8_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>优点：</strong></p><ul><li>TPLinker这种one-stage的联合抽取模型<strong>解决了暴露偏差和误差传递的问题</strong>，同时<strong>理论上能够解决SEO、EPO、SOO等关系重叠问题</strong></li></ul><p><strong>缺点：</strong></p><ul><li><strong>TPLinker的标注复杂度高，存在很多冗余的操作和信息，</strong>若关系数目很大，需要标注2𝑁+1个标签表，就像1.2中PRGC提到的关系冗余，导致解码部分矩阵参数量很大，标签表会非常稀疏，训练收敛速度慢</li><li><strong>TPLinker的解码效率并不是很高</strong>，下图为1.2中PRGC论文中的模型效率对比图，可以发现TPLinker的计算复杂度和解码效率并不是很高</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-3ab19f5e977082481837a75c814eb0eb_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li>实体和关系各自进行标注抽取，<strong>实体和关系没有进行很深的交互和关联</strong></li></ul><h3 id="grte">3.2 GRTE</h3><p><ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2109.06705">ANovel Global Feature-Oriented Relational Triple Extraction Model basedon Table Filling</a>，ACL 2021</p><p>GPTE认为TPLinker这些现有方法在填充关系表时仅仅依赖于局部特征（localfeatures），局部特征要么从单一的token pair或者从有限的tokenpairs的填充历史中提取得到，然而却<strong>忽略了两种有价值的全局特征（globalfeatures），即tokenpairs和各类关系的全局关联关系</strong>，现有的模型不能对这两类全局特征进行学习建模。</p><blockquote><p>论文中所述的全局特征包括两个方面：<strong>tokenpairs之间的关联</strong>和<strong>关系之间的关联</strong>，以“EdwardThomas and John are from New York City, USA.”为例： *****同一文本中(Edward Thomas, live_in, New York) 和 (John, live_in,USA)两个三元组的提取是可以互相促进的，因为这两个三元组中的subject和object实体类型相同，<strong>高度相似的两个tokenpairs很可能具有相同的关系</strong>； *****上述live_in关系的两个元组可以帮助推断一个新的关系的三元组(New York,located_in, USA)，因为located_in和live_in关系是语义相关的，located_in要求subject和object都为location实体，live_in要求object为location实体，因此两个<strong>live_in关系的三元组到一个新的located_in关系三元组之间能够形成很明显的推断路径</strong></p></blockquote><p><strong>① GRTE的填表策略（Table Filling Strategy）</strong></p><p>给定一个长度为 𝑛 的的文本序列，为每一个关系 𝑟∈𝑅 维持一个 𝑛×𝑛 大小的表𝑡𝑎𝑏𝑙𝑒𝑟 ，模型的关键是为表中每个位置也就是token pair填充正确的标签。表第𝑖 行和第 𝑗 列表示为 (𝑤𝑖,𝑤𝑗) , 这一个token pair的标签为 𝑙，GRTE的填表规则策略如下：</p><ul><li>填充表的标签集合为：𝐿={′N/A′,′MMH′,′MMT′,′MSH′,′MST′,′SMH′,′SMT′,′SS′}<ul><li>′N/A′ 表示两个tokens没有任何关联关系，其他标签表示(𝑤𝑖,𝑤𝑗)和同一个(𝑠𝑢𝑏𝑗𝑒𝑐𝑡,𝑜𝑏𝑗𝑒𝑐𝑡) 实体对相关联</li><li>标签第一个字符表示 𝑠𝑢𝑏𝑗𝑒𝑐𝑡 是一个多tokens实体（ ′M′）还是一个单token实体（ ′S′ ）</li><li>标签第二个字符表示 𝑜𝑏𝑗𝑒𝑐𝑡 是一个多tokens实体（ ′M′）还是一个单token实体（ ′S′ ）</li><li>标签第三个字符表示 𝑤𝑖 和 𝑤𝑗 均为 𝑠𝑢𝑏𝑗𝑒𝑐𝑡 和 𝑜𝑏𝑗𝑒𝑐𝑡 实体的headtoken（ ′H′ ）或者都是 𝑠𝑢𝑏𝑗𝑒𝑐𝑡 和 𝑜𝑏𝑗𝑒𝑐𝑡 的tail token（ ′T′ ）</li><li>′SS′ 表示(𝑤𝑖,𝑤𝑗)本身就是一个 (𝑠𝑢𝑏𝑗𝑒𝑐𝑡,𝑜𝑏𝑗𝑒𝑐𝑡) 实体对</li></ul></li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-ecb92ac47547c7cf9b2061b192431f84_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>GRTE的填表策略需要填充的数目为： 𝑛2|𝑅| , 低于TPLinker需要填充的数目(2𝑅+1)𝑛2+𝑛2 。</p><p><strong>② 模型细节（Model Details）</strong></p><p>模型结构图如下，主要包括四个部分：编码模块（Encoder）、表特征生成模块（TableFeature Generation，TFG）、全局特征挖掘模块（Global FeatureMining，GFM）和三元组生成模块（TripleGeneration，TG）。其中，文本经过编码层一次编码，然后，经过TFG和GFM以迭代的方式进行多次的计算来一步步的更新并获得最终的表特征，最后利用TG模块提取三元组。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-8f43804a9bc8ecebf8270e4d8886f74a_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>Encoder Module</strong></li></ul><p>编码模块利用BERT对文本token序列进行编码获得token表示序列 𝐻∈𝑅𝑛×𝑑ℎ,并利用两个独立的全连接模块FNN获得初始化的subjects特征 𝐻𝑠(1)和objects特征𝐻𝑜(1)</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-011eb3e25928a3fc3d380ac62c14c4d6_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>TFG Module</strong></li></ul><p>由于TFG和GFM两个模块是需要进行多轮的迭代计算，令在第 𝑡轮中，subjects和objects特征为 𝐻𝑠(𝑡) 和 𝐻𝑜(𝑡) ，关系 𝑟 的表特征为 𝑇𝐹𝑟(𝑡)，其中的每一项特征𝑇𝐹𝑟(𝑡)(𝑖,𝑗)为(𝑤𝑖,𝑤𝑗)对应的特征值</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-6c4642e9eaddbc0d33fc876bd974c9b7_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>GFM Module</strong></li></ul><p>TFG模块学习了tokenpairs之间的局部关联特征并生成每个关系的表特征，而GFM模块在此基础上挖掘建模两类全局特征，并产生新的subjects和objects特征，传入TFG模块进行下一轮的计算</p><p><strong>Step1：</strong>将所有关系的表特征进行拼接得到一个统一的表特征 𝑇𝐹(𝑡)，然后用max pooling操作和FNN模块获得一个subjects相关的表特征𝑇𝐹𝑠(𝑡)和一个objects相关的表特征𝑇𝐹𝑜(𝑡)</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-2025453032c33ec3c7c3005d75a3eae3_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>Step 2：</strong>利用基于Transformer的模型来挖掘关系之间以及tokenpairs之间的全局关联。1）对于关系之间的全局关联，作者在𝑇𝐹𝑠/𝑜(𝑡)上进行多头自注意力计算；2）对于tokenpairs之间的全局关联，在token序列 𝐻 和𝑇𝐹𝑠/𝑜(𝑡)^上进行多头自注意力计算; 3)然后利用FFN模块产生新的subjects特征和objects特征</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-baed23ccc2c1400b3fea2987ecd09516_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>Step3：</strong>为了缓解梯度消失问题，使用残差连接生成最终的subjects和objects特征表示</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-fb389360e4aa04d288d94607b748fa43_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>TG Module</strong></li></ul><p>TG模块对经过 𝑁 轮计算得到的填充表𝑇𝐹(𝑁)进行解码并推断出所有的三元组，即针对每一个关系 𝑟，预测其关系表中每一项的标签，最后基于标签表进行三元组推断。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-682509e3f0b97246d5558db3816239d5_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>在解码中为每个关系提取实体对时，作者设计了三个并行的搜索路径：一是前向搜索（forwardsearch），即按顺序从head tokens到tailtokens生成实体对；二是逆向搜索（reverse search），即按从tailtokens到headtokens的顺序生成实体对，这一搜索方式是为了解决实体重叠的问题；三是由singletoken组成的实体对生成</p><p><strong>优点：</strong></p><ul><li>GRTE<strong>能够解决暴漏偏差和误差传递的问题，能够解决SEO、EPO、SOO关系重叠问题</strong></li><li>相比TPLinker<strong>能够挖掘全局特征，对关系间和不同tokenpairs之间进行关联建模</strong></li><li>相比TPLinker，<strong>GRTE的填表策略减少了填表数目，减少了冗余的信息，</strong>论文指出了相比其他模型训练epoches少、收敛速度快些</li></ul><p><strong>缺点：</strong></p><ul><li>GRTE基于Transformer迭代的挖掘全局特征的<strong>GFM模块使得模型复杂度提升并且计算效率降低</strong>，并且值得注意的是GRTE去除GFM模块并不比TPLinker性能好</li><li><strong>模型解码部分参数量变大，解码推断效率变低</strong>，下图为论文中的计算效率对比图，可以看出整体的参数量和推断时间要比TPLinker大</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-87c457a918263bc39cffca33661cb5a1_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="others">3.3 Others</h3><p>基于填表的抽取方法的不同点多在于填表的方案策略以及基于填充表的解码算法，下面也是基于填表的方法，由于篇幅长度的问题，模型详细的细节可以见原论文。</p><p><strong>1） UNIRE</strong></p><p><ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2021.acl-long.19.pdf">UNIRE:A Unifified Label Space for Entity Relation Extraction，ACL 2021</a></p><p>UNIRE认为现有模型将实体检测和关系分类两个子任务设置在两个独立分开的标签空间，损害了实体和关系之间的信息交互。</p><ul><li><strong>UNIRE将实体和关系两个任务标签整合，统一联合标签空间</strong>，将实体关系联合抽取看成一个填表问题，利用统一的分类器预测表中每个单元的标签<ul><li>如下图，在填充的表中实体是正方形并且在对角线上，关系是长方形在对角线两侧</li></ul></li><li><strong>模型通过在损失函数结构正则化对表格施加两个结构约束</strong><ul><li>Symmetry，即对称性，表格中实体对应的正方形是关于对角线对称的，而对称等价的两个关系三元组对应的长方形也是关于对角线对称的</li><li>Implication，即蕴含性，如果一个关系存在，那么对应的两个实体也应该存在，也就是表中一个关系的概率应该小于其关联的每个实体的概率</li></ul></li><li><strong>模型设计了简单快速的解码方法，同时还增强了实体和关系的交互。</strong>解码分为三步：span解码、实体类型解码和关系类型解码</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-8e2b883c3da30f7be1e885aac30eeab6_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>该论文在实验对比部分并没有和CasRel、PRGC和TPLinker等模型进行对比，主要是和PURE模型对比，性能和效率很难说明。</p><p><strong>2）OneRel</strong></p><p><ahref="https://link.zhihu.com/?target=https%3A//www.aaai.org/AAAI22Papers/AAAI-246.ShangYM.pdf">OneRel:Joint Entity and Relation Extraction with One Module in One Step， AAAI2022</a></p><p>这篇论文的方法和TPLinker非常相似，TPLinker需要标注 2𝑁+1个标签矩阵，而OneRel减少了矩阵为 𝑁个，即每个关系一个矩阵，因此减少了冗余的信息，提升了模型效率，也增加了实体和关系的交互，具体可见论文。</p><h2 id="基于阅读理解的方法mrc-based-methods">4. 基于阅读理解的方法（MRCbased methods）</h2><h3 id="multi-turn-qa">4.1 Multi-turn QA</h3><p><ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1905.05529%3Fcontext%3Dcs">Entity-RelationExtraction as Multi-turn Question Answering</a>, ACL 2019</p><p>在论文中提出了一种新的关系抽取模式，将实体关系抽取看作多轮问答（Multi-turnQuestion Answering，QA）问题，进而将实体和关系的抽取转化成从文本中识别答案片段的任务。在该模式中，每个实体类别和关系类别都由一个查询模板（QueryTemplate）来表征，同时实体和关系通过回答问题来提取，答案片段利用标准的机器阅读理解（MachineReading Comprehension ，MRC）框架模型来提取。</p><p>模型整体包括两个阶段：</p><p><strong>1）头实体抽取阶段（Head-entity Extraction）</strong></p><p>利用实体查询模板 𝐸𝑛𝑡𝑖𝑡𝑦𝑄𝑢𝑒𝑠𝑇𝑒𝑚𝑝𝑙𝑎𝑡𝑒𝑠将每个实体类型转化成一个问题，将问题与文本拼接来提取头实体 𝑒ℎ𝑒𝑎𝑑。在这一阶段，输入和文本会和每个实体类型问题进行拼接并计算判断文本中是否有该类型的实体，有则提取实体，没有则输出𝑁𝑂𝑁𝐸 token。</p><blockquote><p>论文中利用模板生成实体问题的方式有两个，分别是自然语言问题（naturallanguage question）和伪问题（pseudoquestion），实验证明自然语言问题性能效果会更好。以下图中的人名类型实体为例，可以构造以下两类问题查询语句：①“句子中提到的人是谁？” ---&gt; 自然语言问题 ②“人名” ---&gt; 伪问题</p></blockquote><p><strong>2） 关系和尾实体抽取阶段（Relation and Tail-entityExtraction）</strong></p><p>关系类型𝑟𝑒𝑙也定义了问题模板 𝐶ℎ𝑎𝑖𝑛𝑂𝑓𝑅𝑒𝑙𝑇𝑒𝑚𝑝𝑙𝑎𝑡𝑒𝑠，每个关系型𝑟𝑒𝑙对应的问题模板中都包含了一些槽位slots，需要利用将第一阶段提取的头实体𝑒ℎ𝑒𝑎𝑑进行填充，构建出关系问题。将关系问题与文本拼接，提取出头实体和关系对应的尾实体𝑒𝑡𝑎𝑖𝑙，进而获得提取的实体关系三元组（）（𝑒ℎ𝑒𝑎𝑑,𝑟𝑒𝑙,𝑒𝑡𝑎𝑖𝑙） 。</p><blockquote><p>以下图为例，第一阶段提取出了"人名"类型的实体"普京"，预先定义好的"毕业"关系的问题模板为"___毕业于哪所学校？"， 将第一阶段提取的"普京"填入模板构造"毕业"关系的问题。</p></blockquote><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-c5cae0719967f628c4153200eb0ceb84_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>Two-Stage MRC实体关系抽取示意图</p><h2 id="基于生成的方法-generation-based-methods">6. 基于生成的方法（Generation based methods）</h2><p>不同于上述的各类抽取方法，这部分是完全不同的抽取模式，文章[4]中将上述的各类方法归纳为<strong>“抽取范式”</strong>，而本章节的方法称为<strong>“生成范式”</strong>。其实，从2018年左右生成范式的抽取模型就有被陆续提出，这部分模型以RNN为基本的模型，采用传统Seq2Seq深度生成框架，但这些生成式的模型和抽取式模型相比并未有明显的优势。直到近年来UniLM、BART、T5和GPT等生成式预训练模型的广泛使用，使得构建有效的生成式信息抽取模型成为了可能。2022年各个平台上最火的信息抽取模型应该百度和中科院联合发表的UIE模型，它就是一个生成式的通用信息抽取模型，直接将生成式的信息抽取推向了最前沿的研究方向。</p><p>基于预训练模型的生成式抽取模型的优势在于：首先，<strong>生成式模型相比抽取式模型迁移性、扩展性更强</strong>，抽取式更容易受到schema的限制；其次，<strong>生成式模型使得统一不同场景、不同任务、不同schema的信息抽取成为可能</strong>，比如UIE，同时能够达到即插即用、使用方便的优点；最后，<strong>生成式抽取模型对zero-shot和few-shot这类低资源场景下的抽取任务更加有效</strong>。</p><h3 id="copy-model">6.1 Copy Model</h3><p><strong>(1) CopyRE</strong></p><p>CopyRE: <ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/P18-1047.pdf">ExtractingRelational Facts by an End-to-End Neural Model with Copy Mechanism, ACL2018</a></p><p>CopyRE是一个基于复制机制（CopyMechanism）的序列到序列（Sequence-to-Sequence，Seq2Seq）学习的端到端联合抽取模型，能够解决SEO和EPO关系重叠问题。模型包括一个Encoder和一个Decoder，Encoder将文本序列编码，Decoder对文本进行一步步解码生成所有的三元组。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-2db01fd9ed88e612e31d3483c2e15908_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>CopyRE模型结构图</p><p><strong>① Encoder</strong></p><p>模型利用双向RNN对输入文本进行编码，编码函数为:𝑜𝑡𝐸,ℎ𝑡𝐸=𝐵𝑖𝑅𝑁𝑁𝐸(𝑥𝑡,ℎ𝑡−1𝐸)。编码后获得token序列表示 𝑂𝐸={𝑜1𝐸,...,𝑜𝑛𝐸}，将前后的RNN隐层向量拼接作为文本表示 𝑠=[ℎ𝑛𝐸→;ℎ𝑛𝐸←] 编码函数为：𝑜𝑡𝐸,ℎ𝑡𝐸=𝐵𝑖𝑅𝑁𝑁𝐸(𝑥𝑡,ℎ𝑡−1𝐸)</p><p><strong>② Decoder</strong></p><p>模型使用单向的RNN对文本序列从左向右进行一步步解码生成所有的三元组，解码函数为：𝑜𝑡𝐷,ℎ𝑡𝐷=𝑅𝑁𝑁𝐷(𝑢𝑡,ℎ𝑡−1𝐷)。ℎ𝑡−1𝐷 为上一步 𝑡−1的隐层状态，编码器的最后一个隐向量作为解码器的初始隐向量ℎ0𝐷； 𝑢𝑡为编码器 𝑡 时刻的输入，计算公式为： 𝑢𝑡=[𝑣𝑡;𝑐𝑡]𝑊𝑢˙ 。 𝑣𝑡 表示 𝑡−1时刻解码输出的实体或关系的嵌入向量； 𝑐𝑡 为解码器上一时刻隐层向量 ℎ𝑡−1𝐷对经过编码的文本序列 𝑂𝐸 进行注意力求和得到的向量</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-3b67f08522121a20f8fbedc954409ebd_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>解码时，每三个时间步为一个循环提取一个三元组，依次生成三元组的关系relation、从原来的文本中复制三元组的第一个实体、从原来的文本中复制三元组的第二个实体，构成完整的三元组。解码器不断重复上面三步生成多个三元组。</p><ul><li><strong>Relation Prediction</strong></li></ul><p>在 𝑡%3=1 时，模型使用 𝑡时刻的输出来预测一个关系，及进行多分类模块。其中 𝑞𝑟为各个关系类别的置信分数，𝑞𝑁𝐴为NA关系的置信分数。选择概率最高的位置对应的关系，并将该关系的嵌入向量作为下一时刻的输入𝑣𝑡+1</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-22715404c42873ee3634a0a9187eec0d_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>Copy the First Entity</strong></li></ul><p>在𝑡%3=2时，模型使用 𝑡时刻的输出与原文本序列进行关联计算，获得一个概率分布。选择概率最高的位置对应的token，并将该token的嵌入向量作为下一时刻的输入𝑣𝑡+1</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-0c4ab153e1a3a29c5449cbadc0c335e2_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-11a8715c0626dcb38b1a3752d33cf48e_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>Copy the Second Entity</strong>.</li></ul><p>在t%3=0时，模型使用 t时刻的输出与原文本序列进行关联计算，与上一步类似获得一个实体token，不同的是此时复制的实体与上一步的实体应该不相同，因此计算概率分布时使用了一个mask矩阵M，其中上一步提取的token位置值为0，其余为1</p><figure><imgsrc="data:image/svg+xml;utf8,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20width=&#39;403&#39;%20height=&#39;39&#39;%3E%3C/svg%3E"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>同样，将概率最高的word作为预测的实体token，并将token的向量作为下一时刻的输入v_{t+1}</p><p><strong>③</strong> <strong>MultiDecoder Model</strong></p><p>上述的是一个OneDecoder模型，一个解码器解码生成所有的三元组，论文还设计了MultiDecoderModel，利用多个分开的解码器级联来解码生成多个三元组，论文实验也证明了MultiDecoder性能要好于OneDecoder</p><figure><imgsrc="data:image/svg+xml;utf8,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20width=&#39;838&#39;%20height=&#39;334&#39;%3E%3C/svg%3E"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>CopyRE应该是最早提出的Seq2Seq这一新范式的联合抽取模型，但它存在以下缺点使得它的性能还有很大的提升空间：</p><ul><li>在copy两个实体时，模型只能copy实体的最后一个token，<strong>对于由多个token组成的实体是不能完整提取的</strong></li><li><strong>模型无法区分head实体和tail实体</strong>，容易将两个实体的位置顺序弄混</li><li>MultiDecoder在训练时训练固定数目的Decoder，<strong>推断时三元组的数目超过Decoder数目时就无法完全提取</strong></li></ul><p><strong>CopyRE提出之后，带来了Seq2Seq新的抽取模式，但它本身存在一些问题，后续有一些列工作提出了改进</strong></p><p><strong>(2) CopyRE + RL</strong></p><p><ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/D19-1035.pdf">Learningthe Extraction Order of Multiple Relational Facts in a Sentence withReinforcement Learning, ACL 2019</a></p><p>这篇文章认为文本句子中多个三元组间的抽取顺序是很重要的，为了<strong>自动学习句子中多个三元组的抽取顺序，论文将强化学习（ReinforcementLearning，RL）应用在CopyRE模型上</strong>，将三元组的生成过程看做RL过程，并用REINFORCE算法优化模型</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-e8133d85402a5535d28e33ed1992bb08_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>(3) CopyMTL</strong></p><p><ahref="https://link.zhihu.com/?target=https%3A//ojs.aaai.org/index.php/AAAI/article/view/6495">CopyMTL:Copy Mechanism for Joint Extraction of Entities and Relations withMulti-Task Learning, AAAI 2020</a></p><p>论文中作者经过试验分析发现CopyRE存在两个关键的问题：一方面，<strong>模型实体预测部分不稳定</strong>，常将head和tail实体顺序混淆；另一方面，<strong>模型无法提取多tokens组成的实体</strong>。未解决上述问题，<strong>提出CopyMTL模型，它是一个基于多任务学习的模型，同时改进了CopyRE的实体复制的结构能够预测多token实体</strong></p><p>针对实体预测不稳定问题，在CopyRE复制实体部分增加非线性的全连接层，单独预测head和tail实体的概率分布，tail实体预测也能接收head实体预测的信息</p><p>针对无法copy多token实体，模型使用CRF对句子进行BIO序列标注完整的识别所有的实体，实体识别的结果用于后续的解码部分的实体预测，并将CRF实体识别损失函数与CopyRE解码损失函数联合，进行多任务学习</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-9a67aa272a6a578d4f561036ca18b163_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>(4) WDec &amp; PNDec</strong></p><p><ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1911.09886.pdf">EffectiveModeling of Encoder-Decoder Architecture for Joint Entity and RelationExtraction, AAAI 2020</a></p><p>论文仍然是基于复制机制的Seq2Seq结构的取实体关系联合抽取模型，解码器生成提取的三元组，作者提出了一种新的三元组表示schema，如下图所示，'|'用于分割三元组，';'三元组内实体和关系，这使得<strong>解码器可以提取具有重叠实体的多个三元组，以及多token组成的实体关联的三元组</strong>。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-337056b657cc2b0f6820b4bb6428329d_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>作者提出了两种解码方法：WordDecoding (WDec) 和 PtrNetDecoding(PNDec)</p><ul><li><strong>WDec</strong>：类似CopyRE利用LSTM对文本进行解码，按上图中的schema一步步生成三元组，同时利用mask机制控制生成的内容仅包括当前句子中的tokens、关系tokens、特殊分隔符tokens</li><li><strong>PNDec</strong>：作者提出了基于指针网络（PointerNetwork）的解码方法，不同于WDec每一步生成一个token或word，PNDec每一不生成一个三元组。PNDec获得当前解码的隐层表示后，传入两个全连接层分别识别出两个实体的开始和结束位置，然后再利用两个实体表示判断关系。</li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-74e20803253fb7f1ce987dce622e08f7_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="snp">6.2 SNP</h3><p>SPN: <ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2011.01675.pdf">JointEntity and Relation Extraction with Set Prediction Networks,2020</a></p><p><strong>[动机]：</strong>上述的基于copy机制的Seq2Seq抽取模型均使用自回归的解码器(autoregressive)，需要将预测的三元组集合转化成三元组序列，并用解码器一步一步的生成三元组。但是这些基于自回归解码的模型存在两个问题：首先，<strong>需要考虑多个三元组之间的抽取顺序</strong>，但是文本中包含的三元组本质上没有内在顺序，为了适应输出为序列的自回归解码器，无序的三元组在训练时必须按一定的顺序排序；其次，<strong>交叉熵是一个对序列排列敏感的损失函数</strong>，对每个位置预测错误的三元组都会产生惩罚。</p><p>论文将实体关系联合抽取看做一个集合预测问题，不用考虑多个三元组之间的顺序。SPN采用非自回归的并行解码方式，能够直接一次性输出最终预测的三元组集合。同时，提出了二分匹配损失bipartitematchingloss，它通过忽略三元组顺序并专注于关系类型和实体，为模型提供更准确的训练信号。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-346b784c03c52c20f094a91740e9730d_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>模型细节</strong></li></ul><p><strong>[Sentence Encoder]:</strong> 利用BERT对输入的文本句子 𝑋进行编码，获得token序列的隐层表示 𝐻𝑒</p><p><strong>[Non-Autoregressive Decoder]:</strong> 下式为给定输入文本 𝑋，目标三元组集合 𝑌 的概率密度函数， 𝑝𝐿(𝑛|𝑋)为目标三元组集合的大小。在解码之前，解码器需要知道生成目标集合的大小，论文将𝑝𝐿(𝑛|𝑋)设置为固定大小𝑚 ，其中 𝑚 大于一个句子中常规的三元组数目。解码器的输入被初始化为 𝑚个可学习的embeddings，且所有句子共享。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-6ba01e3db987584756958dcda4c1e48f_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>将 𝑚 个三元组queries的embeddings传入decoder，经过一个由 𝑁个transformer层的模块对三元组之间的关系进行建模，并获得 𝑚个输出embeddings，表示为 𝐻𝑑。𝐻𝑑最后经过前馈神经网络FFN解码为关系类型和实体，最终组成 𝑚个预测的三元组。</p><p>给定解码器输出的embedding向量 ℎ𝑑∈𝐻𝑑 ,通过下式获得预测的关系类型：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-381c7629e77b0c05cbe42099090035d4_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>预测的实体通过分类器预测的实体开始和结束的索引解码得到：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-bc9c2a7e50c8737595783def10b00403_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>[Bipartite Matching Loss]:</strong>SPN预测的三元组并没有考虑顺序，而交叉熵对预测的三元组之间位置的置换非常敏感，因此提出了一个setpredictionloss，它可以在预测的三元组和真实三元组之间进行最佳的二分匹配。</p><p>𝑌 表示真实的三元组集合，其中每个三元组表示为𝑌𝑖=(𝑟𝑖,𝑠𝑖𝑠𝑡𝑎𝑟𝑡,𝑠𝑖𝑒𝑛𝑑,𝑜𝑖𝑠𝑡𝑎𝑟𝑡,𝑜𝑖𝑒𝑛𝑑)；𝑌<sup>表示预测的三元组集合，其中每个预测的三元组表示为𝑌𝑖</sup>=(𝑝𝑖𝑟,𝑝𝑖𝑠−𝑠𝑡𝑎𝑟𝑡,𝑝𝑖𝑠−𝑒𝑛𝑑,𝑝𝑖𝑜−𝑠𝑡𝑎𝑟𝑡,𝑝𝑖𝑜−𝑒𝑛𝑑)。通过最小化如下的损失函数优化模型：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-ec1b8bd9ea2e1d6c7af186eaf46b4d55_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>𝐶𝑚𝑎𝑡𝑐ℎ(.)是一个pair-wise的匹配代价函数，通过考虑真实三元组和预测三元组的关系类别和实体的起始位置来计算得到：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-1f2871200381a4c4d250c5943ee9043c_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="cgt">6.3 CGT</h3><p><ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2009.06207.pdf">ContrastiveTriple Extraction with Generative Transformer, AAAI 2021</a></p><p><strong>[动机]：</strong>论文关注的是生成式三元组抽取，但是已有的CopyRE这一系列基于复制机制并以RNN作为编解码器的模型存在两个关键的问题：一是<strong>无法捕捉文本的长距离依赖关系</strong>，很难应用于长文本；二是<strong>很少关注生成可信的三元组</strong>，比如文本“Obama was born in Honolulu”中正确的三元组是“(Obama, was born,Honolulu)”，而模型生成“(Obama, live in, Honolulu)”，虽然逻辑上可能是对的，但是文本中却没有直接的证据来推断。</p><p>为解决以上的问题，将三元组抽取看做一个序列生成问题，并受到当前基于Transformer的自然语言生成研究的启发，提出一个基于生成式Transformer的对比三元组抽取模型（<strong>C</strong>ontrastivetriple extraction with <strong>G</strong>enerative<strong>T</strong>ransformer，CGT)。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-0b226eed4730ffe2fa3c78785065d63f_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>CGT模型结构图</p><ul><li><strong>Input Encoder</strong></li></ul><p>CGT的基本模型架构是参考微软提出的预训练模型<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.03197.pdf">UniLM</a>中的Sequence-to-SequenceLM任务部分。输入句子的tokens组成sourcesequence，所有三元组的通过特殊标志[S2S_SEQ]拼接组成targetsource，如下所示：</p><blockquote><p><strong>Source Sequence</strong>: <em>[CLS]The United StatesPresident Trump was raised in the borough of Queens in New York City,and lived there until age 13. [SEP]</em> <strong>TargetSequence</strong>:<em>[SOS]Trump-&gt;president-&gt;of-&gt;United-&gt;States-&gt;[S2S_SEQ]-&gt;Trump,born-&gt;in-&gt;Queens-&gt;[S2S_SEQ]-&gt;Trump-&gt;live-&gt;in-&gt;Queens[EOS]</em></p></blockquote><p>在训练时，encoder的输入由source sequence和target sequence，即𝑥0,𝑥1,...,𝑥𝑚,[𝑆𝐸𝑃],𝑦0,𝑦1,𝑦𝑛，用生成式transformer对输入进行编码并生成输出，利用交叉熵损失函数优化生成过程：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-28e3fcc636e75c0444b4e0d7df00d14a_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>在测试推断时，encoder输入的是source sequence，模型生成targetsequence。</p><p>生成式transformer在每一层的自注意力计算时使用了partial causalmask，source sequence中的tokens间可以自由交互，targetsequence只能与左侧的tokens以及source sequence中的tokens进行交互</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-69770684134e598709eb7dc5f6c368b9_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>Triplet Contrastive Learning</strong></li></ul><p>为了增强生成三元组的可信度并与原句语境保持一致，在上述模型基础上引出三元组对比学习。将正确的三元组作为正样例，将三元组中的一个实体随机替换为文本中tokens作为负样例。编码器输入时仅将文本与一个三元组拼接，编码后将[CLS]的隐层表示传入MLP进行二分类，并用交叉熵损失函数优化三元组对比过程：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-cdc596c271f8a9c694c301c41dcd9590_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>在三元组对比学习时，编码器Transformer的自注意力计算使用的是全0mask，与三元组生成的partial causal mask不同</p><ul><li><strong>Training and Inference Details</strong></li></ul><p>在训练优化时，针对三元组生成和三元组对比学习两个不同的任务的共同优化提出了批量动态注意力掩码（batch-wisedynamic attentionmasking）。作者利用Bernoulli分布抽取一部分样例用于三元组生成，剩余的用于三元组对比学习，用不同的样本训练两个任务，并进行联合优化。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-aa1937bb426d7e6af0e8f495c3ff30aa_720w.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>在推断时，模型先利用beamsearch生成所有的三元组序列，然后利用三元组校准算法过滤不可信的三元组。利用三元组对比分类模块计算文本三元组匹配分值，过滤小于一定阈值𝜃的三元组；同时还利用一些启发性规则生成三元组，比如头实体生成之后要生成关系等。</p><ul><li><strong>模型分析</strong></li></ul><p>实验结果表明CGT较CopyRE这类已有的生成式模型性能提升较大，和CasRel这类抽取式的模型相比获得了可比较的性能结果，这是由于生成式模型的搜索空间远大于抽取式模型。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-fc0f568941c04d6692ca49f1b86f606e_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>同时还进行了错误分析，展示了模型的生成三元组时的三个缺点：一是模糊的上下文难以处理，一些上下文相似的文本模型更倾向于预测高频的关系；二是边界错误，三元组生成时很难捕捉判断实体的边界；三是错误的三元组，这个是在说WeNLG数据集存在错误样例，属于无效分析......</p><h3 id="rebel">6.4 REBEL</h3><p><ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2021.findings-emnlp.204.pdf">REBEL:Relation Extraction By End-to-end Language generation, EMNLP2021</a></p><p><strong>[动机]：</strong>现有模型往往涉及多步的层级模块且计算复杂度高，各个以任务为中心的模块（e.g.,实体识别和关系分类）需要训练适配不同的实体和关系数目，无法灵活的处理不同类型或不同领域的抽取任务，并且对于新的数据常常需要长时间的训练优化。</p><p>针对上述问题，论文将关系抽取看做Seq2Seq任务，基于 <ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1910.13461.pdf">BART:Denoising Sequence-to-Sequence Pre-training for Natural LanguageGeneration, Translation, and Comprehension</a>提出端到端语言生成的关系抽模型REBEL，并构建了一个大规模的远程监督数据集。利用构建的REBEL数据集对BART进行预训练，然后在下游的抽取任务上微调很少的epochs就能达到SOTA性能。REBEL模型能够灵活的适应新的领域和更长的文档数据，同时不需要从头训练特定的模块，使得训练更高效。</p><ul><li><strong>Model Details</strong></li></ul><p>REBEL利用BART-large作为基础模型，采用如下图所示的encoder-decoder结构，将原始的文本句子作为输入，将生成的三元组集合作为输出，并利用交叉熵损失函数优化模型。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-01b42a9d5c30d1170a4e8244248a22a2_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>Triplets linearization</strong></li></ul><p>作者设计了三元组线性化规则将解码器生成的三元组用token序列表示，如下图所示。三元组输出线性化表示一方面使得模型在解码过程中可以同时利用编码器的输入和解码器已经输出的信息，捕捉更长距离的依赖；另一方面能够最小化生成tokens的数目，使得解码和优化更高效。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-94ab7fbc8bb57fc53c0c5523278b4a5b_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><triplet> 表示一个新的三元组的开始，即头实体； <subj>表示头实体的结束和尾实体的开始； <obj>表示尾实体的结束和关系的开始。</p><p>解码生成的三元组按照头实体在文本中出现的顺序进行排序，头实体重叠的多个三元组不需要每次都将头实体列出以减少生成序列的长度。最后，利用解码器生成的token序列转化成三元组。</p><ul><li><strong>REBEL dataset</strong></li></ul><p>BART模型需要大量的数据来训练，但是现有的关系抽取数据集很少并且通常很小，因此作者利用Wikipedia构建了一个大规模的实体关系数据集用于BART预训练。</p><p>作者使用 wikimapper 将文本中超链接对应的词作为实体链接到 Wikidata的实体，提取了Wikidata中这些实体之间存在的所有关系。为了滤除噪声，使用预训练的RoBERTa模型进行蕴含预测判断文本是否包含某个关系组，将文本与三元组拼接（i.e.,text [sep] subject relationobject）输入RoBERTa预测分数，高于一定阈值才保留，否则丢弃。</p><p>论文选取句子级的样例，并保留最多的220种关系构成句子级数据集，预训练BART-large作为REBELpre−training</p><ul><li><strong>实验结果分析</strong><ul><li>REBELpre−training在所有数据集上都超过了SOTA模型性能，而没有进行预训练的REBEL模型性能有所下降，尤其是在规模更小或有更多实体类别的数据集上，但仍然达到了可比较的性能。</li><li>REBELpre−training能够灵活的适应新的场景领域，REBEL在构建的数据集上与训练一次，在新的数据集上只需要训练微调很少的epoches就能快速收敛并获得较好的结果。</li></ul></li></ul><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-6ca8365b5545a81e301e41d9bd75d112_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h3 id="uie">6.5 UIE</h3><p><ahref="https://link.zhihu.com/?target=https%3A//aclanthology.org/2022.acl-long.395.pdf">UnififiedStructure Generation for Universal Information Extraction, ACL2022</a></p><p><ahref="https://link.zhihu.com/?target=https%3A//openreview.net/pdf%3Fid%3Da8qX5RG36jd">UnifyingInformation Extraction with Latent Adaptive Structure-aware GenerativeLanguage Model， NeruIPS 2022</a></p><p><strong>[动机]：</strong>当前信息抽取IE由于其不同的抽取目标（实体、关系、事件、情感）、异质的抽取结构（实体-&gt;span片段、关系-&gt;三元组、事件-&gt;记录）、不同的schema模式使其任务非常多样。当前IE方法都是任务特定的（<em>Task-Specialized</em>），针对不同的IE任务构建专用的架构、独立的模型和专用的知识源，导致了以下三个问题：① 为大量不同的IE任务、配置、场景开发专用的模型架构时非常复杂的；②学习独立的模型严重限制了相关任务和配置间的知识共享；③针对不同IE任务构建数据集和知识源是非常昂贵和耗时的。因此，开发一种通用的IE 架构（<em>Universal IE</em>），可以对不同的 IE任务进行统一建模，自适应地预测异构结构并有效地从各种资源中学习。</p><figure><imgsrc="data:image/svg+xml;utf8,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20width=&#39;502&#39;%20height=&#39;391&#39;%3E%3C/svg%3E"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>针对以上问题，作者提出了一个统一的文本到结构（text-to-structure）的生成式信息抽取模型-UIE，它能够对不同的IE任务进行统一的建模、自适应地生成目标结构、从不同的知识源协同学习通用的IE能力。</p><ul><li>设计了一个<strong>结构化抽取语言</strong> ( Structural ExtractionLanguage, <strong>SEL</strong>)，有效地将不同的IE结构转化成一个统一的表示。因此，各种IE任务可以在同一个text-to-structure框架下进行统一建模。</li><li>提出了一个<strong>结构化模式指导器</strong> ( Structural SchemaInstructor, <strong>SSI</strong> ),能够针对不同的IE任务自适应的生成目标结构。SSI是一种基于Schema的Prompt机制，控制着不同任务抽取生成的内容。</li><li>利用从网络上获取的大规模、异质的数据集对UIE进行预训练，学习通用的IE能力，大规模预训练的UIE模型能够快速适用于新的场景、任务、配置。</li></ul><figure><imgsrc="data:image/svg+xml;utf8,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20width=&#39;989&#39;%20height=&#39;239&#39;%3E%3C/svg%3E"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>Structured Extraction Language for Uniform StructureEncoding （输出机构化）</strong></li></ul><p>SEL将异质的信息抽取结构转化成统一输出表示，即实体识别、关系抽取、事件抽取等不同任务的输出经过统一的结构、规则、模型进行编码。IE的结构生成可以分解成两类原子操作：①Spotting：表示定位句子中的目标信息片段，如实体或事件触发词；②Associating：表示链接不同的信息片段Spotting，如实体间的关系或事件的论元的角色。</p><p>SEL就是基于Spotting-Associating结构的，SEL表达式包括三中类型的语义单元：<strong>①</strong><strong>SPOTNAME</strong>：表示原文本中存在SpotName类型的信息片段；<strong>②ASSONAME：</strong>表示源文本中存在一个特定的信息片段，它与结构中的上层Spotted 信息具有 AssoName 关联；<strong>③INFOSPAN</strong>：表示与文本中特定的Spotting或Associating信息片段相对应的文本片段。如下图为SEL的结构和编码示例：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-d631c42113207d039f66ae88833fd4bf_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>使用SEL作为生成输出编码的好处有三点：首先，对不同的IE结构统一编码使得不同的IE任务可以建模为相同的text-to-structure生成过程；其次，将句子的所有提取结果高效地表示为相同结构可以自然地进行联合提取；最后，生成的输出结构非常紧凑，大大降低了解码的复杂度。</p><ul><li><strong>Structural Schema Instructor for Controllable IE StructureGeneration （输入结构化）</strong></li></ul><p>SSI是一种基于schema的prompt机制，它将不同任务的schema作为提示，在抽取过程中自适应地控制那种类型的信息需要被生成。将SSI序列𝑠=[𝑠1,...,𝑠|𝑠|] 与文本序列 𝑥=[𝑥1,...,𝑥|𝑥|]拼接作为UIE模型的输入，生成SEL序列𝑦=[𝑦1,...,𝑦|𝑦|]。即 𝑦=𝑈𝐼𝐸(𝑠⊕𝑥)，UIE利用encoder-decoder的结构（比如BART或T5模型）完成text-to-SEL的生成过程，首先对输入编码获得输入的隐层表示𝐻，然后UIE以自回归的方式对输入解码生成SEL序列，最后将预测的SEL表达式转化成提取的正常记录结构。</p><p>下式为输入的形式，SSI作为文本的前缀，其中包括三种类型的token段：①SPOTNAME，比如实体类别；② ASSONAME，比如关系类别；③ ) 特殊符号（[spot],[asso], [text]），需要分别放置在 SPOTNAME、ASSONAME和文本的前面。</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-51c7f71639921d1440db638ec61f0a81_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>以实体识别和关系抽取任务为例，SSI如下表所示：</p><figure><imgsrc="/images/NER与关系抽取任务中常用的模型/v2-f644225d9e53d097e4c50a0bff6e9d26_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><ul><li><strong>Pre-training and Fine-tuning for UIE</strong></li></ul><p><strong>[ Pre-training ]</strong>作者和REBEL模型类似，利用Wikipedia、Wikidatadump和ConceptNet构建一个大规模预训练语料库对UIE模型进行预训练学习通用的IE能力。作者构建了三部分预训练数据利用三类序列生成任务对UIE进行预训练：</p><p>① 𝐷𝑃𝑎𝑖𝑟={(𝑥,𝑦)} 是text-structure并行数据，其中每个样例为&lt;token序列𝑥 ，结构化记录 𝑦 &gt;。𝐷𝑃𝑎𝑖𝑟用于学习模型基础的text-to-structure映射生成能力</p><p>② 𝐷𝑅𝑒𝑐𝑜𝑟𝑑是只包含SEL表达式的数据，用于预训练UIE的解码器，学习生成由SEL和schema定义的结构的能力</p><p>③ 𝐷𝑇𝑒𝑥𝑡是原始文本数据，通过T5模型中的掩码语言模型任务预训练UIE，增强模型的语义表示能力</p><p>论文将<ahref="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1910.10683.pdf">T5( Exploring the Limits of Transfer Learning with a Unified Text-to-TextTransformer )</a> 作为基本的模型结构,使用T5-v1.1-base andT5-v1.1-large分别初始化UIE-base和UIE-large，并整合上述三个任务对UIE进行预训练，预训练目标函数为：𝐿=𝐿𝑃𝑎𝑖𝑟+𝐿𝑅𝑒𝑐𝑜𝑟𝑑+𝐿𝑇𝑒𝑥𝑡</p><p><strong>[ Fine-tuning ]</strong> 利用预训练好的模型 UIEpre_training可以快速的在不同任务和配置上进行微调，给定新标注的语料库 𝐷𝑡𝑎𝑠𝑘={(𝑠,𝑥,𝑦)},通过teacher-forcing的交叉熵损失函数 𝐿𝐹𝑇 微调模型。</p><p>为了缓解暴露偏差问题，作者设计了一个<em><strong>Rejection</strong>机制来有效微调模型。给定样例</em> (𝑠,𝑥,𝑦),对进行SEL编码，然后以一定的概率随机插入具有错误SPOTNAME和ASSONAME的[NULL]单元，即(SPOTNAME, [NULL]) 和 (ASSONAME, [NULL])。这样，UIE 可以通过生成 [NULL]token来有效地拒绝错误的生成。</p><ul><li><strong>实验分析</strong></li></ul><p><strong>[Experiments on Supervised Settings]:</strong>UIE模型在4个任务的13数据集上与SOTA模型相相比，大多数数据集上性能均有所提升，或者获得了可比较的性能。这说明UIE这种统一的生成式抽取方式是有效的，大规模的预训练模型确实为通用IE提供能较好的性能基础。最重要的是UIE通过统一的对不同IE任务进行建模并在大规模数据集上预训练，有效捕捉了共享、可迁移的信息抽取能力，这种能力十分重要和有效。</p><p><strong>[** **Experiments on Low-resource Settings]:</strong>从实验结果来看，UIE更重要的能力在于处理低资源的信息抽取任务，对于少样本任务性能提升很明显，这仍然是得益于大规模预训练模型、以及多IE任务统一建模预训练。</p>]]></content>
    
    
    <categories>
      
      <category>NLP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>NER模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模型剪枝原理与实现</title>
    <link href="/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9Dpruning.html"/>
    <url>/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9Dpruning.html</url>
    
    <content type="html"><![CDATA[<p>仿照生物的稀疏神经网络, 将大型网络中的稠密连接变成稀疏的连接,并同样达到SOTA的效果, 就是模型剪枝的原动力. <span id="more"></span></p><h2 id="什么是模型的剪枝">1.什么是模型的剪枝<a href="#1">¶</a></h2><ul><li><p>基于深度神经网络的大型预训练模型拥有庞大的参数量,才能达到SOTA的效果. 但是我们参考生物的神经网络,发现却是依靠大量稀疏的连接来完成复杂的意识活动.</p></li><li><p>仿照生物的稀疏神经网络, 将大型网络中的稠密连接变成稀疏的连接,并同样达到SOTA的效果, 就是模型剪枝的原动力.</p></li></ul><figure><img src="/images/模型剪枝/2_2.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><hr /><ul><li>Pytorch中对模型剪枝的支持在torch.nn.utils.prune模块中,分以下几种剪枝方式:<ul><li>对特定网络模块的剪枝(Pruning Model).</li><li>多参数模块的剪枝(Pruning multiple parameters).</li><li>全局剪枝(GLobal pruning).</li><li>用户自定义剪枝(Custom pruning).</li></ul></li></ul><hr /><blockquote><ul><li>注意: 保证Pytorch的版本在1.4.0以上, 支持剪枝操作.</li></ul></blockquote><hr /><h2id="对特定网络模块的剪枝pruning-model.">2.对特定网络模块的剪枝(PruningModel).<a href="#2pruning-model">¶</a></h2><ul><li>首先导入工具包:</li></ul><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> torch<br><span class="hljs-title">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> torch.nn.utils.prune <span class="hljs-keyword">as</span> prune<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br></code></pre></td></tr></table></figure><hr /><ul><li>创建一个网络, 我们以经典的LeNet来示例:</li></ul><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">device</span> = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><span class="hljs-class"></span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">LeNet</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">LeNet</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        # 1: 图像的输入通道(1是黑白图像), 6: 输出通道, 3x3: 卷积核的尺寸</span><br><span class="hljs-class">        self.conv1 = nn.<span class="hljs-type">Conv2d</span>(1, 6, 3)</span><br><span class="hljs-class">        self.conv2 = nn.<span class="hljs-type">Conv2d</span>(6, 16, 3)</span><br><span class="hljs-class">        self.fc1 = nn.<span class="hljs-type">Linear</span>(16 * 5 * 5, 120)  # 5x5 是经历卷积操作后的图片尺寸</span><br><span class="hljs-class">        self.fc2 = nn.<span class="hljs-type">Linear</span>(120, 84)</span><br><span class="hljs-class">        self.fc3 = nn.<span class="hljs-type">Linear</span>(84, 10)</span><br><span class="hljs-class"></span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>, <span class="hljs-title">x</span>):</span><br><span class="hljs-class">        x = <span class="hljs-type">F</span>.max_pool2d(<span class="hljs-type">F</span>.<span class="hljs-title">relu</span>(<span class="hljs-title">self</span>.<span class="hljs-title">conv1</span>(<span class="hljs-title">x</span>)), (2, 2))</span><br><span class="hljs-class">        x = <span class="hljs-type">F</span>.max_pool2d(<span class="hljs-type">F</span>.<span class="hljs-title">relu</span>(<span class="hljs-title">self</span>.<span class="hljs-title">conv2</span>(<span class="hljs-title">x</span>)), 2)</span><br><span class="hljs-class">        x = x.view(-1, <span class="hljs-title">int</span>(<span class="hljs-title">x</span>.<span class="hljs-title">nelement</span>() / x.shape[0]))</span><br><span class="hljs-class">        x = <span class="hljs-type">F</span>.relu(<span class="hljs-title">self</span>.<span class="hljs-title">fc1</span>(<span class="hljs-title">x</span>))</span><br><span class="hljs-class">        x = <span class="hljs-type">F</span>.relu(<span class="hljs-title">self</span>.<span class="hljs-title">fc2</span>(<span class="hljs-title">x</span>))</span><br><span class="hljs-class">        x = self.fc3(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return x</span><br><span class="hljs-class"></span><br><span class="hljs-class">model = <span class="hljs-type">LeNet</span>().to(<span class="hljs-title">device</span>=<span class="hljs-title">device</span>)</span><br></code></pre></td></tr></table></figure><hr /><ul><li>调用:</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">module = model<span class="hljs-selector-class">.conv1</span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(list(module.named_parameters()</span></span>))<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;weight</span>&#x27;, Parameter containing:<br>tensor([[[[ <span class="hljs-number">0.0853</span>, <span class="hljs-number">-0.0203</span>, <span class="hljs-number">-0.0784</span>],<br>          [ <span class="hljs-number">0.3327</span>, <span class="hljs-number">-0.0904</span>, <span class="hljs-number">-0.0374</span>],<br>          [<span class="hljs-name">-0.0037</span>, <span class="hljs-number">-0.2629</span>, <span class="hljs-number">-0.2536</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.1313</span>,  <span class="hljs-number">0.0249</span>,  <span class="hljs-number">0.2735</span>],<br>          [ <span class="hljs-number">0.0630</span>,  <span class="hljs-number">0.0625</span>, <span class="hljs-number">-0.0468</span>],<br>          [ <span class="hljs-number">0.3328</span>,  <span class="hljs-number">0.3249</span>, <span class="hljs-number">-0.2640</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.1931</span>, <span class="hljs-number">-0.2246</span>,  <span class="hljs-number">0.0102</span>],<br>          [ <span class="hljs-number">0.3319</span>,  <span class="hljs-number">0.1740</span>, <span class="hljs-number">-0.0799</span>],<br>          [<span class="hljs-name">-0.0195</span>, <span class="hljs-number">-0.1295</span>, <span class="hljs-number">-0.0964</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.3005</span>,  <span class="hljs-number">0.2704</span>,  <span class="hljs-number">0.3162</span>],<br>          [<span class="hljs-name">-0.2560</span>,  <span class="hljs-number">0.0295</span>,  <span class="hljs-number">0.2605</span>],<br>          [<span class="hljs-name">-0.1056</span>, <span class="hljs-number">-0.0730</span>,  <span class="hljs-number">0.0436</span>]]],<br><br><br>        [[[<span class="hljs-name">-0.3205</span>,  <span class="hljs-number">0.1927</span>, <span class="hljs-number">-0.0761</span>],<br>          [ <span class="hljs-number">0.0142</span>, <span class="hljs-number">-0.0562</span>, <span class="hljs-number">-0.3087</span>],<br>          [ <span class="hljs-number">0.1202</span>,  <span class="hljs-number">0.1119</span>, <span class="hljs-number">-0.1336</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0568</span>,  <span class="hljs-number">0.1142</span>,  <span class="hljs-number">0.3079</span>],<br>          [ <span class="hljs-number">0.2000</span>, <span class="hljs-number">-0.1661</span>, <span class="hljs-number">-0.2935</span>],<br>          [<span class="hljs-name">-0.1652</span>, <span class="hljs-number">-0.2606</span>, <span class="hljs-number">-0.0559</span>]]]], device=<span class="hljs-symbol">&#x27;cuda:0</span>&#x27;, requires_grad=True)), (<span class="hljs-symbol">&#x27;bias</span>&#x27;, Parameter containing:<br>tensor([ <span class="hljs-number">0.1085</span>, <span class="hljs-number">-0.1044</span>,  <span class="hljs-number">0.1366</span>,  <span class="hljs-number">0.3240</span>, <span class="hljs-number">-0.1522</span>,  <span class="hljs-number">0.1630</span>], device=<span class="hljs-symbol">&#x27;cuda:0</span>&#x27;,<br>       requires_grad=True))]<br></code></pre></td></tr></table></figure><hr /><ul><li>再打印一个特殊的属性张量</li></ul><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-function"><span class="hljs-title">print</span>(<span class="hljs-title">list</span>(<span class="hljs-variable">module.named_buffers</span>()))</span><br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 这里面打印出一个空列表, 至于这个空列表代表什么含义? 剪枝操作后同学们就明白了!</span><br><span class="hljs-section">[]</span><br></code></pre></td></tr></table></figure><hr /><ul><li>直接调用prune函数对模型进行剪枝操作:</li></ul><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs clean"># 第一个参数: <span class="hljs-keyword">module</span>, 代表要进行剪枝的特定模块, 之前我们已经制定了<span class="hljs-keyword">module</span>=model.conv1,<br>#             说明这里要对第一个卷积层执行剪枝.<br># 第二个参数: name, 指定要对选中的模块中的哪些参数执行剪枝.<br>#             这里设定为name=<span class="hljs-string">&quot;weight&quot;</span>, 意味着对连接网络中的weight剪枝, 而不对bias剪枝.<br># 第三个参数: amount, 指定要对模型中多大比例的参数执行剪枝.<br>#             amount是一个介于<span class="hljs-number">0.0</span><span class="hljs-number">-1.0</span>的float数值, 或者一个正整数指定剪裁掉多少条连接边.<br><br>prune.random_unstructured(<span class="hljs-keyword">module</span>, name=<span class="hljs-string">&quot;weight&quot;</span>, amount=<span class="hljs-number">0.3</span>)<br></code></pre></td></tr></table></figure><hr /><ul><li>调用:</li></ul><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-function"><span class="hljs-title">print</span>(<span class="hljs-title">list</span>(<span class="hljs-variable">module.named_parameters</span>()))</span><br><span class="hljs-function"><span class="hljs-title">print</span>(<span class="hljs-title">list</span>(<span class="hljs-variable">module.named_buffers</span>()))</span><br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;bias</span>&#x27;, Parameter containing:<br>tensor([ <span class="hljs-number">0.1861</span>,  <span class="hljs-number">0.2483</span>, <span class="hljs-number">-0.3235</span>,  <span class="hljs-number">0.0667</span>,  <span class="hljs-number">0.0790</span>,  <span class="hljs-number">0.1807</span>], device=<span class="hljs-symbol">&#x27;cuda:0</span>&#x27;,<br>       requires_grad=True)), (<span class="hljs-symbol">&#x27;weight_orig</span>&#x27;, Parameter containing:<br>tensor([[[[<span class="hljs-name">-0.1544</span>, <span class="hljs-number">-0.3045</span>,  <span class="hljs-number">0.1339</span>],<br>          [ <span class="hljs-number">0.2605</span>, <span class="hljs-number">-0.1201</span>,  <span class="hljs-number">0.3060</span>],<br>          [<span class="hljs-name">-0.2502</span>, <span class="hljs-number">-0.0023</span>, <span class="hljs-number">-0.0362</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.3147</span>, <span class="hljs-number">-0.1034</span>, <span class="hljs-number">-0.1772</span>],<br>          [<span class="hljs-name">-0.2250</span>, <span class="hljs-number">-0.1071</span>,  <span class="hljs-number">0.2489</span>],<br>          [ <span class="hljs-number">0.2741</span>, <span class="hljs-number">-0.1926</span>, <span class="hljs-number">-0.2046</span>]]],<br><br><br>        [[[<span class="hljs-name">-0.1022</span>, <span class="hljs-number">-0.2210</span>, <span class="hljs-number">-0.1349</span>],<br>          [<span class="hljs-name">-0.2938</span>,  <span class="hljs-number">0.0679</span>,  <span class="hljs-number">0.2485</span>],<br>          [ <span class="hljs-number">0.1108</span>, <span class="hljs-number">-0.0564</span>, <span class="hljs-number">-0.3328</span>]]],<br><br><br>        [[[<span class="hljs-name">-0.0464</span>,  <span class="hljs-number">0.0138</span>,  <span class="hljs-number">0.0283</span>],<br>          [<span class="hljs-name">-0.3205</span>,  <span class="hljs-number">0.0184</span>,  <span class="hljs-number">0.0521</span>],<br>          [ <span class="hljs-number">0.2219</span>, <span class="hljs-number">-0.2403</span>, <span class="hljs-number">-0.2881</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.3320</span>, <span class="hljs-number">-0.0684</span>, <span class="hljs-number">-0.1715</span>],<br>          [<span class="hljs-name">-0.0381</span>,  <span class="hljs-number">0.1819</span>,  <span class="hljs-number">0.1796</span>],<br>          [<span class="hljs-name">-0.3321</span>, <span class="hljs-number">-0.2684</span>, <span class="hljs-number">-0.0477</span>]]],<br><br><br>        [[[<span class="hljs-name">-0.1638</span>, <span class="hljs-number">-0.0969</span>,  <span class="hljs-number">0.0077</span>],<br>          [ <span class="hljs-number">0.0906</span>,  <span class="hljs-number">0.2051</span>,  <span class="hljs-number">0.2174</span>],<br>          [<span class="hljs-name">-0.2174</span>,  <span class="hljs-number">0.1875</span>, <span class="hljs-number">-0.2978</span>]]]], device=<span class="hljs-symbol">&#x27;cuda:0</span>&#x27;, requires_grad=True))]<br>[(<span class="hljs-symbol">&#x27;weight_mask</span>&#x27;, tensor([[[[<span class="hljs-name">1.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.]]],<br><br><br>        [[[<span class="hljs-name">0.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">0</span>.],<br>          [<span class="hljs-name">0.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">0.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.]]],<br><br><br>        [[[<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">0.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.]]],<br><br><br>        [[[<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.]]],<br><br><br>        [[[<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">0</span>.]]],<br><br><br>        [[[<span class="hljs-name">1.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">0.</span>, <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.],<br>          [<span class="hljs-name">1.</span>, <span class="hljs-number">1</span>., <span class="hljs-number">0</span>.]]]], device=<span class="hljs-symbol">&#x27;cuda:0</span>&#x27;))]<br></code></pre></td></tr></table></figure><hr /><blockquote><ul><li>结论: 模型经历剪枝操作后, 原始的权重矩阵weight参数不见了,变成了weight_orig. 并且刚刚打印为空列表的module.named_buffers(),此时拥有了一个weight_mask参数.</li></ul></blockquote><hr /><ul><li>这时打印module.weight属性值, 看看有什么启发?</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(module.weight)</span></span><br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs prolog">tensor([[[[<span class="hljs-number">-0.1544</span>, <span class="hljs-number">-0.0000</span>,  <span class="hljs-number">0.1339</span>],<br>          [ <span class="hljs-number">0.2605</span>, <span class="hljs-number">-0.0000</span>,  <span class="hljs-number">0.3060</span>],<br>          [<span class="hljs-number">-0.2502</span>, <span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.0362</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.0000</span>],<br>          [<span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.1071</span>,  <span class="hljs-number">0.2489</span>],<br>          [ <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.2046</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.1022</span>, <span class="hljs-number">-0.2210</span>, <span class="hljs-number">-0.1349</span>],<br>          [<span class="hljs-number">-0.0000</span>,  <span class="hljs-number">0.0679</span>,  <span class="hljs-number">0.2485</span>],<br>          [ <span class="hljs-number">0.1108</span>, <span class="hljs-number">-0.0564</span>, <span class="hljs-number">-0.3328</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.0464</span>,  <span class="hljs-number">0.0138</span>,  <span class="hljs-number">0.0283</span>],<br>          [<span class="hljs-number">-0.3205</span>,  <span class="hljs-number">0.0184</span>,  <span class="hljs-number">0.0521</span>],<br>          [ <span class="hljs-number">0.2219</span>, <span class="hljs-number">-0.2403</span>, <span class="hljs-number">-0.2881</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.3320</span>, <span class="hljs-number">-0.0684</span>, <span class="hljs-number">-0.1715</span>],<br>          [<span class="hljs-number">-0.0381</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.1796</span>],<br>          [<span class="hljs-number">-0.3321</span>, <span class="hljs-number">-0.2684</span>, <span class="hljs-number">-0.0000</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.1638</span>, <span class="hljs-number">-0.0000</span>,  <span class="hljs-number">0.0077</span>],<br>          [ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.2174</span>],<br>          [<span class="hljs-number">-0.2174</span>,  <span class="hljs-number">0.1875</span>, <span class="hljs-number">-0.0000</span>]]]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,<br>       grad_fn=&lt;<span class="hljs-symbol">MulBackward0</span>&gt;)<br></code></pre></td></tr></table></figure><hr /><blockquote><ul><li>结论: 经过剪枝操作后的模型, 原始的参数存放在了weight_orig中,对应的剪枝矩阵存放在weight_mask中, 而将weight_mask视作掩码张量,再和weight_orig相乘的结果就存放在了weight中.</li></ul></blockquote><hr /><blockquote><ul><li>注意: 剪枝操作后的weight已经不再是module的参数(parameter),而只是module的一个属性(attribute).</li></ul></blockquote><hr /><p>我们可以对模型的任意子结构进行剪枝操作, 除了在weight上面剪枝,还可以对bias进行剪枝.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 第一个参数: module, 代表剪枝的对象, 此处代表LeNet中的conv1</span><br><span class="hljs-comment"># 第二个参数: name, 代表剪枝对象中的具体参数, 此处代表偏置量</span><br><span class="hljs-comment"># 第三个参数: amount, 代表剪枝的数量, 可以设置为0.0-1.0之间表示比例, 也可以用正整数表示剪枝的参数绝对数量</span><br>prune.l1_unstructured(module, <span class="hljs-attribute">name</span>=<span class="hljs-string">&quot;bias&quot;</span>, <span class="hljs-attribute">amount</span>=3)<br><br><span class="hljs-comment"># 再次打印模型参数</span><br><span class="hljs-built_in">print</span>(list(module.named_parameters()))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><span class="hljs-built_in">print</span>(list(module.named_buffers()))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><span class="hljs-built_in">print</span>(module.bias)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果</li></ul><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[(<span class="hljs-string">&#x27;weight_orig&#x27;</span>, <span class="hljs-symbol">Parameter</span> containing:<br>tensor([[[[<span class="hljs-number">-0.0159</span>, <span class="hljs-number">-0.3175</span>, <span class="hljs-number">-0.0816</span>],<br>          [ <span class="hljs-number">0.3144</span>, <span class="hljs-number">-0.1534</span>, <span class="hljs-number">-0.0924</span>],<br>          [<span class="hljs-number">-0.2885</span>, <span class="hljs-number">-0.1054</span>, <span class="hljs-number">-0.1872</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0835</span>, <span class="hljs-number">-0.1258</span>, <span class="hljs-number">-0.2760</span>],<br>          [<span class="hljs-number">-0.3174</span>,  <span class="hljs-number">0.0669</span>, <span class="hljs-number">-0.1867</span>],<br>          [<span class="hljs-number">-0.0381</span>,  <span class="hljs-number">0.1156</span>,  <span class="hljs-number">0.0078</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.1416</span>, <span class="hljs-number">-0.2907</span>, <span class="hljs-number">-0.0249</span>],<br>          [ <span class="hljs-number">0.1018</span>,  <span class="hljs-number">0.1757</span>, <span class="hljs-number">-0.0326</span>],<br>          [ <span class="hljs-number">0.2736</span>, <span class="hljs-number">-0.1980</span>, <span class="hljs-number">-0.1162</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.1835</span>,  <span class="hljs-number">0.1600</span>,  <span class="hljs-number">0.3178</span>],<br>          [ <span class="hljs-number">0.0579</span>, <span class="hljs-number">-0.0647</span>, <span class="hljs-number">-0.1039</span>],<br>          [<span class="hljs-number">-0.0160</span>, <span class="hljs-number">-0.0715</span>,  <span class="hljs-number">0.2746</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.2314</span>, <span class="hljs-number">-0.1759</span>, <span class="hljs-number">-0.1820</span>],<br>          [<span class="hljs-number">-0.0594</span>,  <span class="hljs-number">0.2355</span>, <span class="hljs-number">-0.2087</span>],<br>          [ <span class="hljs-number">0.0216</span>,  <span class="hljs-number">0.0066</span>, <span class="hljs-number">-0.0624</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.2772</span>,  <span class="hljs-number">0.1479</span>, <span class="hljs-number">-0.0983</span>],<br>          [<span class="hljs-number">-0.3307</span>, <span class="hljs-number">-0.2360</span>, <span class="hljs-number">-0.0596</span>],<br>          [ <span class="hljs-number">0.2785</span>,  <span class="hljs-number">0.0648</span>,  <span class="hljs-number">0.2869</span>]]]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="hljs-symbol">True</span>)), (<span class="hljs-string">&#x27;bias_orig&#x27;</span>, <span class="hljs-symbol">Parameter</span> containing:<br>tensor([<span class="hljs-number">-0.1924</span>, <span class="hljs-number">-0.1420</span>, <span class="hljs-number">-0.0235</span>,  <span class="hljs-number">0.0325</span>,  <span class="hljs-number">0.0188</span>,  <span class="hljs-number">0.0120</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,<br>       requires_grad=<span class="hljs-symbol">True</span>))]<br>**************************************************<br>[(<span class="hljs-string">&#x27;weight_mask&#x27;</span>, tensor([[[[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>          [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>]]]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)), (<span class="hljs-string">&#x27;bias_mask&#x27;</span>, tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>))]<br>**************************************************<br>tensor([<span class="hljs-number">-0.1924</span>, <span class="hljs-number">-0.1420</span>, <span class="hljs-number">-0.0000</span>,  <span class="hljs-number">0.0325</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,<br>       grad_fn=&lt;<span class="hljs-symbol">MulBackward0</span>&gt;)<br>**************************************************<br></code></pre></td></tr></table></figure><hr /><blockquote><ul><li>结论: 在module的不同参数集合上应用不同的剪枝策略,我们发现模型参数中不仅仅有了weight_orig, 也有了bias_orig.在起到掩码张量作用的named_buffers中,也同时出现了weight_mask和bias_mask.</li></ul></blockquote><hr /><ul><li>序列化一个剪枝模型(Serializing a pruned model):</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 对于一个模型来说, 不管是它原始的参数, 拥有的属性值, 还是剪枝的mask buffers参数</span><br><span class="hljs-comment"># 全部都存储在模型的状态字典中, 即state_dict()中.</span><br><span class="hljs-comment"># 将模型初始的状态字典打印出来</span><br><span class="hljs-built_in">print</span>(model.state_dict().keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 对模型进行剪枝操作, 分别在weight和bias上剪枝</span><br>module = model.conv1<br>prune.random_unstructured(module, <span class="hljs-attribute">name</span>=<span class="hljs-string">&quot;weight&quot;</span>, <span class="hljs-attribute">amount</span>=0.3)<br>prune.l1_unstructured(module, <span class="hljs-attribute">name</span>=<span class="hljs-string">&quot;bias&quot;</span>, <span class="hljs-attribute">amount</span>=3)<br><br><span class="hljs-comment"># 再将剪枝后的模型的状态字典打印出来</span><br><span class="hljs-built_in">print</span>(model.state_dict().keys())<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sml">odict_keys([<span class="hljs-symbol">&#x27;conv1</span>.weight&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.bias&#x27;])<br>**************************************************<br>odict_keys([<span class="hljs-symbol">&#x27;conv1</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.bias_orig&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.bias_mask&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.bias&#x27;])<br></code></pre></td></tr></table></figure><hr /><ul><li>关键一步: 对模型执行剪枝remove操作.<ul><li>通过module中的参数weight_orig和weight_mask进行剪枝,本质上属于置零遮掩, 让权重连接失效.</li><li>这个remove是无法undo的,也就是说一旦执行就是对模型参数的永久改变.</li></ul></li></ul><hr /><ul><li>执行remove操作的演示代码:</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 打印剪枝后的模型参数</span><br><span class="hljs-built_in">print</span>(list(module.named_parameters()))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 打印剪枝后的模型mask buffers参数</span><br><span class="hljs-built_in">print</span>(list(module.named_buffers()))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 打印剪枝后的模型weight属性值</span><br><span class="hljs-built_in">print</span>(module.weight)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 执行剪枝永久化操作remove</span><br>prune.<span class="hljs-built_in">remove</span>(module, <span class="hljs-string">&#x27;weight&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># remove后再次打印模型参数</span><br><span class="hljs-built_in">print</span>(list(module.named_parameters()))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># remove后再次打印模型mask buffers参数</span><br><span class="hljs-built_in">print</span>(list(module.named_buffers()))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[(<span class="hljs-string">&#x27;weight_orig&#x27;</span>, <span class="hljs-symbol">Parameter</span> containing:<br>tensor([[[[ <span class="hljs-number">0.1668</span>,  <span class="hljs-number">0.0369</span>, <span class="hljs-number">-0.2930</span>],<br>          [<span class="hljs-number">-0.2630</span>, <span class="hljs-number">-0.1777</span>, <span class="hljs-number">-0.1096</span>],<br>          [ <span class="hljs-number">0.0481</span>, <span class="hljs-number">-0.0898</span>,  <span class="hljs-number">0.1920</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0729</span>,  <span class="hljs-number">0.1445</span>, <span class="hljs-number">-0.0471</span>],<br>          [ <span class="hljs-number">0.1525</span>,  <span class="hljs-number">0.2986</span>,  <span class="hljs-number">0.2602</span>],<br>          [<span class="hljs-number">-0.0929</span>, <span class="hljs-number">-0.2725</span>, <span class="hljs-number">-0.0069</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.2006</span>, <span class="hljs-number">-0.2577</span>,  <span class="hljs-number">0.2754</span>],<br>          [ <span class="hljs-number">0.0999</span>,  <span class="hljs-number">0.2106</span>, <span class="hljs-number">-0.0046</span>],<br>          [<span class="hljs-number">-0.2813</span>, <span class="hljs-number">-0.2794</span>, <span class="hljs-number">-0.0580</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.2944</span>, <span class="hljs-number">-0.2214</span>, <span class="hljs-number">-0.0795</span>],<br>          [<span class="hljs-number">-0.0773</span>,  <span class="hljs-number">0.2931</span>, <span class="hljs-number">-0.2249</span>],<br>          [<span class="hljs-number">-0.0796</span>, <span class="hljs-number">-0.2343</span>, <span class="hljs-number">-0.0457</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.1965</span>,  <span class="hljs-number">0.2550</span>,  <span class="hljs-number">0.2606</span>],<br>          [ <span class="hljs-number">0.0213</span>, <span class="hljs-number">-0.2839</span>,  <span class="hljs-number">0.2037</span>],<br>          [<span class="hljs-number">-0.2068</span>, <span class="hljs-number">-0.0507</span>, <span class="hljs-number">-0.3097</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0030</span>,  <span class="hljs-number">0.2340</span>, <span class="hljs-number">-0.1122</span>],<br>          [<span class="hljs-number">-0.0302</span>, <span class="hljs-number">-0.0261</span>,  <span class="hljs-number">0.1168</span>],<br>          [ <span class="hljs-number">0.0927</span>,  <span class="hljs-number">0.1553</span>,  <span class="hljs-number">0.1167</span>]]]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="hljs-symbol">True</span>)), (<span class="hljs-string">&#x27;bias_orig&#x27;</span>, <span class="hljs-symbol">Parameter</span> containing:<br>tensor([ <span class="hljs-number">0.1147</span>,  <span class="hljs-number">0.2439</span>, <span class="hljs-number">-0.1753</span>, <span class="hljs-number">-0.2578</span>, <span class="hljs-number">-0.0994</span>,  <span class="hljs-number">0.0588</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,<br>       requires_grad=<span class="hljs-symbol">True</span>))]<br>**************************************************<br>[(<span class="hljs-string">&#x27;weight_mask&#x27;</span>, tensor([[[[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>],<br>          [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]],<br><br><br>        [[[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>          [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>          [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)), (<span class="hljs-string">&#x27;bias_mask&#x27;</span>, tensor([<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>))]<br>**************************************************<br>tensor([[[[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.0000</span>],<br>          [<span class="hljs-number">-0.2630</span>, <span class="hljs-number">-0.1777</span>, <span class="hljs-number">-0.1096</span>],<br>          [ <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.0898</span>,  <span class="hljs-number">0.1920</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0729</span>,  <span class="hljs-number">0.1445</span>, <span class="hljs-number">-0.0471</span>],<br>          [ <span class="hljs-number">0.1525</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.2602</span>],<br>          [<span class="hljs-number">-0.0929</span>, <span class="hljs-number">-0.2725</span>, <span class="hljs-number">-0.0069</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.2006</span>, <span class="hljs-number">-0.2577</span>,  <span class="hljs-number">0.0000</span>],<br>          [ <span class="hljs-number">0.0999</span>,  <span class="hljs-number">0.2106</span>, <span class="hljs-number">-0.0046</span>],<br>          [<span class="hljs-number">-0.2813</span>, <span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.0580</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.2214</span>, <span class="hljs-number">-0.0795</span>],<br>          [<span class="hljs-number">-0.0773</span>,  <span class="hljs-number">0.2931</span>, <span class="hljs-number">-0.2249</span>],<br>          [<span class="hljs-number">-0.0796</span>, <span class="hljs-number">-0.2343</span>, <span class="hljs-number">-0.0000</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.1965</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.2606</span>],<br>          [ <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.2839</span>,  <span class="hljs-number">0.0000</span>],<br>          [<span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.0507</span>, <span class="hljs-number">-0.3097</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0030</span>,  <span class="hljs-number">0.2340</span>, <span class="hljs-number">-0.1122</span>],<br>          [<span class="hljs-number">-0.0302</span>, <span class="hljs-number">-0.0000</span>,  <span class="hljs-number">0.0000</span>],<br>          [ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.1553</span>,  <span class="hljs-number">0.1167</span>]]]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,<br>       grad_fn=&lt;<span class="hljs-symbol">MulBackward0</span>&gt;)<br>**************************************************<br><span class="hljs-symbol">OrderedDict</span>([(<span class="hljs-number">0</span>, &lt;torch.nn.utils.prune.<span class="hljs-symbol">RandomUnstructured</span> object at <span class="hljs-number">0x7f65b879e7f0</span>&gt;), (<span class="hljs-number">1</span>, &lt;torch.nn.utils.prune.<span class="hljs-symbol">L1Unstructured</span> object at <span class="hljs-number">0x7f655c5ebfd0</span>&gt;)])<br>[(<span class="hljs-string">&#x27;bias_orig&#x27;</span>, <span class="hljs-symbol">Parameter</span> containing:<br>tensor([ <span class="hljs-number">0.1147</span>,  <span class="hljs-number">0.2439</span>, <span class="hljs-number">-0.1753</span>, <span class="hljs-number">-0.2578</span>, <span class="hljs-number">-0.0994</span>,  <span class="hljs-number">0.0588</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,<br>       requires_grad=<span class="hljs-symbol">True</span>)), (<span class="hljs-string">&#x27;weight&#x27;</span>, <span class="hljs-symbol">Parameter</span> containing:<br>tensor([[[[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.0000</span>],<br>          [<span class="hljs-number">-0.2630</span>, <span class="hljs-number">-0.1777</span>, <span class="hljs-number">-0.1096</span>],<br>          [ <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.0898</span>,  <span class="hljs-number">0.1920</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0729</span>,  <span class="hljs-number">0.1445</span>, <span class="hljs-number">-0.0471</span>],<br>          [ <span class="hljs-number">0.1525</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.2602</span>],<br>          [<span class="hljs-number">-0.0929</span>, <span class="hljs-number">-0.2725</span>, <span class="hljs-number">-0.0069</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.2006</span>, <span class="hljs-number">-0.2577</span>,  <span class="hljs-number">0.0000</span>],<br>          [ <span class="hljs-number">0.0999</span>,  <span class="hljs-number">0.2106</span>, <span class="hljs-number">-0.0046</span>],<br>          [<span class="hljs-number">-0.2813</span>, <span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.0580</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.2214</span>, <span class="hljs-number">-0.0795</span>],<br>          [<span class="hljs-number">-0.0773</span>,  <span class="hljs-number">0.2931</span>, <span class="hljs-number">-0.2249</span>],<br>          [<span class="hljs-number">-0.0796</span>, <span class="hljs-number">-0.2343</span>, <span class="hljs-number">-0.0000</span>]]],<br><br><br>        [[[<span class="hljs-number">-0.1965</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.2606</span>],<br>          [ <span class="hljs-number">0.0000</span>, <span class="hljs-number">-0.2839</span>,  <span class="hljs-number">0.0000</span>],<br>          [<span class="hljs-number">-0.0000</span>, <span class="hljs-number">-0.0507</span>, <span class="hljs-number">-0.3097</span>]]],<br><br><br>        [[[ <span class="hljs-number">0.0030</span>,  <span class="hljs-number">0.2340</span>, <span class="hljs-number">-0.1122</span>],<br>          [<span class="hljs-number">-0.0302</span>, <span class="hljs-number">-0.0000</span>,  <span class="hljs-number">0.0000</span>],<br>          [ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.1553</span>,  <span class="hljs-number">0.1167</span>]]]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="hljs-symbol">True</span>))]<br>**************************************************<br>[(<span class="hljs-string">&#x27;bias_mask&#x27;</span>, tensor([<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>))]<br></code></pre></td></tr></table></figure><hr /><p>结论: 对模型的weight执行remove操作后,模型参数集合中只剩下bias_orig了, weight_orig消失, 变成了weight,说明针对weight的剪枝已经永久化生效. 对于named_buffers张量打印可以看出,只剩下bias_mask了, 因为针对weight做掩码的weight_mask已经生效完毕,不再需要保留了.</p><hr /><hr /><hr /><h2 id="多参数模块的剪枝pruning-multiple-parameters.">3.多参数模块的剪枝(Pruning multiple parameters).<ahref="#3-pruning-multiple-parameters">¶</a></h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs routeros">model = LeNet().<span class="hljs-keyword">to</span>(<span class="hljs-attribute">device</span>=device)<br><br><span class="hljs-comment"># 打印初始模型的所有状态字典</span><br><span class="hljs-built_in">print</span>(model.state_dict().keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 打印初始模型的mask buffers张量字典名称</span><br><span class="hljs-built_in">print</span>(dict(model.named_buffers()).keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 对于模型进行分模块参数的剪枝</span><br><span class="hljs-keyword">for</span> name, module <span class="hljs-keyword">in</span> model.named_modules():<br>    # 对模型中所有的卷积层执行l1_unstructured剪枝操作, 选取20%的参数剪枝<br>    <span class="hljs-keyword">if</span> isinstance(module, torch.nn.Conv2d):<br>        prune.l1_unstructured(module, <span class="hljs-attribute">name</span>=<span class="hljs-string">&quot;weight&quot;</span>, <span class="hljs-attribute">amount</span>=0.2)<br>    # 对模型中所有全连接层执行ln_structured剪枝操作, 选取40%的参数剪枝<br>    elif isinstance(module, torch.nn.Linear):<br>        prune.ln_structured(module, <span class="hljs-attribute">name</span>=<span class="hljs-string">&quot;weight&quot;</span>, <span class="hljs-attribute">amount</span>=0.4, <span class="hljs-attribute">n</span>=2)<br><br><span class="hljs-comment"># 打印多参数模块剪枝后的mask buffers张量字典名称</span><br><span class="hljs-built_in">print</span>(dict(model.named_buffers()).keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 打印多参数模块剪枝后模型的所有状态字典名称</span><br><span class="hljs-built_in">print</span>(model.state_dict().keys())<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sml">odict_keys([<span class="hljs-symbol">&#x27;conv1</span>.weight&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.bias&#x27;])<br>**************************************************<br>dict_keys(<span class="hljs-literal">[]</span>)<br>**************************************************<br>dict_keys([<span class="hljs-symbol">&#x27;conv1</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight_mask&#x27;])<br>**************************************************<br>odict_keys([<span class="hljs-symbol">&#x27;conv1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight_mask&#x27;])<br></code></pre></td></tr></table></figure><hr /><blockquote><ul><li>结论: 对比初始化模型的状态字典和剪枝后的状态字典,可以看到所有的weight参数都没有了, 变成了weight_orig和weight_mask的组合.初始化的模型named_buffers是空列表,剪枝后拥有了所有参与剪枝的参数层的weight_mask张量.</li></ul></blockquote><hr /><hr /><hr /><h2 id="全局剪枝global-pruning.">4. 全局剪枝(GLobal pruning).<ahref="#4-global-pruning">¶</a></h2><p>第一种, 第二种剪枝策略本质上属于局部剪枝(local pruning),需要程序员按照自己的定义one by one的进行操作.最主要的问题就是模型剪枝效果的好坏很大程度上取决于程序员的剪枝经验,而且就算经验丰富的程序员也很难肯定的说某种剪枝策略一定更优.</p><hr /><p>更普遍也更通用的剪枝策略是采用全局剪枝(global pruning),比如在整体网络的视角下剪枝掉20%的权重参数,而不是在每一层上都剪枝掉20%的权重参数. 采用全局剪枝后,不同的层被剪掉的百分比不同.</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs routeros">model = LeNet().<span class="hljs-keyword">to</span>(<span class="hljs-attribute">device</span>=device)<br><br><span class="hljs-comment"># 首先打印初始化模型的状态字典</span><br><span class="hljs-built_in">print</span>(model.state_dict().keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span><span class="hljs-number">*50</span>)<br><br><span class="hljs-comment"># 构建参数集合, 决定哪些层, 哪些参数集合参与剪枝</span><br>parameters_to_prune = (<br>            (model.conv1, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.conv2, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.fc1, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.fc2, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.fc3, <span class="hljs-string">&#x27;weight&#x27;</span>))<br><br><span class="hljs-comment"># 调用prune中的全局剪枝函数global_unstructured执行剪枝操作, 此处针对整体模型中的20%参数量进行剪枝</span><br>prune.global_unstructured(parameters_to_prune, <span class="hljs-attribute">pruning_method</span>=prune.L1Unstructured, <span class="hljs-attribute">amount</span>=0.2)<br><br><span class="hljs-comment"># 最后打印剪枝后的模型的状态字典</span><br><span class="hljs-built_in">print</span>(model.state_dict().keys())<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sml">odict_keys([<span class="hljs-symbol">&#x27;conv1</span>.weight&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.bias&#x27;])<br>**************************************************<br>odict_keys([<span class="hljs-symbol">&#x27;conv1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;conv1</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;conv2</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;fc1</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;fc2</span>.weight_mask&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.bias&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight_orig&#x27;, <span class="hljs-symbol">&#x27;fc3</span>.weight_mask&#x27;])<br></code></pre></td></tr></table></figure><hr /><ul><li>针对模型剪枝后, 不同的层会有不同比例的权重参数被剪掉,利用代码打印出来看看:</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">model = LeNet().<span class="hljs-keyword">to</span>(device=device)<br><br>parameters_to_prune = (<br>            (model.conv1, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.conv2, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.fc1, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.fc2, <span class="hljs-string">&#x27;weight&#x27;</span>),<br>            (model.fc3, <span class="hljs-string">&#x27;weight&#x27;</span>))<br><br>prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=<span class="hljs-number">0.2</span>)<br><br>print(<br>    &quot;Sparsity in conv1.weight: &#123;:.2f&#125;%&quot;.format(<br>    <span class="hljs-number">100.</span> * <span class="hljs-type">float</span>(torch.sum(model.conv1.weight == <span class="hljs-number">0</span>))<br>    / <span class="hljs-type">float</span>(model.conv1.weight.nelement())<br>    ))<br><br>print(<br>    &quot;Sparsity in conv2.weight: &#123;:.2f&#125;%&quot;.format(<br>    <span class="hljs-number">100.</span> * <span class="hljs-type">float</span>(torch.sum(model.conv2.weight == <span class="hljs-number">0</span>))<br>    / <span class="hljs-type">float</span>(model.conv2.weight.nelement())<br>    ))<br><br>print(<br>    &quot;Sparsity in fc1.weight: &#123;:.2f&#125;%&quot;.format(<br>    <span class="hljs-number">100.</span> * <span class="hljs-type">float</span>(torch.sum(model.fc1.weight == <span class="hljs-number">0</span>))<br>    / <span class="hljs-type">float</span>(model.fc1.weight.nelement())<br>    ))<br><br>print(<br>    &quot;Sparsity in fc2.weight: &#123;:.2f&#125;%&quot;.format(<br>    <span class="hljs-number">100.</span> * <span class="hljs-type">float</span>(torch.sum(model.fc2.weight == <span class="hljs-number">0</span>))<br>    / <span class="hljs-type">float</span>(model.fc2.weight.nelement())<br>    ))<br><br>print(<br>    &quot;Sparsity in fc3.weight: &#123;:.2f&#125;%&quot;.format(<br>    <span class="hljs-number">100.</span> * <span class="hljs-type">float</span>(torch.sum(model.fc3.weight == <span class="hljs-number">0</span>))<br>    / <span class="hljs-type">float</span>(model.fc3.weight.nelement())<br>    ))<br><br>print(<br>    &quot;Global sparsity: &#123;:.2f&#125;%&quot;.format(<br>    <span class="hljs-number">100.</span> * <span class="hljs-type">float</span>(torch.sum(model.conv1.weight == <span class="hljs-number">0</span>)<br>               + torch.sum(model.conv2.weight == <span class="hljs-number">0</span>)<br>               + torch.sum(model.fc1.weight == <span class="hljs-number">0</span>)<br>               + torch.sum(model.fc2.weight == <span class="hljs-number">0</span>)<br>               + torch.sum(model.fc3.weight == <span class="hljs-number">0</span>))<br>         / <span class="hljs-type">float</span>(model.conv1.weight.nelement()<br>               + model.conv2.weight.nelement()<br>               + model.fc1.weight.nelement()<br>               + model.fc2.weight.nelement()<br>               + model.fc3.weight.nelement())<br>    ))<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Sparsity</span> in conv1.weight: <span class="hljs-number">1</span>.<span class="hljs-number">85</span>%<br><span class="hljs-attribute">Sparsity</span> in conv2.weight: <span class="hljs-number">7</span>.<span class="hljs-number">87</span>%<br><span class="hljs-attribute">Sparsity</span> in fc1.weight: <span class="hljs-number">21</span>.<span class="hljs-number">99</span>%<br><span class="hljs-attribute">Sparsity</span> in fc2.weight: <span class="hljs-number">12</span>.<span class="hljs-number">56</span>%<br><span class="hljs-attribute">Sparsity</span> in fc3.weight: <span class="hljs-number">9</span>.<span class="hljs-number">17</span>%<br><span class="hljs-attribute">Global</span> sparsity: <span class="hljs-number">20</span>.<span class="hljs-number">00</span>%<br></code></pre></td></tr></table></figure><hr /><blockquote><ul><li>结论: 当采用全局剪枝策略的时候(假定20%比例参数参与剪枝),仅保证模型总体参数量的20%被剪枝掉,具体到每一层的情况则由模型的具体参数分布情况来定.</li></ul></blockquote><hr /><hr /><hr /><h2 id="用户自定义剪枝custom-pruning.">5.用户自定义剪枝(Custompruning).<a href="#5custom-pruning">¶</a></h2><ul><li>所谓用户自定义剪枝, 就是程序员自己定义通过什么样的规则进行剪枝,而不是依赖Pytorch定义好的比如l1_unstructured,ln_structured等等预设好的剪枝规则来进行剪枝.</li></ul><hr /><ul><li>剪枝模型通过继承class BasePruningMethod()来执行剪枝, 内部有若干方法:<strong>call</strong>, apply_mask, apply, prune, remove等等. 一般来说,用户只需要实现__init__,和compute_mask两个函数即可完成自定义的剪枝规则设定.</li></ul><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-comment"># 自定义剪枝方法的类, 一定要继承prune.BasePruningMethod</span><br><span class="hljs-keyword">class</span> myself_pruning_method(prune.<span class="hljs-title class_">BasePruningMethod</span>):<br>    <span class="hljs-variable constant_">PRUNING_TYPE</span> = <span class="hljs-string">&quot;unstructured&quot;</span><br><br>    <span class="hljs-comment"># 内部实现compute_mask函数, 完成程序员自己定义的剪枝规则, 本质上就是如何去mask掉权重参数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_mask</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, t, default_mask</span>):<br>        mask = default_mask.clone()<br>        <span class="hljs-comment"># 此处定义的规则是每隔一个参数就遮掩掉一个, 最终参与剪枝的参数量的50%被mask掉</span><br>        mask.view(-<span class="hljs-number">1</span>)[<span class="hljs-symbol">:</span><span class="hljs-symbol">:</span><span class="hljs-number">2</span>] = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">return</span> mask<br><br><span class="hljs-comment"># 自定义剪枝方法的函数, 内部直接调用剪枝类的方法apply</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">myself_unstructured_pruning</span>(<span class="hljs-params"><span class="hljs-keyword">module</span>, name</span>):<br>    myself_pruning_method.apply(<span class="hljs-keyword">module</span>, name)<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">module</span><br></code></pre></td></tr></table></figure><hr /><ul><li>调用:</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 实例化模型类</span><br>model = LeNet().<span class="hljs-keyword">to</span>(<span class="hljs-attribute">device</span>=device)<br><br>start = time.time()<br><span class="hljs-comment"># 调用自定义剪枝方法的函数, 对model中的第三个全连接层fc3中的偏置bias执行自定义剪枝</span><br>myself_unstructured_pruning(model.fc3, <span class="hljs-attribute">name</span>=<span class="hljs-string">&quot;bias&quot;</span>)<br><br><span class="hljs-comment"># 剪枝成功的最大标志, 就是拥有了bias_mask参数</span><br><span class="hljs-built_in">print</span>(model.fc3.bias_mask)<br><br><span class="hljs-comment"># 打印一下自定义剪枝的耗时</span><br>duration = time.time() - start<br><span class="hljs-built_in">print</span>(duration * 1000, <span class="hljs-string">&#x27;ms&#x27;</span>)<br></code></pre></td></tr></table></figure><hr /><ul><li>输出结果:</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tensor</span>([<span class="hljs-number">0</span>., <span class="hljs-number">1</span>., <span class="hljs-number">0</span>., <span class="hljs-number">1</span>., <span class="hljs-number">0</span>., <span class="hljs-number">1</span>., <span class="hljs-number">0</span>., <span class="hljs-number">1</span>., <span class="hljs-number">0</span>., <span class="hljs-number">1</span>.], device=&#x27;cuda:<span class="hljs-number">0</span>&#x27;)<br><span class="hljs-attribute">1</span>.<span class="hljs-number">7154216766357422</span> ms<br></code></pre></td></tr></table></figure><hr /><p>结论: 打印出来的bias_mask张量,完全是按照预定义的方式每隔一位遮掩掉一位, 0和1交替出现,后续执行remove操作的时候,原始的bias_orig中的权重就会同样的被每隔一位剪枝掉一位.在GPU机器上执行自定义剪枝速度特别快, 仅需1.7ms.</p>]]></content>
    
    
    <categories>
      
      <category>模型压缩技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>剪枝</tag>
      
      <tag>模型处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>知识蒸馏的原理与实现</title>
    <link href="/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html"/>
    <url>/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F.html</url>
    
    <content type="html"><![CDATA[<h2 id="什么是模型蒸馏">1.什么是模型蒸馏</h2><p>在工业级的应用中, 除了要求模型要有好的预测效果之外,往往还希望它的"消耗"足够小.也就是说一般希望部署在线上的应用模型消耗较小的资源.这些资源包括存储空间, 包括算力.</p><p>在深度学习背景下, 如果希望模型的效果足够好, 通常会有两种方案: -使用更大规模的参数. - 使用集成模型, 将多个弱模型集成起来.</p><p>注意: 上面两种方案往往需要较大的计算资源, 对部署非常不利.由此产生了模型压缩的动机: 我们希望有一个小模型,但又能达到大模型一样或相当的效果.</p><p>模型蒸馏是一种通过将一个复杂模型（教师模型）的知识转移给一个简单模型（学生模型）的方法，以提高学生模型的性能。在减小模型体积的同时，保持或提升模型性能。- 知识蒸馏的概念最早由Hinton在2015年提出, 在2019年后火热起来. -知识蒸馏在目前已经成为一种既前沿又常用的提高模型泛化能力和部署优势的方法.</p><h2 id="知识蒸馏的原理和算法">2.知识蒸馏的原理和算法</h2><h3 id="教师模型">2.1 教师模型</h3><ul><li><strong>定义：</strong>复杂的、高性能的模型，通常是大型深度神经网络。</li><li><strong>特点：</strong> 参数量大，能够学习复杂的特征和关系。</li></ul><h3 id="学生模型">2.2 学生模型</h3><ul><li><strong>定义：</strong>简化的、小型的模型，通常是教师模型的子集。</li><li><strong>特点：</strong> 参数量较小，适用于资源受限的场景。</li></ul><h3 id="蒸馏过程">2.3 蒸馏过程</h3><p>下图非常直观, 又经典的展示了知识蒸馏的架构图, 相当于有两部分的分支: *一部分是大模型的softmax分布作为"知识标签", 让小模型去学习. *一部分是真实label(ground truth)作为"真实标签", 让小模型去匹配.</p><figure><img src="/images/模型蒸馏/3_2.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>我们对知识蒸馏进行公式化处理:先训练好一个精度较高的Teacher网络(一般是复杂度较高的大规模预训练模型),然后将Teacher网络的预测结果q作为Student网络的"学习目标",来训练Student网络(一般是速度较快的小规模模型),最终使得Student网络的结果p接近于q. 损失函数如下:</p><figure><img src="/images/模型蒸馏/3_4.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><blockquote><ul><li>上式中CE是交叉熵(Cross Entropy), y是真实标签,q是Teacher网络的输出结果, p是Student网络的输出结果.</li></ul></blockquote><p>原始论文中提出了softmax-T公式来计算上图中的q:</p><figure><img src="/images/模型蒸馏/3_3.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><blockquote><ul><li>上式中pi是Student网络学习的对象, 也就是所谓的软目标(soft targets),zi是神经网络softmax前的输出logits.</li></ul></blockquote><p>不同的温度系数T值, 对softmax-T算法有不同的影响, 总结如下: -如果将T值取1, softmax-T公式就成为softmax公式,根据logits输出各个类别的概率. - 如果T越接近于0, 则最大值会越接近1,其他值会接近0, 类似于退化成one-hot编码. - 如果T越大,则输出的结果分布越平缓, 相当于标签平滑的原理, 起到保留相似信息的作用. -如果T趋于无穷大, 则演变成均匀分布.</p><h2id="模型蒸馏的代码实现----详细代码见github">3.模型蒸馏的代码实现----详细代码见<ahref="https://github.com/linxkon/">github</a></h2><p>工具类函数的路径为：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-number">05</span>-bert_distil<span class="hljs-regexp">/src/u</span>tils.py<br></code></pre></td></tr></table></figure><p>导入工具包如下：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> torch<br><span class="hljs-title">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> time<br><span class="hljs-title">from</span> datetime <span class="hljs-keyword">import</span> timedelta<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pickle <span class="hljs-keyword">as</span> pkl<br></code></pre></td></tr></table></figure><h3 id="工具类函数build_vocab">3.1 工具类函数build_vocab()</h3><p>build_vocab()是位于utils.py中的独立函数，用于将文本数据中的单词映射为索引。函数的主要步骤如下：</p><ol type="1"><li><strong>初始化：</strong>函数开始时定义了三个特殊符号（<code>UNK</code>, <code>PAD</code>,<code>CLS</code>），它们分别代表未知符号、填充符号和综合信息符号。这些符号在构建词汇表时将被添加。</li><li><strong>遍历文本文件：</strong>函数通过打开指定路径的文本文件，逐行遍历文件中的内容。每行通常包含一段文本，这里选择每行的第一个字段作为内容。</li><li><strong>分词和构建词汇表：</strong>对每个内容使用给定的分词器进行分词，然后更新词汇表字典。分词的结果是将文本划分为单词或子词，而词汇表字典则记录了每个单词出现的次数。</li><li><strong>筛选高频词汇：</strong>对词汇表字典根据词频进行排序，选择出现频率较高的词汇。这里根据参数<code>min_freq</code> 指定的最小出现频率进行筛选。</li><li><strong>构建最终词汇表：</strong>将选定的高频词汇构建为字典，将每个词汇映射到一个唯一的索引。此外，函数还将特殊符号（<code>UNK</code>,<code>PAD</code>,<code>CLS</code>）添加到词汇表中，分别赋予它们额外的索引。</li><li><strong>返回结果：</strong>返回构建好的词汇表字典，其中每个词汇都与一个唯一的索引相关联。这个词汇表后续可用于将文本数据转换为模型可接受的输入形式，即将文本中的每个单词映射为对应的索引。</li></ol><p>具体实现如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python">UNK, PAD, CLS = <span class="hljs-string">&quot;[UNK]&quot;</span>, <span class="hljs-string">&quot;[PAD]&quot;</span>, <span class="hljs-string">&quot;[CLS]&quot;</span>  <span class="hljs-comment"># padding符号, bert中综合信息符号</span><br>MAX_VOCAB_SIZE = <span class="hljs-number">10000</span>  <span class="hljs-comment"># 词表长度限制</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_vocab</span>(<span class="hljs-params">file_path, tokenizer, max_size, min_freq</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    构建词汇表的函数。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    参数：</span><br><span class="hljs-string">    - file_path (str): 包含文本数据的文件路径。</span><br><span class="hljs-string">    - tokenizer (function): 用于分词的函数，接受一个字符串并返回分词后的结果。</span><br><span class="hljs-string">    - max_size (int): 词汇表的最大大小，即保留的词汇数量上限。</span><br><span class="hljs-string">    - min_freq (int): 词汇表中词语的最小出现频率，低于此频率的词汇将被过滤掉。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    返回：</span><br><span class="hljs-string">    - vocab_dic (dict): 一个字典，将词汇映射到索引的词汇表。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    vocab_dic = &#123;&#125;  <span class="hljs-comment"># 用于存储词汇表的字典，键为单词，值为单词出现的次数</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tqdm(f):<br>            line = line.strip()<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> line:<br>                <span class="hljs-keyword">continue</span><br>            content = line.split(<span class="hljs-string">&quot;\t&quot;</span>)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 以制表符分隔的文本，这里取第一列的内容</span><br>            <span class="hljs-comment"># 使用给定的分词器（tokenizer）对文本进行分词，并更新词汇表</span><br>            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokenizer(content):<br>                vocab_dic[word] = vocab_dic.get(word, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span><br>        <span class="hljs-comment"># 根据词频对词汇表进行排序，并选择出现频率较高的词汇</span><br>        vocab_list = <span class="hljs-built_in">sorted</span>([_ <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> vocab_dic.items() <span class="hljs-keyword">if</span> _[<span class="hljs-number">1</span>] &gt;= min_freq],<br>                            key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)[:max_size]<br>        <span class="hljs-comment"># 将选定的词汇构建为字典，键为单词，值为索引</span><br>        vocab_dic = &#123;word_count[<span class="hljs-number">0</span>]: idx <span class="hljs-keyword">for</span> idx, word_count <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(vocab_list)&#125;<br>        <span class="hljs-comment"># 添加特殊符号到词汇表，例如未知符号（UNK）、填充符号（PAD）</span><br>        vocab_dic.update(&#123;UNK: <span class="hljs-built_in">len</span>(vocab_dic), PAD: <span class="hljs-built_in">len</span>(vocab_dic) + <span class="hljs-number">1</span>,CLS: <span class="hljs-built_in">len</span>(vocab_dic) + <span class="hljs-number">2</span>&#125;)<br>    <span class="hljs-keyword">return</span> vocab_dic<br></code></pre></td></tr></table></figure><h3 id="工具类函数build_dataset_cnn">3.2工具类函数build_dataset_CNN()</h3><p>build_dataset_CNN()是位于utils.py中的独立函数，用于创建专为text_cnn模型设计的数据集。以下是代码的主要作用：</p><p><code>d_dataset_CNN</code>的函数，用于创建专为卷积神经网络（CNN）模型设计的数据集。以下是代码的主要作用：</p><ol type="1"><li>分词（Tokenization）：定义了一个简单的字符级分词器，将每个输入文本转换为单个字符的列表。</li><li><strong>构建词汇表（Vocabulary Building）：</strong></li></ol><p>函数首先检查是否存在指定路径 <code>config.vocab_path</code>下的词汇表文件。如果存在，则加载词汇表；否则，使用训练数据构建新的词汇表。</p><ol type="1"><li><strong>加载数据集（Dataset Loading）：</strong></li></ol><p><code>load_dataset</code> 是 <code>build_dataset_CNN</code>内部的辅助函数，用于从给定文件（训练、验证、测试）加载数据集。</p><ol type="1"><li><strong>数据集拆分（Dataset Splitting）：</strong></li></ol><p>函数通过在相应文件路径上调用 <code>load_dataset</code>来加载训练、验证和测试的数据集，并返回。</p><p>具体实现如下所示：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">def build_dataset_CNN(config):<br>    <span class="hljs-comment"># 定义字符级别分词器</span><br>    tokenizer = lambda x: [y <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> x]  <br>    <span class="hljs-comment"># 检查是否存在词汇表文件，如果存在则加载，否则构建新的词汇表</span><br>    <span class="hljs-keyword">if</span> os.path.exists(config.vocab_path):<br>        vocab = pkl.<span class="hljs-built_in">load</span>(<span class="hljs-built_in">open</span>(config.vocab_path, <span class="hljs-string">&quot;rb&quot;</span>))<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 构建词汇表</span><br>        vocab = build_vocab(config.train_path, tokenizer=tokenizer, max_size=MAX_VOCAB_SIZE, min_freq=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 保存词汇表</span><br>        pkl.dump(vocab, <span class="hljs-built_in">open</span>(config.vocab_path, <span class="hljs-string">&quot;wb&quot;</span>))<br>    print(f<span class="hljs-string">&quot;Vocab size: &#123;len(vocab)&#125;&quot;</span>)<br><br>    <span class="hljs-comment"># 定义加载数据集的辅助函数</span><br>    def load_dataset(path, pad_size=<span class="hljs-number">32</span>):<br>        contents = []<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> <span class="hljs-built_in">line</span> <span class="hljs-keyword">in</span> tqdm(f):<br>                lin = <span class="hljs-built_in">line</span>.strip()<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> lin:<br>                    continue<br>                content, label = lin.<span class="hljs-built_in">split</span>(<span class="hljs-string">&quot;\t&quot;</span>)<br>                words_line = []<br>                <span class="hljs-keyword">token</span> = tokenizer(content)<br>                seq_len = <span class="hljs-built_in">len</span>(<span class="hljs-keyword">token</span>)<br><br>                <span class="hljs-comment"># 填充或截断序列至指定长度</span><br>                <span class="hljs-keyword">if</span> pad_size:<br>                    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(<span class="hljs-keyword">token</span>) &lt; pad_size:<br>                        <span class="hljs-keyword">token</span>.extend([PAD] * (pad_size - <span class="hljs-built_in">len</span>(<span class="hljs-keyword">token</span>)))<br>                    <span class="hljs-keyword">else</span>:<br>                        <span class="hljs-keyword">token</span> = <span class="hljs-keyword">token</span>[:pad_size]<br>                        seq_len = pad_size<br><br>                <span class="hljs-comment"># 将词转换为对应的id</span><br>                <span class="hljs-keyword">for</span> <span class="hljs-built_in">word</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">token</span>:<br>                    words_line.append(vocab.<span class="hljs-built_in">get</span>(<span class="hljs-built_in">word</span>, vocab.<span class="hljs-built_in">get</span>(UNK)))<br><br>                <span class="hljs-comment"># 将数据添加到 contents 列表</span><br>                contents.append((words_line, int(label), seq_len))<br>        <span class="hljs-literal">return</span> contents  <span class="hljs-comment"># [([...], 0), ([...], 1), ...]</span><br><br>    <span class="hljs-comment"># 加载训练、验证和测试数据集</span><br>    train = load_dataset(config.train_path, config.pad_size)<br>    dev = load_dataset(config.dev_path, config.pad_size)<br>    test = load_dataset(config.test_path, config.pad_size)<br><br>    <span class="hljs-literal">return</span> vocab, train, dev, test<br></code></pre></td></tr></table></figure><h3 id="其他工具类函数">3.3 其他工具类函数</h3><p>其他工具类函数build_dataset(),build_iterator()，get_time_dif()都位于utils.py中的独立函数，这些函数与Bert模型章节是一样的，不再赘述。</p><h2 id="模型类">4.模型类</h2><h3 id="teacher模型">4.1 Teacher模型</h3><p>Teacher模型采用BERT，接下来实现一个基于BERT的文本分类模型，并包含了相关的配置信息。该部分代码在：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-number">05</span>-bert_distil<span class="hljs-regexp">/src/m</span>odels/bert.py<br></code></pre></td></tr></table></figure><p>主要内容包含：</p><p>配置类 <code>Config</code>：和模型类 <code>Model</code>：</p><p>首先<strong>导入工具包</strong>：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> os<br><span class="hljs-title">from</span> transformers <span class="hljs-keyword">import</span> BertModel, BertTokenizer, BertConfig<br></code></pre></td></tr></table></figure><h4 id="实现config类代码">1 实现Config类代码</h4><p>配置类 <code>Config</code>中主要包含以下内容：</p><ul><li><code>Config</code> 类包含了用于模型训练和数据处理的各种参数。</li><li>定义了模型名称、数据集路径、训练集、验证集、测试集文件路径、类别名单等信息。</li><li>包含模型训练结果和量化模型存储结果的路径。</li><li>配置了训练设备（GPU或CPU）、类别数、epoch数、mini-batch大小、句子长度等。</li><li>BERT预训练模型的路径、分词器、BERT模型配置、隐藏层大小等。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Config</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        配置类，包含模型和训练所需的各种参数。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.model_name = <span class="hljs-string">&quot;bert&quot;</span> <span class="hljs-comment"># 模型名称</span><br>        self.data_path = <span class="hljs-string">&quot;/Users/mac/Desktop/投满分项目/03-code/04-bert/data/data1/&quot;</span> <span class="hljs-comment">#数据集的根路径</span><br>        self.train_path = self.data_path + <span class="hljs-string">&quot;train.txt&quot;</span>  <span class="hljs-comment"># 训练集</span><br>        self.dev_path = self.data_path + <span class="hljs-string">&quot;dev.txt&quot;</span>  <span class="hljs-comment"># 验证集</span><br>        self.test_path = self.data_path + <span class="hljs-string">&quot;test.txt&quot;</span>  <span class="hljs-comment"># 测试集</span><br>        self.class_list = [x.strip() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(self.data_path + <span class="hljs-string">&quot;class.txt&quot;</span>).readlines()]  <span class="hljs-comment"># 类别名单</span><br><br>        self.save_path = <span class="hljs-string">&quot;/Users/mac/Desktop/投满分项目/03-code/04-bert/src/saved_dic&quot;</span> <span class="hljs-comment">#模型训练结果保存路径</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(self.save_path):<br>            os.mkdir(self.save_path)<br>        self.save_path += <span class="hljs-string">&quot;/&quot;</span> + self.model_name + <span class="hljs-string">&quot;.pt&quot;</span>  <span class="hljs-comment"># 模型训练结果</span><br><br><br>        <span class="hljs-comment"># 模型训练+预测的时候, 放开下一行代码, 在GPU上运行.</span><br>        self.device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <br><br>        self.num_classes = <span class="hljs-built_in">len</span>(self.class_list)  <span class="hljs-comment"># 类别数</span><br>        self.num_epochs = <span class="hljs-number">2</span>  <span class="hljs-comment"># epoch数</span><br>        self.batch_size = <span class="hljs-number">128</span>  <span class="hljs-comment"># mini-batch大小</span><br>        self.pad_size = <span class="hljs-number">32</span>  <span class="hljs-comment"># 每句话处理成的长度(短填长切)</span><br>        self.learning_rate = <span class="hljs-number">5e-5</span>  <span class="hljs-comment"># 学习率</span><br>        self.bert_path = <span class="hljs-string">&quot;/Users/mac/Desktop/投满分项目/03-code/04-bert/data/bert_pretrain&quot;</span> <span class="hljs-comment"># 预训练BERT模型的路径</span><br>        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path) <span class="hljs-comment"># BERT模型的分词器</span><br>        self.bert_config = BertConfig.from_pretrained(self.bert_path + <span class="hljs-string">&#x27;/bert_config.json&#x27;</span>) <span class="hljs-comment"># BERT模型的配置</span><br>        self.hidden_size = <span class="hljs-number">768</span> <span class="hljs-comment"># BERT模型的隐藏层大小</span><br></code></pre></td></tr></table></figure><h4 id="实现model类代码">2.实现Model类代码</h4><p><strong>模型类 <code>Model</code></strong>主要实现以下内容：</p><ul><li><code>Model</code> 类继承自<code>nn.Module</code>，实现了一个基于BERT的文本分类模型。</li><li>在初始化方法中，加载预训练的BERT模型和配置，并定义了一个全连接层用于文本分类。</li><li>在前向传播方法中，通过BERT模型获取句子的表示，然后通过全连接层进行分类</li></ul><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.<span class="hljs-title class_">Module</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, config</span>):<br>        <span class="hljs-variable language_">super</span>(<span class="hljs-title class_">Model</span>, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-comment"># 预训练BERT模型</span><br>        <span class="hljs-variable language_">self</span>.bert = <span class="hljs-title class_">BertModel</span>.from_pretrained(config.bert_path, config=config.bert_config)<br>        <span class="hljs-comment"># 全连接层，用于文本分类</span><br>        <span class="hljs-variable language_">self</span>.fc = nn.<span class="hljs-title class_">Linear</span>(config.hidden_size, config.num_classes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, x</span>):<br>        <span class="hljs-comment"># x: 模型输入，包含句子、句子长度和填充掩码。</span><br>        context = x[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 输入的句子</span><br>        mask = x[<span class="hljs-number">2</span>]  <span class="hljs-comment"># 对padding部分进行mask，和句子一个size，padding部分用0表示，如：[1, 1, 1, 1, 0, 0]</span><br>        <span class="hljs-comment"># _是占位符，接收模型的所有输出，而 pooled 是池化的结果,将整个句子的信息压缩成一个固定长度的向量</span><br>        _, pooled = <span class="hljs-variable language_">self</span>.bert(context, attention_mask=mask, return_dict=<span class="hljs-title class_">False</span>)<br>        <span class="hljs-comment"># 模型输出，用于文本分类</span><br>        out = <span class="hljs-variable language_">self</span>.fc(pooled)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><p>bert.py文件提供了一个简单而灵活的BERT文本分类模型，通过配置类可以方便地调整模型参数，适应不同的文本分类任务，通过model类构建整个网络结构。</p><h3 id="student模型">4.2 Student模型</h3><p>Student模型采用textCNN，接下来实现一个基于textCNN的文本分类模型，并包含了相关的配置信息。该部分代码在：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-number">05</span>-bert_distil<span class="hljs-regexp">/src/m</span>odels/textCNN.py<br></code></pre></td></tr></table></figure><p>首先看textCNN模型的架构图:</p><figure><img src="/images/模型蒸馏/2_3.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>导入相关的工具包：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> os<br></code></pre></td></tr></table></figure><h4 id="实现config类代码-1">1.实现Config类代码</h4><p>config配置类用于设置存储模型的各种参数和路径。包括数据集的路径、模型保存路径、设备选择、超参数等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Config</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.model_name = <span class="hljs-string">&quot;textCNN&quot;</span><br>        self.data_path = <span class="hljs-string">&quot;/Users/mac/Desktop/投满分项目/03-code/05-bert_distil/data/data/&quot;</span><br>        self.train_path = self.data_path + <span class="hljs-string">&quot;train.txt&quot;</span>  <span class="hljs-comment"># 训练集</span><br>        self.dev_path = self.data_path + <span class="hljs-string">&quot;dev.txt&quot;</span>  <span class="hljs-comment"># 验证集</span><br>        self.test_path = self.data_path + <span class="hljs-string">&quot;test.txt&quot;</span>  <span class="hljs-comment"># 测试集</span><br>        self.class_list = [x.strip() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(self.data_path+<span class="hljs-string">&quot;class.txt&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>).readlines()]<br>        self.vocab_path = self.data_path + <span class="hljs-string">&quot;vocab.pkl&quot;</span>  <span class="hljs-comment"># 词表</span><br>        self.save_path = <span class="hljs-string">&quot;/Users/mac/Desktop/投满分项目/03-code/05-bert_distil/src/saved_dict&quot;</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(self.save_path):<br>            os.mkdir(self.save_path)<br>        self.save_path += <span class="hljs-string">&quot;/&quot;</span> + self.model_name + <span class="hljs-string">&quot;.pt&quot;</span>  <span class="hljs-comment"># 模型训练结果</span><br>        self.device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <span class="hljs-comment"># 设备</span><br><br>        self.dropout = <span class="hljs-number">0.5</span>  <span class="hljs-comment"># 随机失活</span><br>        self.require_improvement = <span class="hljs-number">1000</span>  <span class="hljs-comment"># 若超过1000batch效果还没提升，则提前结束训练</span><br>        self.num_classes = <span class="hljs-built_in">len</span>(self.class_list)  <span class="hljs-comment"># 类别数</span><br>        self.n_vocab = <span class="hljs-number">0</span>  <span class="hljs-comment"># 词表大小，在运行时赋值</span><br>        self.num_epochs = <span class="hljs-number">3</span>  <span class="hljs-comment"># epoch数</span><br>        self.batch_size = <span class="hljs-number">128</span>  <span class="hljs-comment"># mini-batch大小</span><br>        self.pad_size = <span class="hljs-number">32</span>  <span class="hljs-comment"># 每句话处理成的长度(短填长切)</span><br>        self.learning_rate = <span class="hljs-number">1e-3</span>  <span class="hljs-comment"># 学习率</span><br>        self.embed = <span class="hljs-number">300</span>  <span class="hljs-comment"># 字向量维度</span><br>        self.filter_sizes = (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>) <span class="hljs-comment"># 卷积核的大小</span><br>        self.num_filters = <span class="hljs-number">256</span> <span class="hljs-comment"># 卷积核的数量</span><br></code></pre></td></tr></table></figure><h4 id="实现model类代码-1">2.实现Model类代码</h4><p>TextCNN（卷积神经网络用于文本分类）模型包含词嵌入层、多个卷积核大小的卷积层、池化层、随机失活层和全连接层。其中，卷积层通过不同大小的卷积核捕捉不同范围的文本信息，随机失活层用于防止过拟合，全连接层用于输出最终的分类结果。包含以下三个方法：</p><ol type="1"><li><strong><code>__init__</code> 方法：</strong>初始化模型。它包括词嵌入层，多个卷积层，池化层，随机失活层和全连接层。</li><li><strong><code>conv_and_pool</code> 方法：</strong>定义卷积和池化的操作。ReLU激活函数应用于卷积输出，然后通过最大池化层进行池化。</li><li><strong><code>forward</code> 方法：</strong>定义前向传播逻辑。通过词嵌入层将输入文本序列转换为嵌入表示，然后应用多个卷积核并进行池化。最后，通过全连接层生成最终的分类结果。</li></ol><p>具体实现如下：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Model</span>(<span class="hljs-title">nn</span>.<span class="hljs-title">Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span></span>(<span class="hljs-keyword">self</span>, config):<br>        <span class="hljs-keyword">super</span>(Model, <span class="hljs-keyword">self</span>).__init__()<br>        <span class="hljs-keyword">self</span>.embedding = nn.Embedding(config.n_vocab, config.embed, padding_idx=config.n_vocab - <span class="hljs-number">1</span>) <span class="hljs-comment"># 词嵌入层</span><br>        <span class="hljs-keyword">self</span>.convs = nn.ModuleList(<br>            [nn.Conv2d(<span class="hljs-number">1</span>, config.num_filters, (k, config.embed)) <span class="hljs-keyword">for</span> k in config.filter_sizes]<br>        )   <span class="hljs-comment"># 卷积层列表，包含不同卷积核大小的卷积层</span><br>        <span class="hljs-keyword">self</span>.dropout = nn.Dropout(config.dropout)  <span class="hljs-comment"># 随机失活层</span><br>        <span class="hljs-keyword">self</span>.fc = nn.Linear(config.num_filters * len(config.filter_sizes), config.num_classes)   <span class="hljs-comment"># 全连接层</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">conv_and_pool</span></span>(<span class="hljs-keyword">self</span>, x, conv):<br>        <span class="hljs-comment"># 卷积和池化操作</span><br>        x = F.relu(conv(x)).squeeze(<span class="hljs-number">3</span>)<br>        x = F.max_pool1d(x, x.size(<span class="hljs-number">2</span>)).squeeze(<span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span></span>(<span class="hljs-keyword">self</span>, x):<br>        <span class="hljs-comment"># 前向传播</span><br>        <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.embedding(x[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">out</span> = <span class="hljs-keyword">out</span>.unsqueeze(<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 对每个卷积层进行卷积和池化操作，然后拼接在一起</span><br>        <span class="hljs-keyword">out</span> = torch.cat([<span class="hljs-keyword">self</span>.conv_and_pool(<span class="hljs-keyword">out</span>, conv) <span class="hljs-keyword">for</span> conv in <span class="hljs-keyword">self</span>.convs], <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.dropout(<span class="hljs-keyword">out</span>)  <span class="hljs-comment"># 随机失活</span><br>        <span class="hljs-keyword">out</span> = <span class="hljs-keyword">self</span>.fc(<span class="hljs-keyword">out</span>)   <span class="hljs-comment"># 全连接层</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">out</span><br></code></pre></td></tr></table></figure><h2id="编写训练函数测试函数评估函数">5.编写训练函数,测试函数,评估函数</h2><p>这几个函数共同编写在一个代码文件中:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-number">05</span>-bert_distil<span class="hljs-regexp">/src/</span>train_eval.py<br></code></pre></td></tr></table></figure><p>首先导入相关的工具包：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-title">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">import</span> time<br><span class="hljs-title">from</span> utils <span class="hljs-keyword">import</span> get_time_dif<br><span class="hljs-title">from</span> transformers.optimization <span class="hljs-keyword">import</span> AdamW<br><span class="hljs-title">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> logging<br></code></pre></td></tr></table></figure><p>在具体实现之前，我们先看下训练的架构图：</p><figure><img src="/images/模型蒸馏/3_2.png" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>以下是模型蒸馏的基本训练步骤：</p><ol type="1"><li><strong>准备教师模型（bert大模型）：</strong>使用一个较大的模型进行训练, 这个模型在任务上表现很好。</li><li><strong>使用教师模型生成软目标：</strong>对训练数据集进行推理，得到教师模型的输出概率分布（软目标）。这些概率分布包含了模型对每个类别的置信度信息。</li><li><strong>准备学生模型（textcnn小模型）：</strong>初始化一个较小的模型，这是我们要训练的目标模型。</li><li><strong>使用软目标和硬标签进行训练：</strong>使用原始的硬标签（实际标签）和教师模型生成的软目标来训练学生模型。损失函数由两部分组成：</li><li><strong>硬标签损失（通常为交叉熵损失）：</strong>学生模型的输出与实际标签之间的差距。</li><li><strong>软目标损失：</strong>学生模型的输出与教师模型生成的软目标之间的差距。这通常使用 KL散度（Kullback-Leibler Divergence）来度量。</li><li><strong>调整温度参数：</strong> KL散度的计算涉及一个温度参数，该参数可以调整软目标的分布。温度较高会使分布更加平滑。在训练过程中，可以逐渐降低温度以提高蒸馏效果。</li></ol><p>通过这个过程，学生模型可以通过教师模型的知识进行训练，达到在小模型上获得类似大模型性能的目的。模型蒸馏在资源受限的环境中特别有用，例如移动设备或边缘设备上。</p><h3 id="获取teacher网络输出的函数">5.1 获取Teacher网络输出的函数</h3><p>使用Bert作为Teacher模型, 需要用Bert对全部训练数据做预测,并将结果预先存储进一个list中. 这些预测结果就是soft targets,未来给Student模型做"学习标签"使用.具体步骤如下所示：</p><ol type="1"><li>将教师模型设置为评估（推断）模式，通过<code>teacher_model.eval()</code>实现。在评估模式下，模型不会计算梯度，这有助于提高推断速度并减少内存消耗。</li><li>创建一个空列表<code>teacher_outputs</code>，用于存储教师模型对训练集每个批次的输出。</li><li>遍历训练集迭代器<code>train_iter</code>，对每个批次的数据调用教师模型，获取模型的输出。</li><li>将每个批次的输出添加到 <code>teacher_outputs</code> 列表中。</li><li>最后，返回包含教师模型对训练集所有批次输出的结果。</li></ol><p>具体实现如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">fetch_teacher_outputs</span>(<span class="hljs-params">teacher_model, train_iter</span>):<br>    <span class="hljs-comment"># 将教师模型设置为评估（推断）模式，避免在获取输出时进行梯度计算</span><br>    teacher_model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-comment"># 用于存储教师模型对训练集的输出</span><br>    teacher_outputs = []<br>    <span class="hljs-comment"># 禁用梯度计算</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># 遍历训练集数据</span><br>        <span class="hljs-keyword">for</span> i, (data_batch, labels_batch) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            <span class="hljs-comment"># 获取教师模型的输出</span><br>            outputs = teacher_model(data_batch)<br>            <span class="hljs-comment"># 将输出添加到列表中</span><br>            teacher_outputs.append(outputs)<br>    <span class="hljs-comment"># 返回教师模型对训练集的所有输出</span><br>    <span class="hljs-keyword">return</span> teacher_outputs<br></code></pre></td></tr></table></figure><p>需要注意的是Teacher模型和Student模型的DataLoader不是同一个,batch_size和顺序都要保持一致, 才能保证后续的训练样本与softtargets对齐!</p><h3 id="损失函数">5.2 损失函数</h3><figure><img src="images/image-20231117114309994.png"alt="image-20231117114309994" /><figcaption aria-hidden="true">image-20231117114309994</figcaption></figure><p>通常采用的交叉熵损失函数, 有一点需要注意,F.cross_entropy()对输入有限制, 要求label必须是one-hot格式的.但Teacher网络的输出soft targets是概率分布的形式,不匹配，因此采用KL散度作为soft targets的loss, 注意:Pytorch中的KL散度函数可以接收概率分布形式的label.包含的步骤是：</p><ol type="1"><li><code>loss_fn</code> 是用于一般的交叉熵损失函数，适用于训练 BERT模型。</li><li><code>criterion</code> 是定义 KL 散度损失的 PyTorch 损失类。</li><li><code>loss_fn_kd</code>是蒸馏损失函数，用于蒸馏训练。它接受三个参数：<code>outputs</code>（学生模型的输出），<code>labels</code>（真实标签），<code>teacher_outputs</code>（教师模型的输出）。</li><li>设置两个超参数：<code>alpha</code>控制软损失和硬损失的权重，<code>T</code>是温度参数，影响软化的程度。</li><li>计算学生模型（Student）的输出分布值和教师模型（Teacher）的输出分布值。对学生模型的输出进行log_softmax 处理，对教师模型的输出进行 softmax 处理。</li><li>计算软损失，即学生模型和教师模型的输出分布之间的 KL 散度损失。</li><li>计算硬损失，即学生模型和真实标签的交叉熵损失。</li><li>计算总损失，通过加权软损失和硬损失得到。</li></ol><p>具体实现如下所示：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-comment"># 交叉熵损失: 训练bert模型</span><br>def loss_fn<span class="hljs-punctuation">(</span>outputs<span class="hljs-punctuation">,</span> labels<span class="hljs-punctuation">)</span><span class="hljs-operator">:</span><br>    <span class="hljs-built_in">return</span> nn.CrossEntropyLoss<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">(</span>outputs<span class="hljs-punctuation">,</span> labels<span class="hljs-punctuation">)</span><br><br><span class="hljs-comment"># KL散度损失（要求student输入为log-probabilities,软目标为probabilities）</span><br>criterion <span class="hljs-operator">=</span> nn.KLDivLoss<span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><br><br><span class="hljs-comment"># 定义蒸馏损失函数</span><br>def loss_fn_kd<span class="hljs-punctuation">(</span>outputs<span class="hljs-punctuation">,</span> labels<span class="hljs-punctuation">,</span> teacher_outputs<span class="hljs-punctuation">)</span><span class="hljs-operator">:</span><br>    <span class="hljs-comment"># 设置两个重要超参数</span><br>    alpha <span class="hljs-operator">=</span> <span class="hljs-number">0.8</span><br>    <span class="hljs-built_in">T</span> <span class="hljs-operator">=</span> <span class="hljs-number">2</span><br><br>    <span class="hljs-comment"># 1.学生网络的带有T参数的log_softmax输出分布</span><br>    output_student <span class="hljs-operator">=</span> F.log_softmax<span class="hljs-punctuation">(</span>outputs <span class="hljs-operator">/</span> <span class="hljs-built_in">T</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">dim</span><span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><br>    <span class="hljs-comment"># 2.教师网络的带有T参数的softmax输出分布</span><br>    output_teacher <span class="hljs-operator">=</span> F.softmax<span class="hljs-punctuation">(</span>teacher_outputs <span class="hljs-operator">/</span> <span class="hljs-built_in">T</span><span class="hljs-punctuation">,</span> <span class="hljs-built_in">dim</span><span class="hljs-operator">=</span><span class="hljs-number">1</span><span class="hljs-punctuation">)</span><br><br>    <span class="hljs-comment"># 3.计算软目标损失,使用KLDivLoss(),第一个参数为student网络输出, 第二个参数为teacher网络输出</span><br>    soft_loss <span class="hljs-operator">=</span> criterion<span class="hljs-punctuation">(</span>output_student<span class="hljs-punctuation">,</span> output_teacher<span class="hljs-punctuation">)</span><br><br>    <span class="hljs-comment"># 4.硬目标损失，学生网络的输出概率和真实标签之间的损失, 因为真实标签是one-hot编码, 因此直接使用交叉熵损失即可</span><br>    hard_loss <span class="hljs-operator">=</span> F.cross_entropy<span class="hljs-punctuation">(</span>outputs<span class="hljs-punctuation">,</span> labels<span class="hljs-punctuation">)</span><br><br>    <span class="hljs-comment"># 5.计算总损失</span><br>    <span class="hljs-comment"># 原始论文中已经证明, 引入T会导致软目标产生的梯度和真实目标产生的梯度相比只有1/(T*T)</span><br>    <span class="hljs-comment"># 因此计算完软目标的loss值后要乘以T^2.</span><br>    KD_loss <span class="hljs-operator">=</span> soft_loss <span class="hljs-operator">*</span> alpha <span class="hljs-operator">*</span> <span class="hljs-built_in">T</span> <span class="hljs-operator">*</span> <span class="hljs-built_in">T</span> <span class="hljs-operator">+</span> hard_loss <span class="hljs-operator">*</span> <span class="hljs-punctuation">(</span><span class="hljs-number">1.0</span> <span class="hljs-operator">-</span> alpha<span class="hljs-punctuation">)</span><br>    <span class="hljs-built_in">return</span> KD_loss<br></code></pre></td></tr></table></figure><h3 id="teacher模型训练函数">5.3 Teacher模型训练函数</h3><p>该部分的内容与Bert模型章节的训练函数是类似的，具体步骤包含以下内容：</p><ol type="1"><li>初始化训练开始时间，将模型设置为训练模式。</li><li>对模型参数进行优化，使用AdamW优化器，同时设置不同参数组的权重衰减。</li><li>迭代训练，每个epoch内遍历训练集。在每个batch内，进行前向传播、损失计算、反向传播和参数更新。</li><li>每400个batch，打印一次训练信息，并在验证集上进行评估。判断当前模型是否是最佳模型，如果是则保存。</li><li>训练完成后，在测试集上进行最终测试。</li></ol><p>具体实现如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">config, model, train_iter, dev_iter, test_iter</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    参数:</span><br><span class="hljs-string">    - config: 包含超参数和设置的配置对象。</span><br><span class="hljs-string">    - model: 要训练的神经网络模型。</span><br><span class="hljs-string">    - train_iter: 用于训练数据集的迭代器。</span><br><span class="hljs-string">    - dev_iter: 用于验证（开发）数据集的迭代器。</span><br><span class="hljs-string">    - test_iter: 用于测试数据集的迭代器。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 记录训练开始时间</span><br>    start_time = time.time()<br>    <span class="hljs-comment"># 将模型设置为训练模式</span><br>    model.train()<br>    <span class="hljs-comment"># 获取模型参数</span><br>    param_optimizer = <span class="hljs-built_in">list</span>(model.named_parameters())<br>    no_decay = [<span class="hljs-string">&quot;bias&quot;</span>, <span class="hljs-string">&quot;LayerNorm.bias&quot;</span>, <span class="hljs-string">&quot;LayerNorm.weight&quot;</span>]<br>    <span class="hljs-comment"># 分组参数并设置优化的权重衰减</span><br>    optimizer_grouped_parameters = [<br>        &#123;<br>            <span class="hljs-string">&quot;params&quot;</span>: [p <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> param_optimizer <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(nd <span class="hljs-keyword">in</span> n <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> no_decay)],<br>            <span class="hljs-string">&quot;weight_decay&quot;</span>: <span class="hljs-number">0.01</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;params&quot;</span>: [p <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> param_optimizer <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(nd <span class="hljs-keyword">in</span> n <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> no_decay)],<br>            <span class="hljs-string">&quot;weight_decay&quot;</span>: <span class="hljs-number">0.0</span><br>        &#125;]<br>    <span class="hljs-comment"># 使用AdamW优化器，设置学习率</span><br>    optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate)<br>    <span class="hljs-comment"># 记录最佳验证损失</span><br>    dev_best_loss = <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>)<br>    <span class="hljs-comment"># 遍历每个epoch</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(config.num_epochs):<br>        total_batch = <span class="hljs-number">0</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="hljs-built_in">format</span>(epoch + <span class="hljs-number">1</span>, config.num_epochs))<br>        <span class="hljs-comment"># 遍历训练数据集的每个batch</span><br>        <span class="hljs-keyword">for</span> i, (trains, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(train_iter)):<br>            <span class="hljs-comment"># 梯度清零</span><br>            model.zero_grad()<br>            <span class="hljs-comment"># 前向传播</span><br>            outputs = model(trains)<br>            <span class="hljs-comment"># 计算损失</span><br>            loss = loss_fn(outputs, labels)<br>            <span class="hljs-comment"># 反向传播和优化</span><br>            loss.backward()<br>            optimizer.step()<br>            total_batch += <span class="hljs-number">1</span><br>            <span class="hljs-comment"># 每400个batch打印一次训练信息</span><br>            <span class="hljs-keyword">if</span> total_batch % <span class="hljs-number">400</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> total_batch &gt; <span class="hljs-number">0</span>:<br>                true = labels.data.cpu()<br>                predic = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu()<br>                train_acc = metrics.accuracy_score(true, predic)<br>                <span class="hljs-comment"># 在验证集上进行评估</span><br>                dev_acc, dev_loss = evaluate(config, model, dev_iter)<br>                <span class="hljs-comment"># 检查当前模型是否是最佳模型</span><br>                <span class="hljs-keyword">if</span> dev_loss &lt; dev_best_loss:<br>                    dev_best_loss = dev_loss<br>                    <span class="hljs-comment"># 当模型有提升时保存模型权重</span><br>                    torch.save(model.state_dict(), config.save_path)<br>                    improve = <span class="hljs-string">&quot;*&quot;</span><br>                <span class="hljs-keyword">else</span>:<br>                    improve = <span class="hljs-string">&quot;&quot;</span><br>                time_dif = get_time_dif(start_time)<br>                msg = <span class="hljs-string">&quot;Iter: &#123;0:&gt;6&#125;,  Train Loss: &#123;1:&gt;5.2&#125;,  Train Acc: &#123;2:&gt;6.2%&#125;,  Val Loss: &#123;3:&gt;5.2&#125;,  Val Acc: &#123;4:&gt;6.2%&#125;,  Time: &#123;5&#125; &#123;6&#125;&quot;</span><br>                <span class="hljs-built_in">print</span>(msg.<span class="hljs-built_in">format</span>(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))<br>                <span class="hljs-comment"># 将模型重新设置为训练模式</span><br>                model.train()<br>    <span class="hljs-comment"># 在测试集上测试最终的模型</span><br>    test(config, model, test_iter)<br></code></pre></td></tr></table></figure><h3 id="知识蒸馏训练函数">5.4 知识蒸馏训练函数</h3><p>使用知识蒸馏（KnowledgeDistillation）的方式训练深度学习模型的训练函数完成的任务如下所示：</p><ol type="1"><li>初始化优化器和其他训练参数,将CNN模型设置为训练模式，BERT模型设置为评估模式。</li><li>获取BERT模型的输出，作为教师模型的预测结果。</li><li>遍历每个epoch，对CNN模型进行训练。计算蒸馏损失（软损失）和交叉熵损失（硬损失）的组合，并进行反向传播和优化。</li><li>在训练过程中输出训练信息，包括训练损失、准确率以及在验证集上的表现。保存在验证集上表现最好的CNN模型。</li><li>在训练结束后，使用测试集对最终的CNN模型进行测试。</li></ol><p>具体的实现如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_kd</span>(<span class="hljs-params">cnn_config, bert_model, cnn_model,</span><br><span class="hljs-params">             bert_train_iter, cnn_train_iter, cnn_dev_iter, cnn_test_iter</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    使用知识蒸馏（Knowledge Distillation）的方式训练模型。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    参数:</span><br><span class="hljs-string">    - cnn_config: 包含CNN模型超参数和设置的配置对象。</span><br><span class="hljs-string">    - bert_model: BERT模型。</span><br><span class="hljs-string">    - cnn_model: CNN模型。</span><br><span class="hljs-string">    - bert_train_iter: 用于BERT模型训练的迭代器。</span><br><span class="hljs-string">    - cnn_train_iter: 用于CNN模型训练的迭代器。</span><br><span class="hljs-string">    - cnn_dev_iter: 用于CNN模型验证的迭代器。</span><br><span class="hljs-string">    - cnn_test_iter: 用于CNN模型测试的迭代器。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 记录训练开始时间</span><br>    start_time = time.time()<br>    <span class="hljs-comment"># 获取CNN模型参数</span><br>    param_optimizer = <span class="hljs-built_in">list</span>(cnn_model.named_parameters())<br>    no_decay = [<span class="hljs-string">&quot;bias&quot;</span>, <span class="hljs-string">&quot;LayerNorm.bias&quot;</span>, <span class="hljs-string">&quot;LayerNorm.weight&quot;</span>]<br>    optimizer_grouped_parameters = [<br>        &#123;<br>            <span class="hljs-string">&quot;params&quot;</span>: [p <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> param_optimizer <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(nd <span class="hljs-keyword">in</span> n <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> no_decay)],<br>            <span class="hljs-string">&quot;weight_decay&quot;</span>: <span class="hljs-number">0.01</span><br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;params&quot;</span>: [p <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> param_optimizer <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(nd <span class="hljs-keyword">in</span> n <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> no_decay)],<br>            <span class="hljs-string">&quot;weight_decay&quot;</span>: <span class="hljs-number">0.0</span><br>        &#125;]<br><br>    <span class="hljs-comment"># 使用AdamW优化器，设置学习率</span><br>    optimizer = AdamW(optimizer_grouped_parameters, lr=cnn_config.learning_rate)<br>    <span class="hljs-comment"># 记录最佳验证损失</span><br>    dev_best_loss = <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>)<br>    <span class="hljs-comment"># 将CNN模型设置为训练模式</span><br>    cnn_model.train()<br>    <span class="hljs-comment"># 将BERT模型设置为评估模式</span><br>    bert_model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-comment"># 获取BERT模型的输出作为教师模型的预测结果</span><br>    teacher_outputs = fetch_teacher_outputs(bert_model, bert_train_iter)<br>    <span class="hljs-comment"># 遍历每个epoch</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cnn_config.num_epochs):<br>        total_batch = <span class="hljs-number">0</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="hljs-built_in">format</span>(epoch + <span class="hljs-number">1</span>, cnn_config.num_epochs))<br>        <span class="hljs-comment"># 遍历CNN模型训练数据集的每个batch</span><br>        <span class="hljs-keyword">for</span> i, (trains, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(cnn_train_iter)):<br>            <span class="hljs-comment"># 梯度清零</span><br>            cnn_model.zero_grad()<br>            <span class="hljs-comment"># 前向传播</span><br>            outputs = cnn_model(trains)<br>            <span class="hljs-comment"># 计算蒸馏损失</span><br>            loss = loss_fn_kd(outputs, labels, teacher_outputs[i])<br>            <span class="hljs-comment"># 反向传播和优化</span><br>            loss.backward()<br>            optimizer.step()<br>            total_batch += <span class="hljs-number">1</span><br>            <span class="hljs-comment"># 每400个batch打印一次训练信息</span><br>            <span class="hljs-keyword">if</span> total_batch % <span class="hljs-number">400</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> total_batch &gt; <span class="hljs-number">0</span>:<br>                true = labels.data.cpu()<br>                predic = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu()<br>                train_acc = metrics.accuracy_score(true, predic)<br>                <span class="hljs-comment"># 在CNN验证集上进行评估</span><br>                dev_acc, dev_loss = evaluate(cnn_config, cnn_model, cnn_dev_iter)<br>                <span class="hljs-comment"># 检查当前CNN模型是否是最佳模型</span><br>                <span class="hljs-keyword">if</span> dev_loss &lt; dev_best_loss:<br>                    dev_best_loss = dev_loss<br>                    torch.save(cnn_model.state_dict(), cnn_config.save_path)<br>                    improve = <span class="hljs-string">&quot;*&quot;</span><br>                <span class="hljs-keyword">else</span>:<br>                    improve = <span class="hljs-string">&quot;&quot;</span><br>                time_dif = get_time_dif(start_time)<br>                msg = <span class="hljs-string">&quot;Iter: &#123;0:&gt;6&#125;,  Train Loss: &#123;1:&gt;5.2&#125;,  Train Acc: &#123;2:&gt;6.2%&#125;,  Val Loss: &#123;3:&gt;5.2&#125;,  Val Acc: &#123;4:&gt;6.2%&#125;,  Time: &#123;5&#125; &#123;6&#125;&quot;</span><br>                <span class="hljs-built_in">print</span>(msg.<span class="hljs-built_in">format</span>(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))<br>                <span class="hljs-comment"># 将CNN模型重新设置为训练模式</span><br>                cnn_model.train()<br>    <span class="hljs-comment"># 在CNN测试集上测试最终的CNN模型</span><br>    test(cnn_config, cnn_model, cnn_test_iter)<br></code></pre></td></tr></table></figure><h3 id="评估函数和测试函数">5.5 评估函数和测试函数</h3><p>评估函数和测试函数的实现与bert章节是一样的，这里不再赘述。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">config, model, test_iter</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    模型测试函数，用于在测试集上进行最终的模型测试。</span><br><span class="hljs-string">    参数：</span><br><span class="hljs-string">    - config: 配置信息对象。</span><br><span class="hljs-string">    - model: 待测试的模型。</span><br><span class="hljs-string">    - test_iter: 测试集的数据迭代器。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    model.load_state_dict(torch.load(config.save_path,map_location=torch.device(config.device)))<br>    model.<span class="hljs-built_in">eval</span>()<br>    start_time = time.time()<br>    <span class="hljs-comment"># 调用验证函数计算评估指标</span><br>    test_acc, test_loss, test_report, test_confusion = evaluate(config, model, test_iter, test=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 打印测试结果信息:输出测试集上的损失、准确率、分类报告和混淆矩阵等信息</span><br>    msg = <span class="hljs-string">&quot;Test Loss: &#123;0:&gt;5.2&#125;,  Test Acc: &#123;1:&gt;6.2%&#125;&quot;</span><br>    <span class="hljs-built_in">print</span>(msg.<span class="hljs-built_in">format</span>(test_loss, test_acc))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Precision, Recall and F1-Score...&quot;</span>)<br>    <span class="hljs-built_in">print</span>(test_report)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Confusion Matrix...&quot;</span>)<br>    <span class="hljs-built_in">print</span>(test_confusion)<br>    time_dif = get_time_dif(start_time)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Time usage:&quot;</span>, time_dif)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">config, model, data_iter, test=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    模型评估函数。</span><br><span class="hljs-string">    参数：</span><br><span class="hljs-string">    - config: 配置信息对象。</span><br><span class="hljs-string">    - model: 待评估的模型。</span><br><span class="hljs-string">    - data_iter: 数据迭代器。</span><br><span class="hljs-string">    - test: 是否为测试集评估。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    loss_total = <span class="hljs-number">0</span><br>    <span class="hljs-comment"># 预测结果</span><br>    predict_all = np.array([], dtype=<span class="hljs-built_in">int</span>)<br>    <span class="hljs-comment"># label信息</span><br>    labels_all = np.array([], dtype=<span class="hljs-built_in">int</span>)<br>    <span class="hljs-comment"># 不进行梯度计算</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># 遍历数据集</span><br>        <span class="hljs-keyword">for</span> texts, labels <span class="hljs-keyword">in</span> data_iter:<br>            <span class="hljs-comment"># 将数据送入网络中</span><br>            outputs = model(texts)<br>            <span class="hljs-comment"># 损失函数</span><br>            loss = F.cross_entropy(outputs, labels)<br>            <span class="hljs-comment"># 损失和</span><br>            loss_total += loss<br>            <span class="hljs-comment"># 获取label信息</span><br>            labels = labels.data.cpu().numpy()<br>            <span class="hljs-comment"># 获取预测结果</span><br>            predic = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu().numpy()<br>            labels_all = np.append(labels_all, labels)<br>            predict_all = np.append(predict_all, predic)<br>    <span class="hljs-comment"># 计算准确率</span><br>    acc = metrics.accuracy_score(labels_all, predict_all)<br>    <span class="hljs-keyword">if</span> test:<br>        <span class="hljs-comment"># 如果是测试集评估，计算分类报告和混淆矩阵</span><br>        report = metrics.classification_report(labels_all, predict_all, target_names=config.class_list, digits=<span class="hljs-number">4</span>)<br>        confusion = metrics.confusion_matrix(labels_all, predict_all)<br>        <span class="hljs-keyword">return</span> acc, loss_total / <span class="hljs-built_in">len</span>(data_iter), report, confusion<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 如果是验证集评估，仅返回准确率和平均损失</span><br>        <span class="hljs-keyword">return</span> acc, loss_total / <span class="hljs-built_in">len</span>(data_iter)<br></code></pre></td></tr></table></figure><h2 id="编写运行主函数">6.编写运行主函数</h2><p>该部分代码在</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-number">05</span>-bert_distil/src/<span class="hljs-built_in">run</span>.py<br></code></pre></td></tr></table></figure><p>中，用于训练深度学习模型（BERT或使用知识蒸馏的TextCNN）。具体任务是通过命令行参数<code>--task</code>指定的方式进行，可以选择训练BERT模型（<code>trainbert</code>）或者训练使用知识蒸馏的TextCNN模型（<code>train_kd</code>）。</p><p>执行过程如下：</p><ol type="1"><li>根据命令行参数选择任务，如果是<code>trainbert</code>，则加载BERT模型进行训练；如果是<code>train_kd</code>，则加载BERT模型作为教师模型，加载TextCNN模型作为学生模型，进行知识蒸馏训练。</li><li>初始化相关配置，包括随机种子等。</li><li>加载数据集，对于<code>trainbert</code>任务，加载BERT数据集；对于<code>train_kd</code>任务，加载TextCNN的数据集和BERT的训练数据集。</li><li>加载模型，对于<code>trainbert</code>任务，加载BERT模型；对于<code>train_kd</code>任务，加载BERT和TextCNN模型。</li><li>执行训练，对于<code>trainbert</code>任务，调用<code>train</code>函数；对于<code>train_kd</code>任务，调用<code>train_kd</code>函数。</li></ol><p>此脚本的设计使得可以方便地选择不同的任务，并在一个脚本中完成相应模型的训练过程。</p><p>具体实现如下所示：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">import numpy as np<br>import torch<br>from train_eval import train_kd, train<br>from importlib import import_module<br>import argparse<br>from utils import <span class="hljs-keyword">build_dataset, </span><span class="hljs-keyword">build_iterator, </span><span class="hljs-keyword">build_dataset_CNN</span><br><span class="hljs-keyword"></span><br><span class="hljs-comment"># 解析命令行参数</span><br>parser = argparse.ArgumentParser(description=<span class="hljs-string">&quot;Chinese Text Classification&quot;</span>)<br>parser.<span class="hljs-keyword">add_argument(&quot;--task&quot;, </span>type=str, default=<span class="hljs-string">&#x27;train_kd&#x27;</span>, help=<span class="hljs-string">&quot;choose a task: trainbert, or train_kd&quot;</span>)<br>args = parser.parse_args()<br><br>if __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># 根据任务类型选择不同的模型和配置</span><br>    if args.task == <span class="hljs-string">&quot;trainbert&quot;</span>:<br>        model_name = <span class="hljs-string">&quot;bert&quot;</span><br>        x = import_module(<span class="hljs-string">&quot;models.&quot;</span> + model_name)  <span class="hljs-comment"># 动态导入模型</span><br>        <span class="hljs-built_in">config</span> = x.Config()  <span class="hljs-comment"># 使用模型的配置</span><br>        <span class="hljs-comment"># 初始化</span><br>        np.random.seed(<span class="hljs-number">1</span>)<br>        torch.manual_seed(<span class="hljs-number">1</span>)<br>        torch.cuda.manual_seed_all(<span class="hljs-number">1</span>)<br>        torch.<span class="hljs-keyword">backends.cudnn.deterministic </span>= True  <span class="hljs-comment"># 保证每次结果一样</span><br>        <span class="hljs-comment"># 数据集构建</span><br>        print(<span class="hljs-string">&quot;Loading data for Bert Model...&quot;</span>)<br>        train_data, dev_data, test_data = <span class="hljs-keyword">build_dataset(config) </span> <span class="hljs-comment"># 构建数据集</span><br>        train_iter = <span class="hljs-keyword">build_iterator(train_data, </span><span class="hljs-built_in">config</span>)  <span class="hljs-comment"># 构建数据迭代器</span><br>        dev_iter = <span class="hljs-keyword">build_iterator(dev_data, </span><span class="hljs-built_in">config</span>)<br>        test_iter = <span class="hljs-keyword">build_iterator(test_data, </span><span class="hljs-built_in">config</span>)<br>        <span class="hljs-comment"># 模型实例化与训练</span><br>        model = x.Model(<span class="hljs-built_in">config</span>).to(<span class="hljs-built_in">config</span>.device)  <span class="hljs-comment"># 实例化模型，并将模型移动到设备上</span><br>        train(<span class="hljs-built_in">config</span>, model, train_iter, dev_iter, test_iter)<br><br>    if args.task == <span class="hljs-string">&quot;train_kd&quot;</span>:<br>        <span class="hljs-comment"># 加载bert模型</span><br>        model_name = <span class="hljs-string">&quot;bert&quot;</span><br>        <span class="hljs-keyword">bert_module </span>= import_module(<span class="hljs-string">&quot;models.&quot;</span> + model_name)<br>        <span class="hljs-keyword">bert_config </span>= <span class="hljs-keyword">bert_module.Config() </span> <span class="hljs-comment"># 使用BERT模型的配置</span><br>        <span class="hljs-comment"># 加载cnn模型</span><br>        model_name = <span class="hljs-string">&quot;textCNN&quot;</span><br>        cnn_module = import_module(<span class="hljs-string">&quot;models.&quot;</span> + model_name)<br>        cnn_config = cnn_module.Config()  <span class="hljs-comment"># 使用TextCNN模型的配置</span><br>        <span class="hljs-comment"># 初始化</span><br>        np.random.seed(<span class="hljs-number">1</span>)<br>        torch.manual_seed(<span class="hljs-number">1</span>)<br>        torch.cuda.manual_seed_all(<span class="hljs-number">1</span>)<br>        torch.<span class="hljs-keyword">backends.cudnn.deterministic </span>= True  <span class="hljs-comment"># 保证每次结果一样</span><br>        <span class="hljs-comment"># 构建bert数据集，因为只需要训练结果作为软目标，这里不需要dev_iter和test_iter</span><br>        <span class="hljs-keyword">bert_train_data, </span>_, _ = <span class="hljs-keyword">build_dataset(bert_config)</span><br><span class="hljs-keyword"></span>        <span class="hljs-keyword">bert_train_iter </span>= <span class="hljs-keyword">build_iterator(bert_train_data, </span><span class="hljs-keyword">bert_config)</span><br><span class="hljs-keyword"></span>        <span class="hljs-comment"># 构建cnn数据集</span><br>        vocab, cnn_train_data, cnn_dev_data, cnn_test_data = <span class="hljs-keyword">build_dataset_CNN(cnn_config)</span><br><span class="hljs-keyword"></span>        cnn_train_iter = <span class="hljs-keyword">build_iterator(cnn_train_data, </span>cnn_config)<br>        cnn_dev_iter = <span class="hljs-keyword">build_iterator(cnn_dev_data, </span>cnn_config)<br>        cnn_test_iter = <span class="hljs-keyword">build_iterator(cnn_test_data, </span>cnn_config)<br>        cnn_config.n_vocab = len(vocab)<br>        <span class="hljs-comment"># 加载训练好的teacher模型</span><br>        <span class="hljs-keyword">bert_model </span>= <span class="hljs-keyword">bert_module.Model(bert_config).to(bert_config.device)</span><br><span class="hljs-keyword"></span>        <span class="hljs-comment"># 加载student模型</span><br>        cnn_model = cnn_module.Model(cnn_config).to(cnn_config.device)<br>        print(<span class="hljs-string">&quot;Teacher and student models loaded, start training&quot;</span>)<br>        train_kd(<span class="hljs-keyword">bert_config, </span>cnn_config, <span class="hljs-keyword">bert_model, </span>cnn_model,<br>                 <span class="hljs-keyword">bert_train_iter, </span>cnn_train_iter, cnn_dev_iter, cnn_test_iter) <br></code></pre></td></tr></table></figure><h3 id="训练teacher模型">6.1 训练Teacher模型</h3><p>执行训练Teacher模型，如下所示：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 将--task修改为trainbert，直接执行run文件</span><br>parser.add_argument(<span class="hljs-string">&quot;--task&quot;</span>, <span class="hljs-attribute">type</span>=str, <span class="hljs-attribute">default</span>=<span class="hljs-string">&#x27;trainbert&#x27;</span>, <span class="hljs-attribute">help</span>=<span class="hljs-string">&quot;choose a task: trainbert, or train_kd&quot;</span>)<br><br><span class="hljs-comment"># 或者 直接在命令行运行训练Teacher模型的代码</span><br>python run.py --task trainbert<br></code></pre></td></tr></table></figure><ul><li>输出结果:</li></ul><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs tap">Loading data for Bert Model...<br>180000it [00:37, 4820.80it/s]<br>10000it [00:02, 4954.00it/s]<br>10000it [00:02, 4952.50it/s]<br>Epoch [1/3]<br> 14%|█████████▉                                                            | 200/1407 [02:06&lt;13:26,  1.50it/s]Iter:    200,  Train Loss:   0.3,  Train Acc: 91.41%,  Val Loss:  0.29,  Val Acc: 90.86%,  Time: 0:02:26 *<br> 28%|███████████████████▉                                                  | 400/1407 [04:44&lt;11:46,  1.43it/s]Iter:    400,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.26,  Val Acc: 92.10%,  Time: 0:05:07 *<br> 43%|█████████████████████████████▊                                        | 600/1407 [07:26&lt;09:25,  1.43it/s]Iter:    600,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.25,  Val Acc: 92.10%,  Time: 0:07:49 *<br> 57%|███████████████████████████████████████▊                              | 800/1407 [10:08&lt;07:06,  1.42it/s]Iter:    800,  Train Loss:  0.15,  Train Acc: 94.53%,  Val Loss:  0.22,  Val Acc: 92.85%,  Time: 0:10:31 *<br> 71%|█████████████████████████████████████████████████                    | 1000/1407 [12:50&lt;04:43,  1.44it/s]Iter:   1000,  Train Loss:  0.17,  Train Acc: 94.53%,  Val Loss:  0.22,  Val Acc: 93.00%,  Time: 0:13:10 <br>No optimization for a long time, auto-stopping...<br>Test Loss:   0.2,  Test Acc: 93.64%<br>Precision, Recall and F1-Score...<br>               precision    recall  f1-score   support<br><br>      finance     0.9246    0.9320    0.9283      1000<br>       realty     0.9484    0.9370    0.9427      1000<br>       stocks     0.8787    0.8980    0.8882      1000<br>    education     0.9511    0.9730    0.9619      1000<br>      science     0.9236    0.8950    0.9091      1000<br>      society     0.9430    0.9270    0.9349      1000<br>     politics     0.9267    0.9100    0.9183      1000<br>       sports     0.9780    0.9780    0.9780      1000<br>         game     0.9514    0.9600    0.9557      1000<br>entertainment     0.9390    0.9540    0.9464      1000<br><br>     accuracy                         0.9364     10000<br>    macro avg     0.9365    0.9364    0.9364     10000<br> weighted avg     0.9365    0.9364    0.9364     10000<br><br>Confusion Matrix...<br>[[932 <span class="hljs-number"> 10 </span><span class="hljs-number"> 37 </span> <span class="hljs-number"> 2 </span> <span class="hljs-number"> 5 </span> <span class="hljs-number"> 5 </span> <span class="hljs-number"> 7 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 1 </span>  0]<br> [<span class="hljs-number"> 13 </span>937 <span class="hljs-number"> 11 </span> <span class="hljs-number"> 2 </span> <span class="hljs-number"> 4 </span><span class="hljs-number"> 10 </span> <span class="hljs-number"> 5 </span> <span class="hljs-number"> 5 </span> <span class="hljs-number"> 5 </span>  8]<br> [<span class="hljs-number"> 49 </span><span class="hljs-number"> 12 </span>898  <span class="hljs-number"> 1 </span><span class="hljs-number"> 19 </span> <span class="hljs-number"> 1 </span><span class="hljs-number"> 15 </span> <span class="hljs-number"> 0 </span> <span class="hljs-number"> 2 </span>  3]<br> [ <span class="hljs-number"> 1 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 0 </span>973  <span class="hljs-number"> 0 </span> <span class="hljs-number"> 8 </span> <span class="hljs-number"> 7 </span> <span class="hljs-number"> 0 </span> <span class="hljs-number"> 1 </span>  9]<br> [ <span class="hljs-number"> 4 </span> <span class="hljs-number"> 4 </span><span class="hljs-number"> 28 </span> <span class="hljs-number"> 7 </span>895 <span class="hljs-number"> 10 </span><span class="hljs-number"> 12 </span> <span class="hljs-number"> 2 </span><span class="hljs-number"> 27 </span> 11]<br> [ <span class="hljs-number"> 2 </span> <span class="hljs-number"> 8 </span> <span class="hljs-number"> 4 </span><span class="hljs-number"> 16 </span> <span class="hljs-number"> 5 </span>927 <span class="hljs-number"> 18 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 5 </span> 14]<br> [ <span class="hljs-number"> 3 </span> <span class="hljs-number"> 8 </span><span class="hljs-number"> 34 </span><span class="hljs-number"> 12 </span> <span class="hljs-number"> 9 </span><span class="hljs-number"> 19 </span>910  <span class="hljs-number"> 0 </span> <span class="hljs-number"> 0 </span>  5]<br> [ <span class="hljs-number"> 2 </span> <span class="hljs-number"> 3 </span> <span class="hljs-number"> 2 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 4 </span>978  <span class="hljs-number"> 1 </span>  7]<br> [ <span class="hljs-number"> 0 </span> <span class="hljs-number"> 2 </span> <span class="hljs-number"> 4 </span> <span class="hljs-number"> 0 </span><span class="hljs-number"> 24 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 3 </span> <span class="hljs-number"> 1 </span>960   5]<br> [ <span class="hljs-number"> 2 </span> <span class="hljs-number"> 3 </span> <span class="hljs-number"> 4 </span> <span class="hljs-number"> 9 </span> <span class="hljs-number"> 7 </span> <span class="hljs-number"> 1 </span> <span class="hljs-number"> 1 </span><span class="hljs-number"> 12 </span> <span class="hljs-number"> 7 </span>954]]<br>Time usage: 0:00:19<br> 71%|█████████████████████████████████████████████████                    | 1000/1407 [13:29&lt;05:29,  1.24it/s]<br></code></pre></td></tr></table></figure><blockquote><ul><li>结论: Teacher模型在测试集上的表现是Test Acc: 93.64%</li></ul></blockquote><h3 id="训练student模型">6.2 训练Student模型</h3><p>设定Config中的重要参数如下:</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 模型迭代3轮</span><br><span class="hljs-attr">self.num_epochs</span> = <span class="hljs-number">3</span><br><br><span class="hljs-comment"># 卷积核尺寸分别选2, 3, 4</span><br><span class="hljs-attr">self.filter_sizes</span> = (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br><br><span class="hljs-comment"># 卷积核的个数512</span><br><span class="hljs-attr">self.num_filters</span> = <span class="hljs-number">512</span><br></code></pre></td></tr></table></figure><p>执行run文件</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 将--task修改为train_kd，直接执行run文件</span><br>parser.add_argument(<span class="hljs-string">&quot;--task&quot;</span>, <span class="hljs-attribute">type</span>=str, <span class="hljs-attribute">default</span>=<span class="hljs-string">&#x27;train_kd&#x27;</span>, <span class="hljs-attribute">help</span>=<span class="hljs-string">&quot;choose a task: trainbert, or train_kd&quot;</span>)<br><span class="hljs-comment"># 或直接在命令行运行训练Student模型的代码</span><br>python run.py --task train_kd<br></code></pre></td></tr></table></figure><ul><li>输出结果:</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">180000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:37</span>, <span class="hljs-number">4862.</span><span class="hljs-string">22it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:02</span>, <span class="hljs-number">4988.</span><span class="hljs-string">47it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:02</span>, <span class="hljs-number">4981.</span><span class="hljs-string">50it/s</span>]<br><span class="hljs-attr">Vocab size:</span> <span class="hljs-number">4762</span><br><span class="hljs-string">180000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:02</span>, <span class="hljs-number">69598.</span><span class="hljs-string">12it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:00</span>, <span class="hljs-number">82889.</span><span class="hljs-string">25it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:00</span>, <span class="hljs-number">82326.</span><span class="hljs-string">33it/s</span>]<br><span class="hljs-string">Data</span> <span class="hljs-string">loaded,</span> <span class="hljs-string">now</span> <span class="hljs-string">load</span> <span class="hljs-string">teacher</span> <span class="hljs-string">model</span><br><span class="hljs-string">Teacher</span> <span class="hljs-string">and</span> <span class="hljs-string">student</span> <span class="hljs-string">models</span> <span class="hljs-string">loaded,</span> <span class="hljs-string">start</span> <span class="hljs-string">training</span><br><span class="hljs-string">Epoch</span> [<span class="hljs-number">1</span><span class="hljs-string">/20</span>]<br> <span class="hljs-number">14</span><span class="hljs-string">%|█████████▉</span>                                                            <span class="hljs-string">|</span> <span class="hljs-number">199</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:08&lt;00:50</span>, <span class="hljs-number">23.</span><span class="hljs-string">87it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.29</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">69.53</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.85</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">82.36</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:05:32</span> <span class="hljs-string">*</span><br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▉</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">400</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:17&lt;00:42</span>, <span class="hljs-number">23.</span><span class="hljs-string">95it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.27</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">73.44</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.81</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">84.00</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:05:40</span> <span class="hljs-string">*</span><br> <span class="hljs-number">43</span><span class="hljs-string">%|█████████████████████████████▊</span>                                        <span class="hljs-string">|</span> <span class="hljs-number">598</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:25&lt;00:33</span>, <span class="hljs-number">23.</span><span class="hljs-string">86it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">600</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.24</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">83.59</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.76</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">85.97</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:05:49</span> <span class="hljs-string">*</span><br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">799</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:34&lt;00:25</span>, <span class="hljs-number">23.</span><span class="hljs-string">91it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.23</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">83.59</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.76</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">85.49</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:05:58</span> <br> <span class="hljs-number">71</span><span class="hljs-string">%|█████████████████████████████████████████████████</span>                    <span class="hljs-string">|</span> <span class="hljs-number">1000</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:43&lt;00:17</span>, <span class="hljs-number">23.</span><span class="hljs-string">89it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1000</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.21</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">84.38</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.74</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">85.94</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:07</span> <span class="hljs-string">*</span><br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1198</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:52&lt;00:08</span>, <span class="hljs-number">23.</span><span class="hljs-string">80it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.22</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">85.94</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.72</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">86.92</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:16</span> <span class="hljs-string">*</span><br> <span class="hljs-number">99</span><span class="hljs-string">%|████████████████████████████████████████████████████████████████████▌|</span> <span class="hljs-number">1399</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:01&lt;00:00</span>, <span class="hljs-number">23.</span><span class="hljs-string">85it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.24</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">79.69</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.72</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">86.87</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:24</span> <span class="hljs-string">*</span><br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:01&lt;00:00</span>, <span class="hljs-number">22.</span><span class="hljs-string">73it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">2</span><span class="hljs-string">/20</span>]<br> <span class="hljs-number">14</span><span class="hljs-string">%|█████████▊</span>                                                            <span class="hljs-string">|</span> <span class="hljs-number">198</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:08&lt;00:50</span>, <span class="hljs-number">23.</span><span class="hljs-string">95it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.23</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">85.16</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>   <span class="hljs-number">0.7</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.34</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:33</span> <span class="hljs-string">*</span><br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▊</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">399</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:17&lt;00:42</span>, <span class="hljs-number">23.</span><span class="hljs-string">92it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.23</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">82.81</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.68</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.36</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:42</span> <span class="hljs-string">*</span><br> <span class="hljs-number">43</span><span class="hljs-string">%|█████████████████████████████▊</span>                                        <span class="hljs-string">|</span> <span class="hljs-number">600</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:25&lt;00:33</span>, <span class="hljs-number">24.</span><span class="hljs-string">06it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">600</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>   <span class="hljs-number">0.2</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">91.41</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.68</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.26</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:51</span> <span class="hljs-string">*</span><br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▋</span>                              <span class="hljs-string">|</span> <span class="hljs-number">798</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:34&lt;00:25</span>, <span class="hljs-number">23.</span><span class="hljs-string">98it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.21</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">87.50</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.67</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.83</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:00</span> <span class="hljs-string">*</span><br> <span class="hljs-number">71</span><span class="hljs-string">%|█████████████████████████████████████████████████▋</span>                    <span class="hljs-string">|</span> <span class="hljs-number">999</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:43&lt;00:17</span>, <span class="hljs-number">23.</span><span class="hljs-string">94it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1000</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.19</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">91.41</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.68</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.52</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:09</span> <br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1200</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:52&lt;00:08</span>, <span class="hljs-number">24.</span><span class="hljs-string">00it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>   <span class="hljs-number">0.2</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">88.28</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.67</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.07</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:17</span> <span class="hljs-string">*</span><br> <span class="hljs-number">99</span><span class="hljs-string">%|████████████████████████████████████████████████████████████████████▌|</span> <span class="hljs-number">1398</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:00&lt;00:00</span>, <span class="hljs-number">23.</span><span class="hljs-string">81it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.21</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">86.72</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.67</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.87</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:26</span> <span class="hljs-string">*</span><br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:01&lt;00:00</span>, <span class="hljs-number">22.</span><span class="hljs-string">79it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">3</span><span class="hljs-string">/20</span>]<br> <span class="hljs-number">14</span><span class="hljs-string">%|█████████▊</span>                                                            <span class="hljs-string">|</span> <span class="hljs-number">198</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:08&lt;00:50</span>, <span class="hljs-number">23.</span><span class="hljs-string">90it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.22</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">85.16</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.15</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:35</span> <span class="hljs-string">*</span><br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▊</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">399</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:17&lt;00:42</span>, <span class="hljs-number">23.</span><span class="hljs-string">98it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.21</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">84.38</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.43</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:44</span> <span class="hljs-string">*</span><br> <span class="hljs-number">43</span><span class="hljs-string">%|█████████████████████████████▊</span>                                        <span class="hljs-string">|</span> <span class="hljs-number">600</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:25&lt;00:33</span>, <span class="hljs-number">24.</span><span class="hljs-string">07it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">600</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>   <span class="hljs-number">0.2</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">91.41</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.65</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.54</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:53</span> <br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▋</span>                              <span class="hljs-string">|</span> <span class="hljs-number">798</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:34&lt;00:25</span>, <span class="hljs-number">23.</span><span class="hljs-string">95it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>   <span class="hljs-number">0.2</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">88.28</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.50</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:08:01</span> <br> <span class="hljs-number">71</span><span class="hljs-string">%|█████████████████████████████████████████████████▋</span>                    <span class="hljs-string">|</span> <span class="hljs-number">999</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:43&lt;00:17</span>, <span class="hljs-number">23.</span><span class="hljs-string">93it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1000</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.18</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">90.62</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.66</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.14</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:08:10</span> <br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1200</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:52&lt;00:08</span>, <span class="hljs-number">24.</span><span class="hljs-string">03it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.19</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">92.97</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.65</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.36</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:08:19</span> <br> <span class="hljs-number">99</span><span class="hljs-string">%|████████████████████████████████████████████████████████████████████▌|</span> <span class="hljs-number">1398</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:00&lt;00:00</span>, <span class="hljs-number">24.</span><span class="hljs-string">01it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>   <span class="hljs-number">0.2</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">86.72</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.65</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.24</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:08:28</span> <br><span class="hljs-literal">No</span> <span class="hljs-string">optimization</span> <span class="hljs-string">for</span> <span class="hljs-string">a</span> <span class="hljs-string">long</span> <span class="hljs-string">time,</span> <span class="hljs-string">auto-stopping...</span><br><span class="hljs-attr">Test Loss:</span>  <span class="hljs-number">0.62</span><span class="hljs-string">,</span>  <span class="hljs-attr">Test Acc:</span> <span class="hljs-number">89.89</span><span class="hljs-string">%</span><br><span class="hljs-string">Precision,</span> <span class="hljs-string">Recall</span> <span class="hljs-string">and</span> <span class="hljs-string">F1-Score...</span><br>               <span class="hljs-string">precision</span>    <span class="hljs-string">recall</span>  <span class="hljs-string">f1-score</span>   <span class="hljs-string">support</span><br><br>      <span class="hljs-string">finance</span>     <span class="hljs-number">0.9297</span>    <span class="hljs-number">0.8730</span>    <span class="hljs-number">0.9005</span>      <span class="hljs-number">1000</span><br>       <span class="hljs-string">realty</span>     <span class="hljs-number">0.9341</span>    <span class="hljs-number">0.9070</span>    <span class="hljs-number">0.9203</span>      <span class="hljs-number">1000</span><br>       <span class="hljs-string">stocks</span>     <span class="hljs-number">0.8183</span>    <span class="hljs-number">0.8780</span>    <span class="hljs-number">0.8471</span>      <span class="hljs-number">1000</span><br>    <span class="hljs-string">education</span>     <span class="hljs-number">0.9564</span>    <span class="hljs-number">0.9430</span>    <span class="hljs-number">0.9496</span>      <span class="hljs-number">1000</span><br>      <span class="hljs-string">science</span>     <span class="hljs-number">0.8964</span>    <span class="hljs-number">0.8220</span>    <span class="hljs-number">0.8576</span>      <span class="hljs-number">1000</span><br>      <span class="hljs-string">society</span>     <span class="hljs-number">0.8359</span>    <span class="hljs-number">0.9220</span>    <span class="hljs-number">0.8768</span>      <span class="hljs-number">1000</span><br>     <span class="hljs-string">politics</span>     <span class="hljs-number">0.8920</span>    <span class="hljs-number">0.8590</span>    <span class="hljs-number">0.8752</span>      <span class="hljs-number">1000</span><br>       <span class="hljs-string">sports</span>     <span class="hljs-number">0.9436</span>    <span class="hljs-number">0.9540</span>    <span class="hljs-number">0.9488</span>      <span class="hljs-number">1000</span><br>         <span class="hljs-string">game</span>     <span class="hljs-number">0.9263</span>    <span class="hljs-number">0.9050</span>    <span class="hljs-number">0.9155</span>      <span class="hljs-number">1000</span><br><span class="hljs-string">entertainment</span>     <span class="hljs-number">0.8736</span>    <span class="hljs-number">0.9260</span>    <span class="hljs-number">0.8990</span>      <span class="hljs-number">1000</span><br><br>     <span class="hljs-string">accuracy</span>                         <span class="hljs-number">0.8989</span>     <span class="hljs-number">10000</span><br>    <span class="hljs-string">macro</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9006</span>    <span class="hljs-number">0.8989</span>    <span class="hljs-number">0.8991</span>     <span class="hljs-number">10000</span><br> <span class="hljs-string">weighted</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9006</span>    <span class="hljs-number">0.8989</span>    <span class="hljs-number">0.8991</span>     <span class="hljs-number">10000</span><br><br><span class="hljs-string">Confusion</span> <span class="hljs-string">Matrix...</span><br>[[<span class="hljs-number">873</span>   <span class="hljs-number">9</span>  <span class="hljs-number">68</span>   <span class="hljs-number">1</span>   <span class="hljs-number">6</span>  <span class="hljs-number">19</span>  <span class="hljs-number">14</span>   <span class="hljs-number">3</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span>]<br> [ <span class="hljs-number">15</span> <span class="hljs-number">907</span>  <span class="hljs-number">13</span>   <span class="hljs-number">2</span>   <span class="hljs-number">4</span>  <span class="hljs-number">18</span>  <span class="hljs-number">13</span>   <span class="hljs-number">6</span>   <span class="hljs-number">2</span>  <span class="hljs-number">20</span>]<br> [ <span class="hljs-number">38</span>  <span class="hljs-number">24</span> <span class="hljs-number">878</span>   <span class="hljs-number">1</span>  <span class="hljs-number">18</span>  <span class="hljs-number">10</span>  <span class="hljs-number">23</span>   <span class="hljs-number">2</span>   <span class="hljs-number">4</span>   <span class="hljs-number">2</span>]<br> [  <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">4</span> <span class="hljs-number">943</span>   <span class="hljs-number">4</span>  <span class="hljs-number">19</span>   <span class="hljs-number">6</span>   <span class="hljs-number">5</span>   <span class="hljs-number">3</span>  <span class="hljs-number">13</span>]<br> [  <span class="hljs-number">2</span>   <span class="hljs-number">3</span>  <span class="hljs-number">54</span>   <span class="hljs-number">5</span> <span class="hljs-number">822</span>  <span class="hljs-number">30</span>  <span class="hljs-number">26</span>   <span class="hljs-number">2</span>  <span class="hljs-number">36</span>  <span class="hljs-number">20</span>]<br> [  <span class="hljs-number">1</span>  <span class="hljs-number">14</span>   <span class="hljs-number">4</span>  <span class="hljs-number">19</span>   <span class="hljs-number">6</span> <span class="hljs-number">922</span>  <span class="hljs-number">14</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>  <span class="hljs-number">17</span>]<br> [  <span class="hljs-number">8</span>   <span class="hljs-number">8</span>  <span class="hljs-number">35</span>   <span class="hljs-number">9</span>  <span class="hljs-number">11</span>  <span class="hljs-number">47</span> <span class="hljs-number">859</span>   <span class="hljs-number">5</span>   <span class="hljs-number">2</span>  <span class="hljs-number">16</span>]<br> [  <span class="hljs-number">1</span>   <span class="hljs-number">1</span>   <span class="hljs-number">3</span>   <span class="hljs-number">1</span>   <span class="hljs-number">3</span>  <span class="hljs-number">12</span>   <span class="hljs-number">3</span> <span class="hljs-number">954</span>   <span class="hljs-number">1</span>  <span class="hljs-number">21</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">9</span>   <span class="hljs-number">2</span>  <span class="hljs-number">37</span>   <span class="hljs-number">6</span>   <span class="hljs-number">5</span>  <span class="hljs-number">15</span> <span class="hljs-number">905</span>  <span class="hljs-number">21</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">3</span>   <span class="hljs-number">5</span>   <span class="hljs-number">3</span>   <span class="hljs-number">6</span>  <span class="hljs-number">20</span>   <span class="hljs-number">0</span>  <span class="hljs-number">18</span>  <span class="hljs-number">19</span> <span class="hljs-number">926</span>]]<br><span class="hljs-attr">Time usage:</span> <span class="hljs-number">0</span><span class="hljs-string">:00:00</span><br> <span class="hljs-number">99</span><span class="hljs-string">%|████████████████████████████████████████████████████████████████████▌|</span> <span class="hljs-number">1398</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:01&lt;00:00</span>, <span class="hljs-number">22.</span><span class="hljs-string">65it/s</span>]<br></code></pre></td></tr></table></figure><blockquote><ul><li>结论: Student模型在测试集上的表现是Test Acc: 89.89%</li></ul></blockquote><h3 id="调参训练student模型">6.3 调参训练Student模型</h3><ul><li>对Config类中的若干超参数做出重要修改:</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 模型迭代30轮</span><br><span class="hljs-attribute">self</span>.num_epochs = <span class="hljs-number">30</span><br><br><span class="hljs-comment"># 卷积核尺寸分别选2, 3, 4, 5</span><br><span class="hljs-attribute">self</span>.filter_sizes = (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># 卷积核的个数1024</span><br><span class="hljs-attribute">self</span>.num_filters = <span class="hljs-number">1024</span><br></code></pre></td></tr></table></figure><ul><li>调参后再次训练Student模型:</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 将--task修改为train_kd，直接执行run文件</span><br>parser.add_argument(<span class="hljs-string">&quot;--task&quot;</span>, <span class="hljs-attribute">type</span>=str, <span class="hljs-attribute">default</span>=<span class="hljs-string">&#x27;train_kd&#x27;</span>, <span class="hljs-attribute">help</span>=<span class="hljs-string">&quot;choose a task: trainbert, or train_kd&quot;</span>)<br><span class="hljs-comment"># 或直接在命令行运行训练Student模型的代码</span><br>python run.py --task train_kd<br></code></pre></td></tr></table></figure><ul><li>输出结果:</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">180000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:37</span>, <span class="hljs-number">4830.</span><span class="hljs-string">81it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:02</span>, <span class="hljs-number">4935.</span><span class="hljs-string">57it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:02</span>, <span class="hljs-number">4955.</span><span class="hljs-string">57it/s</span>]<br><span class="hljs-attr">Vocab size:</span> <span class="hljs-number">4762</span><br><span class="hljs-string">180000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:02</span>, <span class="hljs-number">69735.</span><span class="hljs-string">78it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:00</span>, <span class="hljs-number">82937.</span><span class="hljs-string">77it/s</span>]<br><span class="hljs-string">10000it</span> [<span class="hljs-number">00</span><span class="hljs-string">:00</span>, <span class="hljs-number">82402.</span><span class="hljs-string">02it/s</span>]<br><span class="hljs-string">Data</span> <span class="hljs-string">loaded,</span> <span class="hljs-string">now</span> <span class="hljs-string">load</span> <span class="hljs-string">teacher</span> <span class="hljs-string">model</span><br><span class="hljs-string">Teacher</span> <span class="hljs-string">and</span> <span class="hljs-string">student</span> <span class="hljs-string">models</span> <span class="hljs-string">loaded,</span> <span class="hljs-string">start</span> <span class="hljs-string">training</span><br><span class="hljs-string">Epoch</span> [<span class="hljs-number">1</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▊</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">399</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:39&lt;01:40</span>, <span class="hljs-number">10.</span><span class="hljs-string">06it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.29</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">75.00</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.76</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">84.65</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:00</span> <span class="hljs-string">*</span><br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">800</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:20&lt;01:00</span>, <span class="hljs-number">10.</span><span class="hljs-string">05it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.24</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">82.81</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.71</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">86.89</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:06:41</span> <span class="hljs-string">*</span><br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1200</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:01&lt;00:20</span>, <span class="hljs-number">10.</span><span class="hljs-string">06it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.23</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">82.81</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.72</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">85.35</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:07:22</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:23&lt;00:00</span>,  <span class="hljs-number">9.</span><span class="hljs-string">80it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">2</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▉</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">400</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:39&lt;01:40</span>, <span class="hljs-number">10.</span><span class="hljs-string">06it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.23</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">79.69</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.67</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.46</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:08:24</span> <span class="hljs-string">*</span><br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">800</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:20&lt;01:00</span>, <span class="hljs-number">10.</span><span class="hljs-string">08it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.21</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">86.72</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.66</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.74</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:09:04</span> <span class="hljs-string">*</span><br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1199</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:01&lt;00:20</span>, <span class="hljs-number">10.</span><span class="hljs-string">09it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.21</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">92.19</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.67</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">88.86</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:09:45</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:22&lt;00:00</span>,  <span class="hljs-number">9.</span><span class="hljs-string">85it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">3</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▉</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">400</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:39&lt;01:39</span>, <span class="hljs-number">10.</span><span class="hljs-string">13it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.22</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">82.81</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.63</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.46</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:10:46</span> <span class="hljs-string">*</span><br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">799</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:20&lt;00:59</span>, <span class="hljs-number">10.</span><span class="hljs-string">15it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>   <span class="hljs-number">0.2</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">92.97</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.56</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:11:27</span> <br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1199</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:00&lt;00:20</span>, <span class="hljs-number">10.</span><span class="hljs-string">15it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.19</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">92.19</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.66</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:12:08</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:22&lt;00:00</span>,  <span class="hljs-number">9.</span><span class="hljs-string">89it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">4</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▉</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">400</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:39&lt;01:39</span>, <span class="hljs-number">10.</span><span class="hljs-string">17it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.19</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">90.62</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.44</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:13:08</span> <br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">799</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:19&lt;00:59</span>, <span class="hljs-number">10.</span><span class="hljs-string">18it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.18</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">95.31</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.62</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.96</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:13:49</span> <span class="hljs-string">*</span><br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1199</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:00&lt;00:20</span>, <span class="hljs-number">10.</span><span class="hljs-string">18it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.18</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">92.19</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.69</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:14:29</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:21&lt;00:00</span>,  <span class="hljs-number">9.</span><span class="hljs-string">92it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">5</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▊</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">399</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:39&lt;01:38</span>, <span class="hljs-number">10.</span><span class="hljs-string">25it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>   <span class="hljs-number">0.2</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">88.28</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.63</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.28</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:15:30</span> <br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">799</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:19&lt;00:59</span>, <span class="hljs-number">10.</span><span class="hljs-string">29it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.19</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">90.62</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.60</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:16:10</span> <br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1199</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:59&lt;00:20</span>, <span class="hljs-number">10.</span><span class="hljs-string">29it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.17</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">96.88</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">89.51</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">0</span><span class="hljs-string">:16:50</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:20&lt;00:00</span>, <span class="hljs-number">10.</span><span class="hljs-string">02it/s</span>]<br><br><span class="hljs-string">......</span><br><span class="hljs-string">......</span><br><span class="hljs-string">......</span><br><br><span class="hljs-string">Epoch</span> [<span class="hljs-number">28</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▉</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">400</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:38&lt;01:36</span>, <span class="hljs-number">10.</span><span class="hljs-string">40it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.15</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">98.44</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.58</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:08:43</span> <br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">800</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:17&lt;00:58</span>, <span class="hljs-number">10.</span><span class="hljs-string">43it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.16</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">98.44</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.63</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">91.09</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:09:22</span> <br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1200</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:57&lt;00:19</span>, <span class="hljs-number">10.</span><span class="hljs-string">43it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.15</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">96.88</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.55</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:10:02</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:18&lt;00:00</span>, <span class="hljs-number">10.</span><span class="hljs-string">17it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">29</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▉</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">400</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:38&lt;01:36</span>, <span class="hljs-number">10.</span><span class="hljs-string">41it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.15</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">97.66</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.78</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:11:01</span> <br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">800</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:17&lt;00:58</span>, <span class="hljs-number">10.</span><span class="hljs-string">42it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.16</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">98.44</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.63</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.58</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:11:40</span> <br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1200</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:57&lt;00:19</span>, <span class="hljs-number">10.</span><span class="hljs-string">41it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.15</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">97.66</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.62</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.72</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:12:20</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:18&lt;00:00</span>, <span class="hljs-number">10.</span><span class="hljs-string">17it/s</span>]<br><span class="hljs-string">Epoch</span> [<span class="hljs-number">30</span><span class="hljs-string">/30</span>]<br> <span class="hljs-number">28</span><span class="hljs-string">%|███████████████████▉</span>                                                  <span class="hljs-string">|</span> <span class="hljs-number">400</span><span class="hljs-string">/1407</span> [<span class="hljs-number">00</span><span class="hljs-string">:38&lt;01:36</span>, <span class="hljs-number">10.</span><span class="hljs-string">40it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">400</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.16</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">98.44</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.65</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.66</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:13:19</span> <br> <span class="hljs-number">57</span><span class="hljs-string">%|███████████████████████████████████████▊</span>                              <span class="hljs-string">|</span> <span class="hljs-number">800</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:17&lt;00:58</span>, <span class="hljs-number">10.</span><span class="hljs-string">43it/s</span>]<span class="hljs-attr">Iter:</span>    <span class="hljs-number">800</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.15</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">98.44</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.63</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.79</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:13:59</span> <br> <span class="hljs-number">85</span><span class="hljs-string">%|██████████████████████████████████████████████████████████▊</span>          <span class="hljs-string">|</span> <span class="hljs-number">1200</span><span class="hljs-string">/1407</span> [<span class="hljs-number">01</span><span class="hljs-string">:57&lt;00:19</span>, <span class="hljs-number">10.</span><span class="hljs-string">40it/s</span>]<span class="hljs-attr">Iter:</span>   <span class="hljs-number">1200</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Loss:</span>  <span class="hljs-number">0.15</span><span class="hljs-string">,</span>  <span class="hljs-attr">Train Acc:</span> <span class="hljs-number">99.22</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Val Loss:</span>  <span class="hljs-number">0.64</span><span class="hljs-string">,</span>  <span class="hljs-attr">Val Acc:</span> <span class="hljs-number">90.65</span><span class="hljs-string">%,</span>  <span class="hljs-attr">Time:</span> <span class="hljs-number">1</span><span class="hljs-string">:14:38</span> <br><span class="hljs-number">100</span><span class="hljs-string">%|█████████████████████████████████████████████████████████████████████|</span> <span class="hljs-number">1407</span><span class="hljs-string">/1407</span> [<span class="hljs-number">02</span><span class="hljs-string">:18&lt;00:00</span>, <span class="hljs-number">10.</span><span class="hljs-string">17it/s</span>]<br><span class="hljs-attr">Test Loss:</span>   <span class="hljs-number">0.6</span><span class="hljs-string">,</span>  <span class="hljs-attr">Test Acc:</span> <span class="hljs-number">91.25</span><span class="hljs-string">%</span><br><span class="hljs-string">Precision,</span> <span class="hljs-string">Recall</span> <span class="hljs-string">and</span> <span class="hljs-string">F1-Score...</span><br>               <span class="hljs-string">precision</span>    <span class="hljs-string">recall</span>  <span class="hljs-string">f1-score</span>   <span class="hljs-string">support</span><br><br>      <span class="hljs-string">finance</span>     <span class="hljs-number">0.9105</span>    <span class="hljs-number">0.9050</span>    <span class="hljs-number">0.9077</span>      <span class="hljs-number">1000</span><br>       <span class="hljs-string">realty</span>     <span class="hljs-number">0.9311</span>    <span class="hljs-number">0.9320</span>    <span class="hljs-number">0.9315</span>      <span class="hljs-number">1000</span><br>       <span class="hljs-string">stocks</span>     <span class="hljs-number">0.8912</span>    <span class="hljs-number">0.8440</span>    <span class="hljs-number">0.8670</span>      <span class="hljs-number">1000</span><br>    <span class="hljs-string">education</span>     <span class="hljs-number">0.9532</span>    <span class="hljs-number">0.9570</span>    <span class="hljs-number">0.9551</span>      <span class="hljs-number">1000</span><br>      <span class="hljs-string">science</span>     <span class="hljs-number">0.8836</span>    <span class="hljs-number">0.8730</span>    <span class="hljs-number">0.8783</span>      <span class="hljs-number">1000</span><br>      <span class="hljs-string">society</span>     <span class="hljs-number">0.8306</span>    <span class="hljs-number">0.9270</span>    <span class="hljs-number">0.8762</span>      <span class="hljs-number">1000</span><br>     <span class="hljs-string">politics</span>     <span class="hljs-number">0.9041</span>    <span class="hljs-number">0.8770</span>    <span class="hljs-number">0.8904</span>      <span class="hljs-number">1000</span><br>       <span class="hljs-string">sports</span>     <span class="hljs-number">0.9733</span>    <span class="hljs-number">0.9470</span>    <span class="hljs-number">0.9600</span>      <span class="hljs-number">1000</span><br>         <span class="hljs-string">game</span>     <span class="hljs-number">0.9467</span>    <span class="hljs-number">0.9240</span>    <span class="hljs-number">0.9352</span>      <span class="hljs-number">1000</span><br><span class="hljs-string">entertainment</span>     <span class="hljs-number">0.9108</span>    <span class="hljs-number">0.9390</span>    <span class="hljs-number">0.9247</span>      <span class="hljs-number">1000</span><br><br>     <span class="hljs-string">accuracy</span>                         <span class="hljs-number">0.9125</span>     <span class="hljs-number">10000</span><br>    <span class="hljs-string">macro</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9135</span>    <span class="hljs-number">0.9125</span>    <span class="hljs-number">0.9126</span>     <span class="hljs-number">10000</span><br> <span class="hljs-string">weighted</span> <span class="hljs-string">avg</span>     <span class="hljs-number">0.9135</span>    <span class="hljs-number">0.9125</span>    <span class="hljs-number">0.9126</span>     <span class="hljs-number">10000</span><br><br><span class="hljs-string">Confusion</span> <span class="hljs-string">Matrix...</span><br>[[<span class="hljs-number">905</span>  <span class="hljs-number">10</span>  <span class="hljs-number">38</span>   <span class="hljs-number">4</span>   <span class="hljs-number">5</span>  <span class="hljs-number">19</span>  <span class="hljs-number">11</span>   <span class="hljs-number">3</span>   <span class="hljs-number">0</span>   <span class="hljs-number">5</span>]<br> [ <span class="hljs-number">13</span> <span class="hljs-number">932</span>  <span class="hljs-number">13</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>  <span class="hljs-number">17</span>   <span class="hljs-number">6</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span>   <span class="hljs-number">7</span>]<br> [ <span class="hljs-number">54</span>  <span class="hljs-number">23</span> <span class="hljs-number">844</span>   <span class="hljs-number">1</span>  <span class="hljs-number">32</span>   <span class="hljs-number">6</span>  <span class="hljs-number">33</span>   <span class="hljs-number">1</span>   <span class="hljs-number">4</span>   <span class="hljs-number">2</span>]<br> [  <span class="hljs-number">2</span>   <span class="hljs-number">2</span>   <span class="hljs-number">1</span> <span class="hljs-number">957</span>   <span class="hljs-number">4</span>  <span class="hljs-number">15</span>   <span class="hljs-number">6</span>   <span class="hljs-number">1</span>   <span class="hljs-number">3</span>   <span class="hljs-number">9</span>]<br> [  <span class="hljs-number">3</span>   <span class="hljs-number">5</span>  <span class="hljs-number">24</span>   <span class="hljs-number">5</span> <span class="hljs-number">873</span>  <span class="hljs-number">32</span>  <span class="hljs-number">17</span>   <span class="hljs-number">3</span>  <span class="hljs-number">25</span>  <span class="hljs-number">13</span>]<br> [  <span class="hljs-number">2</span>  <span class="hljs-number">15</span>   <span class="hljs-number">3</span>  <span class="hljs-number">18</span>   <span class="hljs-number">5</span> <span class="hljs-number">927</span>  <span class="hljs-number">12</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>  <span class="hljs-number">17</span>]<br> [ <span class="hljs-number">12</span>  <span class="hljs-number">10</span>  <span class="hljs-number">16</span>  <span class="hljs-number">10</span>  <span class="hljs-number">14</span>  <span class="hljs-number">48</span> <span class="hljs-number">877</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">8</span>]<br> [  <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">3</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>  <span class="hljs-number">21</span>   <span class="hljs-number">4</span> <span class="hljs-number">947</span>   <span class="hljs-number">1</span>  <span class="hljs-number">19</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">3</span>   <span class="hljs-number">3</span>  <span class="hljs-number">43</span>   <span class="hljs-number">8</span>   <span class="hljs-number">2</span>   <span class="hljs-number">5</span> <span class="hljs-number">924</span>  <span class="hljs-number">12</span>]<br> [  <span class="hljs-number">1</span>   <span class="hljs-number">4</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">7</span>  <span class="hljs-number">23</span>   <span class="hljs-number">2</span>   <span class="hljs-number">8</span>  <span class="hljs-number">11</span> <span class="hljs-number">939</span>]]<br><span class="hljs-attr">Time usage:</span> <span class="hljs-number">0</span><span class="hljs-string">:00:01</span><br></code></pre></td></tr></table></figure><p>结论: 调参后的Student模型在测试集上的表现是Test Acc: 91.25%</p><p>完成知识蒸馏后, 我们获得了两个模型, Teacher模型和Student模型：</p><figure><img src="/images/模型蒸馏/image-20231117134733605.png"alt="image-20231117134733605" /><figcaption aria-hidden="true">image-20231117134733605</figcaption></figure><p>从上述结果中可以看出:</p><p>Teacher模型大小为409.2MB, Student模型大小为11.3MB和23.1MB.</p><p>Teacher模型测试集准确率为93.64%,Student模型测试集准确率为89.89%和91.25%.</p><h2 id="结论">7.结论</h2><p>模型进行知识蒸馏后模型大小和准确率的变化：</p><p>1、模型大小明显减少.</p><ul><li>BERT模型409.2MB, 最优的textCNN模型23.1MB.</li><li>模型大小压缩为原来的5.65%, 缩小了17.7倍.</li></ul><p>2、模型在测试集上准确率仅有2.39%的下降.</p><ul><li>BERT模型准确率93.64%</li><li>textCNN模型知识蒸馏后30个epochs准确率91.25%</li></ul>]]></content>
    
    
    <categories>
      
      <category>模型压缩技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>剪枝</tag>
      
      <tag>模型处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于GRU模型的带编-解码器和注意力机制的英译法任务实现</title>
    <link href="/%E5%9F%BA%E4%BA%8EGRU%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%84%E5%BB%BA%E5%B8%A6%E7%BC%96-%E8%A7%A3%E7%A0%81%E5%99%A8%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E8%8B%B1%E8%AF%91%E6%B3%95%E4%BB%BB%E5%8A%A1%E5%AE%9E%E7%8E%B0.html"/>
    <url>/%E5%9F%BA%E4%BA%8EGRU%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%84%E5%BB%BA%E5%B8%A6%E7%BC%96-%E8%A7%A3%E7%A0%81%E5%99%A8%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E8%8B%B1%E8%AF%91%E6%B3%95%E4%BB%BB%E5%8A%A1%E5%AE%9E%E7%8E%B0.html</url>
    
    <content type="html"><![CDATA[<figure><img src="/images/编解码器框架/编解码器流程框架_inverted.png"alt="模型整体结构示意" /><figcaption aria-hidden="true">模型整体结构示意</figcaption></figure><h3 id="基础准备">1.基础准备</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 用于正则表达式</span><br><span class="hljs-keyword">import</span> re<br><span class="hljs-comment"># 用于构建网络结构和函数的torch工具包</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-comment"># torch中预定义的优化方法工具包</span><br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> time<br><span class="hljs-comment"># 用于随机生成数据</span><br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 设备选择, 我们可以选择在cuda或者cpu上运行你的代码</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><span class="hljs-comment"># 起始标志</span><br>SOS_token = <span class="hljs-number">0</span><br><span class="hljs-comment"># 结束标志</span><br>EOS_token = <span class="hljs-number">1</span><br><span class="hljs-comment"># 最大句子长度不能超过10个 (包含标点)</span><br>MAX_LENGTH = <span class="hljs-number">10</span><br><span class="hljs-comment"># 数据文件路径</span><br>data_path = <span class="hljs-string">&#x27;./data/eng-fra-v2.txt&#x27;</span><br><br><span class="hljs-comment"># 文本清洗工具函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalizeString</span>(<span class="hljs-params">s</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;字符串规范化函数, 参数s代表传入的字符串&quot;&quot;&quot;</span><br>    s = s.lower().strip()<br>    <span class="hljs-comment"># 在.!?前加一个空格  这里的\1表示第一个分组   正则中的\num</span><br>    s = re.sub(<span class="hljs-string">r&quot;([.!?])&quot;</span>, <span class="hljs-string">r&quot; \1&quot;</span>, s)<br>    <span class="hljs-comment"># s = re.sub(r&quot;([.!?])&quot;, r&quot; &quot;, s)</span><br>    <span class="hljs-comment"># 使用正则表达式将字符串中 不是 大小写字母和正常标点的都替换成空格</span><br>    s = re.sub(<span class="hljs-string">r&quot;[^a-zA-Z.!?]+&quot;</span>, <span class="hljs-string">r&quot; &quot;</span>, s)<br>    <span class="hljs-keyword">return</span> s<br></code></pre></td></tr></table></figure><h3 id="数据预处理">2.数据预处理</h3><h4 id="构建数据获取源对象">构建数据获取源对象</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_getdata</span>():<br><br>    <span class="hljs-comment"># 1 按行读文件 open().read().strip().split(\n)</span><br>    my_lines = <span class="hljs-built_in">open</span>(data_path, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>).read().strip().split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;my_lines---&gt;&#x27;</span>, <span class="hljs-built_in">len</span>(my_lines))<br><br>    <span class="hljs-comment"># 2 按行清洗文本 构建语言对 my_pairs</span><br>    my_pairs = [[normalizeString(s) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> l.split(<span class="hljs-string">&#x27;\t&#x27;</span>)] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> my_lines]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(pairs)---&gt;&#x27;</span>, <span class="hljs-built_in">len</span>(my_pairs))<br><br>    <span class="hljs-comment"># 打印前4条数据</span><br>    <span class="hljs-built_in">print</span>(my_pairs[:<span class="hljs-number">4</span>])<br><br>    <span class="hljs-comment"># 打印第8000条的英文 法文数据</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;my_pairs[8000][0]---&gt;&#x27;</span>, my_pairs[<span class="hljs-number">8000</span>][<span class="hljs-number">0</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;my_pairs[8000][1]---&gt;&#x27;</span>, my_pairs[<span class="hljs-number">8000</span>][<span class="hljs-number">1</span>])<br><br>    <span class="hljs-comment"># 3 遍历语言对 构建英语单词字典 法语单词字典</span><br>    <span class="hljs-comment"># 3-1 english_word2index english_word_n french_word2index french_word_n</span><br>    english_word2index = &#123;<span class="hljs-string">&quot;SOS&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;EOS&quot;</span>: <span class="hljs-number">1</span>&#125;<br>    english_word_n = <span class="hljs-number">2</span><br><br>    french_word2index = &#123;<span class="hljs-string">&quot;SOS&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;EOS&quot;</span>: <span class="hljs-number">1</span>&#125;<br>    french_word_n = <span class="hljs-number">2</span><br><br>    <span class="hljs-comment"># 遍历语言对 获取英语单词字典 法语单词字典</span><br>    <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> my_pairs:<br>       <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> pair[<span class="hljs-number">0</span>].split(<span class="hljs-string">&#x27; &#x27;</span>):<br>           <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> english_word2index:<br>               english_word2index[word] = english_word_n<br>               english_word_n += <span class="hljs-number">1</span><br><br>       <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> pair[<span class="hljs-number">1</span>].split(<span class="hljs-string">&#x27; &#x27;</span>):<br>           <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> french_word2index:<br>               french_word2index[word] = french_word_n<br>               french_word_n += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 3-2 english_index2word french_index2word</span><br>    english_index2word = &#123;v:k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> english_word2index.items()&#125;<br>    french_index2word = &#123;v:k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> french_word2index.items()&#125;<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(english_word2index)--&gt;&#x27;</span>, <span class="hljs-built_in">len</span>(english_word2index))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;len(french_word2index)--&gt;&#x27;</span>, <span class="hljs-built_in">len</span>(french_word2index))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;english_word_n---&gt;&#x27;</span>, english_word_n, <span class="hljs-string">&#x27;french_word_n--&gt;&#x27;</span>, french_word_n)<br><br>    <span class="hljs-keyword">return</span> english_word2index, english_index2word, english_word_n, french_word2index, french_index2word, french_word_n, my_pairs<br>english_word2index, english_index2word, english_word_n, french_word2index, french_index2word, french_word_n, my_pairs=my_getdata()<br></code></pre></td></tr></table></figure><h4 id="构建数据处理迭代对象">构建数据处理迭代对象</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyPairsDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, my_pairs</span>):<br>        <span class="hljs-comment"># 样本x</span><br>        self.my_pairs = my_pairs<br><br>        <span class="hljs-comment"># 样本条目数</span><br>        self.sample_len = <span class="hljs-built_in">len</span>(my_pairs)<br><br>    <span class="hljs-comment"># 获取样本条数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.sample_len<br><br>    <span class="hljs-comment"># 获取第几条 样本数据</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br><br>        <span class="hljs-comment"># 对index异常值进行修正 [0, self.sample_len-1]</span><br>        index = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">max</span>(index, <span class="hljs-number">0</span>), self.sample_len-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 按索引获取 数据样本 x y</span><br>        x = self.my_pairs[index][<span class="hljs-number">0</span>]<br>        y = self.my_pairs[index][<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># 样本x 文本数值化</span><br>        x = [english_word2index[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> x.split(<span class="hljs-string">&#x27; &#x27;</span>)]<br>        x.append(EOS_token)<br>        tensor_x = torch.tensor(x, dtype=torch.long, device=device)<br><br>        <span class="hljs-comment"># 样本y 文本数值化</span><br>        y = [french_word2index[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> y.split(<span class="hljs-string">&#x27; &#x27;</span>)]<br>        y.append(EOS_token)<br>        tensor_y = torch.tensor(y, dtype=torch.long, device=device)<br>        <span class="hljs-comment"># 注意 tensor_x tensor_y都是一维数组，通过DataLoader拿出数据是二维数据</span><br>        <span class="hljs-comment"># print(&#x27;tensor_y.shape===&gt;&#x27;, tensor_y.shape, tensor_y)</span><br><br>        <span class="hljs-comment"># 返回结果</span><br>        <span class="hljs-keyword">return</span> tensor_x, tensor_y<br></code></pre></td></tr></table></figure><h3 id="基于gru的编码器">3.基于GRU的编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size</span>):<br><br>        <span class="hljs-comment"># input_size 编码器 词嵌入层单词数 eg：2803</span><br>        <span class="hljs-comment"># hidden_size 编码器 词嵌入层每个单词的特征数 eg 256</span><br>        <span class="hljs-built_in">super</span>(EncoderRNN, self).__init__()<br>        self.input_size = input_size<br>        self.hidden_size = hidden_size<br><br>        <span class="hljs-comment"># 实例化nn.Embedding层</span><br>        self.embedding = nn.Embedding(input_size, hidden_size)<br><br>        <span class="hljs-comment"># 实例化nn.GRU层 注意参数batch_first=True</span><br>        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden</span>):<br><br>        <span class="hljs-comment"># 数据经过词嵌入层 数据形状 [1,6] --&gt; [1,6,256]</span><br>        output = self.embedding(<span class="hljs-built_in">input</span>)<br><br>        <span class="hljs-comment"># 数据经过gru层 数据形状 gru([1,6,256],[1,1,256]) --&gt; [1,6,256] [1,1,256]</span><br>        output, hidden = self.gru(output, hidden)<br>        <span class="hljs-keyword">return</span> output, hidden<br>        <span class="hljs-comment"># output 提供了输入序列的详细表示，可用于注意力机制。</span><br>        <span class="hljs-comment"># hidden 是整个输入序列的压缩表示，用于初始化解码器。</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inithidden</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 将隐层张量初始化成为1x1xself.hidden_size大小的张量</span><br>        <span class="hljs-keyword">return</span> torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, self.hidden_size, device=device)<br><br></code></pre></td></tr></table></figure><h3 id="构建基于gru和attention的解码器">4构建基于GRU和Attention的解码器</h3><p>使用软注意力机制的类点积缩放模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AttnDecoderRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, output_size, hidden_size, dropout_p=<span class="hljs-number">0.1</span>, max_length=MAX_LENGTH</span>):<br><br>        <span class="hljs-comment"># output_size   编码器 词嵌入层单词数 eg：4345</span><br>        <span class="hljs-comment"># hidden_size   编码器 词嵌入层每个单词的特征数 eg 256</span><br>        <span class="hljs-comment"># dropout_p     置零比率，默认0.1,</span><br>        <span class="hljs-comment"># max_length    最大长度10</span><br>        <span class="hljs-built_in">super</span>(AttnDecoderRNN, self).__init__()<br>        self.output_size = output_size<br>        self.hidden_size = hidden_size<br>        self.dropout_p = dropout_p<br>        self.max_length = max_length<br><br>        <span class="hljs-comment"># 定义nn.Embedding层 nn.Embedding(4345,256)</span><br>        self.embedding = nn.Embedding(self.output_size, self.hidden_size)<br><br>        <span class="hljs-comment"># 定义线性层1：求q的注意力权重分布</span><br>        self.attn = nn.Linear(self.hidden_size * <span class="hljs-number">2</span>, self.max_length)<br><br>        <span class="hljs-comment"># 定义线性层2：q+注意力结果表示融合后，在按照指定维度输出</span><br>        self.attn_combine = nn.Linear(self.hidden_size * <span class="hljs-number">2</span>, self.hidden_size)<br><br>        <span class="hljs-comment"># 定义dropout层</span><br>        self.dropout = nn.Dropout(self.dropout_p)<br><br>        <span class="hljs-comment"># 定义gru层</span><br>        self.gru = nn.GRU(self.hidden_size, self.hidden_size, batch_first=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment"># 定义out层 解码器按照类别进行输出(256,4345)</span><br>        self.out = nn.Linear(self.hidden_size, self.output_size)<br><br>        <span class="hljs-comment"># 实例化softomax层 数值归一化 以便分类</span><br>        self.softmax = nn.LogSoftmax(dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, hidden, encoder_outputs</span>):<br>        <span class="hljs-comment"># input代表q [1,1] 二维数据 hidden代表k [1,1,256] encoder_outputs代表v [10,256]</span><br><br>        <span class="hljs-comment"># 数据经过词嵌入层</span><br>        <span class="hljs-comment"># 数据形状 [1,1] --&gt; [1,1,256]</span><br>        embedded = self.embedding(<span class="hljs-built_in">input</span>)<br><br>        <span class="hljs-comment"># 使用dropout进行随机丢弃，防止过拟合</span><br>        embedded = self.dropout(embedded)<br><br>        <span class="hljs-comment"># 1 求查询张量q的注意力权重分布, attn_weights[1,10]</span><br>        attn_weights = F.softmax(<br>            self.attn(torch.cat((embedded[<span class="hljs-number">0</span>], hidden[<span class="hljs-number">0</span>]), <span class="hljs-number">1</span>)), dim=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 2 求查询张量q的注意力结果表示 bmm运算, attn_applied[1,1,256]</span><br>        <span class="hljs-comment"># [1,1,10],[1,10,256] ---&gt; [1,1,256]</span><br>        attn_applied = torch.bmm(attn_weights.unsqueeze(<span class="hljs-number">0</span>), encoder_outputs.unsqueeze(<span class="hljs-number">0</span>))<br><br>        <span class="hljs-comment"># 3 q 与 attn_applied 融合，再按照指定维度输出 output[1,1,256]</span><br>        output = torch.cat((embedded[<span class="hljs-number">0</span>], attn_applied[<span class="hljs-number">0</span>]), <span class="hljs-number">1</span>)<br>        output = self.attn_combine(output).unsqueeze(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># 查询张量q的注意力结果表示 使用relu激活</span><br>        output = F.relu(output)<br><br>        <span class="hljs-comment"># 查询张量经过gru、softmax进行分类结果输出</span><br>        <span class="hljs-comment"># 数据形状[1,1,256],[1,1,256] --&gt; [1,1,256], [1,1,256]</span><br>        output, hidden = self.gru(output, hidden)<br>        <span class="hljs-comment"># 数据形状[1,1,256]-&gt;[1,256]-&gt;[1,4345]</span><br>        output = self.softmax(self.out(output[<span class="hljs-number">0</span>]))<br><br>        <span class="hljs-comment"># 返回解码器分类output[1,4345]，最后隐层张量hidden[1,1,256] 注意力权重张量attn_weights[1,10]</span><br>        <span class="hljs-keyword">return</span> output, hidden, attn_weights<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inithidden</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 将隐层张量初始化成为1x1xself.hidden_size大小的张量</span><br>        <span class="hljs-keyword">return</span> torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, self.hidden_size, device=device)<br><br></code></pre></td></tr></table></figure><h3 id="模型构建与训练">5 模型构建与训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 基础模型训练参数</span><br>mylr = <span class="hljs-number">2e-4</span><br>epochs = <span class="hljs-number">2</span><br><span class="hljs-comment"># 设置teacher_forcing比率为0.5</span><br>teacher_forcing_ratio = <span class="hljs-number">0.5</span><br><br>print_interval_num = <span class="hljs-number">1000</span><br>plot_interval_num = <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><h4 id="训练迭代器">训练迭代器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># from torch.utils.tensorboard import SummaryWriter</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Train_Iters</span>(<span class="hljs-params">x, y, my_encoderrnn, my_attndecoderrnn, myadam_encode, myadam_decode, mycrossentropyloss</span>):<br>    <span class="hljs-comment"># # 初始化SummaryWriter</span><br>    <span class="hljs-comment"># writer = SummaryWriter()</span><br><br>    <span class="hljs-comment"># 1 编码 encode_output, encode_hidden = my_encoderrnn(x, encode_hidden)</span><br>    encode_hidden = my_encoderrnn.inithidden().to(device)<br>    x=x.to(device)<br>    <span class="hljs-comment"># 模型可视化</span><br>    <span class="hljs-comment"># writer.add_graph(my_encoderrnn, (x, encode_hidden))</span><br>    encode_output, encode_hidden = my_encoderrnn(x, encode_hidden) <span class="hljs-comment"># 一次性送数据</span><br>    <span class="hljs-comment"># [1,6],[1,1,256] --&gt; [1,6,256],[1,1,256]</span><br><br>    <span class="hljs-comment"># 2 解码参数准备和解码</span><br>    <span class="hljs-comment"># 解码参数1 encode_output_c [10,256]</span><br>    encode_output_c = torch.zeros(MAX_LENGTH, my_encoderrnn.hidden_size, device=device)<br>    <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(x.shape[<span class="hljs-number">1</span>]):<br>        encode_output_c[idx] = encode_output[<span class="hljs-number">0</span>, idx]<br><br>    <span class="hljs-comment"># 解码参数2</span><br>    decode_hidden = encode_hidden<br><br>    <span class="hljs-comment"># 解码参数3</span><br>    input_y = torch.tensor([[SOS_token]], device=device)<br>                         <br>    myloss = <span class="hljs-number">0.0</span><br>    y_len = y.shape[<span class="hljs-number">1</span>]<br><br>    <span class="hljs-comment"># ### 张量可视化</span><br>    <span class="hljs-comment"># writer.add_graph(my_attndecoderrnn, (input_y, decode_hidden, encode_output_c))</span><br><br>    use_teacher_forcing = <span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> random.random() &lt; teacher_forcing_ratio <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>    <span class="hljs-keyword">if</span> use_teacher_forcing:<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(y_len):<br>            <span class="hljs-comment"># 数据形状数据形状 [1,1],[1,1,256],[10,256] ---&gt; [1,4345],[1,1,256],[1,10]</span><br>            output_y, decode_hidden, attn_weight = my_attndecoderrnn(input_y, decode_hidden, encode_output_c)<br>            target_y = y[<span class="hljs-number">0</span>][idx].view(<span class="hljs-number">1</span>)<br>            myloss = myloss + mycrossentropyloss(output_y, target_y)<br>            input_y = y[<span class="hljs-number">0</span>][idx].view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(y_len):<br>            <span class="hljs-comment"># 数据形状数据形状 [1,1],[1,1,256],[10,256] ---&gt; [1,4345],[1,1,256],[1,10]</span><br>            output_y, decode_hidden, attn_weight = my_attndecoderrnn(input_y, decode_hidden, encode_output_c)<br>            target_y = y[<span class="hljs-number">0</span>][idx].view(<span class="hljs-number">1</span>)<br>            myloss = myloss + mycrossentropyloss(output_y, target_y)<br><br>            topv, topi = output_y.topk(<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> topi.squeeze().item() == EOS_token:<br>                <span class="hljs-keyword">break</span><br>            input_y = topi.detach()<br><br>    <span class="hljs-comment"># 梯度清零</span><br>    myadam_encode.zero_grad()<br>    myadam_decode.zero_grad()<br><br>    <span class="hljs-comment"># 反向传播</span><br>    myloss.backward()<br><br>    <span class="hljs-comment"># 梯度更新</span><br>    myadam_encode.step()<br>    myadam_decode.step()<br><br>    <span class="hljs-comment"># 返回 损失列表myloss.item()/y_len</span><br>    <span class="hljs-keyword">return</span> myloss.item() / y_len<br><br></code></pre></td></tr></table></figure><h4 id="训练模型">训练模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Train_seq2seq</span>():<br>    <br>    <span class="hljs-comment"># 初始化SummaryWriter</span><br>    writer = SummaryWriter()<br><br>    <span class="hljs-comment"># 实例化 mypairsdataset对象  实例化 mydataloader</span><br>    mypairsdataset = MyPairsDataset(my_pairs)<br>    mydataloader = DataLoader(dataset=mypairsdataset, batch_size=<span class="hljs-number">1</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 实例化编码器 my_encoderrnn 实例化解码器 my_attndecoderrnn</span><br>    my_encoderrnn = EncoderRNN(<span class="hljs-number">2803</span>, <span class="hljs-number">256</span>).to(device)<br>    my_attndecoderrnn = AttnDecoderRNN(output_size=<span class="hljs-number">4345</span>, hidden_size=<span class="hljs-number">256</span>, dropout_p=<span class="hljs-number">0.1</span>, max_length=<span class="hljs-number">10</span>).to(device)<br><br><br><br>    <span class="hljs-comment"># 实例化编码器优化器 myadam_encode 实例化解码器优化器 myadam_decode</span><br>    myadam_encode = optim.Adam(my_encoderrnn.parameters(), lr=mylr)<br>    myadam_decode = optim.Adam(my_attndecoderrnn.parameters(), lr=mylr)<br><br>    <span class="hljs-comment"># 实例化损失函数 mycrossentropyloss = nn.NLLLoss()</span><br>    mycrossentropyloss = nn.NLLLoss()<br><br>    <span class="hljs-comment"># 定义模型训练的参数</span><br>    plot_loss_list = []<br><br>    <span class="hljs-comment"># 外层for循环 控制轮数 for epoch_idx in range(1, 1+epochs):</span><br>    <span class="hljs-keyword">for</span> epoch_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>+epochs):<br><br>        print_loss_total, plot_loss_total = <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span><br>        starttime = time.time()<br><br>        <span class="hljs-comment"># 内层for循环 控制迭代次数</span><br>        <span class="hljs-keyword">for</span> item, (x, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(mydataloader, start=<span class="hljs-number">1</span>):<br>            x=x.to(device)<br>            y=y.to(device)<br>            <br>            <span class="hljs-comment"># 调用内部训练函数</span><br>            myloss = Train_Iters(x, y, my_encoderrnn, my_attndecoderrnn, myadam_encode, myadam_decode, mycrossentropyloss)<br>            <span class="hljs-comment"># break</span><br>            print_loss_total += myloss<br>            plot_loss_total += myloss<br><br>            <span class="hljs-comment"># 计算打印屏幕间隔损失-每隔1000次</span><br>            <span class="hljs-keyword">if</span> item % print_interval_num ==<span class="hljs-number">0</span> :<br>                print_loss_avg = print_loss_total / print_interval_num<br>                <span class="hljs-comment"># 将总损失归0</span><br>                print_loss_total = <span class="hljs-number">0</span><br>                <span class="hljs-comment"># 打印日志，日志内容分别是：训练耗时，当前迭代步，当前进度百分比，当前平均损失</span><br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;轮次%d  损失%.6f 时间:%d&#x27;</span> % (epoch_idx, print_loss_avg, time.time() - starttime))<br><br>            <span class="hljs-comment"># 计算画图间隔损失-每隔100次</span><br>            <span class="hljs-keyword">if</span> item % plot_interval_num == <span class="hljs-number">0</span>:<br>                <span class="hljs-comment"># 通过总损失除以间隔得到平均损失</span><br>                plot_loss_avg = plot_loss_total / plot_interval_num<br>                <span class="hljs-comment"># 将平均损失添加plot_loss_list列表中</span><br>                plot_loss_list.append(plot_loss_avg)<br>                writer.add_scalar(<span class="hljs-string">&#x27;Train_loss&#x27;</span>, plot_loss_avg, epoch_idx * <span class="hljs-built_in">len</span>(mydataloader) + item)<br>                <span class="hljs-comment"># 总损失归0</span><br>                plot_loss_total = <span class="hljs-number">0</span><br>        <span class="hljs-comment"># 每个轮次保存模型</span><br>        torch.save(my_encoderrnn.state_dict(), <span class="hljs-string">&#x27;./my_encoderrnn_%d.pth&#x27;</span> % epoch_idx)<br>        torch.save(my_attndecoderrnn.state_dict(), <span class="hljs-string">&#x27;./my_attndecoderrnn_%d.pth&#x27;</span> % epoch_idx)<br><br>    <span class="hljs-comment"># 所有轮次训练完毕 画损失图</span><br>    <span class="hljs-comment"># plt.figure()</span><br>    <span class="hljs-comment"># plt.plot(plot_loss_list)</span><br>    <span class="hljs-comment"># plt.savefig(&#x27;./s2sq_loss.png&#x27;)</span><br>    <span class="hljs-comment"># plt.show()</span><br><br>    <span class="hljs-comment"># return plot_loss_list</span><br>Train_seq2seq()<br></code></pre></td></tr></table></figure><h3 id="模型评估">6 模型评估</h3><h4 id="构建模型评估函数">构建模型评估函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 模型评估代码与模型预测代码类似，需要注意使用with torch.no_grad()</span><br><span class="hljs-comment"># 模型预测时，第一个时间步使用SOS_token作为输入 后续时间步采用预测值作为输入，也就是自回归机制</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">Seq2Seq_Evaluate</span>(<span class="hljs-params">x, my_encoderrnn, my_attndecoderrnn</span>):<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># 1 编码：一次性的送数据</span><br>        encode_hidden = my_encoderrnn.inithidden()<br>        encode_output, encode_hidden = my_encoderrnn(x, encode_hidden)<br><br>        <span class="hljs-comment"># 2 解码参数准备</span><br>        <span class="hljs-comment"># 解码参数1 固定长度中间语义张量c</span><br>        encoder_outputs_c = torch.zeros(MAX_LENGTH, my_encoderrnn.hidden_size, device=device)<br>        x_len = x.shape[<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(x_len):<br>            encoder_outputs_c[idx] = encode_output[<span class="hljs-number">0</span>, idx]<br><br>        <span class="hljs-comment"># 解码参数2 最后1个隐藏层的输出 作为 解码器的第1个时间步隐藏层输入</span><br>        decode_hidden = encode_hidden<br><br>        <span class="hljs-comment"># 解码参数3 解码器第一个时间步起始符</span><br>        input_y = torch.tensor([[SOS_token]], device=device)<br><br>        <span class="hljs-comment"># 3 自回归方式解码</span><br>        <span class="hljs-comment"># 初始化预测的词汇列表</span><br>        decoded_words = []<br>        <span class="hljs-comment"># 初始化attention张量</span><br>        decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(MAX_LENGTH): <span class="hljs-comment"># note:MAX_LENGTH=10</span><br>            output_y, decode_hidden, attn_weights = my_attndecoderrnn(input_y, decode_hidden, encoder_outputs_c)<br>            <span class="hljs-comment"># 预测值作为为下一次时间步的输入值</span><br>            topv, topi = output_y.topk(<span class="hljs-number">1</span>)<br>            decoder_attentions[idx] = attn_weights<br><br>            <span class="hljs-comment"># 如果输出值是终止符，则循环停止</span><br>            <span class="hljs-keyword">if</span> topi.squeeze().item() == EOS_token:<br>                decoded_words.append(<span class="hljs-string">&#x27;&lt;EOS&gt;&#x27;</span>)<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">else</span>:<br>                decoded_words.append(french_index2word[topi.item()])<br><br>            <span class="hljs-comment"># 将本次预测的索引赋值给 input_y，进行下一个时间步预测</span><br>            input_y = topi.detach()<br><br>        <span class="hljs-comment"># 返回结果decoded_words， 注意力张量权重分布表(把没有用到的部分切掉)</span><br>        <span class="hljs-keyword">return</span> decoded_words, decoder_attentions[:idx + <span class="hljs-number">1</span>]<br><br></code></pre></td></tr></table></figure><h4 id="加载模型并评估">加载模型并评估</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 加载模型</span><br>PATH1 = <span class="hljs-string">&#x27;./gpumodel/my_encoderrnn.pth&#x27;</span><br>PATH2 = <span class="hljs-string">&#x27;./gpumodel/my_attndecoderrnn.pth&#x27;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dm_test_Seq2Seq_Evaluate</span>():<br>    <span class="hljs-comment"># 实例化dataset对象</span><br>    mypairsdataset = MyPairsDataset(my_pairs)<br>    <span class="hljs-comment"># 实例化dataloader</span><br>    mydataloader = DataLoader(dataset=mypairsdataset, batch_size=<span class="hljs-number">1</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 实例化模型</span><br>    input_size = english_word_n<br>    hidden_size = <span class="hljs-number">256</span>  <span class="hljs-comment"># 观察结果数据 可使用8</span><br>    my_encoderrnn = EncoderRNN(input_size, hidden_size)<br>    <span class="hljs-comment"># my_encoderrnn.load_state_dict(torch.load(PATH1))</span><br>    my_encoderrnn.load_state_dict(torch.load(PATH1, map_location=<span class="hljs-keyword">lambda</span> storage, loc: storage), <span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;my_encoderrnn模型结构---&gt;&#x27;</span>, my_encoderrnn)<br><br>    <span class="hljs-comment"># 实例化模型</span><br>    input_size = french_word_n<br>    hidden_size = <span class="hljs-number">256</span>  <span class="hljs-comment"># 观察结果数据 可使用8</span><br>    my_attndecoderrnn = AttnDecoderRNN(input_size, hidden_size)<br>    <span class="hljs-comment"># my_attndecoderrnn.load_state_dict(torch.load(PATH2))</span><br>    my_attndecoderrnn.load_state_dict(torch.load(PATH2, map_location=<span class="hljs-keyword">lambda</span> storage, loc: storage), <span class="hljs-literal">False</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;my_decoderrnn模型结构---&gt;&#x27;</span>, my_attndecoderrnn)<br><br>    my_samplepairs = [<br>      [<span class="hljs-string">&#x27;i m impressed with your french .&#x27;</span>, <span class="hljs-string">&#x27;je suis impressionne par votre francais .&#x27;</span>],<br>      [<span class="hljs-string">&#x27;i m more than a friend .&#x27;</span>, <span class="hljs-string">&#x27;je suis plus qu une amie .&#x27;</span>],<br>      [<span class="hljs-string">&#x27;she is beautiful like her mother .&#x27;</span>, <span class="hljs-string">&#x27;elle est belle comme sa mere .&#x27;</span>]<br>    ]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;my_samplepairs---&gt;&#x27;</span>, <span class="hljs-built_in">len</span>(my_samplepairs))<br><br>    <span class="hljs-keyword">for</span> index, pair <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(my_samplepairs):<br>        x = pair[<span class="hljs-number">0</span>]<br>        y = pair[<span class="hljs-number">1</span>]<br><br>        <span class="hljs-comment"># 样本x 文本数值化</span><br>        tmpx = [english_word2index[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> x.split(<span class="hljs-string">&#x27; &#x27;</span>)]<br>        tmpx.append(EOS_token)<br>        tensor_x = torch.tensor(tmpx, dtype=torch.long, device=device).view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 模型预测</span><br>        decoded_words, attentions = Seq2Seq_Evaluate(tensor_x, my_encoderrnn, my_attndecoderrnn)<br>        <span class="hljs-comment"># print(&#x27;decoded_words-&gt;&#x27;, decoded_words)</span><br>        output_sentence = <span class="hljs-string">&#x27; &#x27;</span>.join(decoded_words)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&gt;&#x27;</span>, x)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;=&#x27;</span>, y)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&lt;&#x27;</span>, output_sentence)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>NLP</tag>
      
      <tag>代码实现</tag>
      
      <tag>注意力机制</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer的代码实现-基于Pytorch</title>
    <link href="/Transformer%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-%E5%9F%BA%E4%BA%8EPytorch.html"/>
    <url>/Transformer%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-%E5%9F%BA%E4%BA%8EPytorch.html</url>
    
    <content type="html"><![CDATA[<p>本文是Transfomrer的Pytorch版本实现.实现的过程中非常考验<strong>维度控制</strong>的功底. 本文实现参考<ahref="https://wmathor.com/index.php/archives/1455/">Transformer 的PyTorch 实现</a>, 我对其在个别地方进行了修改,并对所有的数据<strong>全部</strong>加上了维度注释.</p><p>本文的代码已经放到了Colab上, 打开设置GPU就可以复现(需要科学上网).</p><figure><img src="https://colab.research.google.com/assets/colab-badge.svg"alt="右键我在COLAB中打开!" /><figcaption aria-hidden="true">右键我在COLAB中打开!</figcaption></figure><p><strong>右键我在COLAB中打开!</strong></p><p>如果你不能科学上网, 应该看不到<code>Open in Colab</code>的图标.</p><p>在开头需要说明的是:</p><ul><li>网上的所有流传的代码, 一般都会把<code>batch_size</code>放在第0维.因为我们基本上不对batch维做操作,放在最前面来防止影响后面总需要使用<code>transpose</code>移动.</li><li>如果对Transformer不熟悉, 最好熟悉后再来看这篇文章.</li><li>注意<code>view</code>和<code>transpose</code>拆维度时不要乱了.</li></ul><h2 id="preparing">Preparing</h2><p>按照惯例, 先导包:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data <span class="hljs-keyword">as</span> Data<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><p>因为后面需要用到一些关于Transformer的超参数,所以在开头就先全部定义出来:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">d_model = <span class="hljs-number">512</span> <span class="hljs-comment"># embedding size </span><br>max_len = <span class="hljs-number">1024</span> <span class="hljs-comment"># max length of sequence</span><br>d_ff = <span class="hljs-number">2048</span> <span class="hljs-comment"># feedforward nerual network  dimension</span><br>d_k = d_v = <span class="hljs-number">64</span> <span class="hljs-comment"># dimension of k(same as q) and v</span><br>n_layers = <span class="hljs-number">6</span> <span class="hljs-comment"># number of encoder and decoder layers</span><br>n_heads = <span class="hljs-number">8</span> <span class="hljs-comment"># number of heads in multihead attention</span><br>p_drop = <span class="hljs-number">0.1</span> <span class="hljs-comment"># propability of dropout</span><br></code></pre></td></tr></table></figure><p>如果你对Transformer足够熟悉, 看变量名和注释一定能看出来它们的含义,它们依次是:</p><ul><li>d_model: Embedding的大小.</li><li>max_len: 输入序列的最长大小.</li><li>d_ff: 前馈神经网络的隐藏层大小, 一般是d_model的四倍.</li><li>d_k, d_v: 自注意力中K和V的维度, Q的维度直接用K的维度代替,因为这二者必须始终相等.</li><li>n_layers: Encoder和Decoder的层数.</li><li>n_heads: 自注意力多头的头数.</li><li>p_drop: Dropout的概率.</li></ul><h2 id="mask">Mask</h2><p>Mask分为两种, 一种是因为在数据中使用了padding,不希望pad被加入到注意力中进行计算的Pad Mask for Attention,还有一种是保证Decoder自回归信息不泄露的Subsequent Mask for Decoder.</p><h3 id="pad-mask-for-attention">Pad Mask for Attention</h3><p>为了方便, 假设<code>&lt;PAD&gt;</code>在字典中的Index是0,遇到输入为0直接将其标为True.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_attn_pad_mask</span>(<span class="hljs-params">seq_q, seq_k</span>):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  Padding, because of unequal in source_len and target_len.</span><br><span class="hljs-string"></span><br><span class="hljs-string">  parameters:</span><br><span class="hljs-string">  seq_q: [batch, seq_len]</span><br><span class="hljs-string">  seq_k: [batch, seq_len]</span><br><span class="hljs-string"></span><br><span class="hljs-string">  return:</span><br><span class="hljs-string">  mask: [batch, len_q, len_k]</span><br><span class="hljs-string"></span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  batch, len_q = seq_q.size()<br>  batch, len_k = seq_k.size()<br>  <span class="hljs-comment"># we define index of PAD is 0, if tensor equals (zero) PAD tokens</span><br>  pad_attn_mask = seq_k.data.eq(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, 1, len_k]</span><br><br>  <span class="hljs-keyword">return</span> pad_attn_mask.expand(batch, len_q, len_k) <span class="hljs-comment"># [batch, len_q, len_k]</span><br></code></pre></td></tr></table></figure><p>在Encoder和Decoder中使用Mask的情况可能各有不同:</p><ul><li>在Encoder中使用Mask,是为了将<code>encoder_input</code>中没有内容而打上PAD的部分进行Mask,方便矩阵运算.</li><li>在Decoder中使用Mask,可能是在Decoder的自注意力对<code>decoder_input</code> 的PAD进行Mask,也有可能是对Encoder -Decoder自注意力时对<code>encoder_input</code>和<code>decoder_input</code>的PAD进行Mask.</li></ul><h3 id="subsequent-mask-for-decoder">Subsequent Mask for Decoder</h3><p>该Mask是为了防止Decoder的自回归信息泄露而生的Mask,直接生成一个上三角矩阵即可:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_attn_subsequent_mask</span>(<span class="hljs-params">seq</span>):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  Build attention mask matrix for decoder when it autoregressing.</span><br><span class="hljs-string"></span><br><span class="hljs-string">  parameters:</span><br><span class="hljs-string">  seq: [batch, target_len]</span><br><span class="hljs-string"></span><br><span class="hljs-string">  return:</span><br><span class="hljs-string">  subsequent_mask: [batch, target_len, target_len] </span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  attn_shape = [seq.size(<span class="hljs-number">0</span>), seq.size(<span class="hljs-number">1</span>), seq.size(<span class="hljs-number">1</span>)] <span class="hljs-comment"># [batch, target_len, target_len]</span><br>  subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, target_len, target_len] </span><br>  subsequent_mask = torch.from_numpy(subsequent_mask)<br><br>  <span class="hljs-keyword">return</span> subsequent_mask <span class="hljs-comment"># [batch, target_len, target_len] </span><br></code></pre></td></tr></table></figure><p>其中, 用到了生成上三角的函数<code>np.triu</code>, 其用法为:</p><p>python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">np.triu(np.ones([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), k=<span class="hljs-number">1</span>)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">array([[0., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 0., 1., 1.],</span><br><span class="hljs-string">       [0., 0., 0., 1.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>np.triu(np.ones([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), k=<span class="hljs-number">0</span>)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">array([[1., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 0., 1., 1.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>np.triu(np.ones([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), k=-<span class="hljs-number">1</span>)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">array([[1., 1., 1., 1.],</span><br><span class="hljs-string">       [1., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 1., 1., 1.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>其中<code>k</code>能控制上三角的大小, 越大则上三角范围越小.与之完全<strong>相反</strong>的函数是<code>np.tril</code>,能够生成下三角矩阵.</p><h2 id="positional-encoding">Positional Encoding</h2><p>在Transformer中, 使用的是绝对位置编码, 用于传输给模型Self -Attention所不能传输的位置信息, 编码使用正余弦公式实现:𝑃𝐸(𝑝𝑜𝑠,2𝑖)=sin⁡(𝑝𝑜𝑠/100002𝑖𝑑𝑚𝑜𝑑𝑒𝑙)𝑃𝐸(𝑝𝑜𝑠,2𝑖+1)=cos⁡(𝑝𝑜𝑠/100002𝑖𝑑𝑚𝑜𝑑𝑒𝑙)基于上述公式, 我们把它实现出来:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionalEncoding</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, dropout=<span class="hljs-number">.1</span>, max_len=<span class="hljs-number">1024</span></span>):<br>    <span class="hljs-built_in">super</span>(PositionalEncoding, self).__init__()<br>    self.dropout = nn.Dropout(p=p_drop)<br><br>    positional_encoding = torch.zeros(max_len, d_model) <span class="hljs-comment"># [max_len, d_model]</span><br>    position = torch.arange(<span class="hljs-number">0</span>, max_len).<span class="hljs-built_in">float</span>().unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># [max_len, 1]</span><br><br>    div_term = torch.exp(torch.arange(<span class="hljs-number">0</span>, d_model, <span class="hljs-number">2</span>).<span class="hljs-built_in">float</span>() * <br>                         (-torch.log(torch.Tensor([<span class="hljs-number">10000</span>])) / d_model)) <span class="hljs-comment"># [max_len / 2]</span><br><br>    positional_encoding[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>] = torch.sin(position * div_term) <span class="hljs-comment"># even</span><br>    positional_encoding[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>] = torch.cos(position * div_term) <span class="hljs-comment"># odd</span><br><br>    <span class="hljs-comment"># [max_len, d_model] -&gt; [1, max_len, d_model] -&gt; [max_len, 1, d_model]</span><br>    positional_encoding = positional_encoding.unsqueeze(<span class="hljs-number">0</span>).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># register pe to buffer and require no grads</span><br>    self.register_buffer(<span class="hljs-string">&#x27;pe&#x27;</span>, positional_encoding)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-comment"># x: [seq_len, batch, d_model]</span><br>    <span class="hljs-comment"># we can add positional encoding to x directly, and ignore other dimension</span><br>    x = x + self.pe[:x.size(<span class="hljs-number">0</span>), ...]<br><br>    <span class="hljs-keyword">return</span> self.dropout(x)<br></code></pre></td></tr></table></figure><p>实现1/100002𝑖𝑑𝑚𝑜𝑑𝑒𝑙 时既可以像我写出的那样使用幂指运算,也可以直接写出.</p><p><code>register_buffer</code>能够申请一个缓冲区中的<strong>常量</strong>,并且它不会被加入到计算图中, 也就不会参与反向传播.</p><p>更多关于<code>register</code>在<code>parameter</code>和<code>buffer</code>上的区别请见<ahref="https://zhuanlan.zhihu.com/p/89442276">Pytorch模型中的parameter与buffer</a>.</p><h2 id="feed-forward-neural-network">Feed Forward Neural Network</h2><p>在Transformer中,Encoder或者Decoder每个Block都需要用一个前馈神经网络来添加<strong>非线性</strong>:FFN(𝑥)=ReLU(𝑥𝑊1+𝑏1)𝑊2+𝑏2 注意, 这里它们都是有偏置的,而且这两个Linear可以用两个1×1 的卷积来实现:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeedForwardNetwork</span>(nn.Module):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  Using nn.Conv1d replace nn.Linear to implements FFN.</span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(FeedForwardNetwork, self).__init__()<br>    <span class="hljs-comment"># self.ff1 = nn.Linear(d_model, d_ff)</span><br>    <span class="hljs-comment"># self.ff2 = nn.Linear(d_ff, d_model)</span><br>    self.ff1 = nn.Conv1d(d_model, d_ff, <span class="hljs-number">1</span>)<br>    self.ff2 = nn.Conv1d(d_ff, d_model, <span class="hljs-number">1</span>)<br>    self.relu = nn.ReLU()<br><br>    self.dropout = nn.Dropout(p=p_drop)<br>    self.layer_norm = nn.LayerNorm(d_model)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-comment"># x: [batch, seq_len, d_model]</span><br>    residual = x<br>    x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, d_model, seq_len]</span><br>    x = self.ff1(x)<br>    x = self.relu(x)<br>    x = self.ff2(x)<br>    x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, seq_len, d_model]</span><br><br>    <span class="hljs-keyword">return</span> self.layer_norm(residual + x)<br></code></pre></td></tr></table></figure><p>作为一个子层, 不要忘记Transformer中提到的Residual Connection和LayerNorm.</p><p>我选择用两个卷积代替Linear. 在<code>nn.Conv1d</code>中,要求数据的规格为<code>[batch, x, ...]</code>,我们是要对<code>d_model</code> 上的数据进行卷积,所以还是需要<code>transpose</code>一下.</p><h2 id="multi---head-attention">Multi - Head Attention</h2><p>先说多头注意力, 因为多头注意力能够决定缩放点积注意力的输入大小.作为一个子层, 其中的Residual Connection和Layer Norm是必须的.</p><p>多头注意力是多个不同的头来获取不同的特征,类似于多个<strong>卷积核</strong>所达到的效果.在计算完后通过一个Linear调整大小:MultiHead(𝑄,𝐾,𝑉)=Concat(head1,head2,…,headℎ)𝑊𝑂wherehead𝑖=Attention(𝑄𝑊𝑖𝑄,𝐾𝑊𝑖𝐾,𝑉𝑊𝑖𝑉)多头注意力在Encoder和Decoder中的使用略有区别, 主要区别在于Mask的不同.我们前面已经实现了两种Mask函数, 在这里会用到.</p><p>多头注意力实际上不是通过弄出很多大小相同的矩阵然后相乘来实现的,只需要合并到一个矩阵进行计算:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiHeadAttention</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_heads=<span class="hljs-number">8</span></span>):<br>    <span class="hljs-built_in">super</span>(MultiHeadAttention, self).__init__()<br>    <span class="hljs-comment"># do not use more instance to implement multihead attention</span><br>    <span class="hljs-comment"># it can be complete in one matrix</span><br>    self.n_heads = n_heads<br><br>    <span class="hljs-comment"># we can&#x27;t use bias because there is no bias term in formular</span><br>    self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=<span class="hljs-literal">False</span>)<br>    self.W_K = nn.Linear(d_model, d_k * n_heads, bias=<span class="hljs-literal">False</span>)<br>    self.W_V = nn.Linear(d_model, d_v * n_heads, bias=<span class="hljs-literal">False</span>)<br>    self.fc = nn.Linear(d_v * n_heads, d_model, bias=<span class="hljs-literal">False</span>)<br>    self.layer_norm = nn.LayerNorm(d_model)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_Q, input_K, input_V, attn_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    To make sure multihead attention can be used both in encoder and decoder, </span><br><span class="hljs-string">    we use Q, K, V respectively.</span><br><span class="hljs-string">    input_Q: [batch, len_q, d_model]</span><br><span class="hljs-string">    input_K: [batch, len_k, d_model]</span><br><span class="hljs-string">    input_V: [batch, len_v, d_model]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    residual, batch = input_Q, input_Q.size(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># [batch, len_q, d_model] -- matmul W_Q --&gt; [batch, len_q, d_q * n_heads] -- view --&gt; </span><br>    <span class="hljs-comment"># [batch, len_q, n_heads, d_k,] -- transpose --&gt; [batch, n_heads, len_q, d_k]</span><br><br>    Q = self.W_Q(input_Q).view(batch, -<span class="hljs-number">1</span>, n_heads, d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, n_heads, len_q, d_k]</span><br>    K = self.W_K(input_K).view(batch, -<span class="hljs-number">1</span>, n_heads, d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, n_heads, len_k, d_k]</span><br>    V = self.W_V(input_V).view(batch, -<span class="hljs-number">1</span>, n_heads, d_v).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, n_heads, len_v, d_v]</span><br><br>    attn_mask = attn_mask.unsqueeze(<span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, n_heads, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, n_heads, seq_len, seq_len]</span><br><br>    <span class="hljs-comment"># prob: [batch, n_heads, len_q, d_v] attn: [batch, n_heads, len_q, len_k]</span><br>    prob, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)<br><br>    prob = prob.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous() <span class="hljs-comment"># [batch, len_q, n_heads, d_v]</span><br>    prob = prob.view(batch, -<span class="hljs-number">1</span>, n_heads * d_v).contiguous() <span class="hljs-comment"># [batch, len_q, n_heads * d_v]</span><br><br>    output = self.fc(prob) <span class="hljs-comment"># [batch, len_q, d_model]</span><br><br>    <span class="hljs-keyword">return</span> self.layer_norm(residual + output), attn<br></code></pre></td></tr></table></figure><p>提两个非常重要的点:</p><ol type="1"><li>在拆维度时不要破坏维度原来本身的意义.</li><li>虽然新版本已经有<code>reshape</code>函数可以用了, 但是仍然不要忘记,<code>transpose</code>后如果接<code>permute</code>或者<code>view</code>必须要加<code>contiguous</code>,这是<strong>数据真实存储连续与否</strong>的问题, 请参见<ahref="https://adaning.github.io/posts/42255.html">Pytorch之张量基础操作</a>中的<strong>维度变换</strong>部分.</li></ol><h2 id="scaled-dotproduct-attention">Scaled DotProduct Attention</h2><p>Tranformer中非常重要的概念, 缩放点积注意力, 公式如下:Attention(𝑄,𝐾,𝑉)=softmax(𝑄𝐾𝑇𝑑𝑘)𝑉 实现起来非常简单, 只需要把Q,K两个矩阵一乘, 然后再缩放, 过一次Softmax, 再和V乘下:</p><p>python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ScaledDotProductAttention</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(ScaledDotProductAttention, self).__init__()<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, Q, K, V, attn_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Q: [batch, n_heads, len_q, d_k]</span><br><span class="hljs-string">    K: [batch, n_heads, len_k, d_k]</span><br><span class="hljs-string">    V: [batch, n_heads, len_v, d_v]</span><br><span class="hljs-string">    attn_mask: [batch, n_heads, seq_len, seq_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    scores = torch.matmul(Q, K.transpose(-<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>)) / np.sqrt(d_k) <span class="hljs-comment"># [batch, n_heads, len_q, len_k]</span><br>    scores.masked_fill_(attn_mask, -<span class="hljs-number">1e9</span>)<br><br>    attn = nn.Softmax(dim=-<span class="hljs-number">1</span>)(scores) <span class="hljs-comment"># [batch, n_heads, len_q, len_k]</span><br>    prob = torch.matmul(attn, V) <span class="hljs-comment"># [batch, n_heads, len_q, d_v]</span><br>    <span class="hljs-keyword">return</span> prob, attn<br></code></pre></td></tr></table></figure><p><code>masked_fill_</code>能把传进来的Mask为True的地方全都填充上某个值,这里需要用一个很大的负数来保证𝑒𝑥→0, 使得其在Softmax 中可以被忽略.</p><h2 id="encoder-and-decoder">Encoder and Decoder</h2><h3 id="encoder">Encoder</h3><p>先写出Encoder的每个Layer, 由多头注意力和FFN组成:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderLayer</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(EncoderLayer, self).__init__()<br>    self.encoder_self_attn = MultiHeadAttention()<br>    self.ffn = FeedForwardNetwork()<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_input, encoder_pad_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    encoder_input: [batch, source_len, d_model]</span><br><span class="hljs-string">    encoder_pad_mask: [batch, n_heads, source_len, source_len]</span><br><span class="hljs-string"></span><br><span class="hljs-string">    encoder_output: [batch, source_len, d_model]</span><br><span class="hljs-string">    attn: [batch, n_heads, source_len, source_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    encoder_output, attn = self.encoder_self_attn(encoder_input, encoder_input, encoder_input, encoder_pad_mask)<br>    encoder_output = self.ffn(encoder_output) <span class="hljs-comment"># [batch, source_len, d_model]</span><br><br>    <span class="hljs-keyword">return</span> encoder_output, attn<br></code></pre></td></tr></table></figure><p>对于给定的<code>encoder_input</code>和<code>encoder_pad_pask</code>,Encoder应该能够完成整个Block(Layer)的计算流程. 然后实现整个Encoder:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(Encoder, self).__init__()<br>    self.source_embedding = nn.Embedding(source_vocab_size, d_model)<br>    self.positional_embedding = PositionalEncoding(d_model)<br>    self.layers = nn.ModuleList([EncoderLayer() <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers)])<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_input</span>):<br>    <span class="hljs-comment"># encoder_input: [batch, source_len]</span><br>    encoder_output = self.source_embedding(encoder_input) <span class="hljs-comment"># [batch, source_len, d_model]</span><br>    encoder_output = self.positional_embedding(encoder_output.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, source_len, d_model]</span><br><br>    encoder_self_attn_mask = get_attn_pad_mask(encoder_input, encoder_input) <span class="hljs-comment"># [batch, source_len, source_len]</span><br>    encoder_self_attns = <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>      <span class="hljs-comment"># encoder_output: [batch, source_len, d_model]</span><br>      <span class="hljs-comment"># encoder_self_attn: [batch, n_heads, source_len, source_len]</span><br>      encoder_output, encoder_self_attn = layer(encoder_output, encoder_self_attn_mask)<br>      encoder_self_attns.append(encoder_self_attn)<br><br>    <span class="hljs-keyword">return</span> encoder_output, encoder_self_attns<br></code></pre></td></tr></table></figure><p>对于整个Encoder, 直接将Token的Index传入Embedding中, 再添入位置编码,之后就经过多层Transformer Encoder. 在传入Block前,先需要计算Padding的Mask, 再将上层的输出作为下层输入依次迭代.</p><h3 id="decoder">Decoder</h3><p>其实实现了Encoder, Decoder的实现部分都是对应的.先实现Decoder的Block:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DecoderLayer</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(DecoderLayer, self).__init__()<br>    self.decoder_self_attn = MultiHeadAttention()<br>    self.encoder_decoder_attn = MultiHeadAttention()<br>    self.ffn = FeedForwardNetwork()<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, decoder_input, encoder_output, decoder_self_mask, decoder_encoder_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    decoder_input: [batch, target_len, d_mdoel]</span><br><span class="hljs-string">    encoder_output: [batch, source_len, d_model]</span><br><span class="hljs-string">    decoder_self_mask: [batch, target_len, target_len]</span><br><span class="hljs-string">    decoder_encoder_mask: [batch, target_len, source_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># masked mutlihead attention</span><br>    <span class="hljs-comment"># Q, K, V all from decoder it self</span><br>    <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>    <span class="hljs-comment"># decoder_self_attn: [batch, n_heads, target_len, target_len]</span><br>    decoder_output, decoder_self_attn = self.decoder_self_attn(decoder_input, decoder_input, decoder_input, decoder_self_mask)<br><br>    <span class="hljs-comment"># Q from decoder, K, V from encoder</span><br>    <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>    <span class="hljs-comment"># decoder_encoder_attn: [batch, n_heads, target_len, source_len]</span><br>    decoder_output, decoder_encoder_attn = self.encoder_decoder_attn(decoder_output, encoder_output, encoder_output, decoder_encoder_mask)<br>    decoder_output = self.ffn(decoder_output) <span class="hljs-comment"># [batch, target_len, d_model]</span><br><br>    <span class="hljs-keyword">return</span> decoder_output, decoder_self_attn, decoder_encoder_attn<br></code></pre></td></tr></table></figure><p>与Encoder相对应, 只不过因为多了一个Encoder - Decoder自注意力,所以需要额外计算一个Encoder - Decoder的Mask. 然后写出整个Decoder:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(Decoder, self).__init__()<br>    self.target_embedding = nn.Embedding(target_vocab_size, d_model)<br>    self.positional_embedding = PositionalEncoding(d_model)<br>    self.layers = nn.ModuleList([DecoderLayer() <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers)])<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, decoder_input, encoder_input, encoder_output</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    decoder_input: [batch, target_len]</span><br><span class="hljs-string">    encoder_input: [batch, source_len]</span><br><span class="hljs-string">    encoder_output: [batch, source_len, d_model]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    decoder_output = self.target_embedding(decoder_input) <span class="hljs-comment"># [batch, target_len, d_model]</span><br>    decoder_output = self.positional_embedding(decoder_output.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, target_len, d_model]</span><br>    decoder_self_attn_mask = get_attn_pad_mask(decoder_input, decoder_input) <span class="hljs-comment"># [batch, target_len, target_len]</span><br>    decoder_subsequent_mask = get_attn_subsequent_mask(decoder_input) <span class="hljs-comment"># [batch, target_len, target_len]</span><br><br>    decoder_encoder_attn_mask = get_attn_pad_mask(decoder_input, encoder_input) <span class="hljs-comment"># [batch, target_len, source_len]</span><br><br>    decoder_self_mask = torch.gt(decoder_self_attn_mask + decoder_subsequent_mask, <span class="hljs-number">0</span>)<br>    decoder_self_attns, decoder_encoder_attns = [], []<br><br>    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>      <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>      <span class="hljs-comment"># decoder_self_attn: [batch, n_heads, target_len, target_len]</span><br>      <span class="hljs-comment"># decoder_encoder_attn: [batch, n_heads, target_len, source_len]</span><br>      decoder_output, decoder_self_attn, decoder_encoder_attn = layer(decoder_output, encoder_output, decoder_self_mask, decoder_encoder_attn_mask)<br>      decoder_self_attns.append(decoder_self_attn)<br>      decoder_encoder_attns.append(decoder_encoder_attn)<br><br>    <span class="hljs-keyword">return</span> decoder_output, decoder_self_attns, decoder_encoder_attns<br></code></pre></td></tr></table></figure><p>和Encoder相对应, 但Decoder和Encoder使用了两个不同的Embedding.对于Mask, 可以把自回归Mask和PaddingMask用<code>torch.gt</code>整合成一个Mask, 送入其中.</p><h2 id="transformer">Transformer</h2><p>终于到了这一步, 虽然后面还有一些小小的工作,但现在终于能看到Transformer的<strong>全貌</strong>了:</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/transformer.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>里面有一个Encoder, 一个Decoder,在Decoder端还需要加上投影层来分类:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transformer</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(Transformer, self).__init__()<br><br>    self.encoder = Encoder()<br>    self.decoder = Decoder()<br>    self.projection = nn.Linear(d_model, target_vocab_size, bias=<span class="hljs-literal">False</span>)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_input, decoder_input</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    encoder_input: [batch, source_len]</span><br><span class="hljs-string">    decoder_input: [batch, target_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># encoder_output: [batch, source_len, d_model]</span><br>    <span class="hljs-comment"># encoder_attns: [n_layers, batch, n_heads, source_len, source_len]</span><br>    encoder_output, encoder_attns = self.encoder(encoder_input)<br>    <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>    <span class="hljs-comment"># decoder_self_attns: [n_layers, batch, n_heads, target_len, target_len]</span><br>    <span class="hljs-comment"># decoder_encoder_attns: [n_layers, batch, n_heads, target_len, source_len]</span><br>    decoder_output, decoder_self_attns, decoder_encoder_attns = self.decoder(decoder_input, encoder_input, encoder_output)<br>    decoder_logits = self.projection(decoder_output) <span class="hljs-comment"># [batch, target_len, target_vocab_size]</span><br><br>    <span class="hljs-comment"># decoder_logits: [batch * target_len, target_vocab_size]</span><br>    <span class="hljs-keyword">return</span> decoder_logits.view(-<span class="hljs-number">1</span>, decoder_logits.size(-<span class="hljs-number">1</span>)), encoder_attns, decoder_self_attns, decoder_encoder_attns<br></code></pre></td></tr></table></figure><p>最后对logits的处理是<code>view</code>成了<code>[batch * target_len, target_vocab_size]</code>,前面的大小并不影响我们一会用交叉熵计算损失.</p><h2 id="input-data">Input Data</h2><p>输入数据没什么好说的,为了方便直接采用了硬编码的方式构造<code>word2index</code>,这样我们的输入序列都被转换为了Token的index输入到Embedding层中,自动转化为嵌入在低维空间的稠密向量:</p><p>Decoder的输入构造过程采用了<strong>Teaching Forcing</strong>,保证了训练过程是可以保持<strong>并行</strong>的.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">sentences = [<br>        <span class="hljs-comment"># enc_input           dec_input         dec_output</span><br>        [<span class="hljs-string">&#x27;ich mochte ein bier P&#x27;</span>, <span class="hljs-string">&#x27;S i want a beer .&#x27;</span>, <span class="hljs-string">&#x27;i want a beer . E&#x27;</span>],<br>        [<span class="hljs-string">&#x27;ich mochte ein cola P&#x27;</span>, <span class="hljs-string">&#x27;S i want a coke .&#x27;</span>, <span class="hljs-string">&#x27;i want a coke . E&#x27;</span>]<br>]<br><br><span class="hljs-comment"># Padding Should be Zero</span><br>source_vocab = &#123;<span class="hljs-string">&#x27;P&#x27;</span> : <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;ich&#x27;</span> : <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;mochte&#x27;</span> : <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;ein&#x27;</span> : <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;bier&#x27;</span> : <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;cola&#x27;</span> : <span class="hljs-number">5</span>&#125;<br>source_vocab_size = <span class="hljs-built_in">len</span>(source_vocab)<br><br>target_vocab = &#123;<span class="hljs-string">&#x27;P&#x27;</span> : <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;i&#x27;</span> : <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;want&#x27;</span> : <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;a&#x27;</span> : <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;beer&#x27;</span> : <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;coke&#x27;</span> : <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;S&#x27;</span> : <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;E&#x27;</span> : <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;.&#x27;</span> : <span class="hljs-number">8</span>&#125;<br>idx2word = &#123;i: w <span class="hljs-keyword">for</span> i, w <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(target_vocab)&#125;<br>target_vocab_size = <span class="hljs-built_in">len</span>(target_vocab)<br>source_len = <span class="hljs-number">5</span> <span class="hljs-comment"># max length of input sequence</span><br>target_len = <span class="hljs-number">6</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_data</span>(<span class="hljs-params">sentences</span>):<br>  encoder_inputs, decoder_inputs, decoder_outputs = [], [], []<br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sentences)):<br>    encoder_input = [source_vocab[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentences[i][<span class="hljs-number">0</span>].split()]<br>    decoder_input = [target_vocab[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentences[i][<span class="hljs-number">1</span>].split()]<br>    decoder_output = [target_vocab[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentences[i][<span class="hljs-number">2</span>].split()]<br>    encoder_inputs.append(encoder_input)<br>    decoder_inputs.append(decoder_input)<br>    decoder_outputs.append(decoder_output)<br><br>  <span class="hljs-keyword">return</span> torch.LongTensor(encoder_inputs), torch.LongTensor(decoder_inputs), torch.LongTensor(decoder_outputs)<br></code></pre></td></tr></table></figure><p>数据量非常的少, 所以等会的训练会根本不充分.</p><h2 id="dataset">DataSet</h2><p>制作一个Seq2Seq的数据集, 只需要按照Index返回Encoder的输出,Decoder的输入, Decoder的输出(label)就好:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2SeqDataset</span>(Data.Dataset):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder_input, decoder_input, decoder_output</span>):<br>    <span class="hljs-built_in">super</span>(Seq2SeqDataset, self).__init__()<br>    self.encoder_input = encoder_input<br>    self.decoder_input = decoder_input<br>    self.decoder_output = decoder_output<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-keyword">return</span> self.encoder_input.shape[<span class="hljs-number">0</span>]<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>    <span class="hljs-keyword">return</span> self.encoder_input[idx], self.decoder_input[idx], self.decoder_output[idx]<br></code></pre></td></tr></table></figure><h2 id="training">Training</h2><p>对训练所需的所有东西进行定义:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">64</span><br>epochs = <span class="hljs-number">64</span><br>lr = <span class="hljs-number">1e-3</span><br><br>device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)<br>model = Transformer().to(device)<br>criterion = nn.CrossEntropyLoss(ignore_index=<span class="hljs-number">0</span>)<br>optimizer = optim.Adam(model.parameters(), lr=lr)<br>encoder_inputs, decoder_inputs, decoder_outputs = make_data(sentences)<br>dataset = Seq2SeqDataset(encoder_inputs, decoder_inputs, decoder_outputs)<br>data_loader = Data.DataLoader(dataset, <span class="hljs-number">2</span>, <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>这里有个<code>criterion = nn.CrossEntropyLoss(ignore_index=0)</code>,其中<code>ignore_index=0</code>指的是PAD在计算交叉熵时不应该被包括进去(前面提到过PAD所对应的Index是0).</p><p>我们从定义好的数据集中取出数据到<code>device</code>,然后用torch三件套:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  encoder_input: [batch, source_len]</span><br><span class="hljs-string">  decoder_input: [batch, target_len]</span><br><span class="hljs-string">  decoder_ouput: [batch, target_len]</span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  <span class="hljs-keyword">for</span> encoder_input, decoder_input, decoder_output <span class="hljs-keyword">in</span> data_loader:<br>    encoder_input = encoder_input.to(device)<br>    decoder_input = decoder_input.to(device)<br>    decoder_output = decoder_output.to(device)<br><br>    output, encoder_attns, decoder_attns, decoder_encoder_attns = model(encoder_input, decoder_input)<br>    loss = criterion(output, decoder_output.view(-<span class="hljs-number">1</span>))<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch:&#x27;</span>, <span class="hljs-string">&#x27;%04d&#x27;</span> % (epoch + <span class="hljs-number">1</span>), <span class="hljs-string">&#x27;loss =&#x27;</span>, <span class="hljs-string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(loss))<br><br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br></code></pre></td></tr></table></figure><h2 id="attention-visualization">Attention Visualization</h2><p>这回有了自己造的Transformer, 经过了<strong>根本不完全的训练:)</strong>, 我们可以把它的Attention矩阵画出来看看:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">batch 1:</span><br><span class="hljs-string">[[1, 2, 3, 5, 0],</span><br><span class="hljs-string">[1, 2, 3, 4, 0]]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>temp_batch = <span class="hljs-number">0</span><br>n_layers = <span class="hljs-number">4</span><br>plt.figure(figsize=(n_heads * <span class="hljs-number">3</span>, n_layers * <span class="hljs-number">3</span> + <span class="hljs-number">3</span>))<br><span class="hljs-comment"># encoder_attns: [n_layers, batch, n_heads, source_len, source_len]</span><br>i = <span class="hljs-number">0</span><br>tokens = sentences[temp_batch][<span class="hljs-number">0</span>].split()<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers):<br>  <span class="hljs-keyword">for</span> head <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_heads):<br>    i += <span class="hljs-number">1</span><br>    plt.subplot(n_layers, n_heads, i)<br><br>    plt.title(<span class="hljs-string">&#x27;Layer:&#123;&#125;, Head:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(layer+<span class="hljs-number">1</span>, head+<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">if</span> i % n_heads == <span class="hljs-number">0</span>:<br>      cbar=<span class="hljs-literal">True</span><br>    <span class="hljs-keyword">else</span>:<br>      cbar=<span class="hljs-literal">False</span><br>    sns.heatmap(encoder_attns[layer][temp_batch][head].detach().numpy(), cmap=<span class="hljs-string">&#x27;YlGnBu&#x27;</span>, <br>            xticklabels=tokens, yticklabels=tokens, cbar=cbar, vmin=<span class="hljs-number">0</span>, vmax=<span class="hljs-number">1</span>);<br>    plt.xticks([])<br>    plt.yticks([])<br></code></pre></td></tr></table></figure><p>最后两行<code>plt.xticks</code>和<code>plt.yticks</code>纯粹是为了<strong>方便注释掉</strong>,才又写在了外面.</p><p><strong>不要对结果太在意</strong>,因为<strong>训练是根本不完整的</strong>, 数据也才只有两条.我只是想画出来看看每个头都大致学到了什么:</p><figure><imgsrc="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pytorchtransformer1.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>最右侧是Padding, 这一列的权重都被当做是0来计算.在浅一些的层确实学到了不同Token对不同部分的权重.再深一些的层基本都没有得到训练, 因为数据实在太少了.</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>transformer</tag>
      
      <tag>代码实现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在CentOS上安装Neo4j 5x</title>
    <link href="/%E5%9C%A8CentOS%E4%B8%8A%E5%AE%89%E8%A3%85Neo4j%205.21.2%E7%9A%84%E6%AD%A5%E9%AA%A4.html"/>
    <url>/%E5%9C%A8CentOS%E4%B8%8A%E5%AE%89%E8%A3%85Neo4j%205.21.2%E7%9A%84%E6%AD%A5%E9%AA%A4.html</url>
    
    <content type="html"><![CDATA[<p>本文档将逐步指导您在CentOS操作系统上安装Neo4j 5.21.2。</p><h3 id="前提条件">前提条件</h3><p>在开始安装之前，请确保您有以下条件： - 一台运行CentOS的机器 -具有<code>sudo</code>权限的用户 -已经安装了<code>curl</code>和<code>wget</code>工具</p><h3 id="步骤1更新系统">步骤1：更新系统</h3><p>首先，更新您的CentOS系统，以确保所有软件包都是最新的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo yum update -y<br></code></pre></td></tr></table></figure><h3 id="步骤2安装openjdk-11">步骤2：安装OpenJDK 11</h3><p>Neo4j 5.21.2需要Java 11环境。我们将安装OpenJDK 11。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo yum install -y java-11-openjdk-devel<br></code></pre></td></tr></table></figure><h3 id="步骤3添加neo4j-yum存储库">步骤3：添加Neo4j Yum存储库</h3><p>我们需要将Neo4j的Yum存储库添加到我们的系统中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo rpm --import https://debian.neo4j.com/neotechnology.gpg.key<br>sudo sh -c <span class="hljs-string">&#x27;echo -e &quot;[neo4j]\nname=Neo4j RPM Repository\nbaseurl=https://yum.neo4j.com/stable\nenabled=1\ngpgcheck=1&quot; &gt; /etc/yum.repos.d/neo4j.repo&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="步骤4安装neo4j">步骤4：安装Neo4j</h3><p>现在我们可以安装Neo4j 5.21.2。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo yum install -y neo4j-5.21.2<br></code></pre></td></tr></table></figure><h3 id="步骤5启动neo4j服务">步骤5：启动Neo4j服务</h3><p>安装完成后，启动Neo4j服务并设置为开机启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl start neo4j<br>sudo systemctl <span class="hljs-built_in">enable</span> neo4j<br></code></pre></td></tr></table></figure><h3 id="步骤6配置防火墙">步骤6：配置防火墙</h3><p>默认情况下，Neo4j使用7474端口。我们需要确保防火墙允许该端口的流量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo firewall-cmd --permanent --zone=public --add-port=7474/tcp<br>sudo firewall-cmd --reload<br></code></pre></td></tr></table></figure><h3 id="步骤7访问neo4j-web界面">步骤7：访问Neo4j Web界面</h3><p>打开浏览器，访问以下URL：</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">http:</span><span class="hljs-comment">//&lt;YOUR_SERVER_IP&gt;:7474</span><br></code></pre></td></tr></table></figure><p>您将看到Neo4j的登录界面。初次登录时，默认的用户名和密码均为<code>neo4j</code>。系统会提示您更改默认密码。</p><h3 id="步骤8验证安装">步骤8：验证安装</h3><p>为了确保Neo4j安装成功并正在运行，您可以检查Neo4j服务的状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl status neo4j<br></code></pre></td></tr></table></figure><p>如果一切正常，您将看到服务正在运行的状态。</p><h3 id="结论">结论</h3><p>通过以上步骤，您已经成功在CentOS上安装并配置了Neo4j5.21.2。您现在可以开始使用Neo4j构建和查询图数据库。</p><h2 id="数据库备份与替换">## 数据库备份与替换</h2><ol type="1"><li><p>关闭neo4j服务: <figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">sudo systemctl stop neo4j<br></code></pre></td></tr></table></figure></p></li><li><p>备份数据</p></li></ol><p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">cp</span> /var/lib/neo4j/data /var/lib/neo4j/data_bak<br></code></pre></td></tr></table></figure></p><ol start="2" type="1"><li>替换数据目录:</li></ol><p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">rm</span> -rf /var/lib/neo4j/data<br>sudo unzip /usr/my_python/data.zip -d /var/lib/neo4j/<br>sudo <span class="hljs-built_in">chown</span> -R neo4j:neo4j /var/lib/neo4j/data<br></code></pre></td></tr></table></figure></p><ol start="3" type="1"><li><p>重启neo4j服务: <figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">sudo systemctl <span class="hljs-literal">start</span> neo4j<br></code></pre></td></tr></table></figure></p></li><li><p>检查服务状态: <figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fortran">sudo systemctl <span class="hljs-keyword">status</span> neo4j<br></code></pre></td></tr></table></figure></p></li></ol><p>您需要我解释这些命令的作用吗?或者您对某个步骤有任何疑问吗?</p><hr /><p>此文档旨在帮助用户在CentOS系统上安装Neo4j5.21.2，如有任何问题，请参考官方文档或联系技术支持。</p>]]></content>
    
    
    <categories>
      
      <category>知识图谱</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
      <tag>技术整理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>神经网络简明教程</title>
    <link href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA%E7%9A%84%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.html"/>
    <url>/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA%E7%9A%84%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.html</url>
    
    <content type="html"><![CDATA[<p>本篇文章试图使用最简洁易懂的文字对一个典型神经网络做一个较为完整的介绍。力求读者在读完本篇文章后对神经网络能有一个清晰且全面的认识。</p><h2 id="任务描述">任务描述</h2><p>如下图，我们已知四个数据点(1,1)(-1,1)(-1,-1)(1,-1)，这四个点分别对应I~IV象限，如果这时候给我们一个新的坐标点（比如(2,2)），那么它应该属于哪个象限呢？（没错，当然是第I象限，但我们的任务是要让机器知道）</p><p>“分类”是神经网络的一大应用，我们使用神经网络完成这个分类任务。</p><figure><img src="/images/深度学习/v2-98d50ca5e3a5c1a35eec112813b696f5.jpg"alt="分类任务" /><figcaption aria-hidden="true">分类任务</figcaption></figure><h2 id="两层神经网络">两层神经网络</h2><p>这里我们构建一个两层神经网络，理论上两层神经网络已经可以拟合任意函数。这个神经网络的结构如下图：</p><figure><img src="/images/深度学习/v2-3ecd2eacd744c89bf89335aad73851b3.jpg"alt="图1.两层神经网络的一种典型结构" /><figcaptionaria-hidden="true">图1.两层神经网络的一种典型结构</figcaption></figure><p>是不是觉得有点复杂，没关系，我们一步步看，其实很容易理解。</p><h2id="简化的两层神经网络分析"><strong>1.简化的两层神经网络分析</strong></h2><p>首先去掉图1中一些难懂的东西，如下图（请仔细看一下图中的标注）：</p><figure><img src="/images/深度学习/v2-370e530f126a785c9c11b550a126499b.jpg"alt="图2.简化过后的两层神经网络" /><figcaption aria-hidden="true">图2.简化过后的两层神经网络</figcaption></figure><p><strong>1.1.输入层</strong></p><p>在我们的例子中，输入层是坐标值，例如（1,1），这是一个包含两个元素的数组，也可以看作是一个1<em>2的矩阵。输入层的元素维度与输入量的特征息息相关，如果输入的是一张32</em>32像素的灰度图像，那么输入层的维度就是32*32。</p><p><strong>1.2.从输入层到隐藏层</strong></p><p>连接输入层和隐藏层的是W1和b1。由X计算得到H十分简单，就是矩阵运算：</p><figure><imgsrc="https://pic2.zhimg.com/80/v2-b31ecd1eea01a5e52968075778cb9699_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>如果你学过线性代数，对这个式子一定不陌生。如上图中所示，在设定隐藏层为50维（也可以理解成50个神经元）之后，矩阵H的大小为（1*50）的矩阵。</p><p><strong>1.3.从隐藏层到输出层</strong></p><p>连接隐藏层和输出层的是W2和b2。同样是通过矩阵运算进行的：</p><figure><imgsrc="https://pic4.zhimg.com/80/v2-0c8c9f5ea2376623cb31ba74e9256627_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>1.4.分析</strong></p><p>通过上述两个线性方程的计算，我们就能得到最终的输出Y了，但是如果你还对线性代数的计算有印象的话，应该会知道：*<strong>一系列线性方程的运算最终都可以用一个线性方程表示*</strong>。也就是说，上述两个式子联立后可以用一个线性方程表达。对于两次神经网络是这样，就算网络深度加到100层，也依然是这样。这样的话神经网络就失去了意义。</p><p>所以这里要对网络注入灵魂：<strong>激活层</strong>。</p><h2 id="激活层">2.激活层</h2><p>简而言之，激活层是为矩阵运算的结果添加非线性的。常用的激活函数有三种，分别是阶跃函数、Sigmoid和ReLU。不要被奇怪的函数名吓到，其实它们的形式都很简单，如下图：</p><figure><img src="/images/深度学习/v2-d23194bd4a68209b7cfcf994899d2381.jpg"alt="v2-d23194bd4a68209b7cfcf994899d2381" /><figcaptionaria-hidden="true">v2-d23194bd4a68209b7cfcf994899d2381</figcaption></figure><p>图3.三种常用的激活函数</p><p>阶跃函数：当输入小于等于0时，输出0；当输入大于0时，输出1。</p><p>Sigmoid：当输入趋近于正无穷/负无穷时，输出无限接近于1/0。</p><p>ReLU：当输入小于0时，输出0；当输入大于0时，输出等于输入。</p><p>其中，阶跃函数输出值是跳变的，且只有二值，较少使用；Sigmoid函数在当x的绝对值较大时，曲线的斜率变化很小（梯度消失），并且计算较复杂；ReLU是当前较为常用的激活函数。</p><p>激活函数具体是怎么计算的呢？</p><p>假如经过公式<strong>H=X*W1+b1</strong>计算得到的H值为：(1,-2,3,-4,7...)，那么经过阶跃函数激活层后就会变为(1,0,1,0,1...)，经过ReLU激活层之后会变为(1,0,3,0,7...)。</p><p>需要注意的是，每个隐藏层计算（矩阵线性运算）之后，都需要加一层激活层，要不然该层线性计算是没有意义的。</p><p>此时的神经网络变成了如下图所示的形式：</p><figure><img src="/images/深度学习/v2-c9b81dba190eb6768f419147d1b86c0d.jpg"alt="v2-c9b81dba190eb6768f419147d1b86c0d" /><figcaptionaria-hidden="true">v2-c9b81dba190eb6768f419147d1b86c0d</figcaption></figure><p>图4.加上激活层的两层神经网络</p><p>神经网络是分为“训练”和“使用”两个步骤的。如果是在“使用”的步骤，图4就已经完成整个过程了，在求得的Y（大小为1*4）矩阵中，数值最大的就代表着当前分类。</p><p>但是对于用于“训练”的网络，图4还远远不够。起码当前的输出Y，还不够“漂亮”。</p><h2 id="输出的正规化"><strong>3.输出的正规化</strong></h2><p>在图4中，输出Y的值可能会是(3,1,0.1,0.5)这样的矩阵，诚然我们可以找到里边的最大值“3”，从而找到对应的分类为I，但是这并不直观。我们想让最终的输出为<strong>概率</strong>，也就是说可以生成像(90%,5%,2%,3%)这样的结果，这样做不仅可以找到最大概率的分类，而且可以知道各个分类计算的概率值。</p><p>具体是怎么计算的呢？</p><p>计算公式如下：</p><figure><imgsrc="https://pic4.zhimg.com/80/v2-3ad93ae576918ff385485dab6a2e6b87_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>简单来说分三步进行：（1）以e为底对所有元素求指数幂；（2）将所有指数幂求和；（3）分别将这些指数幂与该和做商。</p><p>这样求出的结果中，所有元素的和一定为1，而每个元素可以代表概率值。</p><p>我们将使用这个计算公式做输出结果正规化处理的层叫做“Softmax”层。此时的神经网络将变成如下图所示：</p><figure><img src="/images/深度学习/v2-3ecd2eacd744c89bf89335aad73851b3.jpg"alt="输出正规化之后的神经网络" /><figcaption aria-hidden="true">输出正规化之后的神经网络</figcaption></figure><h2 id="如何衡量输出的好坏">4.如何衡量输出的好坏</h2><p>通过Softmax层之后，我们得到了I，II，III和IV这四个类别分别对应的概率，但是要注意，这是神经网络计算得到的概率值结果，而非真实的情况。</p><p>比如，Softmax输出的结果是(90%,5%,3%,2%)，真实的结果是(100%,0,0,0)。虽然输出的结果可以正确分类，但是与真实结果之间是有差距的，一个优秀的网络对结果的预测要无限接近于100%，为此，我们需要将Softmax输出结果的好坏程度做一个“量化”。</p><p>一种直观的解决方法，是用1减去Softmax输出的概率，比如1-90%=0.1。不过更为常用且巧妙的方法是，求<strong>对数的负数</strong>。</p><p>还是用90%举例，对数的负数就是：-log0.9=0.046</p><p>可以想见，概率越接近100%，该计算结果值越接近于0，说明结果越准确，该输出叫做“<strong>交叉熵损失</strong>（CrossEntropy Error）”。</p><p>我们训练神经网络的目的，就是尽可能地减少这个“交叉熵损失”。</p><p>此时的网络如下图：</p><figure><img src="/images/深度学习/v2-4c10b2e5e2d4001423524de264a57b05.jpg"alt="图6.计算交叉熵损失后的神经网络" /><figcaptionaria-hidden="true">图6.计算交叉熵损失后的神经网络</figcaption></figure><h2 id="反向传播与参数优化">5.反向传播与参数优化</h2><p>上边的1~4节，讲述了神经网络的正向传播过程。一句话复习一下：<strong>神经网络的传播都是形如Y=WX+b的矩阵运算；为了给矩阵运算加入非线性，需要在隐藏层中加入激活层；输出层结果需要经过Softmax层处理为概率值，并通过交叉熵损失来量化当前网络的优劣。</strong></p><p>算出交叉熵损失后，就要开始反向传播了。其实反向传播就是一个<strong>参数优化</strong>的过程，优化对象就是网络中的所有W和b（因为其他所有参数都是确定的）。</p><p>神经网络的神奇之处，就在于它可以自动做W和b的优化，在深度学习中，参数的数量有时会上亿，不过其优化的原理和我们这个两层神经网络是一样的。</p><p>这里举一个形象的例子描述一下这个参数优化的原理和过程：</p><p>假设我们操纵着一个球型机器行走在沙漠中</p><figure><img src="/images/深度学习/v2-40db4875838c6dd2e4762f9d378030b8.jpg"alt="v2-40db4875838c6dd2e4762f9d378030b8" /><figcaptionaria-hidden="true">v2-40db4875838c6dd2e4762f9d378030b8</figcaption></figure><p>我们在机器中操纵着四个旋钮，分别叫做W1，b1，W2，b2。当我们旋转其中的某个旋钮时，球形机器会发生移动，但是旋转旋钮大小和机器运动方向之间的对应关系是不知道的。而我们的目的就是<strong>走到沙漠的最低点</strong>。</p><figure><img src="/images/深度学习/v2-a2397f4b4b12cb3602e0b26842b59ae0.jpg"alt="v2-a2397f4b4b12cb3602e0b26842b59ae0" /><figcaptionaria-hidden="true">v2-a2397f4b4b12cb3602e0b26842b59ae0</figcaption></figure><p>此时我们该怎么办？只能挨个试喽。</p><p>如果增大W1后，球向上走了，那就减小W1。</p><p>如果增大b1后，球向下走了，那就继续增大b1。</p><p>如果增大W2后，球向下走了一大截，那就多增大些W2。</p><p>。。。</p><p>这就是进行参数优化的形象解释（有没有想到求导？），这个方法叫做梯度下降法。</p><p>当我们的球形机器走到最低点时，也就代表着我们的交叉熵损失达到最小（接近于0）。</p><p>关于反向传播，还有许多可以讲的，但是因为内容较多，就放在下一篇文章中说吧。不过上述例子对于理解神经网络参数优化的过程，还是很有帮助的。</p><p><strong>6.迭代</strong></p><p>神经网络需要反复迭代。</p><p>如上述例子中，第一次计算得到的概率是90%，交叉熵损失值是0.046；将该损失值反向传播，使W1,b1,W2,b2做相应微调；再做第二次运算，此时的概率可能就会提高到92%，相应地，损失值也会下降，然后再反向传播损失值，微调参数W1,b1,W2,b2。依次类推，损失值越来越小，直到我们满意为止。</p><p>此时我们就得到了理想的W1,b1,W2,b2。</p><p>此时如果将任意一组坐标作为输入，利用图4或图5的流程，就能得到分类结果。</p><p>此时,我们一个简单的基本神经网络模型就构建完成啦~</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>光影集-2022</title>
    <link href="/%E5%85%89%E5%BD%B1%E9%9B%862022.html"/>
    <url>/%E5%85%89%E5%BD%B1%E9%9B%862022.html</url>
    
    <content type="html"><![CDATA[<h1 id="难忘那年">难忘那年</h1><figure><img src="/images/光影集2022/image-20240513215734472.png"alt="月色苍茫" /><figcaption aria-hidden="true">月色苍茫</figcaption></figure><figure><img src="/images/光影集2022/image-20240513215908875.png"alt="鱼来鱼往" /><figcaption aria-hidden="true">鱼来鱼往</figcaption></figure><figure><img src="/images/光影集2022/image-20240513220042681.png"alt="花开灿烂" /><figcaption aria-hidden="true">花开灿烂</figcaption></figure><figure><img src="/images/光影集2022/image-20240513220159390.png"alt="绿意盎然" /><figcaption aria-hidden="true">绿意盎然</figcaption></figure><figure><img src="/images/光影集2022/image-20240513220313485.png"alt="雨打蕉叶" /><figcaption aria-hidden="true">雨打蕉叶</figcaption></figure><figure><img src="/images/光影集2022/image-20240513220422759.png"alt="风华正茂" /><figcaption aria-hidden="true">风华正茂</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>生活记录</tag>
      
      <tag>摄影作品</tag>
      
      <tag>难忘那年</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LightGBM参数调优</title>
    <link href="/LightGBM%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98.html"/>
    <url>/LightGBM%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98.html</url>
    
    <content type="html"><![CDATA[<p>LightGBM模型在各领域运用广泛，但想获得更好的模型表现，调参这一过程必不可少，下面我们就来聊聊LightGBM在sklearn接口下调参数的方法，也会在文末给出调参的代码模板。</p><span id="more"></span><h2 id="概述">概述</h2><p><strong>按经验预先固定的参数</strong></p><ul><li>learning_rate</li><li>n_estimators</li><li>min_split_gain</li><li>min_child_sample</li><li>min_child_weight</li></ul><p><strong>需要算法调节的参数</strong></p><ul><li>max_depth</li><li>num_leaves</li><li>subsample</li><li>colsample_bytree</li><li>reg_alpha</li><li>reg_lambda</li></ul><h2 id="lightgbm参数详解">LightGBM参数详解</h2><p>LightGBM有众多参数，建议大家在使用LightGBM前，先仔细阅读参数介绍。</p><p>参数介绍传送门：</p><p>英文版：<ahref="https://lightgbm.readthedocs.io/en/latest/Parameters.html">https://lightgbm.readthedocs.io/en/latest/Parameters.html</a></p><p>中文版：<ahref="https://lightgbm.apachecn.org/%23/docs/6">https://lightgbm.apachecn.org/#/docs/6</a></p><p>其他注解：<ahref="https://medium.com/@gabrieltseng/gradient-boosting-and-xgboost-c306c1bcfaf5">https://medium.com/<spanclass="citation"data-cites="gabrieltseng/gradient-boosting-and-xgboost-c306c1bcfaf5">@gabrieltseng/gradient-boosting-and-xgboost-c306c1bcfaf5</span></a></p><h3id="我们提取对模型性能比较重要的参数来介绍下">我们提取对模型性能比较重要的参数来介绍下。</h3><p><span class="math display">\[w_j=\text{learning rate}\times\frac{\sum_{i\in I_j}\frac{\partialloss}{\partial(\hat{y}=0)}}{\sum_{i\inI_j}(\frac{\partial^2loss}{\partial(\hat{y}=0)^2})+\lambda}\]</span></p><ol type="1"><li>learning_rate:学习率。默认设置为0.1，一般设置在0.05-0.1之间。选择比较小的学习率能获得稳定较好的模型性能。</li><li>n_estimators:boosting的迭代次数。默认设置为100。一般根据数据集和特征数据选择100~1000之间。更保守的做法是设置一个较大的值配合early_stopping_round来让模型根据性能自动选择最好的迭代次数。选择比较大的迭代次数会在训练集获得比较好的性能但容易过拟合造成测试集的性能下降。</li><li>min_split_gain:执行节点分裂的最小增益。默认设置为0。不建议去调整。增大这个数值会得到相对浅的树深。可调整其他参数得到类似效果。</li><li>min_child_sample:一个叶子上的最小数据量。默认设置为20。根据数据量来确定，当数据量比较大时，应该提升这个数值，让叶子节点的数据分布相对稳定，提高模型的泛华能力。</li><li>min_child_weight:一个叶子上的最小hessian和。默认设置为0.001，一般设置为1。不建议调整，增大数值会得到较浅的树深。</li><li>max_depth:树模型的最大深度。防止过拟合的最重要的参数，一般限制为3~5之间。是需要调整的核心参数，对模型性能和泛化能力有决定性作用。</li><li>num_leaves:一棵树上的叶子节点个数。默认设置为31，和max_depth配合来空值树的形状，一般设置为(0,2^max_depth -1]的一个数值。是一个需要重点调节的参数，对模型性能影响很大。</li><li>subsample:若此参数小于1.0，LightGBM将会在每次迭代中在不进行重采样的情况下随机选择部分数据（row），可以用来加速训练及处理过拟合。默认设置为1，一般设置为0。8~1.0之间，防止过拟合。</li><li>colsample_bytree:若此参数小于1.0，LightGBM将会在每次迭代中随机选择部分特征(col)，可以用来加速训练及处理过拟合。默认设置为1，一般设置为0.8~1.0之间，防止过拟合。</li></ol><p><span class="math display">\[L=\sum_{i=0}^nloss(y_{res},h(x))+\frac12\lambda\sum_{j=1}^Tw_j^2+\alpha\sum_{j=1}^T|w_j|\]</span></p><ol type="1"><li>reg_alpha:L1正则化参数，别名：lambda_l1。默认设置为0。一般经过特征选择后这个参数不会有特别大的差异，如果发现这个参数数值大，则说明有一些没有太大作用的特征在模型内。需要调节来控制过拟合</li><li>reg_lambda:L2正则化参数，别名：lambda_l2。默认设置为0。较大的数值会让各个特征对模型的影响力趋于均匀，不会有单个特征把持整个模型的表现。需要调节来控制过拟合</li></ol><h2 id="调参建议">调参建议</h2><p>接下来介绍一下根据我们自己的经验和网上相关帖子总结出来的一点小经验供参考，不同参数在不同数据集上表现会有一定的差异性。</p><p><strong>建议根据经验确定的参数：</strong></p><h4 id="learning_rate">1.<strong>learning_rate:</strong></h4><p>通常来说，学习率越小模型表现的最终表现容易获得比较好的结果，但是过小的学习率往往会导致模型的过拟合以及影响模型训练的时间。一般来说，在调参的过程中会预设一个固定的值如0.1或者0.05，再其他参数确定后再在0.05-0.2之间搜索一个不错的值作为最终模型的参数。通常在学习率较小的时候，n_estimators的数值会大，而学习率大的时候,n_estimators会比较小，他们是一对此消彼长的参数对。</p><h4 id="n_estimators">2.<strong>n_estimators</strong>:</h4><ol type="1"><li>通常来说迭代次数越多模型表现越好，但是过大的迭代次往往会导致模型的过拟合以及影响模型训练的时间。一般我们选择的值在100~1000之间，训练时需要时刻关注过拟合的情况以便及时调整迭代次数。通常通过lgb.plot_metrics(model,metrics='auc)来观察学习曲线的变化，如果在测试集表现趋于下降的时候模型还没有停止训练就说明出现过拟合了。</li><li>通常为了防止过拟合，都会选一个比较大的n_estimators，然后设置early_stop_round为20，50，100来让模型停止在测试集效果还不错的地方，但如果模型过早的停止训练，比如只迭代了20次，那可能这样的结果是有问题的，需要再仔细研究下原因。</li><li>还有个通过交叉检验确定n_estimators的办法，但我们实验的结果表明没有加early-stop_round来的稳定，但也分享给大家，说不定在你的项目里有奇效。具体做法：跑3-5折的交叉检验，训练时加上early_stop_round，记录下每折模型停止时的n_estimators的数值，然后n_estimators取交叉检验模型停止的迭代次数的平均值的1.1倍。然后确定这个数值来调整其他参数，最终模型再通过early_stop_round得到最终的n_estimators的数值。</li></ol><h4 id="min_split_gain">3.<strong>min_split_gain</strong>:</h4><p>不建议去调整。增大这个数值会得到相对浅的树深。可调整其他参数得到类似效果。如果实在要调整，可以画出第一颗树和最后一颗树，把每次决策分叉的gain的数值画出来看一看大致范围，然后确定一个下限。但往往设置后模型性能会下降不少，所以如果不是过拟合很严重且没有其他办法缓解才建议调整这个参数。</p><h4 id="min_child_sample">4.<strong>min_child_sample</strong>:</h4><p>这个参数需要根据数据集来确定，一般小数据集用默认的20就够了，但大数据集还用这个20的话会使得生成的叶子节点上数据量过小，这会出现数据集没有代表性的问题，所以建议按树深为4共16个叶子时平均的训练数据个数的25%的数值来确定这个参数或者在这个范围稍微搜索下。这样模型的稳定性会有所保障。</p><h4 id="min_child_weight">5.<strong>min_child_weight</strong>:</h4><p>和min_child_sample的作用类似，但这个参数本身对模型的性能影响并不大，而且影响的方式不容易被人脑所理解，不建议过多的进行调整。</p><h3id="需要通过算法来搜索的参数"><strong>需要通过算法来搜索的参数：</strong></h3><ol type="1"><li><strong>max_depth:</strong>一般在3，4，5这三个数里挑一个就好了，设置过大的数值过拟合会比较严重。</li><li>num_leaves:在LightGBM里，叶子节点数设置要和max_depth来配合，要小于2<sup>max_depth-1。一般max_depth取3时，叶子数要&lt;=2</sup>3-1=7。如果比这个数值大的话,LightGBM可能会有奇怪的结果。在参数搜索时，需要用max_depth去限制num_leaves的取值范围。</li><li><strong>subsample:</strong>不建议过度的精细的调节，比如用搜索算法搜一个0.814325这样一个数值就不是很好。一般给出大致的搜索范围如[0.8,0.9, 1.0]这样几个比较整的数值就足够了。</li><li><strong>colsample_bytree:</strong> 和subsample同理，在[0.8, 0.9,1.0]这样几个比较整的数值搜索就足够了。不建议过度调节。</li><li><strong>reg_alpha:</strong>此参数服务于L1正则化，一般我们取0-1000的范围去进行调参。如果优化出来这个参数数值过大，则说明有一些不必要的特征可以剔除，可以先做特征筛选后再进行调参，然后调节出来模型效果好的时候reg_alpha是个相对小的数值，那我们对这个模型的信心会大很多。</li><li><strong>reg_lambda:</strong>此参数服务于L2正则化，一般也是在0-1000的范围去进行调参。如果有非常强势的特征，可以人为加大一些reg_lambda使得整体特征效果平均一些，一般会比reg_alpha的数值略大一些，但如果这个参数大的夸张也需要再查看一遍特征是否合理。</li></ol><p>总的来说，再开始时调参前应该做特征筛选，在确定特征后，根据数据规模和几个模型尝试的结果来初步敲定learning_rate,n_estimators, min_split_gain, min_child_sample,min_child_weight这几个参数，然后使用grid_search, Bayesianoptimization或random search来调整 max_depth, num_leaves, subsample,colsample_bytree, reg_alpha, reg_lambda。其中重点要调节max_depth,num_leaves，并且注意他们的约束关系num_leaves&lt;=2^max_depth-1，其次subsample, colsample_bytree在[0.8,0.9, 1.0]几个粗略的离散值上调整下即可，reg_alpha, reg_lambda在[0,1000]的范围调整，最后比较好的模型上这俩参数值不应该过大，尤其是reg_alpha，过大的话需要查看特征。</p><hr /><h2 id="贝叶斯优化调参实战">贝叶斯优化调参实战</h2><p>在参数调节中，常用的调参算法有</p><p>1 grid search</p><p>2 Bayesian optimization</p><p>3 random search</p><p>其中Bayesianoptimization是个性价比比较高的方法，可以在比较短的时间内找出还不错的参数组合。但实际操作中，如果时间等得起，我们会同时使用这三个方法去搜参数然后对比下结果，找出三个算法都认为好的参数组合作为最终模型的结果。接下来给出详细的代码实操。</p><p>参数空间示例：</p><p>使用到hyperopt包定义参数空间：</p><p><ahref="https://link.zhihu.com/?target=http%3A//hyperopt.github.io/hyperopt/getting-started/search_spaces/">http://hyperopt.github.io/hyperopt/getting-started/search_spaces/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python3">space = &#123;<br>    &#x27;max_depth&#x27;: hp.choice(&#x27;max_depth&#x27;, [3, 4, 5]),<br>    &#x27;num_leaves&#x27;: hp.choice(&#x27;num_leaves&#x27;, [5, 6, 7, 12, 13, 14, 15, 28, 29, 30, 31]),<br>    &#x27;subsample&#x27;: hp.choice(&#x27;subsample&#x27;, [0.8, 0.9, 1.0]),<br>    &#x27;colsample_bytree&#x27;: hp.choice(&#x27;colsample_bytree&#x27;, [0.8, 0.9, 1.0]),<br>    &#x27;reg_alpha&#x27;: hp.loguniform(&#x27;reg_alpha&#x27;, np.log(0.01), np.log(1000)),<br>    &#x27;reg_lambda&#x27;: hp.loguniform(&#x27;reg_lambda&#x27;, np.log(0.01), np.log(1000))<br>&#125;<br></code></pre></td></tr></table></figure><p>具体调参的类如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LGBBO</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, fp_path, **kwargs</span>):<br>        self.fp_path = fp_path<br>        self.<span class="hljs-built_in">iter</span> = <span class="hljs-number">0</span><br>        self.train_set = <span class="hljs-literal">None</span><br><br>        self.kfold = kwargs.get(<span class="hljs-string">&#x27;kfold&#x27;</span>, <span class="hljs-number">3</span>)<br>        self.n_estimators = kwargs.get(<span class="hljs-string">&#x27;n_estimators&#x27;</span>, <span class="hljs-number">800</span>)<br><br>        csv_conn = <span class="hljs-built_in">open</span>(self.fp_path, <span class="hljs-string">&#x27;w&#x27;</span>)<br>        writer = csv.writer(csv_conn)<br>        writer.writerow([<span class="hljs-string">&#x27;loss&#x27;</span>, <span class="hljs-string">&#x27;train_auc&#x27;</span>, <span class="hljs-string">&#x27;valid_auc&#x27;</span>, <span class="hljs-string">&#x27;train_ks&#x27;</span>, <span class="hljs-string">&#x27;valid_ks&#x27;</span>,<br>                         <span class="hljs-string">&#x27;lst_train_auc&#x27;</span>, <span class="hljs-string">&#x27;lst_valid_auc&#x27;</span>, <span class="hljs-string">&#x27;lst_train_ks&#x27;</span>, <span class="hljs-string">&#x27;lst_valid_ks&#x27;</span>,<br>                         <span class="hljs-string">&#x27;params&#x27;</span>, <span class="hljs-string">&#x27;iteration&#x27;</span>, <span class="hljs-string">&#x27;train_time&#x27;</span>])<br>        csv_conn.close()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">self, df_data, feature_list, label</span>):<br>        self.df_data = df_data.reset_index(drop=<span class="hljs-literal">True</span>)<br>        self.feature_list = feature_list<br>        self.label = label<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">objective</span>(<span class="hljs-params">self, params</span>):<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">eval_ks</span>(<span class="hljs-params">ytrue, yprob</span>):<br>            fpr, tpr, thr = roc_curve(ytrue, yprob)<br>            ks = <span class="hljs-built_in">max</span>(tpr - fpr)<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;ks&quot;</span>, ks, <span class="hljs-literal">True</span><br><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">eval_auc</span>(<span class="hljs-params">ytrue, yprob</span>):<br>            auc = roc_auc_score(ytrue, yprob)<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;auc&quot;</span>, auc, <span class="hljs-literal">True</span><br><br>        self.<span class="hljs-built_in">iter</span> += <span class="hljs-number">1</span><br>        start = timer()<br>        model = lgb.LGBMClassifier(**params,<br>                                   learning_rate=<span class="hljs-number">0.1</span>,<br>                                   min_child_samples=<span class="hljs-number">20000</span>,<br>                                   objective=<span class="hljs-string">&#x27;cross_entropy&#x27;</span>,<br>                                   importance_type=<span class="hljs-string">&#x27;gain&#x27;</span>,<br>                                   class_weight=<span class="hljs-string">&#x27;balanced&#x27;</span>,<br>                                   boosting_type=<span class="hljs-string">&#x27;gbdt&#x27;</span>, n_estimators=self.n_estimators,<br>                                   silent=<span class="hljs-literal">True</span>, n_jobs=<span class="hljs-number">1</span>, random_state=<span class="hljs-number">0</span><br>                                   )<br><br>        lst_train_auc, lst_valid_auc = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br>        lst_train_ks, lst_valid_ks = <span class="hljs-built_in">list</span>(), <span class="hljs-built_in">list</span>()<br><br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.kfold):<br>            df_cv_train = self.df_data[self.df_data[<span class="hljs-string">f&quot;cv<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>] == <span class="hljs-string">&#x27;train&#x27;</span>]<br>            df_cv_valid = self.df_data[self.df_data[<span class="hljs-string">f&quot;cv<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>] == <span class="hljs-string">&#x27;valid&#x27;</span>]<br>            <span class="hljs-built_in">print</span>(k, df_cv_train.shape, df_cv_valid.shape)<br>            <span class="hljs-built_in">print</span>(params)<br><br>            eval_set = [(df_cv_train[self.feature_list], df_cv_train[self.label]),<br>                        (df_cv_valid[self.feature_list], df_cv_valid[self.label])<br>                        ]<br><br>            model.fit(df_cv_train[self.feature_list], df_cv_train[self.label],<br>                      eval_set=eval_set,<br>                      eval_metric=<span class="hljs-keyword">lambda</span> ytrue, yprob: [eval_auc(ytrue, yprob), eval_ks(ytrue, yprob)],<br>                      early_stopping_rounds=<span class="hljs-number">50</span>,<br>                      verbose=<span class="hljs-number">20</span>)<br><br>            yprob = model.predict_proba(df_cv_train[self.feature_list])[:, <span class="hljs-number">1</span>]<br>            _, train_auc, _ = eval_auc(df_cv_train[self.label], yprob)<br>            _, train_ks, _ = eval_ks(df_cv_train[self.label], yprob)<br>            yprob = model.predict_proba(df_cv_valid[self.feature_list])[:, <span class="hljs-number">1</span>]<br>            _, valid_auc, _ = eval_auc(df_cv_valid[self.label], yprob)<br>            _, valid_ks, _ = eval_ks(df_cv_valid[self.label], yprob)<br><br>            lst_train_auc.append(train_auc)<br>            lst_valid_auc.append(valid_auc)<br>            lst_train_ks.append(train_ks)<br>            lst_valid_ks.append(valid_ks)<br><br>            <span class="hljs-built_in">print</span>(train_auc, valid_auc, train_ks, valid_ks)<br><br>        run_time = timer() - start<br><br>        train_auc_avg = np.mean(lst_train_auc)<br>        valid_auc_avg = np.mean(lst_valid_auc)<br>        train_ks_avg = np.mean(lst_train_ks)<br>        valid_ks_avg = np.mean(lst_valid_ks)<br><br>        loss = -valid_ks_avg<br><br>        csv_conn = <span class="hljs-built_in">open</span>(self.fp_path, <span class="hljs-string">&#x27;a&#x27;</span>)<br>        writer = csv.writer(csv_conn)<br><br>        writer.writerow([loss,<br>                         train_auc_avg, valid_auc_avg,<br>                         train_ks_avg, valid_ks_avg,<br>                         lst_train_auc, lst_valid_auc,<br>                         lst_train_ks, lst_valid_ks,<br>                         params, self.<span class="hljs-built_in">iter</span>, run_time])<br><br>        res = &#123;<span class="hljs-string">&#x27;loss&#x27;</span>: loss,<br>               <span class="hljs-string">&#x27;train_auc&#x27;</span>: train_auc_avg, <span class="hljs-string">&#x27;valid_auc&#x27;</span>: valid_auc_avg,<br>               <span class="hljs-string">&#x27;train_ks&#x27;</span>: train_ks_avg, <span class="hljs-string">&#x27;valid_ks&#x27;</span>: valid_ks_avg,<br>               <span class="hljs-string">&#x27;lst_train_auc&#x27;</span>: lst_train_auc, <span class="hljs-string">&#x27;lst_valid_auc&#x27;</span>: lst_valid_auc,<br>               <span class="hljs-string">&#x27;lst_train_ks&#x27;</span>: lst_train_ks, <span class="hljs-string">&#x27;lst_valid_ks&#x27;</span>: lst_valid_ks,<br>               <span class="hljs-string">&#x27;params&#x27;</span>: params, <span class="hljs-string">&#x27;iteration&#x27;</span>: self.<span class="hljs-built_in">iter</span>, <span class="hljs-string">&#x27;train_time&#x27;</span>: run_time,<br>               <span class="hljs-string">&#x27;status&#x27;</span>: STATUS_OK&#125;<br><br>        <span class="hljs-built_in">print</span>(self.<span class="hljs-built_in">iter</span>)<br>        <span class="hljs-built_in">print</span>(res)<br><br>        <span class="hljs-keyword">return</span> res<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">optimize</span>(<span class="hljs-params">self, max_evals</span>):<br>        self.<span class="hljs-built_in">iter</span> = <span class="hljs-number">0</span><br><br>        space = &#123;<br>            <span class="hljs-string">&#x27;max_depth&#x27;</span>: hp.choice(<span class="hljs-string">&#x27;max_depth&#x27;</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]),<br>            <span class="hljs-string">&#x27;num_leaves&#x27;</span>: hp.choice(<span class="hljs-string">&#x27;num_leaves&#x27;</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">28</span>, <span class="hljs-number">29</span>, <span class="hljs-number">30</span>, <span class="hljs-number">31</span>]),<br>            <span class="hljs-string">&#x27;subsample&#x27;</span>: hp.choice(<span class="hljs-string">&#x27;subsample&#x27;</span>, [<span class="hljs-number">0.8</span>, <span class="hljs-number">0.9</span>, <span class="hljs-number">1.0</span>]),<br>            <span class="hljs-string">&#x27;colsample_bytree&#x27;</span>: hp.choice(<span class="hljs-string">&#x27;colsample_bytree&#x27;</span>, [<span class="hljs-number">0.8</span>, <span class="hljs-number">0.9</span>, <span class="hljs-number">1.0</span>]),<br>            <span class="hljs-string">&#x27;reg_alpha&#x27;</span>: hp.loguniform(<span class="hljs-string">&#x27;reg_alpha&#x27;</span>, np.log(<span class="hljs-number">0.01</span>), np.log(<span class="hljs-number">1000</span>)),<br>            <span class="hljs-string">&#x27;reg_lambda&#x27;</span>: hp.loguniform(<span class="hljs-string">&#x27;reg_lambda&#x27;</span>, np.log(<span class="hljs-number">0.01</span>), np.log(<span class="hljs-number">1000</span>))<br>        &#125;<br><br>        best = fmin(fn=self.objective, space=space, algo=tpe.suggest, max_evals=max_evals,<br>                    trials=Trials(), rstate=np.random.RandomState(<span class="hljs-number">0</span>))<br><br>        <span class="hljs-built_in">print</span>(best)<br>        <span class="hljs-keyword">return</span> best<br></code></pre></td></tr></table></figure><p>调用样例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">kf = StratifiedKFold(n_splits=<span class="hljs-number">3</span>, random_state=<span class="hljs-number">0</span>, shuffle=<span class="hljs-literal">True</span>)<br>pdf_train = pdf_train.reset_index(drop=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">for</span> k, (itrain, ivalid) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(kf.split(pdf_train[selected_features], pdf_train[label])):<br>    pdf_train[<span class="hljs-string">f&quot;cv<span class="hljs-subst">&#123;k&#125;</span>&quot;</span>] = <span class="hljs-literal">None</span><br>    pdf_train.loc[itrain, <span class="hljs-string">f&#x27;cv<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>] = <span class="hljs-string">&#x27;train&#x27;</span><br>    pdf_train.loc[ivalid, <span class="hljs-string">f&#x27;cv<span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>] = <span class="hljs-string">&#x27;valid&#x27;</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;start tuning...&#x27;</span>)<br>bo = LGBBO(<span class="hljs-string">f&#x27;param.csv&#x27;</span>)<br>bo.load_data(pdf_train, selected_features, label)<br>bo.optimize(<span class="hljs-number">10000</span>)<br></code></pre></td></tr></table></figure><p>最后我们想说下，一般在样本不均衡时会额外调节scale_<em>pos_</em>weight这个参数，但在我们实际项目中，如果样本不是特别的偏，class_weight='balanced'就足够能产生不错的效果了，所以在参数调节中没有强调。一般情况下，这一整套调参流程跑下来是足够得到一个还不错的模型效果的参数的。</p>]]></content>
    
    
    <categories>
      
      <category>调参</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>集成学习</tag>
      
      <tag>笔记整理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>人工智能专业术语汇编</title>
    <link href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD%E6%B1%87%E7%BC%96.html"/>
    <url>/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD%E6%B1%87%E7%BC%96.html</url>
    
    <content type="html"><![CDATA[<blockquote><p>本术语库目前拥有专业术语约 2442 个、专项领域篇 2篇，主要为人工智能领域基础概念和术语。</p><p>本术语库前两版主要是将机器之心在编译技术文章和论文过程中所遇到的专业术语记录下来，希望有助于AI从业者的查阅和学习<span id="more"></span> # 人工智能--术语库 引自 github的 <ahref="https://github.com/jiqizhixin/Artificial-Intelligence-Terminology-Database">Artificial-Intelligence-Terminology-Database</a>项目</p></blockquote><table style="width:100%;"><thead><tr class="header"><th>索引编号</th><th>英文术语</th><th>中文翻译</th><th>常用缩写</th><th>来源&amp;扩展</th><th>备注</th></tr></thead><tbody><tr class="odd"><td>AITD-00000</td><td>0-1 Loss Function</td><td>0-1损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00001</td><td>Absolute Loss Function</td><td>绝对损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00002</td><td>Absolute Value Rectification</td><td>绝对值整流</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00003</td><td>Accept-Reject Sampling Method</td><td>接受-拒绝抽样法/接受-拒绝采样法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00004</td><td>Acceptance Distribution</td><td>接受分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00005</td><td>Access Parameters</td><td>访问参数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00006</td><td>Accumulated Error Backpropagation</td><td>累积误差反向传播</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00007</td><td>Accuracy</td><td>准确率</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00008</td><td>Acoustic</td><td>声学</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00009</td><td>Acoustic Modeling</td><td>声学建模</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00010</td><td>Acquisition Function</td><td>采集函数</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-08-18-5">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00011</td><td>Action</td><td>动作</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00012</td><td>Action Value Function</td><td>动作价值函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00013</td><td>Actionism</td><td>行为主义</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00014</td><td>Activation</td><td>活性值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00015</td><td>Activation Function</td><td>激活函数</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-06-11-4">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-18-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[4]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-00016</td><td>Active Learning</td><td>主动学习</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00017</td><td>Actor</td><td>演员</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00018</td><td>Actor-Critic Algorithm</td><td>演员-评论员算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00019</td><td>Actor-Critic Method</td><td>演员-评论员法</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-08-14">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00020</td><td>Adaptive Bitrate Algorithm</td><td>自适应比特率算法</td><td>ABR</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00021</td><td>Adaptive Boosting</td><td>AdaBoost</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00022</td><td>Adaptive Gradient Algorithm</td><td>AdaGrad</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00023</td><td>Adaptive Moment Estimation Algorithm</td><td>Adam算法</td><td>Adam</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00024</td><td>Adaptive Resonance Theory</td><td>自适应谐振理论</td><td>ART</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00025</td><td>Additive Model</td><td>加性模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00026</td><td>Adversarial</td><td>对抗</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00027</td><td>Adversarial Example</td><td>对抗样本</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-06-6">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00028</td><td>Adversarial Networks</td><td>对抗网络</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-08-5">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00029</td><td>Adversarial Training</td><td>对抗训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00030</td><td>Affine Layer</td><td>仿射层</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00031</td><td>Affine Transformation</td><td>仿射变换</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00032</td><td>Affinity Matrix</td><td>亲和矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00033</td><td>Agent</td><td>智能体</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-04-06-6">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-15-6">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-10-2">[3]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-29-5">[4]</a></td><td></td></tr><tr class="odd"><td>AITD-00034</td><td>Agglomerative</td><td>聚合</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00035</td><td>Agnostic PAC Learnable</td><td>不可知PAC可学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00036</td><td>Algorithm</td><td>算法</td><td></td><td><ahref="https://jiqizhixin.github.io/AI-Terminology-page/">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-05-23-4">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-04-2">[3]</a></td><td></td></tr><tr class="even"><td>AITD-00037</td><td>Almost Everywhere</td><td>几乎处处</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00038</td><td>Almost Sure</td><td>几乎必然</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00039</td><td>Almost Sure Convergence</td><td>几乎必然收敛</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00040</td><td>Alpha-Beta Pruning</td><td>α-β修剪法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00041</td><td>Alternative Splicing Dataset</td><td>选择性剪接数据集</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00042</td><td>Ambiguity</td><td>分歧</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00043</td><td>Analytic Gradient</td><td>解析梯度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00044</td><td>Ancestral Sampling</td><td>原始采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00045</td><td>Annealed Importance Sampling</td><td>退火重要采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00046</td><td>Anomaly Detection</td><td>异常检测</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00047</td><td>Aperiodic</td><td>非周期的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00048</td><td>Aperiodic Graph</td><td>非周期性图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00049</td><td>Application-Specific Integrated Circuit</td><td>专用集成电路</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00050</td><td>Approximate Bayesian Computation</td><td>近似贝叶斯计算</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00051</td><td>Approximate Dynamic Programming</td><td>近似动态规划</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00052</td><td>Approximate Inference</td><td>近似推断</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00053</td><td>Approximation</td><td>近似</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00054</td><td>Approximation Error</td><td>近似误差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00055</td><td>Architecture</td><td>架构</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-12">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00056</td><td>Area Under ROC Curve</td><td>AUC（ROC曲线下方面积，度量分类模型好坏的标准）</td><td>AUC</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00057</td><td>Arithmetic Coding</td><td>算术编码</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00058</td><td>Artificial General Intelligence</td><td>通用人工智能</td><td>AGI</td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-06-2">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00059</td><td>Artificial Intelligence</td><td>人工智能</td><td>AI</td><td><a href="https://www.jiqizhixin.com/articles/2017-05-21-4">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-05-21-7">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-05-17-16">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[4]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[5]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-00060</td><td>Artificial Neural Network</td><td>人工神经网络</td><td>ANN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[2]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00061</td><td>Artificial Neuron</td><td>人工神经元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00062</td><td>Association Analysis</td><td>关联分析</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00063</td><td>Associative Memory</td><td>联想记忆</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00064</td><td>Associative Memory Model</td><td>联想记忆模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00065</td><td>Asymptotically Unbiased</td><td>渐近无偏</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00066</td><td>Asynchronous Stochastic Gradient Descent</td><td>异步随机梯度下降</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00067</td><td>Asynchronous</td><td>异步</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00068</td><td>Atrous Convolution</td><td>空洞卷积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00069</td><td>Attention</td><td>注意力</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[2]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-00070</td><td>Attention Cue</td><td>注意力提示</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00071</td><td>Attention Distribution</td><td>注意力分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00072</td><td>Attention Mechanism</td><td>注意力机制</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-06-19-4">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-14-6">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-28-5">[3]</a></td><td></td></tr><tr class="even"><td>AITD-00073</td><td>Attention Model</td><td>注意力模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00074</td><td>Attractor</td><td>吸引点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00075</td><td>Attribute</td><td>属性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00076</td><td>Attribute Conditional Independence Assumption</td><td>属性条件独立性假设</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00077</td><td>Attribute Space</td><td>属性空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00078</td><td>Attribute Value</td><td>属性值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00079</td><td>Augmented Lagrangian</td><td>增广拉格朗日法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00080</td><td>Auto-Regressive Network</td><td>自回归网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00081</td><td>Autoencoder</td><td>自编码器</td><td>AE</td><td><ahref="https://www.jiqizhixin.com/articles/2017-04-26-5">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00082</td><td>Automatic Differentiation</td><td>自动微分</td><td>AD</td><td><ahref="https://www.jiqizhixin.com/articles/2017-11-07">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00083</td><td>Automatic Speech Recognition</td><td>自动语音识别</td><td>ASR</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00084</td><td>Automatic Summarization</td><td>自动摘要</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00085</td><td>Autoregressive Generative Model</td><td>自回归生成模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00086</td><td>Autoregressive Model</td><td>自回归模型</td><td>AR</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00087</td><td>Autoregressive Process</td><td>自回归过程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00088</td><td>Average Gradient</td><td>平均梯度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00089</td><td>Average Pooling Layer</td><td>平均汇聚层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00090</td><td>Average-Pooling</td><td>平均汇聚</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00091</td><td>Averaged Perceptron</td><td>平均感知器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00092</td><td>Back Propagation</td><td>反向传播</td><td>BP</td><td><a href="https://www.jiqizhixin.com/articles/2016-11-25-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[3]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00093</td><td>Back Propagation Algorithm</td><td>反向传播算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00094</td><td>Back Propagation Through Time</td><td>随时间反向传播</td><td>BPTT</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00095</td><td>Back-Off</td><td>回退</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00096</td><td>Backward</td><td>后向</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00097</td><td>Backward Induction</td><td>反向归纳</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00098</td><td>Backward Search</td><td>反向搜索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00099</td><td>Bag of Words</td><td>词袋</td><td>BOW</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00100</td><td>Bagging</td><td>袋装</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00101</td><td>Bandit</td><td>赌博机/老虎机</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00102</td><td>Bandpass Filter</td><td>带通滤波器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00103</td><td>Base</td><td>基</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00104</td><td>Base Classifier</td><td>基分类器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00105</td><td>Base Learner</td><td>基学习器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00106</td><td>Base Learning Algorithm</td><td>基学习算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00107</td><td>Base Vector</td><td>基向量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00108</td><td>Baseline</td><td>基准</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00109</td><td>Basin of Attraction</td><td>吸引域</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00110</td><td>Batch</td><td>批量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00111</td><td>Batch Gradient Descent</td><td>批量梯度下降法</td><td>BGD</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00112</td><td>Batch Learning</td><td>批量学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00113</td><td>Batch Normalization</td><td>批量规范化</td><td>BN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00114</td><td>Batch Size</td><td>批量大小</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00115</td><td>Baum-Welch Algorithm</td><td>Baum-Welch算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00116</td><td>Bayes Classifier</td><td>贝叶斯分类器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00117</td><td>Bayes Decision Rule</td><td>贝叶斯决策准则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00118</td><td>Bayes Error</td><td>贝叶斯误差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00119</td><td>Bayes Model Averaging</td><td>贝叶斯模型平均</td><td>BMA</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00120</td><td>Bayes Optimal Classifier</td><td>贝叶斯最优分类器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00121</td><td>Bayes Risk</td><td>贝叶斯风险</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00122</td><td>Bayes' Rule</td><td>贝叶斯规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00123</td><td>Bayes' Theorem</td><td>贝叶斯定理</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00124</td><td>Bayesian Decision Theory</td><td>贝叶斯决策理论</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00125</td><td>Bayesian Estimation</td><td>贝叶斯估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00126</td><td>Bayesian Inference</td><td>贝叶斯推断</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="even"><td>AITD-00127</td><td>Bayesian Learning</td><td>贝叶斯学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00128</td><td>Bayesian Linear Regression</td><td>贝叶斯线性回归</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00129</td><td>Bayesian Network</td><td>贝叶斯网/贝叶斯网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td>Network翻译为网或网络皆可，只要统一翻译成网或者统一翻译成网络即可；统计，机器学习</td></tr><tr class="odd"><td>AITD-00130</td><td>Bayesian Optimization</td><td>贝叶斯优化</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-11-28">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00131</td><td>Bayesian Probability</td><td>贝叶斯概率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00132</td><td>Bayesian Statistics</td><td>贝叶斯统计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00133</td><td>Beam Search</td><td>束搜索</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-31-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00134</td><td>Benchmark</td><td>基准</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00135</td><td>Belief Network</td><td>信念网/信念网络</td><td>BN</td><td>[1]</td><td>Network翻译为网或网络皆可，只要统一翻译成网或者统一翻译成网络即可</td></tr><tr class="odd"><td>AITD-00136</td><td>Belief Propagation</td><td>信念传播</td><td>BP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00137</td><td>Bellman Equation</td><td>贝尔曼方程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00138</td><td>Bellman Optimality Equation</td><td>贝尔曼最优方程</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00139</td><td>Bernoulli Distribution</td><td>伯努利分布</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-00140</td><td>Bernoulli Output Distribution</td><td>伯努利输出分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00141</td><td>Best-Arm Problem</td><td>最优臂问题</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00142</td><td>Beta Distribution</td><td>贝塔分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00143</td><td>Between-Class Scatter Matrix</td><td>类间散度矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00144</td><td>BFGS</td><td>BFGS</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00145</td><td>Bi-Directional Long-Short Term Memory</td><td>双向长短期记忆</td><td>Bi-LSTM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00146</td><td>Bi-Partition</td><td>二分法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00147</td><td>Bias</td><td>偏差/偏置</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[4]</a></td><td>看上下语境；机器学习</td></tr><tr class="odd"><td>AITD-00148</td><td>Bias In Affine Function</td><td>偏置</td><td></td><td>[1]</td><td>看上下语境</td></tr><tr class="even"><td>AITD-00149</td><td>Bias In Statistics</td><td>偏差</td><td></td><td>[1]</td><td>看上下语境</td></tr><tr class="odd"><td>AITD-00150</td><td>Bias Shift</td><td>偏置偏移</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00151</td><td>Bias-Variance Decomposition</td><td>偏差 - 方差分解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00152</td><td>Bias-Variance Dilemma</td><td>偏差 - 方差困境</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00153</td><td>Biased</td><td>有偏</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-00154</td><td>Biased Importance Sampling</td><td>有偏重要采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00155</td><td>Bidirectional Language Model</td><td>双向语言模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00156</td><td>Bidirectional Recurrent Neural Network</td><td>双向循环神经网络</td><td>Bi-RNN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00157</td><td>Bigram</td><td>二元语法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00158</td><td>Bilingual Evaluation Understudy</td><td>BLEU</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00159</td><td>Binary Classification</td><td>二分类</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00160</td><td>Binary Relation</td><td>二元关系</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00161</td><td>Binary Sparse Coding</td><td>二值稀疏编码</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00162</td><td>Binomial Distribution</td><td>二项分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00163</td><td>Binomial Logistic Regression Model</td><td>二项对数几率回归</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00164</td><td>Binomial Test</td><td>二项检验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00165</td><td>Biological Plausibility</td><td>生物学合理性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00166</td><td>Bit</td><td>比特</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00167</td><td>Block</td><td>块</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00168</td><td>Block Coordinate Descent</td><td>块坐标下降</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00169</td><td>Block Gibbs Sampling</td><td>块吉布斯采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00170</td><td>Boilerplate Code</td><td>样板代码</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00171</td><td>Boltzmann</td><td>玻尔兹曼</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00172</td><td>Boltzmann Distribution</td><td>玻尔兹曼分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00173</td><td>Boltzmann Factor</td><td>玻尔兹曼因子</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00174</td><td>Boltzmann Machine</td><td>玻尔兹曼机</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-10-08-4">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00175</td><td>Boosting</td><td>Boosting（一种模型训练加速方式）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00176</td><td>Boosting Tree</td><td>提升树</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00177</td><td>Bootstrap Aggregating</td><td>Bagging</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00178</td><td>Bootstrap Sampling</td><td>自助采样法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00179</td><td>Bootstrapping</td><td>自助法/自举法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00180</td><td>Bottleneck Layer</td><td>瓶颈层</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00181</td><td>Bottom-Up</td><td>自下而上</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00182</td><td>Bounding Boxes</td><td>边界框</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00183</td><td>Break-Event Point</td><td>平衡点</td><td>BEP</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00184</td><td>Bridge Sampling</td><td>桥式采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00185</td><td>Broadcasting</td><td>广播</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00186</td><td>Broyden's Algorithm</td><td>Broyden类算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00187</td><td>Bucketing</td><td>分桶</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00188</td><td>Burn-In Period</td><td>预烧期</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00189</td><td>Burning-In</td><td>磨合</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00190</td><td>Calculus</td><td>微积分</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00191</td><td>Calculus of Variations</td><td>变分法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00192</td><td>Calibration</td><td>校准</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00193</td><td>Canonical</td><td>正则的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00194</td><td>Canonical Correlation Analysis</td><td>典型相关分析</td><td>CCA</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00195</td><td>Capacity</td><td>容量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00196</td><td>Cartesian Coordinate</td><td>笛卡尔坐标</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00197</td><td>Cascade</td><td>级联</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00198</td><td>Cascade-Correlation</td><td>级联相关</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00199</td><td>Catastrophic Forgetting</td><td>灾难性遗忘</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00200</td><td>Categorical Attribute</td><td>分类属性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00201</td><td>Categorical Distribution</td><td>类别分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00202</td><td>Causal Factor</td><td>因果因子</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00203</td><td>Causal Modeling</td><td>因果模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00204</td><td>Cell</td><td>单元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00205</td><td>Centered Difference</td><td>中心差分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00206</td><td>Central Limit Theorem</td><td>中心极限定理</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00207</td><td>Chain Rule</td><td>链式法则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00208</td><td>Channel</td><td>通道</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00209</td><td>Chaos</td><td>混沌</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00210</td><td>Chebyshev Distance</td><td>切比雪夫距离</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00211</td><td>Chord</td><td>弦</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00212</td><td>Chordal Graph</td><td>弦图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00213</td><td>City Block Distance</td><td>街区距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00214</td><td>Class</td><td>类别</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00215</td><td>Class Label</td><td>类标记</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00216</td><td>Class-Conditional Probability</td><td>类条件概率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00217</td><td>Class-Imbalance</td><td>类别不平衡</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00218</td><td>Classification</td><td>分类</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-00219</td><td>Classification And Regression Tree</td><td>分类与回归树</td><td>CART</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00220</td><td>Classifier</td><td>分类器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00221</td><td>Clip Gradient</td><td>梯度截断</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00222</td><td>Clipping The Gradient</td><td>截断梯度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00223</td><td>Clique</td><td>团</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00224</td><td>Clique Potential</td><td>团势能</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00225</td><td>Clockwork RNN</td><td>时钟循环神经网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00226</td><td>Closed Form Solution</td><td>闭式解</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00227</td><td>Closed-Form</td><td>闭式</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00228</td><td>Cluster</td><td>簇</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00229</td><td>Cluster Analysis</td><td>聚类分析</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00230</td><td>Cluster Assumption</td><td>聚类假设</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00231</td><td>Clustering</td><td>聚类</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-09">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00232</td><td>Clustering Ensemble</td><td>聚类集成</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00233</td><td>Co-Adapting</td><td>共适应</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00234</td><td>Co-Occurrence</td><td>共现</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00235</td><td>Co-Occurrence Frequency</td><td>共现词频</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00236</td><td>Co-Training</td><td>协同训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00237</td><td>Code</td><td>编码</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00238</td><td>Codebook Learning</td><td>码书学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00239</td><td>Coding Matrix</td><td>编码矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00240</td><td>Collaborative Filtering</td><td>协同过滤</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-23-2">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00241</td><td>Collapsed Gibbs Sampling</td><td>收缩的吉布斯抽样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00242</td><td>Collinearity</td><td>共线性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00243</td><td>COLT</td><td>国际学习理论会议</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00244</td><td>Column</td><td>列</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00245</td><td>Column Space</td><td>列空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00246</td><td>Combinatorial Optimization</td><td>组合优化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00247</td><td>Committee-Based Learning</td><td>基于委员会的学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00248</td><td>Common Cause</td><td>共因</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00249</td><td>Common Parent</td><td>同父</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00250</td><td>Compact Singular Value Decomposition</td><td>紧奇异值分解</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00251</td><td>Competitive Learning</td><td>竞争型学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00252</td><td>Complementary Slackness</td><td>互补松弛</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00253</td><td>Complete Graph</td><td>完全图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00254</td><td>Complete Linkage</td><td>完全连接</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00255</td><td>Complete-Data</td><td>完全数据</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00256</td><td>Complex Cell</td><td>复杂细胞</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00257</td><td>Component Learner</td><td>组件学习器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00258</td><td>Compositionality</td><td>组合性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00259</td><td>Comprehensibility</td><td>可解释性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00260</td><td>Computation Cost</td><td>计算代价</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00261</td><td>Computation Graph</td><td>计算图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00262</td><td>Computational Learning Theory</td><td>计算学习理论</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00263</td><td>Computational Linguistics</td><td>计算语言学</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00264</td><td>Computer Vision</td><td>计算机视觉</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00265</td><td>Concatenate</td><td>连结</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00266</td><td>Concept Class</td><td>概念类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00267</td><td>Concept Drift</td><td>概念漂移</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00268</td><td>Concept Learning System</td><td>概念学习系统</td><td>CLS</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00269</td><td>Concept Shift</td><td>概念偏移</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00270</td><td>Conditional Computation</td><td>条件计算</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00271</td><td>Conditional Entropy</td><td>条件熵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00272</td><td>Conditional Independence</td><td>条件独立</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00273</td><td>Conditional Language Model</td><td>条件语言模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00274</td><td>Conditional Mutual Information</td><td>条件互信息</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00275</td><td>Conditional Probability</td><td>条件概率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00276</td><td>Conditional Probability Density Function</td><td>条件概率密度函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00277</td><td>Conditional Probability Distribution</td><td>条件概率分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00278</td><td>Conditional Probability Table</td><td>条件概率表</td><td>CPT</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00279</td><td>Conditional Random Field</td><td>条件随机场</td><td>CRF</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00280</td><td>Conditional Risk</td><td>条件风险</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00281</td><td>Conditionally Independent</td><td>条件独立的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00282</td><td>Conference On Neural Information Processing Systems</td><td>国际神经信息处理系统会议</td><td>NeurIPS</td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-18-9">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00283</td><td>Confidence</td><td>置信度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00284</td><td>Conflict Resolution</td><td>冲突消解</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00285</td><td>Confusion Matrix</td><td>混淆矩阵</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-00286</td><td>Conjugate</td><td>共轭</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00287</td><td>Conjugate Directions</td><td>共轭方向</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00288</td><td>Conjugate Distribution</td><td>共轭分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00289</td><td>Conjugate Gradient</td><td>共轭梯度</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td>优化，数学</td></tr><tr class="odd"><td>AITD-00290</td><td>Conjugate Prior</td><td>共轭先验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00291</td><td>Connection Weight</td><td>连接权</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00292</td><td>Connectionism</td><td>连接主义</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00293</td><td>Consistency</td><td>一致性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00294</td><td>Consistency Convergence</td><td>一致性收敛</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00295</td><td>Constrained Optimization</td><td>约束优化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00296</td><td>Content-Addressable Memory</td><td>基于内容寻址的存储</td><td>CAM</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00297</td><td>Context Variable</td><td>上下文变量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00298</td><td>Context Vector</td><td>上下文向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00299</td><td>Context Window</td><td>上下文窗口</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00300</td><td>Context Word</td><td>上下文词</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00301</td><td>Context-Specific Independences</td><td>特定上下文独立</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00302</td><td>Contextual Bandit</td><td>上下文赌博机/上下文老虎机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00303</td><td>Contextualized Representation</td><td>基于上下文的表示</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00304</td><td>Contingency Table</td><td>列联表</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00305</td><td>Continous Bag-Of-Words Model</td><td>连续词袋模型</td><td>CBOW</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00306</td><td>Continuation Method</td><td>延拓法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00307</td><td>Continuing Task</td><td>持续式任务</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00308</td><td>Continuous Attribute</td><td>连续属性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00309</td><td>Continuous Learning</td><td>持续学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00310</td><td>Continuous Optimization</td><td>连续优化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00311</td><td>Contractive</td><td>收缩</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00312</td><td>Contractive Autoencoder</td><td>收缩自编码器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00313</td><td>Contractive Neural Network</td><td>收缩神经网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00314</td><td>Contrastive Divergence</td><td>对比散度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00315</td><td>Controller</td><td>控制器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00316</td><td>Convergence</td><td>收敛</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00317</td><td>Conversational Agent</td><td>会话智能体</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00318</td><td>Convex Optimization</td><td>凸优化</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-29-4">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00319</td><td>Convex Quadratic Programming</td><td>凸二次规划</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00320</td><td>Convex Set</td><td>凸集</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00321</td><td>Convexity</td><td>凸性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00322</td><td>Convolution</td><td>卷积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00323</td><td>Convolutional Boltzmann Machine</td><td>卷积玻尔兹曼机</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00324</td><td>Convolutional Deep Belief Network</td><td>卷积深度信念网络</td><td>CDBN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00325</td><td>Convolutional Kernel</td><td>卷积核</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00326</td><td>Convolutional Network</td><td>卷积网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00327</td><td>Convolutional Neural Network</td><td>卷积神经网络</td><td>CNN</td><td><a href="https://www.jiqizhixin.com/articles/2017-12-19-8">[1]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-08-6">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-18-2">[3]</a></td><td></td></tr><tr class="odd"><td>AITD-00328</td><td>Coordinate</td><td>坐标</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00329</td><td>Coordinate Ascent</td><td>坐标上升</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00330</td><td>Coordinate Descent</td><td>坐标下降</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00331</td><td>Coparent</td><td>共父</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00332</td><td>Corpus</td><td>语料库</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00333</td><td>Correlation</td><td>相关系数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00334</td><td>Correlation Coefficient</td><td>相关系数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00335</td><td>Cosine</td><td>余弦</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00336</td><td>Cosine Decay</td><td>余弦衰减</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00337</td><td>Cosine Similarity</td><td>余弦相似度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00338</td><td>Cost</td><td>代价</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00339</td><td>Cost Curve</td><td>代价曲线</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00340</td><td>Cost Function</td><td>代价函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-00341</td><td>Cost Matrix</td><td>代价矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00342</td><td>Cost-Sensitive</td><td>代价敏感</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00343</td><td>Covariance</td><td>协方差</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00344</td><td>Covariance Matrix</td><td>协方差矩阵</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00345</td><td>Covariance RBM</td><td>协方差RBM</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00346</td><td>Covariate Shift</td><td>协变量偏移</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00347</td><td>Coverage</td><td>覆盖</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00348</td><td>Credit Assignment Problem</td><td>贡献度分配问题</td><td>CAP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00349</td><td>Criterion</td><td>准则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00350</td><td>Critic</td><td>评论员</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00351</td><td>Critic Network</td><td>评价网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00352</td><td>Critical Point</td><td>临界点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00353</td><td>Critical Temperatures</td><td>临界温度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00354</td><td>Cross Correlation</td><td>互相关</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00355</td><td>Cross Entropy</td><td>交叉熵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00356</td><td>Cross Validation</td><td>交叉验证</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-10-16-4">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00357</td><td>Cross-Entropy Loss Function</td><td>交叉熵损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00358</td><td>Crowdsourcing</td><td>众包</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-28-2">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00359</td><td>Cumulative Distribution Function</td><td>累积分布函数</td><td>CDF</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00360</td><td>Cumulative Function</td><td>累积函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00361</td><td>Curriculum Learning</td><td>课程学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00362</td><td>Curse of Dimensionality</td><td>维数灾难</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00363</td><td>Curvature</td><td>曲率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00364</td><td>Curve-Fitting</td><td>曲线拟合</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00365</td><td>Cut Point</td><td>截断点</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00366</td><td>Cutting Plane Algorithm</td><td>割平面法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00367</td><td>Cybernetics</td><td>控制论</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00368</td><td>Cyclic Learning Rate</td><td>循环学习率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00369</td><td>Damping</td><td>衰减</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00370</td><td>Damping Factor</td><td>阻尼因子</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00371</td><td>Data</td><td>数据</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00372</td><td>Data Augmentation</td><td>数据增强</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00373</td><td>Data Generating Distribution</td><td>数据生成分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00374</td><td>Data Generating Process</td><td>数据生成过程</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00375</td><td>Data Instance</td><td>数据样本</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00376</td><td>Data Mining</td><td>数据挖掘</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00377</td><td>Data Parallelism</td><td>数据并行</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00378</td><td>Data Point</td><td>数据点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00379</td><td>Data Preprocessing</td><td>数据预处理</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00380</td><td>Data Set</td><td>数据集</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-04-6">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a></td><td></td></tr><tr class="even"><td>AITD-00381</td><td>Data Wrangling</td><td>数据整理</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-08-25-5">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00382</td><td>Dataset Augmentation</td><td>数据集增强</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00383</td><td>Davidon-Fletcher-Powell</td><td>DFP</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00384</td><td>Debugging Strategy</td><td>调试策略</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00385</td><td>Decision Boundary</td><td>决策边界</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00386</td><td>Decision Function</td><td>决策函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00387</td><td>Decision Stump</td><td>决策树桩</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00388</td><td>Decision Surface</td><td>决策平面</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00389</td><td>Decision Tree</td><td>决策树</td><td>DT</td><td><a href="https://www.jiqizhixin.com/articles/2018-01-10">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-29-5">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[4]</a></td><td></td></tr><tr class="odd"><td>AITD-00390</td><td>Decoder</td><td>解码器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00391</td><td>Decoding</td><td>解码</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00392</td><td>Decompose</td><td>分解</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00393</td><td>Deconvolution</td><td>反卷积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00394</td><td>Deconvolutional Network</td><td>反卷积网络</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-09-14">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00395</td><td>Deduction</td><td>演绎</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00396</td><td>Deep Belief Network</td><td>深度信念网络</td><td>DBN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00397</td><td>Deep Boltzmann Machine</td><td>深度玻尔兹曼机</td><td>DBM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00398</td><td>Deep Circuit</td><td>深度回路</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00399</td><td>Deep Convolutional Generative Adversarial Network</td><td>深度卷积生成对抗网络</td><td>DCGAN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00400</td><td>Deep Feedforward Network</td><td>深度前馈网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00401</td><td>Deep Generative Model</td><td>深度生成模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00402</td><td>Deep Learning</td><td>深度学习</td><td>DL</td><td><a href="https://www.jiqizhixin.com/articles/2018-01-17-2">[1]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-15-4">[2]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-15-2">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[4]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[5]</a></td><td></td></tr><tr class="even"><td>AITD-00403</td><td>Deep Model</td><td>深度模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00404</td><td>Deep Network</td><td>深度网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00405</td><td>Deep Neural Network</td><td>深度神经网络</td><td>DNN</td><td><a href="https://www.jiqizhixin.com/articles/2018-01-15-2">[1]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-10">[2]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-07-2">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[4]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[5]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[6]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[7]</a></td><td></td></tr><tr class="odd"><td>AITD-00406</td><td>Deep Q-Learning</td><td>深度 Q 学习</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-10-10-2">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-08-22-8">[2]</a></td><td></td></tr><tr class="even"><td>AITD-00407</td><td>Deep Q-Network</td><td>深度Q网络</td><td>DQN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00408</td><td>Deep Reinforcement Learning</td><td>深度强化学习</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00409</td><td>Deep Sequence Model</td><td>深度序列模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00410</td><td>Default Rule</td><td>默认规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00411</td><td>Definite Integral</td><td>定积分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00412</td><td>Degree Of Belief</td><td>信任度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00413</td><td>Delta-Bar-Delta</td><td>Delta-Bar-Delta</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00414</td><td>Denoising</td><td>去噪</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00415</td><td>Denoising Autoencoder</td><td>去噪自编码器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00416</td><td>Denoising Score Matching</td><td>去躁分数匹配</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00417</td><td>Denominator Layout</td><td>分母布局</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00418</td><td>Dense</td><td>稠密</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00419</td><td>Density Estimation</td><td>密度估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00420</td><td>Density-Based Clustering</td><td>密度聚类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00421</td><td>Dependency</td><td>依赖</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00422</td><td>Depth</td><td>深度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00423</td><td>Derivative</td><td>导数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00424</td><td>Description</td><td>描述</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00425</td><td>Design Matrix</td><td>设计矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00426</td><td>Detailed Balance</td><td>细致平衡</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00427</td><td>Detailed Balance Equation</td><td>细致平衡方程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00428</td><td>Detector Stage</td><td>探测级</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00429</td><td>Determinant</td><td>行列式</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00430</td><td>Deterministic</td><td>确定性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00431</td><td>Deterministic Model</td><td>确定性模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00432</td><td>Deterministic Policy</td><td>确定性策略</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00433</td><td>Development Set</td><td>开发集</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00434</td><td>Diagonal Matrix</td><td>对角矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00435</td><td>Diameter</td><td>直径</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00436</td><td>Dictionary</td><td>字典</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00437</td><td>Dictionary Learning</td><td>字典学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00438</td><td>Differentiable Function</td><td>可微函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00439</td><td>Differentiable Neural Computer</td><td>可微分神经计算机</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-04-11-7">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00440</td><td>Differential Entropy</td><td>微分熵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00441</td><td>Differential Equation</td><td>微分方程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00442</td><td>Differentiation</td><td>微分</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00443</td><td>Dilated Convolution</td><td>膨胀卷积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00444</td><td>Dimension</td><td>维度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00445</td><td>Dimension Reduction</td><td>降维</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00446</td><td>Dimensionality Reduction Algorithm</td><td>降维算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-08-31-2">[2]</a></td><td></td></tr><tr class="even"><td>AITD-00447</td><td>Dirac Delta Function</td><td>Dirac Delta函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00448</td><td>Dirac Distribution</td><td>Dirac分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00449</td><td>Directed</td><td>有向</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00450</td><td>Directed Acyclic Graph</td><td>有向非循环图</td><td>DAG</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00451</td><td>Directed Edge</td><td>有向边</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00452</td><td>Directed Graph</td><td>有向图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00453</td><td>Directed Graphical Model</td><td>有向图模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00454</td><td>Directed Model</td><td>有向模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00455</td><td>Directed Separation</td><td>有向分离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00456</td><td>Directional Derivative</td><td>方向导数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00457</td><td>Dirichlet Distribution</td><td>狄利克雷分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00458</td><td>Disagreement Measure</td><td>不合度量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00459</td><td>Disagreement-Based Methods</td><td>基于分歧的方法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00460</td><td>Discount Factor</td><td>衰减系数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00461</td><td>Discounted Return</td><td>折扣回报</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00462</td><td>Discrete Optimization</td><td>离散优化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00463</td><td>Discriminant Function</td><td>判别函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00464</td><td>Discriminative Approach</td><td>判别方法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00465</td><td>Discriminative Model</td><td>判别式模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00466</td><td>Discriminative RBM</td><td>判别RBM</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00467</td><td>Discriminator</td><td>判别器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00468</td><td>Discriminator Network</td><td>判别网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00469</td><td>Distance</td><td>距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00470</td><td>Distance Measure</td><td>距离度量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00471</td><td>Distance Metric Learning</td><td>距离度量学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00472</td><td>Distributed Representation</td><td>分布式表示</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00473</td><td>Distribution</td><td>分布</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-09">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00474</td><td>Diverge</td><td>发散</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00475</td><td>Divergence</td><td>散度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00476</td><td>Diversity</td><td>多样性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00477</td><td>Diversity Measure</td><td>多样性度量/差异性度量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00478</td><td>Divide-And-Conquer</td><td>分而治之</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00479</td><td>Divisive</td><td>分裂</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00480</td><td>Domain</td><td>领域</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00481</td><td>Domain Adaptation</td><td>领域自适应</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00482</td><td>Dominant Eigenvalue</td><td>主特征值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00483</td><td>Dominant Eigenvector</td><td>主特征向量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00485</td><td>Dominant Strategy</td><td>占优策略</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00486</td><td>Dot Product</td><td>点积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00487</td><td>Double Backprop</td><td>双反向传播</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00488</td><td>Doubly Block Circulant Matrix</td><td>双重分块循环矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00489</td><td>Down Sampling</td><td>下采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00490</td><td>Downstream Task</td><td>下游任务</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00491</td><td>Dropout</td><td>暂退法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00492</td><td>Dropout Boosting</td><td>暂退Boosting</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00493</td><td>Dropout Mask</td><td>暂退掩码</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00494</td><td>Dropout Method</td><td>暂退法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00495</td><td>Dual Algorithm</td><td>对偶算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00496</td><td>Dual Problem</td><td>对偶问题</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00497</td><td>Dummy Node</td><td>哑结点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00498</td><td>Dying ReLU Problem</td><td>死亡ReLU问题</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00499</td><td>Dynamic Bayesian Network</td><td>动态贝叶斯网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00500</td><td>Dynamic Computational Graph</td><td>动态计算图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00501</td><td>Dynamic Fusion</td><td>动态融合</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00502</td><td>Dynamic Programming</td><td>动态规划</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00503</td><td>Dynamic Structure</td><td>动态结构</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00504</td><td>Dynamical System</td><td>动力系统</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00505</td><td>Eager Learning</td><td>急切学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00506</td><td>Early Stopping</td><td>早停</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00507</td><td>Earth-Mover's Distance</td><td>推土机距离</td><td>EMD</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00508</td><td>Echo State Network</td><td>回声状态网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00509</td><td>Edge</td><td>边</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00510</td><td>Edge Device</td><td>边缘设备</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-09-24-8">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00511</td><td>Effective Capacity</td><td>有效容量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00512</td><td>Eigendecomposition</td><td>特征分解</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-07-05-2">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00513</td><td>Eigenvalue</td><td>特征值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00514</td><td>Eigenvalue Decomposition</td><td>特征值分解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00515</td><td>Elastic Net Regularization</td><td>弹性网络正则化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00516</td><td>Elastic Weight Consolidation</td><td>弹性权重巩固</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00517</td><td>Element-Wise Product</td><td>逐元素积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00518</td><td>Elementary Basis Vectors</td><td>基本单位向量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00519</td><td>Ellipsoid Method</td><td>椭球法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00520</td><td>Embedding</td><td>嵌入</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-02-5">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00521</td><td>Embedding Lookup Table</td><td>嵌入表</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00522</td><td>Emotional Analysis</td><td>情绪分析</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00523</td><td>Empirical Conditional Entropy</td><td>经验条件熵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00524</td><td>Empirical Distribution</td><td>经验分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00525</td><td>Empirical Entropy</td><td>经验熵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00526</td><td>Empirical Error</td><td>经验误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00527</td><td>Empirical Frequency</td><td>经验频率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00528</td><td>Empirical Loss</td><td>经验损失</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00529</td><td>Empirical Risk</td><td>经验风险</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00530</td><td>Empirical Risk Minimization</td><td>经验风险最小化</td><td>ERM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00531</td><td>Encoder</td><td>编码器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00532</td><td>Encoder-Decoder</td><td>编码器-解码器（模型）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-00533</td><td>Encoding</td><td>编码</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00534</td><td>End-To-End</td><td>端到端</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-15">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00535</td><td>End-To-End Learning</td><td>端到端学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00536</td><td>End-To-End Memory Network</td><td>端到端记忆网络</td><td>Memn2N</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00537</td><td>Energy Function</td><td>能量函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00538</td><td>Energy Gap</td><td>能量差异</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00539</td><td>Energy-Based Model</td><td>基于能量的模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00540</td><td>Ensemble</td><td>集成</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00541</td><td>Ensemble Learning</td><td>集成学习</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-14-8">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00542</td><td>Ensemble Pruning</td><td>集成修剪</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00543</td><td>Entropy</td><td>熵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00544</td><td>Entropy Encoding</td><td>熵编码</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00545</td><td>Environment</td><td>环境</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00546</td><td>Episode</td><td>回合</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00547</td><td>Episodic Task</td><td>回合式任务</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00548</td><td>Epoch</td><td>轮</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00549</td><td>Equal-Width Convolution</td><td>等宽卷积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00550</td><td>Equality Constraint</td><td>等式约束</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00551</td><td>Equilibrium Distribution</td><td>均衡分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00552</td><td>Equivariance</td><td>等变</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00553</td><td>Equivariant Representations</td><td>等变表示</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00554</td><td>Error</td><td>误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00555</td><td>Error Backpropagation Algorithm</td><td>误差反向传播算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00556</td><td>Error Backpropagation</td><td>误差反向传播</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00557</td><td>Error Bar</td><td>误差条</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00558</td><td>Error Correcting Output Codes</td><td>纠错输出编码</td><td>ECOC</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00559</td><td>Error Function</td><td>误差函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00560</td><td>Error Metric</td><td>误差度量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00561</td><td>Error Rate</td><td>错误率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00562</td><td>Error-Ambiguity Decomposition</td><td>误差－分歧分解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00563</td><td>Estimation Error</td><td>估计误差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00564</td><td>Estimation Of Mathematical Expectation</td><td>数学期望估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00565</td><td>Estimator</td><td>估计/估计量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00566</td><td>Euclidean Distance</td><td>欧氏距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00567</td><td>Euclidean Norm</td><td>欧几里得范数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00568</td><td>Euclidean Space</td><td>欧氏空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00569</td><td>Euler-Lagrange Equation</td><td>欧拉-拉格朗日方程</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00570</td><td>Evaluation Criterion</td><td>评价准则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00571</td><td>Evidence</td><td>证据</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00572</td><td>Evidence Lower Bound</td><td>证据下界</td><td>ELBO</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00573</td><td>Evolution</td><td>演化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00574</td><td>Evolutionary Computation</td><td>演化计算</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00575</td><td>Exact</td><td>确切的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00576</td><td>Exact Inference</td><td>精确推断</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00577</td><td>Example</td><td>样例</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00578</td><td>Excess Error</td><td>额外误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00579</td><td>Exchangeable</td><td>可交换的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00580</td><td>Expectation</td><td>期望</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00581</td><td>Expectation Maximization Algorithm</td><td>期望极大算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00582</td><td>Expectation Maximization</td><td>期望最大化</td><td>EM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00583</td><td>Expectation Step</td><td>E步</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00584</td><td>Expected Error</td><td>期望错误</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00585</td><td>Expected Loss</td><td>期望损失</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00586</td><td>Expected Return</td><td>期望回报</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00587</td><td>Expected Risk</td><td>期望风险</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00588</td><td>Expected Value</td><td>期望值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00589</td><td>Experience</td><td>经验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00590</td><td>Experience Replay</td><td>经验回放</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00591</td><td>Expert Network</td><td>专家网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00592</td><td>Expert System</td><td>专家系统</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00593</td><td>Explaining Away</td><td>相消解释</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00594</td><td>Explaining Away Effect</td><td>相消解释作用</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00595</td><td>Explanatory Factort</td><td>解释因子</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00596</td><td>Explicit Density Model</td><td>显式密度模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00597</td><td>Exploding Gradient</td><td>梯度爆炸</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00598</td><td>Exploitation</td><td>利用</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00599</td><td>Exploration</td><td>探索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00600</td><td>Exploration-Exploitation Dilemma</td><td>探索-利用窘境</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00601</td><td>Exponential Decay</td><td>指数衰减</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00602</td><td>Exponential Distribution</td><td>指数分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00603</td><td>Exponential Linear Unit</td><td>指数线性单元</td><td>ELU</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00604</td><td>Exponential Loss</td><td>指数损失</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00605</td><td>Exponential Loss Function</td><td>指数损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00606</td><td>Exponentially Weighted Moving Average</td><td>指数加权移动平均</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00607</td><td>Exposure Bias</td><td>曝光偏差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00608</td><td>External Memory</td><td>外部记忆</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00609</td><td>Extreme Learning Machine</td><td>超限学习机</td><td>ELM</td><td><ahref="https://www.jiqizhixin.com/articles/2016-09-30-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00610</td><td>F Measure</td><td>F值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00611</td><td>F-Score</td><td>F分数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00612</td><td>Factor</td><td>因子</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00613</td><td>Factor Analysis</td><td>因子分析</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00614</td><td>Factor Graph</td><td>因子图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00615</td><td>Factor Loading</td><td>因子负荷量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00616</td><td>Factorization</td><td>因子分解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00617</td><td>Factorized</td><td>分解的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00618</td><td>Factors of Variation</td><td>变差因素</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00619</td><td>False Negative</td><td>假负例</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00620</td><td>False Positive</td><td>假正例</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00621</td><td>False Positive Rate</td><td>假正例率</td><td>FPR</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00622</td><td>Fast Dropout</td><td>快速暂退法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00623</td><td>Fast Persistent Contrastive Divergence</td><td>快速持续性对比散度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00624</td><td>Fault-Tolerant Asynchronous Training</td><td>容错异步训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00625</td><td>Feasible</td><td>可行</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00626</td><td>Feature</td><td>特征</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00627</td><td>Feature Engineering</td><td>特征工程</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00628</td><td>Feature Extraction</td><td>特征抽取</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00629</td><td>Feature Extractor</td><td>特征提取器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00630</td><td>Feature Function</td><td>特征函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00631</td><td>Feature Map</td><td>特征图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00632</td><td>Feature Scaling Transform</td><td>特征尺度变换</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00633</td><td>Feature Selection</td><td>特征选择</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-00634</td><td>Feature Space</td><td>特征空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00635</td><td>Feature Vector</td><td>特征向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00636</td><td>Featured Learning</td><td>特征学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00637</td><td>Feedback</td><td>反馈</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00638</td><td>Feedforward</td><td>前馈</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00639</td><td>Feedforward Classifier</td><td>前馈分类器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00640</td><td>Feedforward Network</td><td>前馈网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00641</td><td>Feedforward Neural Network</td><td>前馈神经网络</td><td>FNN</td><td><a href="https://www.jiqizhixin.com/articles/2017-09-07-9">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-00642</td><td>Few-Shot Learning</td><td>少试学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00643</td><td>Fidelity</td><td>逼真度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00644</td><td>Field Programmable Gated Array</td><td>现场可编程门阵列</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00645</td><td>Filter</td><td>滤波器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00646</td><td>Filter Method</td><td>过滤式方法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00647</td><td>Fine-Tuning</td><td>微调</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00648</td><td>Finite Difference</td><td>有限差分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00649</td><td>First Layer</td><td>第一层</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00650</td><td>First-Order Method</td><td>一阶方法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00651</td><td>First-Order Rule</td><td>一阶规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00652</td><td>Fisher Information Matrix</td><td>Fisher信息矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00653</td><td>Fixed Point Equation</td><td>不动点方程</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00654</td><td>Fixed-Point Arithmetic</td><td>不动点运算</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00655</td><td>Flat Minima</td><td>平坦最小值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00656</td><td>Flip</td><td>翻转</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00657</td><td>Flipping Output</td><td>翻转法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00658</td><td>Float-Point Arithmetic</td><td>浮点运算</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00659</td><td>Fluctuation</td><td>振荡</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00660</td><td>Focus Attention</td><td>聚焦式注意力</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00661</td><td>Folk Theorem</td><td>无名氏定理</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00662</td><td>Forget Gate</td><td>遗忘门</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00663</td><td>Forward</td><td>前向</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00664</td><td>Forward KL Divergence</td><td>前向KL散度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00665</td><td>Forward Mode Accumulation</td><td>前向模式累加</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00666</td><td>Forward Propagation</td><td>前向传播/正向传播</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00667</td><td>Forward Search</td><td>前向搜索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00668</td><td>Forward Stagewise Algorithm</td><td>前向分步算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00669</td><td>Forward-Backward Algorithm</td><td>前向-后向算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00670</td><td>Fourier Transform</td><td>傅立叶变换</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00671</td><td>Fovea</td><td>中央凹</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00672</td><td>Fractionally Strided Convolution</td><td>微步卷积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00673</td><td>Free Energy</td><td>自由能</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00674</td><td>Frequentist</td><td>频率主义学派</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00675</td><td>Frequentist Probability</td><td>频率派概率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00676</td><td>Frequentist Statistics</td><td>频率派统计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00677</td><td>Frobenius Norm</td><td>Frobenius 范数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00678</td><td>Full</td><td>全</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00679</td><td>Full Conditional Distribution</td><td>满条件分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00680</td><td>Full Conditional Probability</td><td>全条件概率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00681</td><td>Full Padding</td><td>全填充</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00682</td><td>Full Singular Value Decomposition</td><td>完全奇异值分解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00683</td><td>Full-Rank Matrix</td><td>满秩矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00684</td><td>Fully Connected Layer</td><td>全连接层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00685</td><td>Fully Connected Neural Network</td><td>全连接神经网络</td><td>FCNN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00686</td><td>Fully Convolutional Network</td><td>全卷积网络</td><td>FCN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00687</td><td>Function</td><td>函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00688</td><td>Functional</td><td>泛函</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00689</td><td>Functional Derivative</td><td>泛函导数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00690</td><td>Functional Margin</td><td>函数间隔</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00691</td><td>Functional Neuron</td><td>功能神经元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00692</td><td>Gabor Function</td><td>Gabor函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00693</td><td>Gain Ratio</td><td>増益率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00694</td><td>Game Payoff</td><td>博弈效用</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00695</td><td>Game Theory</td><td>博弈论</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00696</td><td>Gamma Distribution</td><td>Gamma分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00697</td><td>Gate</td><td>门</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00698</td><td>Gate Controlled RNN</td><td>门控循环神经网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00699</td><td>Gated</td><td>门控</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00700</td><td>Gated Control</td><td>门控</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00701</td><td>Gated Recurrent Net</td><td>门控循环网络</td><td>GRN</td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-24">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00702</td><td>Gated Recurrent Unit</td><td>门控循环单元</td><td>GRU</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00703</td><td>Gated RNN</td><td>门控RNN</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00704</td><td>Gater</td><td>选通器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00705</td><td>Gating Mechanism</td><td>门控机制</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00706</td><td>Gaussian Distribution</td><td>高斯分布</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00707</td><td>Gaussian Error Linear Unit</td><td>高斯误差线性单元</td><td>GELU</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00708</td><td>Gaussian Kernel</td><td>高斯核</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00709</td><td>Gaussian Kernel Function</td><td>高斯核函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00710</td><td>Gaussian Mixture Model</td><td>高斯混合模型</td><td>GMM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00711</td><td>Gaussian Mixtures</td><td>高斯混合（模型）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00712</td><td>Gaussian Output Distribution</td><td>高斯输出分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00713</td><td>Gaussian Process</td><td>高斯过程</td><td>GP</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a></td><td></td></tr><tr class="even"><td>AITD-00714</td><td>Gaussian Process Regression</td><td>高斯过程回归</td><td>GPR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00715</td><td>Gaussian RBM</td><td>高斯RBM</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00716</td><td>Gaussian-Bernoulli RBM</td><td>高斯-伯努利RBM</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00717</td><td>General Problem Solving</td><td>通用问题求解</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00718</td><td>General Purpose GPU</td><td>通用GPU</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00719</td><td>Generalization Ability</td><td>泛化能力</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00720</td><td>Generalization Error</td><td>泛化误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00721</td><td>Generalization Error Bound</td><td>泛化误差上界</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00722</td><td>Generalize</td><td>泛化</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-25-10">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00723</td><td>Generalized Bregman Divergence</td><td>一般化 Bregman 散度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00724</td><td>Generalized Expectation Maximization</td><td>广义期望极大</td><td>GEM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00725</td><td>Generalized Function</td><td>广义函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00726</td><td>Generalized Lagrange Function</td><td>广义拉格朗日函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00727</td><td>Generalized Lagrangian</td><td>广义拉格朗日</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00728</td><td>Generalized Linear Model</td><td>广义线性模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00729</td><td>Generalized Pseudolikelihood</td><td>广义伪似然</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00730</td><td>Generalized Pseudolikelihood Estimator</td><td>广义伪似然估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00731</td><td>Generalized Rayleigh Quotient</td><td>广义瑞利商</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00732</td><td>Generalized Score Matching</td><td>广义得分匹配</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00733</td><td>Generative Adversarial Framework</td><td>生成式对抗框架</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00734</td><td>Generative Adversarial Network</td><td>生成对抗网络</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-12-26-4">[1]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-08-5">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-13-2">[3]</a></td><td></td></tr><tr class="odd"><td>AITD-00735</td><td>Generative Approach</td><td>生成方法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00736</td><td>Generative Model</td><td>生成式模型</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-12-19-7">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-11-6">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-04-5">[3]</a></td><td></td></tr><tr class="odd"><td>AITD-00737</td><td>Generative Modeling</td><td>生成式建模</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00738</td><td>Generative Moment Matching Network</td><td>生成矩匹配网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00739</td><td>Generative Pre-Training</td><td>生成式预训练</td><td>GPT</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00740</td><td>Generative Stochastic Network</td><td>生成随机网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00741</td><td>Generative Weight</td><td>生成权重</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00742</td><td>Generator</td><td>生成器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00743</td><td>Generator Network</td><td>生成器网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00744</td><td>Genetic Algorithm</td><td>遗传算法</td><td>GA</td><td><a href="https://www.jiqizhixin.com/articles/2018-01-17-3">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-22">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-12-2">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[4]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[5]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[6]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-00745</td><td>Geometric Margin</td><td>几何间隔</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00746</td><td>Giant Magnetoresistance</td><td>巨磁阻</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00747</td><td>Gibbs Distribution</td><td>吉布斯分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00748</td><td>Gibbs Sampling</td><td>吉布斯采样/吉布斯抽样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00749</td><td>Gibbs Steps</td><td>吉布斯步数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00750</td><td>Gini Index</td><td>基尼指数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00751</td><td>Global Contrast Normalization</td><td>全局对比度规范化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00752</td><td>Global Markov Property</td><td>全局马尔可夫性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00753</td><td>Global Minima</td><td>全局极小值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00754</td><td>Global Minimizer</td><td>全局极小解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00755</td><td>Global Minimum</td><td>全局最小</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00756</td><td>Global Optimization</td><td>全局优化</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-03-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00757</td><td>Gradient</td><td>梯度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00758</td><td>Gradient Ascent</td><td>梯度上升</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00759</td><td>Gradient Ascent Method</td><td>梯度上升法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00760</td><td>Gradient Boosting</td><td>梯度提升</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00761</td><td>Gradient Boosting Tree</td><td>梯度提升树</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00762</td><td>Gradient Clipping</td><td>梯度截断</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00763</td><td>Gradient Descent</td><td>梯度下降</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[3]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00764</td><td>Gradient Descent In One-Dimensional Space</td><td>一维梯度下降</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00765</td><td>Gradient Descent Method</td><td>梯度下降法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00766</td><td>Gradient Energy Distribution</td><td>梯度能量分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00767</td><td>Gradient Estimation</td><td>梯度估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00768</td><td>Gradient Exploding Problem</td><td>梯度爆炸问题</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-21-14">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00769</td><td>Gradient Field</td><td>梯度场</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00770</td><td>Gradual Warmup</td><td>逐渐预热</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00771</td><td>Gram Matrix</td><td>Gram 矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00772</td><td>Graph</td><td>图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00773</td><td>Graph Analytics</td><td>图分析</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00774</td><td>Graph Attention Network</td><td>图注意力网络</td><td>GAT</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00775</td><td>Graph Convolutional Network</td><td>图卷积神经网络/图卷积网络</td><td>GCN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00776</td><td>Graph Neural Network</td><td>图神经网络</td><td>GNN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00777</td><td>Graph Theory</td><td>图论</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-04-04-4">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00778</td><td>Graphical Model</td><td>图模型</td><td>GM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00779</td><td>Graphics Processing Unit</td><td>图形处理器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00780</td><td>Greedy</td><td>贪心</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00781</td><td>Greedy Algorithm</td><td>贪心算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00782</td><td>Greedy Layer-Wise Pretraining</td><td>贪心逐层预训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00783</td><td>Greedy Layer-Wise Training</td><td>贪心逐层训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00784</td><td>Greedy Layer-Wise Unsupervised Pretraining</td><td>贪心逐层无监督预训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00785</td><td>Greedy Search</td><td>贪心搜索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00786</td><td>Greedy Supervised Pretraining</td><td>贪心监督预训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00787</td><td>Greedy Unsupervised Pretraining</td><td>贪心无监督预训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00788</td><td>Grid Search</td><td>网格搜索</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00789</td><td>Grid World</td><td>网格世界</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00790</td><td>Ground Truth</td><td>真实值</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00791</td><td>Growth Function</td><td>增长函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00792</td><td>Hadamard Product</td><td>Hadamard积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00793</td><td>Hamming Distance</td><td>汉明距离</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00794</td><td>Hard Attention</td><td>硬性注意力</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00795</td><td>Hard Clustering</td><td>硬聚类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00796</td><td>Hard Margin</td><td>硬间隔</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00797</td><td>Hard Margin Maximization</td><td>硬间隔最大化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00798</td><td>Hard Mixture Of Experts</td><td>硬专家混合体</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00799</td><td>Hard Tanh</td><td>硬双曲正切函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00800</td><td>Hard Target</td><td>硬目标</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00801</td><td>Hard Voting</td><td>硬投票</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00802</td><td>Harmonic Mean</td><td>调和平均</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00803</td><td>Harmonium</td><td>簧风琴</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00804</td><td>Harmony</td><td>Harmony</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00805</td><td>Harris Chain</td><td>哈里斯链</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00806</td><td>Hausdorff Distance</td><td>豪斯多夫距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00807</td><td>Hebbian Rule</td><td>赫布法则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00808</td><td>Hebbian Theory</td><td>赫布理论</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00809</td><td>Helmholtz Machine</td><td>Helmholtz机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00810</td><td>Hesse Matrix</td><td>海赛矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00811</td><td>Hessian</td><td>Hessian</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00812</td><td>Hessian Matrix</td><td>黑塞矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00813</td><td>Heterogeneous Information Network</td><td>异质信息网络</td><td>HIN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00814</td><td>Heteroscedastic</td><td>异方差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00815</td><td>Hidden Dynamic Model</td><td>隐动态模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00816</td><td>Hidden Layer</td><td>隐藏层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00817</td><td>Hidden Markov Model</td><td>隐马尔可夫模型</td><td>HMM</td><td><ahref="https://www.jiqizhixin.com/articles/2017-09-21-8">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00818</td><td>Hidden State</td><td>隐状态</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00819</td><td>Hidden Unit</td><td>隐藏单元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00820</td><td>Hidden Variable</td><td>隐变量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00821</td><td>Hierarchical Clustering</td><td>层次聚类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00822</td><td>Hierarchical Reinforcement Learning</td><td>分层强化学习</td><td>HRL</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00823</td><td>Hierarchical Softmax</td><td>层序Softmax/层序软最大化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00824</td><td>Hilbert Space</td><td>希尔伯特空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00825</td><td>Hill Climbing</td><td>爬山</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00826</td><td>Hinge Loss Function</td><td>合页损失函数/Hinge损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00827</td><td>Histogram Method</td><td>直方图方法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00828</td><td>Hold-Out</td><td>留出法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00829</td><td>Homogeneous</td><td>同质</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00830</td><td>Hopfield Network</td><td>Hopfield网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00831</td><td>Huffman Coding</td><td>霍夫曼编码</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00832</td><td>Hybrid Computing</td><td>混合计算</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00833</td><td>Hyperbolic Tangent Function</td><td>双曲正切函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00834</td><td>Hyperparameter</td><td>超参数</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-08-18-5">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-28">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-00835</td><td>Hyperparameter Optimization</td><td>超参数优化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00836</td><td>Hyperplane</td><td>超平面</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>数学</td></tr><tr class="odd"><td>AITD-00837</td><td>Hypothesis</td><td>假设</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00838</td><td>Hypothesis Space</td><td>假设空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00839</td><td>Hypothesis Test</td><td>假设检验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00840</td><td>I.I.D. Assumption</td><td>独立同分布假设</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00841</td><td>Identically Distributed</td><td>同分布的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00842</td><td>Identifiable</td><td>可辨认的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00843</td><td>Identity Function</td><td>恒等函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00844</td><td>Identity Mapping</td><td>恒等映射</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00845</td><td>Identity Matrix</td><td>单位矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00846</td><td>Ill Conditioning</td><td>病态</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00847</td><td>Ill-Formed Problem</td><td>病态问题</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00848</td><td>Image</td><td>图像</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00849</td><td>Image Restoration</td><td>图像还原</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00850</td><td>Imitation Learning</td><td>模仿学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00851</td><td>Immorality</td><td>不道德</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00852</td><td>Imperfect Information</td><td>不完美信息</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-11-16-4">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00853</td><td>Implicit Density Model</td><td>隐式密度模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00854</td><td>Import</td><td>导入</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00855</td><td>Importance Sampling</td><td>重要性采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00856</td><td>Improved Iterative Scaling</td><td>改进的迭代尺度法</td><td>IIS</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00857</td><td>Incomplete-Data</td><td>不完全数据</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00858</td><td>Incremental Learning</td><td>增量学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00859</td><td>Indefinite Integral</td><td>不定积分</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00860</td><td>Independence</td><td>独立</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00861</td><td>Independent</td><td>相互独立的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00862</td><td>Independent and Identically Distributed</td><td>独立同分布</td><td>I.I.D.</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00863</td><td>Independent Component Analysis</td><td>独立成分分析</td><td>ICA</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00864</td><td>Independent Subspace Analysis</td><td>独立子空间分析</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00865</td><td>Index of Matrix</td><td>索引</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00866</td><td>Indicator Function</td><td>指示函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00867</td><td>Individual Learner</td><td>个体学习器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00868</td><td>Induction</td><td>归纳</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00869</td><td>Inductive Bias</td><td>归纳偏好</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00870</td><td>Inductive Learning</td><td>归纳学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00871</td><td>Inductive Logic Programming</td><td>归纳逻辑程序设计</td><td>ILP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00872</td><td>Inductive Transfer Learning</td><td>归纳迁移学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00873</td><td>Inequality Constraint</td><td>不等式约束</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00874</td><td>Inference</td><td>推断</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-14-6">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00875</td><td>Infinite</td><td>无限</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00876</td><td>Infinitely Exchangeable</td><td>无限可交换</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00877</td><td>Information Divergence</td><td>信息散度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00878</td><td>Information Entropy</td><td>信息熵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00879</td><td>Information Gain</td><td>信息增益</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-00880</td><td>Information Gain Ratio</td><td>信息增益比</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-00881</td><td>Information Retrieval</td><td>信息检索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00882</td><td>Information Theory</td><td>信息论</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00883</td><td>Inner Product</td><td>内积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00884</td><td>Input</td><td>输入</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00885</td><td>Input Distribution</td><td>输入分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00886</td><td>Input Gate</td><td>输入门</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00887</td><td>Input Layer</td><td>输入层</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00888</td><td>Input Space</td><td>输入空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00889</td><td>Insensitive Loss</td><td>不敏感损失</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00890</td><td>Instance</td><td>示例</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00891</td><td>Instance Segmentation</td><td>实例分割</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00892</td><td>Integer Linear Programming</td><td>整数线性规划</td><td>ILP</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00893</td><td>Integer Programming</td><td>整数规划</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00894</td><td>Integration</td><td>积分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00895</td><td>Inter-Cluster Similarity</td><td>簇间相似度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00896</td><td>Internal Covariate Shift</td><td>内部协变量偏移</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00897</td><td>Internal Node</td><td>内部结点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00898</td><td>International Conference For Machine Learning</td><td>国际机器学习大会</td><td>ICML</td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-31">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00899</td><td>Intervention Query</td><td>干预查询</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00900</td><td>Intra-Attention</td><td>内部注意力</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00901</td><td>Intra-Cluster Similarity</td><td>簇内相似度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00902</td><td>Intrinsic Value</td><td>固有值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00903</td><td>Invariance</td><td>不变性</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-16-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00904</td><td>Invariant</td><td>不变</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00905</td><td>Inverse Matrix</td><td>逆矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00906</td><td>Inverse Reinforcement Learning</td><td>逆强化学习</td><td>IRL</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00907</td><td>Inverse Resolution</td><td>逆归结</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00908</td><td>Inverse Time Decay</td><td>逆时衰减</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00909</td><td>Invert</td><td>求逆</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00910</td><td>Irreducible</td><td>不可约的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00911</td><td>Irrelevant Feature</td><td>无关特征</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00912</td><td>Isometric Mapping</td><td>等度量映射</td><td>Isomap</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00913</td><td>Isotonic Regression</td><td>等分回归</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00914</td><td>Isotropic</td><td>各向同性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00915</td><td>Isotropic Gaussian Distribution</td><td>各向同性高斯分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00916</td><td>Iteration</td><td>迭代</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[2]</a></td><td>数学、机器学习</td></tr><tr class="odd"><td>AITD-00917</td><td>Iterative Dichotomiser</td><td>迭代二分器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00918</td><td>Jacobian</td><td>雅克比</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00919</td><td>Jacobian Matrix</td><td>雅可比矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00920</td><td>Jensen Inequality</td><td>Jensen不等式</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00921</td><td>Jensen-Shannon Divergence</td><td>JS散度</td><td>JSD</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00922</td><td>Joint Probability Density Function</td><td>联合概率密度函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00923</td><td>Joint Probability Distribution</td><td>联合概率分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00924</td><td>Junction Tree Algorithm</td><td>联合树算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00925</td><td>K-Armed Bandit Problem</td><td>k-摇臂老虎机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00926</td><td>K-Fold Cross Validation</td><td>k 折交叉验证</td><td>K-FOLD CV</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-00927</td><td>K-Means Clustering</td><td>k-均值聚类</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-11-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-00928</td><td>K-Nearest Neighbor Classifier</td><td>k-近邻分类器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00929</td><td>K-Nearest Neighbor Method</td><td>k-近邻</td><td>K-NN</td><td>[1]</td><td>统计</td></tr><tr class="even"><td>AITD-00930</td><td>Karush-Kuhn-Tucker Condition</td><td>KKT条件</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00931</td><td>Karush–Kuhn–Tucker</td><td>Karush–Kuhn–Tucker</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00932</td><td>Kd Tree</td><td>Kd 树</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00933</td><td>Kernel Density Estimation</td><td>核密度估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00934</td><td>Kernel Function</td><td>核函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00935</td><td>Kernel Machine</td><td>核机器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00936</td><td>Kernel Matrix</td><td>核矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00937</td><td>Kernel Method</td><td>核方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-00938</td><td>Kernel Regression</td><td>核回归</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00939</td><td>Kernel Trick</td><td>核技巧</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00940</td><td>Kernelized</td><td>核化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00941</td><td>Kernelized Linear Discriminant Analysis</td><td>核线性判别分析</td><td>KLDA</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00942</td><td>Kernelized PCA</td><td>核主成分分析</td><td>KPCA</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00943</td><td>Key-Value Store</td><td>键-值数据库</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00944</td><td>KL Divergence</td><td>KL散度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00945</td><td>Knowledge</td><td>知识</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00946</td><td>Knowledge Base</td><td>知识库</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-21-10">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00947</td><td>Knowledge Distillation</td><td>知识蒸馏</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00948</td><td>Knowledge Engineering</td><td>知识工程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00949</td><td>Knowledge Graph</td><td>知识图谱</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-11-03-5">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-03-24">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-09-26-8">[3]</a></td><td></td></tr><tr class="even"><td>AITD-00950</td><td>Knowledge Representation</td><td>知识表征</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00951</td><td>Kronecker Product</td><td>Kronecker积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00952</td><td>Krylov Method</td><td>Krylov方法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00953</td><td>L-BFGS</td><td>L-BFGS</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00954</td><td>Label</td><td>标签/标记</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00955</td><td>Label Propagation</td><td>标记传播</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00956</td><td>Label Smoothing</td><td>标签平滑</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00957</td><td>Label Space</td><td>标记空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00958</td><td>Labeled</td><td>标注</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00959</td><td>Lagrange Dual Problem</td><td>拉格朗日对偶问题</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00960</td><td>Lagrange Duality</td><td>拉格朗日对偶性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00961</td><td>Lagrange Function</td><td>拉格朗日函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00962</td><td>Lagrange Multiplier</td><td>拉格朗日乘子</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00963</td><td>Language Model</td><td>语言模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00964</td><td>Language Modeling</td><td>语言模型化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00965</td><td>Laplace Distribution</td><td>Laplace分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00966</td><td>Laplace Smoothing</td><td>拉普拉斯平滑</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00967</td><td>Laplacian Correction</td><td>拉普拉斯修正</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00968</td><td>Large Learning Step</td><td>大学习步骤</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00969</td><td>Las Vegas Method</td><td>拉斯维加斯方法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00970</td><td>Latent</td><td>潜在</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00971</td><td>Latent Dirichlet Allocation</td><td>潜在狄利克雷分配</td><td>LDA</td><td><ahref="https://www.jiqizhixin.com/articles/2017-09-01-7">[1]</a></td><td></td></tr><tr class="even"><td>AITD-00972</td><td>Latent Layer</td><td>潜层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00973</td><td>Latent Semantic Analysis</td><td>潜在语义分析</td><td>LSA</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00974</td><td>Latent Semantic Indexing</td><td>潜在语义索引</td><td>LSI</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00975</td><td>Latent Variable</td><td>潜变量/隐变量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00976</td><td>Law of Large Numbers</td><td>大数定律</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00977</td><td>Layer</td><td>层</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00978</td><td>Layer Normalization</td><td>层规范化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00979</td><td>Layer-Wise</td><td>逐层的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00980</td><td>Layer-Wise Adaptive Rate Scaling</td><td>逐层适应率缩放</td><td>LARS</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00981</td><td>Layer-Wise Normalization</td><td>逐层规范化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00982</td><td>Layer-Wise Pretraining</td><td>逐层预训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00983</td><td>Layer-Wise Training</td><td>逐层训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00984</td><td>Lazy Learning</td><td>懒惰学习</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-00985</td><td>Leaf Node</td><td>叶结点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00986</td><td>Leaky Lelu Function</td><td>泄漏线性整流函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00987</td><td>Leaky Relu</td><td>泄漏修正线性单元/泄漏整流线性单元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00988</td><td>Leaky Unit</td><td>渗漏单元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00989</td><td>Learned</td><td>学成</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00990</td><td>Learned Approximate Inference</td><td>学习近似推断</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00991</td><td>Learner</td><td>学习器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00992</td><td>Learning</td><td>学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00993</td><td>Learning Algorithm</td><td>学习算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00994</td><td>Learning By Analogy</td><td>类比学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00995</td><td>Learning Rate</td><td>学习率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00996</td><td>Learning Rate Annealing</td><td>学习率退火</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00997</td><td>Learning Rate Decay</td><td>学习率衰减</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-00998</td><td>Learning Rate Warmup</td><td>学习率预热</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-00999</td><td>Learning To Learn</td><td>学习的学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01000</td><td>Learning Vector Quantization</td><td>学习向量量化</td><td>LVQ</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01001</td><td>Least General Generalization</td><td>最小一般泛化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01002</td><td>Least Mean Squares</td><td>最小均方</td><td>LMS</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01003</td><td>Least Square Method</td><td>最小二乘法</td><td>LSM</td><td><ahref="https://www.jiqizhixin.com/articles/2017-09-24-5">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01004</td><td>Least Squares Regression Tree</td><td>最小二乘回归树</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01005</td><td>Leave-One-Out Cross Validation</td><td>留一交叉验证</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01006</td><td>Leave-One-Out</td><td>留一法</td><td>LOO</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01007</td><td>Lebesgue-Integrable</td><td>勒贝格可积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01008</td><td>Left Eigenvector</td><td>左特征向量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01009</td><td>Left Singular Vector</td><td>左奇异向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01010</td><td>Leibniz's Rule</td><td>莱布尼兹法则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01011</td><td>Lifelong Learning</td><td>终身学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01012</td><td>Likelihood</td><td>似然</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01013</td><td>Line Search</td><td>线搜索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01014</td><td>Linear Auto-Regressive Network</td><td>线性自回归网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01015</td><td>Linear Chain</td><td>线性链</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01016</td><td>Linear Chain Conditional Random Field</td><td>线性链条件随机场</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01017</td><td>Linear Classification Model</td><td>线性分类模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01018</td><td>Linear Classifier</td><td>线性分类器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01019</td><td>Linear Combination</td><td>线性组合</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>数学</td></tr><tr class="even"><td>AITD-01020</td><td>Linear Dependence</td><td>线性相关</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01021</td><td>Linear Discriminant Analysis</td><td>线性判别分析</td><td>LDA</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td>统计、机器学习</td></tr><tr class="even"><td>AITD-01022</td><td>Linear Factor Model</td><td>线性因子模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01023</td><td>Linear Mapping</td><td>线性映射</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01024</td><td>Linear Model</td><td>线性模型</td><td>LR</td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[2]</a></td><td>统计、机器学习</td></tr><tr class="odd"><td>AITD-01025</td><td>Linear Programming</td><td>线性规划</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01026</td><td>Linear Regression</td><td>线性回归</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-01">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-17-5">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[3]</a></td><td>统计、数学</td></tr><tr class="odd"><td>AITD-01027</td><td>Linear Scaling Rule</td><td>线性缩放规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01028</td><td>Linear Scan</td><td>线性扫描</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01029</td><td>Linear Space</td><td>线性空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01030</td><td>Linear Support Vector Machine</td><td>线性支持向量机</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01031</td><td>Linear Support Vector Machine In Linearly Separable Case</td><td>线性可分支持向量机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01032</td><td>Linear Threshold Units</td><td>线性阈值单元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01033</td><td>Linear Transformation</td><td>线性变换</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01034</td><td>Linearly Independent</td><td>线性无关</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01035</td><td>Linearly Separable</td><td>线性可分</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01036</td><td>Linearly Separable Data Set</td><td>线性可分数据集</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01037</td><td>Link Analysis</td><td>链接分析</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01038</td><td>Link Function</td><td>联系函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01039</td><td>Link Prediction</td><td>链接预测</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01040</td><td>Link Table</td><td>连接表</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01041</td><td>Linkage</td><td>连接</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01042</td><td>Linked Importance Sampling</td><td>链接重要采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01043</td><td>Lipschitz</td><td>Lipschitz</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01044</td><td>Lipschitz Constant</td><td>Lipschitz常数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01045</td><td>Lipschitz Continuous</td><td>Lipschitz连续</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01046</td><td>Liquid State Machine</td><td>流体状态机</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01047</td><td>Local Conditional Probability Distribution</td><td>局部条件概率分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01048</td><td>Local Constancy Prior</td><td>局部不变性先验</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01049</td><td>Local Contrast Normalization</td><td>局部对比度规范化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01050</td><td>Local Curvature</td><td>局部曲率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01051</td><td>Local Descent</td><td>局部下降</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01052</td><td>Local Invariances</td><td>局部不变性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01053</td><td>Local Kernel</td><td>局部核</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01054</td><td>Local Markov Property</td><td>局部马尔可夫性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01055</td><td>Local Maxima</td><td>局部极大值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01056</td><td>Local Maximum</td><td>局部极大点</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01057</td><td>Local Minima</td><td>局部极小</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01058</td><td>Local Minimizer</td><td>局部最小解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01059</td><td>Local Minimum</td><td>局部极小</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01060</td><td>Local Representation</td><td>局部式表示/局部式表征</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01061</td><td>Local Response Normalization</td><td>局部响应规范化</td><td>LRN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01062</td><td>Locally Linear Embedding</td><td>局部线性嵌入</td><td>LLE</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01063</td><td>Log Likelihood</td><td>对数似然函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01064</td><td>Log Linear Model</td><td>对数线性模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01065</td><td>Log-Likelihood</td><td>对数似然</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01066</td><td>Log-Likelihood Loss Function</td><td>对数似然损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01067</td><td>Log-Linear Regression</td><td>对数线性回归</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01068</td><td>Logarithmic Loss Function</td><td>对数损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01069</td><td>Logarithmic Scale</td><td>对数尺度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01070</td><td>Logistic Distribution</td><td>对数几率分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01071</td><td>Logistic Function</td><td>对数几率函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00398/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01072</td><td>Logistic Loss</td><td>对率损失</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01073</td><td>Logistic Regression</td><td>对数几率回归(逻辑回归)</td><td>LR</td><td><a href="https://www.jiqizhixin.com/articles/2017-11-23-6">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[2]</a></td><td>统计、机器学习</td></tr><tr class="even"><td>AITD-01074</td><td>Logistic Sigmoid</td><td>对数几率Sigmoid</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01075</td><td>Logit</td><td>对数几率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01076</td><td>Long Short Term Memory</td><td>长短期记忆</td><td>LSTM</td><td><a href="https://www.jiqizhixin.com/articles/2017-12-18-6">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-10-04-2">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-09-29-7">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[4]</a></td><td></td></tr><tr class="odd"><td>AITD-01077</td><td>Long Short-Term Memory Network</td><td>长短期记忆网络</td><td>LSTM</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01078</td><td>Long-Term Dependencies Problem</td><td>长程依赖问题</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01079</td><td>Long-Term Dependency</td><td>长期依赖</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01080</td><td>Long-Term Memory</td><td>长期记忆</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01081</td><td>Loop</td><td>环</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01082</td><td>Loopy Belief Propagation</td><td>环状信念传播</td><td>LBP</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01083</td><td>Loss</td><td>损失</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01084</td><td>Loss Function</td><td>损失函数</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-03-4">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[2]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01085</td><td>Low Rank Matrix Approximation</td><td>低秩矩阵近似</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01086</td><td>Lp Distance</td><td>Lp距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01087</td><td>Machine Learning Model</td><td>机器学习模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01088</td><td>Machine Learning</td><td>机器学习</td><td>ML</td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01089</td><td>Machine Translation</td><td>机器翻译</td><td>MT</td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-13-5">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01090</td><td>Macro Average</td><td>宏平均</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01091</td><td>Macro-F1</td><td>宏F1</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01092</td><td>Macro-P</td><td>宏查准率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01093</td><td>Macron-R</td><td>宏查全率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01094</td><td>Mahalanobis Distance</td><td>马哈拉诺比斯距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01095</td><td>Main Diagonal</td><td>主对角线</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01096</td><td>Majority Voting</td><td>绝对多数投票</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01097</td><td>Majority Voting Rule</td><td>多数表决规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01098</td><td>Manhattan Distance</td><td>曼哈顿距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01099</td><td>Manifold</td><td>流形</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01100</td><td>Manifold Assumption</td><td>流形假设</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01101</td><td>Manifold Learning</td><td>流形学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01102</td><td>Manifold Tangent Classifier</td><td>流形正切分类器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01103</td><td>Margin</td><td>间隔</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01104</td><td>Margin Theory</td><td>间隔理论</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01105</td><td>Marginal Distribution</td><td>边缘分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01106</td><td>Marginal Independence</td><td>边缘独立性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01107</td><td>Marginal Likelihood</td><td>边缘似然函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01108</td><td>Marginal Probability Distribution</td><td>边缘概率分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01109</td><td>Marginalization</td><td>边缘化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01110</td><td>Markov Blanket</td><td>马尔可夫毯</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01111</td><td>Markov Chain</td><td>马尔可夫链</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01112</td><td>Markov Chain Monte Carlo</td><td>马尔可夫链蒙特卡罗</td><td>MCMC</td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-24-6">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01113</td><td>Markov Decision Process</td><td>马尔可夫决策过程</td><td>MDP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01114</td><td>Markov Network</td><td>马尔可夫网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01115</td><td>Markov Process</td><td>马尔可夫过程</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01116</td><td>Markov Property</td><td>马尔可夫性质</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01117</td><td>Markov Random Field</td><td>马尔可夫随机场</td><td>MRF</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01118</td><td>Mask</td><td>掩码</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01119</td><td>Mask Language Modeling</td><td>掩码语言模型化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01120</td><td>Masked Self-Attention</td><td>掩蔽自注意力</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01121</td><td>Mathematical Optimization</td><td>数学优化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01122</td><td>Matrix</td><td>矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01123</td><td>Matrix Calculus</td><td>矩阵微积分</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01124</td><td>Matrix Completion</td><td>矩阵补全</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01125</td><td>Matrix Decomposition</td><td>矩阵分解</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01126</td><td>Matrix Inversion</td><td>逆矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01127</td><td>Matrix Product</td><td>矩阵乘积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01128</td><td>Max Norm</td><td>最大范数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01129</td><td>Max Pooling</td><td>最大汇聚</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-10-02-5">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01130</td><td>Maxima</td><td>极大值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01131</td><td>Maximal Clique</td><td>最大团</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01132</td><td>Maximization</td><td>极大</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01133</td><td>Maximization Step</td><td>M步</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01134</td><td>Maximization-Maximization Algorithm</td><td>极大-极大算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01135</td><td>Maximum A Posteriori</td><td>最大后验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01136</td><td>Maximum A Posteriori Estimation</td><td>最大后验估计</td><td>MAP</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01137</td><td>Maximum Entropy Model</td><td>最大熵模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01138</td><td>Maximum Likelihood</td><td>极大似然</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01139</td><td>Maximum Likelihood Estimation</td><td>极大似然估计</td><td>MLE</td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-09-6">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01140</td><td>Maximum Likelihood Method</td><td>极大似然法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01141</td><td>Maximum Margin</td><td>最大间隔</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01142</td><td>Maximum Mean Discrepancy</td><td>最大平均偏差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01143</td><td>Maximum Posterior Probability Estimation</td><td>最大后验概率估计</td><td>MAP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01144</td><td>Maximum Weighted Spanning Tree</td><td>最大带权生成树</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01145</td><td>Maxout</td><td>Maxout</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01146</td><td>Maxout Unit</td><td>Maxout单元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01147</td><td>Mean</td><td>均值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01148</td><td>Mean Absolute Error</td><td>平均绝对误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01149</td><td>Mean And Covariance RBM</td><td>均值和协方差RBM</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01150</td><td>Mean Filed</td><td>平均场</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01151</td><td>Mean Filter</td><td>均值滤波</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01152</td><td>Mean Pooling</td><td>平均汇聚</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01153</td><td>Mean Product of Student t-Distribution</td><td>学生 t 分布均值乘积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01154</td><td>Mean Squared Error</td><td>均方误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01155</td><td>Mean-Covariance Restricted Boltzmann Machine</td><td>均值-协方差受限玻尔兹曼机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01156</td><td>Mean-Field</td><td>平均场</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01157</td><td>Meanfield</td><td>均匀场</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01158</td><td>Measure Theory</td><td>测度论</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01159</td><td>Measure Zero</td><td>零测度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01160</td><td>Median</td><td>中位数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01161</td><td>Memory</td><td>记忆</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01162</td><td>Memory Augmented Neural Network</td><td>记忆增强神经网络</td><td>MANN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01163</td><td>Memory Capacity</td><td>记忆容量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01164</td><td>Memory Cell</td><td>记忆元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01165</td><td>Memory Network</td><td>记忆网络</td><td>MN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01166</td><td>Memory Segment</td><td>记忆片段</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01167</td><td>Mercer Kernel</td><td>Mercer 核</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01168</td><td>Message</td><td>消息</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01169</td><td>Message Passing</td><td>消息传递</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01170</td><td>Message Passing Neural Network</td><td>消息传递神经网络</td><td>MPNN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01171</td><td>Meta-Learner</td><td>元学习器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01172</td><td>Meta-Learning</td><td>元学习</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01173</td><td>Meta-Optimization</td><td>元优化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01174</td><td>Meta-Rule</td><td>元规则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01175</td><td>Metric</td><td>指标</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-01176</td><td>Metric Learning</td><td>度量学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01177</td><td>Micro Average</td><td>微平均</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01178</td><td>Micro-F1</td><td>微F1</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01179</td><td>Micro-P</td><td>微査准率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01180</td><td>Micro-R</td><td>微查全率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01181</td><td>Min-Max Normalization</td><td>最小最大值规范化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01182</td><td>Mini-Batch Gradient</td><td>小批量梯度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01183</td><td>Mini-Batch Gradient Descent</td><td>小批量梯度下降法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01184</td><td>Mini-Batch SGD</td><td>小批次随机梯度下降</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01185</td><td>Minibatch</td><td>小批量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01186</td><td>Minibatch Stochastic</td><td>小批量随机</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01187</td><td>Minima</td><td>极小值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01188</td><td>Minimal Description Length</td><td>最小描述长度</td><td>MDL</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01189</td><td>Minimax Game</td><td>极小极大博弈</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01190</td><td>Minimum</td><td>极小点</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01191</td><td>Minkowski Distance</td><td>闵可夫斯基距离</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01192</td><td>Misclassification Cost</td><td>误分类代价</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01193</td><td>Mixing</td><td>混合</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01194</td><td>Mixing Time</td><td>混合时间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01195</td><td>Mixture Density Network</td><td>混合密度网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01196</td><td>Mixture Distribution</td><td>混合分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01197</td><td>Mixture of Experts</td><td>混合专家模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01198</td><td>Mixture-of-Gaussian</td><td>高斯混合</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01199</td><td>Modality</td><td>模态</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01200</td><td>Mode</td><td>峰值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01201</td><td>Model</td><td>模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01202</td><td>Model Averaging</td><td>模型平均</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01203</td><td>Model Collapse</td><td>模型坍塌</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01204</td><td>Model Complexity</td><td>模型复杂度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01205</td><td>Model Compression</td><td>模型压缩</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01206</td><td>Model Identifiability</td><td>模型可辨识性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01207</td><td>Model Parallelism</td><td>模型并行</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01208</td><td>Model Parameter</td><td>模型参数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01209</td><td>Model Predictive Control</td><td>模型预测控制</td><td>MPC</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01210</td><td>Model Selection</td><td>模型选择</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01211</td><td>Model-Agnostic Meta-Learning</td><td>模型无关的元学习</td><td>MAML</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01212</td><td>Model-Based Learning</td><td>有模型学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01213</td><td>Model-Based Reinforcement Learning</td><td>基于模型的强化学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01214</td><td>Model-Free Learning</td><td>免模型学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01215</td><td>Model-Free Reinforcement Learning</td><td>模型无关的强化学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01216</td><td>Moment</td><td>矩</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01217</td><td>Moment Matching</td><td>矩匹配</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01218</td><td>Momentum</td><td>动量</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-07-01-4">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01219</td><td>Momentum Method</td><td>动量法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01220</td><td>Monte Carlo</td><td>蒙特卡罗</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01221</td><td>Monte Carlo Estimate</td><td>蒙特卡罗估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01222</td><td>Monte Carlo Integration</td><td>蒙特卡罗积分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01223</td><td>Monte Carlo Method</td><td>蒙特卡罗方法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01224</td><td>Moore's Law</td><td>摩尔定律</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01225</td><td>Moore-Penrose Pseudoinverse</td><td>Moore-Penrose 伪逆</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01226</td><td>Moral Graph</td><td>端正图/道德图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01227</td><td>Moralization</td><td>道德化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01228</td><td>Most General Unifier</td><td>最一般合一置换</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01229</td><td>Moving Average</td><td>移动平均</td><td>MA</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01230</td><td>Multi-Armed Bandit Problem</td><td>多臂赌博机问题</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01231</td><td>Multi-Class Classification</td><td>多分类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01232</td><td>Multi-Classifier System</td><td>多分类器系统</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01233</td><td>Multi-Document Summarization</td><td>多文档摘要</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01234</td><td>Multi-Head Attention</td><td>多头注意力</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01235</td><td>Multi-Head Self-Attention</td><td>多头自注意力</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01236</td><td>Multi-Hop</td><td>多跳</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01237</td><td>Multi-Kernel Learning</td><td>多核学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01238</td><td>Multi-Label Classification</td><td>多标签分类</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01239</td><td>Multi-Label Learning</td><td>多标记学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01240</td><td>Multi-Layer Feedforward Neural Networks</td><td>多层前馈神经网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01241</td><td>Multi-Layer Perceptron</td><td>多层感知机</td><td>MLP</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00398/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-01242</td><td>Multi-Nominal Logistic Regression Model</td><td>多项对数几率回归模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01243</td><td>Multi-Prediction Deep Boltzmann Machine</td><td>多预测深度玻尔兹曼机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01244</td><td>Multi-Response Linear Regression</td><td>多响应线性回归</td><td>MLR</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01245</td><td>Multi-View Learning</td><td>多视图学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01246</td><td>Multicollinearity</td><td>多重共线性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01247</td><td>Multimodal</td><td>多峰值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01248</td><td>Multimodal Learning</td><td>多模态学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01249</td><td>Multinomial Distribution</td><td>多项分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01250</td><td>Multinoulli Distribution</td><td>Multinoulli分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01251</td><td>Multinoulli Output Distribution</td><td>Multinoulli输出分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01252</td><td>Multiple Dimensional Scaling</td><td>多维缩放</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01253</td><td>Multiple Linear Regression</td><td>多元线性回归</td><td>MLR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[3]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01254</td><td>Multitask Learning</td><td>多任务学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01255</td><td>Multivariate Decision Tree</td><td>多变量决策树</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01256</td><td>Multivariate Gaussian Distribution</td><td>多元高斯分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01257</td><td>Multivariate Normal Distribution</td><td>多元正态分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01258</td><td>Mutual Information</td><td>互信息</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01259</td><td>N-Gram</td><td>N元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01260</td><td>N-Gram Feature</td><td>N元特征</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01261</td><td>N-Gram Model</td><td>N元模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01262</td><td>Naive Bayes Algorithm</td><td>朴素贝叶斯算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01263</td><td>Naive Bayes Classifier</td><td>朴素贝叶斯分类器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01264</td><td>Naive Bayes</td><td>朴素贝叶斯</td><td>NB</td><td><ahref="https://www.jiqizhixin.com/articles/2017-11-20-6">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01265</td><td>Named Entity Recognition</td><td>命名实体识别</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01266</td><td>Narrow Convolution</td><td>窄卷积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01267</td><td>Nash Equilibrium</td><td>纳什均衡</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01268</td><td>Nash Reversion</td><td>纳什回归</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01269</td><td>Nats</td><td>奈特</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01270</td><td>Natural Exponential Decay</td><td>自然指数衰减</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01271</td><td>Natural Language Generation</td><td>自然语言生成</td><td>NLG</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01272</td><td>Natural Language Processing</td><td>自然语言处理</td><td>NLP</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[2]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[4]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-14-5">[5]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-14-4">[6]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-12-3">[7]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01273</td><td>Nearest Neighbor</td><td>最近邻</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01274</td><td>Nearest Neighbor Classifier</td><td>最近邻分类器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01275</td><td>Nearest Neighbor Graph</td><td>最近邻图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01276</td><td>Nearest Neighbor Regression</td><td>最近邻回归</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01277</td><td>Nearest-Neighbor Search</td><td>最近邻搜索</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-24-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01278</td><td>Negative Class</td><td>负类</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01279</td><td>Negative Correlation</td><td>负相关法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01280</td><td>Negative Definite</td><td>负定</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01281</td><td>Negative Log Likelihood</td><td>负对数似然函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01282</td><td>Negative Part Function</td><td>负部函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01283</td><td>Negative Phase</td><td>负相</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01284</td><td>Negative Sample</td><td>负例</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01285</td><td>Negative Sampling</td><td>负采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01286</td><td>Negative Semidefinite</td><td>半负定</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01287</td><td>Neighbourhood Component Analysis</td><td>近邻成分分析</td><td>NCA</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01288</td><td>Nesterov Accelerated Gradient</td><td>Nesterov加速梯度</td><td>NAG</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01289</td><td>Nesterov Momentum</td><td>Nesterov动量法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01290</td><td>Net Activation</td><td>净活性值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01291</td><td>Net Input</td><td>净输入</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01292</td><td>Network</td><td>网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01293</td><td>Network Capacity</td><td>网络容量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01294</td><td>Neural Architecture Search</td><td>神经架构搜索</td><td>NAS</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01295</td><td>Neural Auto-Regressive Density Estimator</td><td>神经自回归密度估计器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01296</td><td>Neural Auto-Regressive Network</td><td>神经自回归网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01297</td><td>Neural Language Model</td><td>神经语言模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01298</td><td>Neural Machine Translation</td><td>神经机器翻译</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-08-22-6">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01299</td><td>Neural Model</td><td>神经模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01300</td><td>Neural Network</td><td>神经网络</td><td>NN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01301</td><td>Neural Turing Machine</td><td>神经图灵机</td><td>NTM</td><td><ahref="https://www.jiqizhixin.com/articles/2017-04-11-7">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01302</td><td>Neurodynamics</td><td>神经动力学</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01303</td><td>Neuromorphic Computing</td><td>神经形态计算</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-09-26-4">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-26-2">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-06-16-6">[3]</a></td><td></td></tr><tr class="even"><td>AITD-01304</td><td>Neuron</td><td>神经元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01305</td><td>Newton Method</td><td>牛顿法</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-03-11-2">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01306</td><td>No Free Lunch Theorem</td><td>没有免费午餐定理</td><td>NFL</td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-03-6">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01307</td><td>Node</td><td>结点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01308</td><td>Noise</td><td>噪声</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01309</td><td>Noise Distribution</td><td>噪声分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01310</td><td>Noise-Contrastive Estimation</td><td>噪声对比估计</td><td>NCE</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01311</td><td>Nominal Attribute</td><td>列名属性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01312</td><td>Non-Autoregressive Process</td><td>非自回归过程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01313</td><td>Non-Convex Optimization</td><td>非凸优化</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-29-4">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01314</td><td>Non-Informative Prior</td><td>无信息先验</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01315</td><td>Non-Linear Model</td><td>非线性模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01316</td><td>Non-Linear Oscillation</td><td>非线性振荡</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01317</td><td>Non-Linear Support Vector Machine</td><td>非线性支持向量机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01318</td><td>Non-Metric Distance</td><td>非度量距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01319</td><td>Non-Negative Matrix Factorization</td><td>非负矩阵分解</td><td>NMF</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01320</td><td>Non-Ordinal Attribute</td><td>无序属性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01321</td><td>Non-Parametric</td><td>非参数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01322</td><td>Non-Parametric Model</td><td>非参数化模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01323</td><td>Non-Probabilistic Model</td><td>非概率模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01324</td><td>Non-Saturating Game</td><td>非饱和博弈</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01325</td><td>Non-Separable</td><td>不可分</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01326</td><td>Nonconvex</td><td>非凸</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01327</td><td>Nondistributed</td><td>非分布式</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01328</td><td>Nondistributed Representation</td><td>非分布式表示</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01329</td><td>Nonlinear Autoregressive With Exogenous Inputs Model</td><td>有外部输入的非线性自回归模型</td><td>NARX</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01330</td><td>Nonlinear Conjugate Gradients</td><td>非线性共轭梯度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01331</td><td>Nonlinear Independent Components Estimation</td><td>非线性独立成分估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01332</td><td>Nonlinear Programming</td><td>非线性规划</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01333</td><td>Nonparametric Density Estimation</td><td>非参数密度估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01334</td><td>Norm</td><td>范数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01335</td><td>Norm-Preserving</td><td>范数保持性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01336</td><td>Normal Distribution</td><td>正态分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01337</td><td>Normal Equation</td><td>正规方程</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01338</td><td>Normalization</td><td>规范化</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>统计、机器学习</td></tr><tr class="odd"><td>AITD-01339</td><td>Normalization Factor</td><td>规范化因子</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01340</td><td>Normalized</td><td>规范化的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01341</td><td>Normalized Initialization</td><td>标准初始化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01342</td><td>Nuclear Norm</td><td>核范数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01343</td><td>Null Space</td><td>零空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01344</td><td>Number of Epochs</td><td>轮数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01345</td><td>Numerator Layout</td><td>分子布局</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01346</td><td>Numeric Value</td><td>数值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01347</td><td>Numerical Attribute</td><td>数值属性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01348</td><td>Numerical Differentiation</td><td>数值微分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01349</td><td>Numerical Method</td><td>数值方法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01350</td><td>Numerical Optimization</td><td>数值优化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01351</td><td>Object Detection</td><td>目标检测</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01352</td><td>Object Recognition</td><td>对象识别</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01353</td><td>Objective</td><td>目标</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01354</td><td>Objective Function</td><td>目标函数</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-11-5">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01355</td><td>Oblique Decision Tree</td><td>斜决策树</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01356</td><td>Observable Variable</td><td>观测变量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01357</td><td>Observation Sequence</td><td>观测序列</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01358</td><td>Occam's Razor</td><td>奥卡姆剃刀</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01359</td><td>Odds</td><td>几率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01360</td><td>Off-Policy</td><td>异策略</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01361</td><td>Offline Inference</td><td>离线推断</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-11-06-5">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01362</td><td>Offset</td><td>偏移量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01363</td><td>Offset Vector</td><td>偏移向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01364</td><td>On-Policy</td><td>同策略</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01365</td><td>One-Shot Learning</td><td>单试学习</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-03-13-2">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-01366</td><td>One-Dependent Estimator</td><td>独依赖估计</td><td>ODE</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01367</td><td>One-Hot</td><td>独热</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01368</td><td>Online</td><td>在线</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01369</td><td>Online Inference</td><td>在线推断</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01370</td><td>Online Learning</td><td>在线学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01371</td><td>Operation</td><td>操作</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01372</td><td>Operator</td><td>运算符</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01373</td><td>Optimal Capacity</td><td>最佳容量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01374</td><td>Optimization</td><td>最优化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01375</td><td>Optimization Landscape</td><td>优化地形</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01376</td><td>Optimizer</td><td>优化器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01377</td><td>Ordered Rule</td><td>带序规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01378</td><td>Ordinal Attribute</td><td>有序属性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01379</td><td>Origin</td><td>原点</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01380</td><td>Orthogonal</td><td>正交</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>数学</td></tr><tr class="odd"><td>AITD-01381</td><td>Orthogonal Initialization</td><td>正交初始化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01382</td><td>Orthogonal Matrix</td><td>正交矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01383</td><td>Orthonormal</td><td>标准正交</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01384</td><td>Out-Of-Bag Estimate</td><td>包外估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01385</td><td>Outer Product</td><td>外积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01386</td><td>Outlier</td><td>异常点</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-01387</td><td>Output</td><td>输出</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01388</td><td>Output Gate</td><td>输出门</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01389</td><td>Output Layer</td><td>输出层</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-01390</td><td>Output Smearing</td><td>输出调制法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01391</td><td>Output Space</td><td>输出空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01392</td><td>Over-Parameterized</td><td>过度参数化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01393</td><td>Overcomplete</td><td>过完备</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01394</td><td>Overestimation</td><td>过估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01395</td><td>Overfitting</td><td>过拟合</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[3]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-01396</td><td>Overfitting Regime</td><td>过拟合机制</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01397</td><td>Overflow</td><td>上溢</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01398</td><td>Oversampling</td><td>过采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01399</td><td>PAC Learning</td><td>PAC学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01400</td><td>Pac-Learnable</td><td>PAC可学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01401</td><td>Padding</td><td>填充</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01402</td><td>Paired t -Test</td><td>成对 t 检验</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01403</td><td>Pairwise</td><td>成对型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01404</td><td>Pairwise Markov Property</td><td>成对马尔可夫性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01405</td><td>Parallel Distributed Processing</td><td>分布式并行处理</td><td>PDP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01406</td><td>Parallel Tempering</td><td>并行回火</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01407</td><td>Parameter</td><td>参数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01408</td><td>Parameter Estimation</td><td>参数估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01409</td><td>Parameter Server</td><td>参数服务器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01410</td><td>Parameter Sharing</td><td>参数共享</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01411</td><td>Parameter Space</td><td>参数空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01412</td><td>Parameter Tuning</td><td>调参</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-03-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[2]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01413</td><td>Parametric Case</td><td>有参情况</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01414</td><td>Parametric Density Estimation</td><td>参数密度估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01415</td><td>Parametric Model</td><td>参数化模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01416</td><td>Parametric ReLU</td><td>参数化修正线性单元/参数化整流线性单元</td><td>PReLU</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01417</td><td>Parse Tree</td><td>解析树</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01418</td><td>Part-Of-Speech Tagging</td><td>词性标注</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01419</td><td>Partial Derivative</td><td>偏导数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01420</td><td>Partially Observable Markov Decision Processes</td><td>部分可观测马尔可夫决策过程</td><td>POMDP</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01421</td><td>Particle Swarm Optimization</td><td>粒子群优化算法</td><td>PSO</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01422</td><td>Partition</td><td>划分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01423</td><td>Partition Function</td><td>配分函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01424</td><td>Path</td><td>路径</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01425</td><td>Pattern</td><td>模式</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01426</td><td>Pattern Recognition</td><td>模式识别</td><td>PR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-01427</td><td>Penalty Term</td><td>罚项</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01428</td><td>Perceptron</td><td>感知机</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-15-2">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[2]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01429</td><td>Performance Measure</td><td>性能度量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01430</td><td>Periodic</td><td>周期的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01431</td><td>Permutation Invariant</td><td>置换不变性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01432</td><td>Perplexity</td><td>困惑度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01433</td><td>Persistent Contrastive Divergence</td><td>持续性对比散度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01434</td><td>Phoneme</td><td>音素</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01435</td><td>Phonetic</td><td>语音</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01436</td><td>Pictorial Structure</td><td>图形结构</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01437</td><td>Piecewise</td><td>分段</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01438</td><td>Piecewise Constant Decay</td><td>分段常数衰减</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01439</td><td>Pipeline</td><td>流水线</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01440</td><td>Plate Notation</td><td>板块表示</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01441</td><td>Plug And Play Generative Network</td><td>即插即用生成网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01442</td><td>Plurality Voting</td><td>相对多数投票</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01443</td><td>Point Estimator</td><td>点估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01444</td><td>Pointer Network</td><td>指针网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01445</td><td>Polarity Detection</td><td>极性检测</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01446</td><td>Policy</td><td>策略</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01447</td><td>Policy Evaluation</td><td>策略评估</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01448</td><td>Policy Gradient</td><td>策略梯度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01449</td><td>Policy Improvement</td><td>策略改进</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01450</td><td>Policy Iteration</td><td>策略迭代</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01451</td><td>Policy Search</td><td>策略搜索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01452</td><td>Polynomial Basis Function</td><td>多项式基函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01453</td><td>Polynomial Kernel Function</td><td>多项式核函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01454</td><td>Polysemy</td><td>一词多义性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01455</td><td>Pool</td><td>汇聚</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01456</td><td>Pooling</td><td>汇聚</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-10-02-5">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01457</td><td>Pooling Function</td><td>汇聚函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01458</td><td>Pooling Layer</td><td>汇聚层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01459</td><td>Poor Conditioning</td><td>病态条件</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01460</td><td>Position Embedding</td><td>位置嵌入</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01461</td><td>Positional Encoding</td><td>位置编码</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01462</td><td>Positive Class</td><td>正类</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01463</td><td>Positive Definite</td><td>正定</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01464</td><td>Positive Definite Kernel Function</td><td>正定核函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01465</td><td>Positive Definite Matrix</td><td>正定矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01466</td><td>Positive Part Function</td><td>正部函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01467</td><td>Positive Phase</td><td>正相</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01468</td><td>Positive Recurrent</td><td>正常返的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01469</td><td>Positive Sample</td><td>正例</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01470</td><td>Positive Semidefinite</td><td>半正定</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01471</td><td>Positive-Semidefinite Matrix</td><td>半正定矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01472</td><td>Post-Hoc Test</td><td>后续检验</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01473</td><td>Post-Pruning</td><td>后剪枝</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01474</td><td>Posterior Distribution</td><td>后验分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01475</td><td>Posterior Inference</td><td>后验推断</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01476</td><td>Posterior Probability</td><td>后验概率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01477</td><td>Potential Function</td><td>势函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01478</td><td>Power Method</td><td>幂法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01479</td><td>PR Curve</td><td>P-R曲线</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01480</td><td>Pre-Trained Initialization</td><td>预训练初始化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01481</td><td>Pre-Training</td><td>预训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01482</td><td>Precision</td><td>查准率/准确率</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>数学、HPC</td></tr><tr class="odd"><td>AITD-01483</td><td>Precision Matrix</td><td>精度矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01484</td><td>Predictive Sparse Decomposition</td><td>预测稀疏分解</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01485</td><td>Prepruning</td><td>预剪枝</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01486</td><td>Pretrained Language Model</td><td>预训练语言模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01487</td><td>Primal Problem</td><td>主问题</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01488</td><td>Primary Visual Cortex</td><td>初级视觉皮层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01489</td><td>Principal Component Analysis</td><td>主成分分析</td><td>PCA</td><td><a href="https://www.jiqizhixin.com/articles/2017-12-03-4">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[4]</a></td><td></td></tr><tr class="even"><td>AITD-01490</td><td>Principle Of Multiple Explanations</td><td>多释原则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01491</td><td>Prior</td><td>先验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01492</td><td>Prior Knowledge</td><td>先验知识</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-01493</td><td>Prior Probability</td><td>先验概率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01494</td><td>Prior Probability Distribution</td><td>先验概率分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01495</td><td>Prior Pseudo-Counts</td><td>伪计数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01496</td><td>Prior Shift</td><td>先验偏移</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01497</td><td>Priority Rule</td><td>优先级规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01498</td><td>Probabilistic Context-Free Grammar</td><td>概率上下文无关文法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01499</td><td>Probabilistic Density Estimation</td><td>概率密度估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01500</td><td>Probabilistic Generative Model</td><td>概率生成模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01501</td><td>Probabilistic Graphical Model</td><td>概率图模型</td><td>PGM</td><td><ahref="https://www.jiqizhixin.com/articles/2017-11-29-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01502</td><td>Probabilistic Latent Semantic Analysis</td><td>概率潜在语义分析</td><td>PLSA</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01503</td><td>Probabilistic Latent Semantic Indexing</td><td>概率潜在语义索引</td><td>PLSI</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01504</td><td>Probabilistic Model</td><td>概率模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01505</td><td>Probabilistic PCA</td><td>概率PCA</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01506</td><td>Probabilistic Undirected Graphical Model</td><td>概率无向图模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01507</td><td>Probability</td><td>概率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01508</td><td>Probability Density Function</td><td>概率密度函数</td><td>PDF</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01509</td><td>Probability Distribution</td><td>概率分布</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01510</td><td>Probability Mass Function</td><td>概率质量函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01511</td><td>Probability Model Estimation</td><td>概率模型估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01512</td><td>Probably Approximately Correct</td><td>概率近似正确</td><td>PAC</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01513</td><td>Product of Expert</td><td>专家之积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01514</td><td>Product Rule</td><td>乘法法则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01515</td><td>Properly PAC Learnable</td><td>恰PAC可学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01516</td><td>Proportional</td><td>成比例</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01517</td><td>Proposal Distribution</td><td>提议分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01518</td><td>Propositional Atom</td><td>原子命题</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01519</td><td>Propositional Rule</td><td>命题规则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01520</td><td>Prototype-Based Clustering</td><td>原型聚类</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01521</td><td>Proximal Gradient Descent</td><td>近端梯度下降</td><td>PGD</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01522</td><td>Pruning</td><td>剪枝</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-09-26">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01523</td><td>Pseudo-Label</td><td>伪标记</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01524</td><td>Pseudolikelihood</td><td>伪似然</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01525</td><td>Q Function</td><td>Q函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01526</td><td>Q-Learning</td><td>Q学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01527</td><td>Q-Network</td><td>Q网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01528</td><td>Quadratic Loss Function</td><td>平方损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01529</td><td>Quadratic Programming</td><td>二次规划</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01530</td><td>Quadrature Pair</td><td>象限对</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01531</td><td>Quantized Neural Network</td><td>量子化神经网络</td><td>QNN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01532</td><td>Quantum Computer</td><td>量子计算机</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-13">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-11-30-5">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-29-5">[3]</a></td><td></td></tr><tr class="odd"><td>AITD-01533</td><td>Quantum Computing</td><td>量子计算</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-13">[1]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-17">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-29-5">[3]</a></td><td></td></tr><tr class="even"><td>AITD-01534</td><td>Quantum Machine Learning</td><td>量子机器学习</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-04-5">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01535</td><td>Quantum Mechanics</td><td>量子力学</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td>物理</td></tr><tr class="even"><td>AITD-01536</td><td>Quasi Newton Method</td><td>拟牛顿法</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-16-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01537</td><td>Quasi-Concave</td><td>拟凹</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01538</td><td>Query</td><td>查询</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01539</td><td>Query Vector</td><td>查询向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01540</td><td>Query-Key-Value</td><td>查询-键-值</td><td>QKV</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01541</td><td>Radial Basis Function</td><td>径向基函数</td><td>RBF</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00398/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-01542</td><td>Random Access Memory</td><td>随机访问存储</td><td>RAM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01543</td><td>Random Field</td><td>随机场</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01544</td><td>Random Forest Algorithm</td><td>随机森林算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01545</td><td>Random Forest</td><td>随机森林</td><td>RF、RFS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00251/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[3]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[4]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[5]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01546</td><td>Random Initialization</td><td>随机初始化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01547</td><td>Random Sampling</td><td>随机采样</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[2]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01548</td><td>Random Search</td><td>随机搜索</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01549</td><td>Random Subspace</td><td>随机子空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01550</td><td>Random Variable</td><td>随机变量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01551</td><td>Random Walk</td><td>随机游走</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01552</td><td>Range</td><td>值域</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01553</td><td>Rank</td><td>秩</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01554</td><td>Ratio Matching</td><td>比率匹配</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01555</td><td>Raw Feature</td><td>原始特征</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01556</td><td>Re-Balance</td><td>再平衡</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01557</td><td>Re-Sampling</td><td>重采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01558</td><td>Re-Weighting</td><td>重赋权</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01559</td><td>Readout Function</td><td>读出函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01560</td><td>Real-Time Recurrent Learning</td><td>实时循环学习</td><td>RTRL</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01561</td><td>Recall</td><td>查全率/召回率</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01562</td><td>Recall-Oriented Understudy For Gisting Evaluation</td><td>ROUGE</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01563</td><td>Receiver Operating Characteristic</td><td>受试者工作特征</td><td>ROC</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01564</td><td>Receptive Field</td><td>感受野</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01565</td><td>Recirculation</td><td>再循环</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01566</td><td>Recognition Weight</td><td>认知权重</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01567</td><td>Recommender System</td><td>推荐系统</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01568</td><td>Reconstruction</td><td>重构</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01569</td><td>Reconstruction Error</td><td>重构误差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01570</td><td>Rectangular Diagonal Matrix</td><td>矩形对角矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01571</td><td>Rectified Linear</td><td>整流线性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01572</td><td>Rectified Linear Transformation</td><td>整流线性变换</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01573</td><td>Rectified Linear Unit</td><td>修正线性单元/整流线性单元</td><td>ReLU</td><td><a href="https://www.jiqizhixin.com/articles/2017-10-21-4">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a></td><td>CHAPTER 2</td></tr><tr class="even"><td>AITD-01574</td><td>Rectifier Network</td><td>整流网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01575</td><td>Recurrence</td><td>循环</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01576</td><td>Recurrent Convolutional Network</td><td>循环卷积网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01577</td><td>Recurrent Multi-Layer Perceptron</td><td>循环多层感知器</td><td>RMLP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01578</td><td>Recurrent Network</td><td>循环网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01579</td><td>Recurrent Neural Network</td><td>循环神经网络</td><td>RNN</td><td><a href="https://www.jiqizhixin.com/articles/2018-01-13-4">[1]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-05-5">[2]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-21-15">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[4]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[5]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[6]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-01580</td><td>Recursive Neural Network</td><td>递归神经网络</td><td>RecNN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01581</td><td>Reducible</td><td>可约的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01582</td><td>Redundant Feature</td><td>冗余特征</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01583</td><td>Reference Model</td><td>参考模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01584</td><td>Region</td><td>区域</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01585</td><td>Regression</td><td>回归</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-21-13">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[2]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[3]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01586</td><td>Regularization</td><td>正则化</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-20">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01587</td><td>Regularizer</td><td>正则化项</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01588</td><td>Reinforcement Learning</td><td>强化学习</td><td>RL</td><td><a href="https://www.jiqizhixin.com/articles/2018-01-17-3">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-28-6">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[4]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[5]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01589</td><td>Rejection Sampling</td><td>拒绝采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01590</td><td>Relation</td><td>关系</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01591</td><td>Relational Database</td><td>关系型数据库</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01592</td><td>Relative Entropy</td><td>相对熵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01593</td><td>Relevant Feature</td><td>相关特征</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01594</td><td>Reparameterization</td><td>再参数化/重参数化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01595</td><td>Reparametrization Trick</td><td>重参数化技巧</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01596</td><td>Replay Buffer</td><td>经验池</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01597</td><td>Representation</td><td>表示</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01598</td><td>Representation Learning</td><td>表示学习</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01599</td><td>Representational Capacity</td><td>表示容量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01600</td><td>Representer Theorem</td><td>表示定理</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01601</td><td>Reproducing Kernel Hilbert Space</td><td>再生核希尔伯特空间</td><td>RKHS</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01602</td><td>Rescaling</td><td>再缩放</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01603</td><td>Reservoir Computing</td><td>储层计算</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01604</td><td>Reset Gate</td><td>重置门</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01605</td><td>Residual Blocks</td><td>残差块</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01606</td><td>Residual Connection</td><td>残差连接</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01607</td><td>Residual Mapping</td><td>残差映射</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01608</td><td>Residual Network</td><td>残差网络</td><td>ResNet</td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-18-2">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01609</td><td>Residual Unit</td><td>残差单元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01610</td><td>Residue Function</td><td>残差函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01611</td><td>Resolution Quotient</td><td>归结商</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01612</td><td>Restricted Boltzmann Machine</td><td>受限玻尔兹曼机</td><td>RBM</td><td><ahref="https://www.jiqizhixin.com/articles/2017-10-08-4">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01613</td><td>Restricted Isometry Property</td><td>限定等距性</td><td>RIP</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01614</td><td>Return</td><td>总回报</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01615</td><td>Reverse Correlation</td><td>反向相关</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01616</td><td>Reverse KL Divergence</td><td>逆向KL散度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01617</td><td>Reverse Mode Accumulation</td><td>反向模式累加</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01618</td><td>Reversible Markov Chain</td><td>可逆马尔可夫链</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01619</td><td>Reward</td><td>奖励</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01620</td><td>Reward Function</td><td>奖励函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01621</td><td>Ridge Regression</td><td>岭回归</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01622</td><td>Riemann Integral</td><td>黎曼积分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01623</td><td>Right Eigenvector</td><td>右特征向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01624</td><td>Right Singular Vector</td><td>右奇异向量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01625</td><td>Risk</td><td>风险</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01626</td><td>Risk Function</td><td>风险函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01627</td><td>Robustness</td><td>稳健性</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>计算机、机器学习</td></tr><tr class="even"><td>AITD-01628</td><td>Root Node</td><td>根结点</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01629</td><td>Round-Off Error</td><td>舍入误差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01630</td><td>Row</td><td>行</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01631</td><td>Rule Engine</td><td>规则引擎</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01632</td><td>Rule Learning</td><td>规则学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01633</td><td>S-Fold Cross Validation</td><td>S 折交叉验证</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01634</td><td>Saccade</td><td>扫视</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01635</td><td>Saddle Point</td><td>鞍点</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-09-08">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01636</td><td>Saddle-Free Newton Method</td><td>无鞍牛顿法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01637</td><td>Saliency Map</td><td>显著图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01638</td><td>Saliency-Based Attention</td><td>基于显著性的注意力</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01639</td><td>Same</td><td>相同</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01640</td><td>Sample</td><td>样本</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01641</td><td>Sample Complexity</td><td>样本复杂度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01642</td><td>Sample Mean</td><td>样本均值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01643</td><td>Sample Space</td><td>样本空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01644</td><td>Sample Variance</td><td>样本方差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01645</td><td>Sampling</td><td>采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01646</td><td>Sampling Method</td><td>采样法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01647</td><td>Saturate</td><td>饱和</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01648</td><td>Saturating Function</td><td>饱和函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01649</td><td>Scalar</td><td>标量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01650</td><td>Scale Invariance</td><td>尺度不变性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01651</td><td>Scatter Matrix</td><td>散布矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01652</td><td>Scheduled Sampling</td><td>计划采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01653</td><td>Score</td><td>得分</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01654</td><td>Score Function</td><td>评分函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01655</td><td>Score Matching</td><td>分数匹配</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01656</td><td>Second Derivative</td><td>二阶导数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01657</td><td>Second Derivative Test</td><td>二阶导数测试</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01658</td><td>Second Layer</td><td>第二层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01659</td><td>Second-Order Method</td><td>二阶方法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01660</td><td>Selective Attention</td><td>选择性注意力</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01661</td><td>Selective Ensemble</td><td>选择性集成</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01662</td><td>Self Information</td><td>自信息</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01663</td><td>Self-Attention</td><td>自注意力</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01664</td><td>Self-Attention Model</td><td>自注意力模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01665</td><td>Self-Contrastive Estimation</td><td>自对比估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01666</td><td>Self-Driving</td><td>自动驾驶</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-12-27-7">[1]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-16">[2]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-08-9">[3]</a></td><td></td></tr><tr class="odd"><td>AITD-01667</td><td>Self-Gated</td><td>自门控</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01668</td><td>Self-Organizing Map</td><td>自组织映射网</td><td>SOM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01669</td><td>Self-Taught Learning</td><td>自学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01670</td><td>Self-Training</td><td>自训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01671</td><td>Semantic Gap</td><td>语义鸿沟</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01672</td><td>Semantic Hashing</td><td>语义哈希</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01673</td><td>Semantic Segmentation</td><td>语义分割</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01674</td><td>Semantic Similarity</td><td>语义相似度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01675</td><td>Semi-Definite Programming</td><td>半正定规划</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01676</td><td>Semi-Naive Bayes Classifiers</td><td>半朴素贝叶斯分类器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01677</td><td>Semi-Restricted Boltzmann Machine</td><td>半受限玻尔兹曼机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01678</td><td>Semi-Supervised</td><td>半监督</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01679</td><td>Semi-Supervised Clustering</td><td>半监督聚类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01680</td><td>Semi-Supervised Learning</td><td>半监督学习</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-12-22-3">[1]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-02">[2]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-07">[3]</a></td><td></td></tr><tr class="odd"><td>AITD-01681</td><td>Semi-Supervised Support Vector Machine</td><td>半监督支持向量机</td><td>S3VM</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01682</td><td>Sentiment Analysis</td><td>情感分析</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-07-7">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01683</td><td>Separable</td><td>可分离的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01684</td><td>Separate</td><td>分离的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01685</td><td>Separating Hyperplane</td><td>分离超平面</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01686</td><td>Separation</td><td>分离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01687</td><td>Sequence Labeling</td><td>序列标注</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01688</td><td>Sequence To Sequence Learning</td><td>序列到序列学习</td><td>Seq2Seq</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01689</td><td>Sequence-To-Sequence</td><td>序列到序列</td><td>Seq2Seq</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01690</td><td>Sequential Covering</td><td>序贯覆盖</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01691</td><td>Sequential Minimal Optimization</td><td>序列最小最优化</td><td>SMO</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01692</td><td>Sequential Model-Based Optimization</td><td>时序模型优化</td><td>SMBO</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01693</td><td>Sequential Partitioning</td><td>顺序分区</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01694</td><td>Setting</td><td>情景</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01695</td><td>Shadow Circuit</td><td>浅度回路</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01696</td><td>Shallow Learning</td><td>浅层学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01697</td><td>Shannon Entropy</td><td>香农熵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01698</td><td>Shannons</td><td>香农</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01699</td><td>Shaping</td><td>塑造</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01700</td><td>Sharp Minima</td><td>尖锐最小值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01701</td><td>Shattering</td><td>打散</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01702</td><td>Shift Invariance</td><td>平移不变性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01703</td><td>Short-Term Memory</td><td>短期记忆</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01704</td><td>Shortcut Connection</td><td>直连边</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01705</td><td>Shortlist</td><td>短列表</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01706</td><td>Siamese Network</td><td>孪生网络</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-02-4">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01707</td><td>Sigmoid</td><td>Sigmoid（一种激活函数）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01708</td><td>Sigmoid Belief Network</td><td>Sigmoid信念网络</td><td>SBN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01709</td><td>Sigmoid Curve</td><td>S 形曲线</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01710</td><td>Sigmoid Function</td><td>Sigmoid函数</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-11-02-26">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01711</td><td>Sign Function</td><td>符号函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01712</td><td>Signed Distance</td><td>带符号距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01713</td><td>Similarity</td><td>相似度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01714</td><td>Similarity Measure</td><td>相似度度量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01715</td><td>Simple Cell</td><td>简单细胞</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01716</td><td>Simple Recurrent Network</td><td>简单循环网络</td><td>SRN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01717</td><td>Simple Recurrent Neural Network</td><td>简单循环神经网络</td><td>S-RNN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01718</td><td>Simplex</td><td>单纯形</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01719</td><td>Simulated Annealing</td><td>模拟退火</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td>统计、机器学习</td></tr><tr class="even"><td>AITD-01720</td><td>Simultaneous Localization And Mapping</td><td>即时定位与地图构建</td><td>SLAM</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01721</td><td>Single Component Metropolis-Hastings</td><td>单分量Metropolis-Hastings</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01722</td><td>Single Linkage</td><td>单连接</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01723</td><td>Singular</td><td>奇异的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01724</td><td>Singular Value</td><td>奇异值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01725</td><td>Singular Value Decomposition</td><td>奇异值分解</td><td>SVD</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01726</td><td>Singular Vector</td><td>奇异向量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01727</td><td>Size</td><td>大小</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01728</td><td>Skip Connection</td><td>跳跃连接</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01729</td><td>Skip-Gram Model</td><td>跳元模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01730</td><td>Skip-Gram Model With Negative Sampling</td><td>跳元模型加负采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01731</td><td>Slack Variable</td><td>松弛变量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01732</td><td>Slow Feature Analysis</td><td>慢特征分析</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01733</td><td>Slowness Principle</td><td>慢性原则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01734</td><td>Smoothing</td><td>平滑</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01735</td><td>Smoothness Prior</td><td>平滑先验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01736</td><td>Soft Attention Mechanism</td><td>软性注意力机制</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01737</td><td>Soft Clustering</td><td>软聚类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01738</td><td>Soft Margin</td><td>软间隔</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01739</td><td>Soft Margin Maximization</td><td>软间隔最大化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01740</td><td>Soft Target</td><td>软目标</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01741</td><td>Soft Voting</td><td>软投票</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01742</td><td>Softmax</td><td>Softmax/软最大化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01743</td><td>Softmax Function</td><td>Softmax函数/软最大化函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00398/978-1-78801-789-3">[1]</a></td><td>统计、机器学习</td></tr><tr class="even"><td>AITD-01744</td><td>Softmax Regression</td><td>Softmax回归/软最大化回归</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01745</td><td>Softmax Unit</td><td>Softmax单元/软最大化单元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01746</td><td>Softplus</td><td>Softplus</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01747</td><td>Softplus Function</td><td>Softplus函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01748</td><td>Source Domain</td><td>源领域</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01749</td><td>Span</td><td>张成子空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01750</td><td>Sparse</td><td>稀疏</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01751</td><td>Sparse Activation</td><td>稀疏激活</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01752</td><td>Sparse Auto-Encoder</td><td>稀疏自编码器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01753</td><td>Sparse Coding</td><td>稀疏编码</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01754</td><td>Sparse Connectivity</td><td>稀疏连接</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01755</td><td>Sparse Initialization</td><td>稀疏初始化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01756</td><td>Sparse Interactions</td><td>稀疏交互</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01757</td><td>Sparse Representation</td><td>稀疏表示</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01758</td><td>Sparse Weights</td><td>稀疏权重</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01759</td><td>Sparsity</td><td>稀疏性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01760</td><td>Specialization</td><td>特化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01761</td><td>Spectral Clustering</td><td>谱聚类</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01762</td><td>Spectral Radius</td><td>谱半径</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01763</td><td>Speech Recognition</td><td>语音识别</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[3]</a><ahref="https://www.jiqizhixin.com/articles/2018-01-01-3">[4]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-04">[5]</a><ahref="https://www.jiqizhixin.com/articles/2017-12-15">[6]</a></td><td></td></tr><tr class="even"><td>AITD-01764</td><td>Sphering</td><td>Sphering</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01765</td><td>Spike And Slab</td><td>尖峰和平板</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01766</td><td>Spike And Slab RBM</td><td>尖峰和平板RBM</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01767</td><td>Spiking Neural Nets</td><td>脉冲神经网络</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-13-7">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01768</td><td>Splitting Point</td><td>切分点</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01769</td><td>Splitting Variable</td><td>切分变量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01770</td><td>Spurious Modes</td><td>虚假模态</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01771</td><td>Square</td><td>方阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01772</td><td>Square Loss</td><td>平方损失</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01773</td><td>Squared Euclidean Distance</td><td>欧氏距离平方</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01774</td><td>Squared Exponential</td><td>平方指数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01775</td><td>Squashing Function</td><td>挤压函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01776</td><td>Stability</td><td>稳定性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01777</td><td>Stability-Plasticity Dilemma</td><td>可塑性-稳定性窘境</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01778</td><td>Stable Base Learner</td><td>稳定基学习器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01779</td><td>Stacked Auto-Encoder</td><td>堆叠自编码器</td><td>SAE</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01780</td><td>Stacked Deconvolutional Network</td><td>堆叠解卷积网络</td><td>SDN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01781</td><td>Stacked Recurrent Neural Network</td><td>堆叠循环神经网络</td><td>SRNN</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01782</td><td>Standard Basis</td><td>标准基</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01783</td><td>Standard Deviation</td><td>标准差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01784</td><td>Standard Error</td><td>标准差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01785</td><td>Standard Normal Distribution</td><td>标准正态分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01786</td><td>Standardization</td><td>标准化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01787</td><td>State</td><td>状态</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01788</td><td>State Action Reward State Action</td><td>SARSA算法</td><td>SARSA</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01789</td><td>State Sequence</td><td>状态序列</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01790</td><td>State Space</td><td>状态空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01791</td><td>State Value Function</td><td>状态值函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01792</td><td>State-Action Value Function</td><td>状态-动作值函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01793</td><td>Statement</td><td>声明</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01794</td><td>Static Computational Graph</td><td>静态计算图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01795</td><td>Static Game</td><td>静态博弈</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01796</td><td>Stationary</td><td>平稳的</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01797</td><td>Stationary Distribution</td><td>平稳分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01798</td><td>Stationary Point</td><td>驻点</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01799</td><td>Statistic Efficiency</td><td>统计效率</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01800</td><td>Statistical Learning</td><td>统计学习</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-01801</td><td>Statistical Learning Theory</td><td>统计学习理论</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01802</td><td>Statistical Machine Learning</td><td>统计机器学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01803</td><td>Statistical Relational Learning</td><td>统计关系学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01804</td><td>Statistical Simulation Method</td><td>统计模拟方法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01805</td><td>Statistics</td><td>统计量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01806</td><td>Status Feature Function</td><td>状态特征函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01807</td><td>Steepest Descent</td><td>最速下降法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01808</td><td>Step Decay</td><td>阶梯衰减</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01809</td><td>Stochastic</td><td>随机</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01810</td><td>Stochastic Curriculum</td><td>随机课程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01811</td><td>Stochastic Dynamical System</td><td>随机动力系统</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01812</td><td>Stochastic Gradient Ascent</td><td>随机梯度上升</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01813</td><td>Stochastic Gradient Descent</td><td>随机梯度下降</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-12-25-10">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01814</td><td>Stochastic Gradient Descent With Warm Restarts</td><td>带热重启的随机梯度下降</td><td>SGDR</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01815</td><td>Stochastic Matrix</td><td>随机矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01816</td><td>Stochastic Maximum Likelihood</td><td>随机最大似然</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01817</td><td>Stochastic Neighbor Embedding</td><td>随机近邻嵌入</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01818</td><td>Stochastic Neural Network</td><td>随机神经网络</td><td>SNN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01819</td><td>Stochastic Policy</td><td>随机性策略</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01820</td><td>Stochastic Process</td><td>随机过程</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01821</td><td>Stop Words</td><td>停用词</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01822</td><td>Stratified Sampling</td><td>分层采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01823</td><td>Stream</td><td>流</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01824</td><td>Stride</td><td>步幅</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01825</td><td>String Kernel Function</td><td>字符串核函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01826</td><td>Strong Classifier</td><td>强分类器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01827</td><td>Strong Duality</td><td>强对偶性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01828</td><td>Strongly Connected Graph</td><td>强连通图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01829</td><td>Strongly Learnable</td><td>强可学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01830</td><td>Structural Risk</td><td>结构风险</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01831</td><td>Structural Risk Minimization</td><td>结构风险最小化</td><td>SRM</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01832</td><td>Structure Learning</td><td>结构学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01833</td><td>Structured Learning</td><td>结构化学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01834</td><td>Structured Probabilistic Model</td><td>结构化概率模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01835</td><td>Structured Variational Inference</td><td>结构化变分推断</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01836</td><td>Student Network</td><td>学生网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01837</td><td>Sub-Optimal</td><td>次最优</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01838</td><td>Subatomic</td><td>亚原子</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01839</td><td>Subsample</td><td>子采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01840</td><td>Subsampling</td><td>下采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01841</td><td>Subsampling Layer</td><td>子采样层</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01842</td><td>Subset Evaluation</td><td>子集评价</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01843</td><td>Subset Search</td><td>子集搜索</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01844</td><td>Subspace</td><td>子空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01845</td><td>Substitution</td><td>置换</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01846</td><td>Successive Halving</td><td>逐次减半</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01847</td><td>Sum Rule</td><td>求和法则</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01848</td><td>Sum-Product</td><td>和积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01849</td><td>Sum-Product Network</td><td>和-积网络</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01850</td><td>Super-Parent</td><td>超父</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01851</td><td>Supervised</td><td>监督</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01852</td><td>Supervised Learning</td><td>监督学习</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[3]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01853</td><td>Supervised Learning Algorithm</td><td>监督学习算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01854</td><td>Supervised Model</td><td>监督模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01855</td><td>Supervised Pretraining</td><td>监督预训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01856</td><td>Support Vector</td><td>支持向量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>统计、机器学习</td></tr><tr class="odd"><td>AITD-01857</td><td>Support Vector Expansion</td><td>支持向量展式</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01858</td><td>Support Vector Machine</td><td>支持向量机</td><td>SVM</td><td><a href="https://www.jiqizhixin.com/articles/2017-10-08">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00251/978-1-78801-789-3">[4]</a></td><td>统计、机器学习</td></tr><tr class="odd"><td>AITD-01859</td><td>Support Vector Regression</td><td>支持向量回归</td><td>SVR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[3]</a></td><td>统计、机器学习</td></tr><tr class="even"><td>AITD-01860</td><td>Surrogat Loss</td><td>替代损失</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01861</td><td>Surrogate Function</td><td>替代函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01862</td><td>Surrogate Loss Function</td><td>代理损失函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01863</td><td>Symbol</td><td>符号</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01864</td><td>Symbolic Differentiation</td><td>符号微分</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01865</td><td>Symbolic Learning</td><td>符号学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01866</td><td>Symbolic Representation</td><td>符号表示</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01867</td><td>Symbolism</td><td>符号主义</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01868</td><td>Symmetric</td><td>对称</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01869</td><td>Symmetric Matrix</td><td>对称矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01870</td><td>Synonymy</td><td>多词一义性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01871</td><td>Synset</td><td>同义词集</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01872</td><td>Synthetic Feature</td><td>合成特征</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01873</td><td>T-Distribution Stochastic Neighbour Embedding</td><td>T分布随机近邻嵌入</td><td>T-SNE</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01874</td><td>Tabular Value Function</td><td>表格值函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01875</td><td>Tagging</td><td>标注</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01876</td><td>Tangent Distance</td><td>切面距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01877</td><td>Tangent Plane</td><td>切平面</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01878</td><td>Tangent Propagation</td><td>正切传播</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01879</td><td>Target</td><td>目标</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01880</td><td>Target Domain</td><td>目标领域</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01881</td><td>Taylor</td><td>泰勒</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01882</td><td>Taylor's Formula</td><td>泰勒公式</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01883</td><td>Teacher Forcing</td><td>强制教学</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01884</td><td>Teacher Network</td><td>教师网络</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01885</td><td>Temperature</td><td>温度</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01886</td><td>Tempered Transition</td><td>回火转移</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01887</td><td>Tempering</td><td>回火</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01888</td><td>Temporal-Difference Learning</td><td>时序差分学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01889</td><td>Tensor</td><td>张量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01890</td><td>Tensor Processing Units</td><td>张量处理单元</td><td>TPU</td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-05-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01891</td><td>Term Frequency-Inverse Document Frequency</td><td>单词频率-逆文本频率</td><td>TF-IDF</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01892</td><td>Terminal State</td><td>终止状态</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01893</td><td>Test Data</td><td>测试数据</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01894</td><td>Test Error</td><td>测试误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01895</td><td>Test Sample</td><td>测试样本</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01896</td><td>Test Set</td><td>测试集</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[3]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01897</td><td>The Collider Case</td><td>碰撞情况</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01898</td><td>Threshold</td><td>阈值</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>数学</td></tr><tr class="odd"><td>AITD-01899</td><td>Threshold Logic Unit</td><td>阈值逻辑单元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01900</td><td>Threshold-Moving</td><td>阈值移动</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01901</td><td>Tied Weight</td><td>捆绑权重</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01902</td><td>Tikhonov Regularization</td><td>Tikhonov正则化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01903</td><td>Tiled Convolution</td><td>平铺卷积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01904</td><td>Time Delay Neural Network</td><td>时延神经网络</td><td>TDNN</td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01905</td><td>Time Homogenous Markov Chain</td><td>时间齐次马尔可夫链</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01906</td><td>Time Step</td><td>时间步</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01907</td><td>Toeplitz Matrix</td><td>Toeplitz矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01908</td><td>Token</td><td>词元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01909</td><td>Tokenize</td><td>词元化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01910</td><td>Tokenization</td><td>词元化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01911</td><td>Tokenizer</td><td>词元分析器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01912</td><td>Tolerance</td><td>容差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01913</td><td>Top-Down</td><td>自顶向下</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-01914</td><td>Topic</td><td>话题</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01915</td><td>Topic Model</td><td>话题模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01916</td><td>Topic Modeling</td><td>话题分析</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01917</td><td>Topic Vector Space</td><td>话题向量空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01918</td><td>Topic Vector Space Model</td><td>话题向量空间模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01919</td><td>Topic-Document Matrix</td><td>话题-文本矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01920</td><td>Topographic ICA</td><td>地质ICA</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01921</td><td>Total Cost</td><td>总体代价</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01922</td><td>Trace</td><td>迹</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01923</td><td>Tractable</td><td>易处理的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01924</td><td>Training</td><td>训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01925</td><td>Training Data</td><td>训练数据</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01926</td><td>Training Error</td><td>训练误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01927</td><td>Training Instance</td><td>训练实例</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01928</td><td>Training Sample</td><td>训练样本</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-01929</td><td>Training Set</td><td>训练集</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-01930</td><td>Trajectory</td><td>轨迹</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01931</td><td>Transcribe</td><td>转录</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01932</td><td>Transcription System</td><td>转录系统</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01933</td><td>Transductive Learning</td><td>直推学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01934</td><td>Transductive Transfer Learning</td><td>直推迁移学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01935</td><td>Transfer Learning</td><td>迁移学习</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-04-7">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[4]</a></td><td></td></tr><tr class="even"><td>AITD-01936</td><td>Transform</td><td>变换</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01937</td><td>Transformer</td><td>Transformer</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01938</td><td>Transformer Model</td><td>Transformer模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01939</td><td>Transition</td><td>转移</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01940</td><td>Transition Kernel</td><td>转移核</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01941</td><td>Transition Matrix</td><td>状态转移矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01942</td><td>Transition Probability</td><td>转移概率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01943</td><td>Transpose</td><td>转置</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01944</td><td>Transposed Convolution</td><td>转置卷积</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01945</td><td>Tree-Structured LSTM</td><td>树结构的长短期记忆模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01946</td><td>Treebank</td><td>树库</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01947</td><td>Trial</td><td>试验</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01948</td><td>Trial And Error</td><td>试错</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01949</td><td>Triangle Inequality</td><td>三角不等式</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01950</td><td>Triangular Cyclic Learning Rate</td><td>三角循环学习率</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01951</td><td>Triangulate</td><td>三角形化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01952</td><td>Triangulated Graph</td><td>三角形化图</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01953</td><td>Trigram</td><td>三元语法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01954</td><td>True Negative</td><td>真负例</td><td>TN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-01955</td><td>True Positive</td><td>真正例</td><td>TP</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-01956</td><td>True Positive Rate</td><td>真正例率</td><td>TPR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-01957</td><td>Truncated Singular Value Decomposition</td><td>截断奇异值分解</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01958</td><td>Truncation Error</td><td>截断误差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01959</td><td>Turing Completeness</td><td>图灵完备</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01960</td><td>Turing Machine</td><td>图灵机</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-04-11-7">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-01961</td><td>Twice-Learning</td><td>二次学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01962</td><td>Two-Dimensional Array</td><td>二维数组</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01963</td><td>Ugly Duckling Theorem</td><td>丑小鸭定理</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01964</td><td>Unbiased</td><td>无偏</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01965</td><td>Unbiased Estimate</td><td>无偏估计</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01966</td><td>Unbiased Sample Variance</td><td>无偏样本方差</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01967</td><td>Unconstrained Optimization</td><td>无约束优化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01968</td><td>Undercomplete</td><td>欠完备</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01969</td><td>Underdetermined</td><td>欠定的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01970</td><td>Underestimation</td><td>欠估计</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01971</td><td>Underfitting</td><td>欠拟合</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-01972</td><td>Underfitting Regime</td><td>欠拟合机制</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01973</td><td>Underflow</td><td>下溢</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01974</td><td>Underlying</td><td>潜在</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01975</td><td>Underlying Cause</td><td>潜在成因</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01976</td><td>Undersampling</td><td>欠采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01977</td><td>Understandability</td><td>可理解性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01978</td><td>Undirected</td><td>无向</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01979</td><td>Undirected Graph</td><td>无向图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01980</td><td>Undirected Graphical Model</td><td>无向图模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01981</td><td>Undirected Model</td><td>无向模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01982</td><td>Unequal Cost</td><td>非均等代价</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01983</td><td>Unfolded Graph</td><td>展开图</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01984</td><td>Unfolding</td><td>展开</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01985</td><td>Unidirectional Language Model</td><td>单向语言模型</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01986</td><td>Unification</td><td>合一</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01987</td><td>Uniform Distribution</td><td>均匀分布</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01988</td><td>Uniform Sampling</td><td>均匀采样</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01989</td><td>Uniform Stability</td><td>均匀稳定性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01990</td><td>Unigram</td><td>一元语法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01991</td><td>Unimodal</td><td>单峰值</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01992</td><td>Unit</td><td>单元</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01993</td><td>Unit Norm</td><td>单位范数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01994</td><td>Unit Test</td><td>单元测试</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01995</td><td>Unit Variance</td><td>单位方差</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01996</td><td>Unit Vector</td><td>单位向量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01997</td><td>Unit-Step Function</td><td>单位阶跃函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-01998</td><td>Unitary Matrix</td><td>酉矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-01999</td><td>Univariate Decision Tree</td><td>单变量决策树</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02000</td><td>Universal Approximation Theorem</td><td>通用近似定理</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02001</td><td>Universal Approximator</td><td>通用近似器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02002</td><td>Universal Function Approximator</td><td>通用函数近似器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02003</td><td>Unknown Token</td><td>未知词元</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02004</td><td>Unlabeled</td><td>未标记</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02005</td><td>Unnormalized Probability Function</td><td>未规范化概率函数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02006</td><td>Unprojection</td><td>反投影</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02007</td><td>Unshared Convolution</td><td>非共享卷积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02008</td><td>Unsupervised</td><td>无监督</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02009</td><td>Unsupervised Feature Learning</td><td>无监督特征学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02010</td><td>Unsupervised Layer-Wise Training</td><td>无监督逐层训练</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02011</td><td>Unsupervised Learning Algorithm</td><td>无监督学习算法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02012</td><td>Unsupervised Learning</td><td>无监督学习</td><td>UL</td><td><a href="https://www.jiqizhixin.com/articles/2017-11-17-5">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="odd"><td>AITD-02013</td><td>Unsupervised Pretraining</td><td>无监督预训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02014</td><td>Update Gate</td><td>更新门</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02015</td><td>Update Model Parameter</td><td>迭代模型参数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02016</td><td>Upper Confidence Bounds</td><td>上置信界限</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02017</td><td>Upsampling</td><td>上采样</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02018</td><td>V-Structure</td><td>V型结构</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02019</td><td>Valid</td><td>有效</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02020</td><td>Validation Set</td><td>验证集</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02021</td><td>Validity Index</td><td>有效性指标</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02022</td><td>Value Function</td><td>价值函数</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02023</td><td>Value Function Approximation</td><td>值函数近似</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02024</td><td>Value Iteration</td><td>值迭代</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02025</td><td>Vanishing And Exploding Gradient Problem</td><td>梯度消失与爆炸问题</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02026</td><td>Vanishing Gradient</td><td>梯度消失</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02027</td><td>Vanishing Gradient Problem</td><td>梯度消失问题</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2018-01-07-2">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02028</td><td>Vapnik-Chervonenkis Dimension</td><td>VC维</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02029</td><td>Variable Elimination</td><td>变量消去</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02030</td><td>Variance</td><td>方差</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02031</td><td>Variance Reduction</td><td>方差减小</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02032</td><td>Variance Scaling</td><td>方差缩放</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02033</td><td>Variational Autoencoder</td><td>变分自编码器</td><td>VAE</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02034</td><td>Variational Bayesian</td><td>变分贝叶斯</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02035</td><td>Variational Derivative</td><td>变分导数</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02036</td><td>Variational Distribution</td><td>变分分布</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02037</td><td>Variational Dropout</td><td>变分暂退法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02038</td><td>Variational EM Algorithm</td><td>变分EM算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02039</td><td>Variational Free Energy</td><td>变分自由能</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02040</td><td>Variational Inference</td><td>变分推断</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02041</td><td>Vector</td><td>向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02042</td><td>Vector Space</td><td>向量空间</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02043</td><td>Vector Space Model</td><td>向量空间模型</td><td>VSM</td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02044</td><td>Vectorization</td><td>向量化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02045</td><td>Version Space</td><td>版本空间</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02046</td><td>Virtual Adversarial Example</td><td>虚拟对抗样本</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02047</td><td>Virtual Adversarial Training</td><td>虚拟对抗训练</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02048</td><td>Visible Layer</td><td>可见层</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02049</td><td>Visible Variable</td><td>可见变量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02050</td><td>Viterbi Algorithm</td><td>维特比算法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02051</td><td>Vocabulary</td><td>词表</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02052</td><td>Von Neumann Architecture</td><td>冯 · 诺伊曼架构</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02053</td><td>Voted Perceptron</td><td>投票感知器</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02054</td><td>Wake Sleep</td><td>醒眠</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02055</td><td>Warp</td><td>线程束</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02056</td><td>Wasserstein Distance</td><td>Wasserstein距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02057</td><td>Wasserstein GAN</td><td>Wasserstein生成对抗网络</td><td>WGAN</td><td><ahref="https://www.jiqizhixin.com/articles/2017-10-05">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02058</td><td>Weak Classifier</td><td>弱分类器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02059</td><td>Weak Duality</td><td>弱对偶性</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02060</td><td>Weak Learner</td><td>弱学习器</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02061</td><td>Weakly Learnable</td><td>弱可学习</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02062</td><td>Weakly Supervised Learning</td><td>弱监督学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02063</td><td>Weight</td><td>权重</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2018-01-08-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-02064</td><td>Weight Decay</td><td>权重衰减</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02065</td><td>Weight Normalization</td><td>权重规范化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02066</td><td>Weight Scaling Inference Rule</td><td>权重比例推断规则</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02067</td><td>Weight Sharing</td><td>权共享</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02068</td><td>Weight Space Symmetry</td><td>权重空间对称性</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02069</td><td>Weight Vector</td><td>权值向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02070</td><td>Weighted Distance</td><td>加权距离</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02071</td><td>Weighted Voting</td><td>加权投票</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02072</td><td>Whitening</td><td>白化</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02073</td><td>Wide Convolution</td><td>宽卷积</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02074</td><td>Width</td><td>宽度</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02075</td><td>Winner-Take-All</td><td>胜者通吃</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02076</td><td>Within-Class Scatter Matrix</td><td>类内散度矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02077</td><td>Word Embedding</td><td>词嵌入</td><td></td><td><a href="https://www.jiqizhixin.com/articles/2017-11-20-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02078</td><td>Word Sense Disambiguation</td><td>词义消歧</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02079</td><td>Word Vector</td><td>词向量</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02080</td><td>Word Vector Space Model</td><td>单词向量空间模型</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02081</td><td>Word-Document Matrix</td><td>单词-文本矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02082</td><td>Word-Topic Matrix</td><td>单词-话题矩阵</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02083</td><td>Working Memory</td><td>工作记忆</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02084</td><td>Wrapper Method</td><td>包裹式方法</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02085</td><td>Z-Score Normalization</td><td>Z值规范化</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02086</td><td>Zero Mean</td><td>零均值</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02087</td><td>Zero Padding</td><td>零填充</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02088</td><td>Zero Tensor</td><td>零张量</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02089</td><td>Zero-Centered</td><td>零中心化的</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02090</td><td>Zero-Data Learning</td><td>零数据学习</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02091</td><td>Zero-Shot Learning</td><td>零试学习</td><td></td><td><ahref="https://www.jiqizhixin.com/articles/2017-03-31-6">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02092</td><td>Zipf's Law</td><td>齐普夫定律</td><td></td><td>[1]</td><td></td></tr><tr class="odd"><td>AITD-02093</td><td>ε-Greedy Method</td><td>ε-贪心法</td><td></td><td>[1]</td><td></td></tr><tr class="even"><td>AITD-02094</td><td>2D Qsar Models</td><td>二维定量构效关系模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>化学</td></tr><tr class="odd"><td>AITD-02095</td><td>3D Cartesian</td><td>三维笛卡尔（坐标）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td>数学</td></tr><tr class="even"><td>AITD-02096</td><td>3D Conformation</td><td>三维构象</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>化学、生化</td></tr><tr class="odd"><td>AITD-02097</td><td>3D Grids</td><td>三维（坐标）网格</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02098</td><td>3D Qsar Models</td><td>三维定量构效关系模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>化学</td></tr><tr class="odd"><td>AITD-02099</td><td>Aberration-Corrected</td><td>像差矫正</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td>物理</td></tr><tr class="even"><td>AITD-02100</td><td>Active Machine Learning</td><td>主动机器学习</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02101</td><td>Adaptive Fuzzy Neural Network</td><td>自适应模糊神经网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02102</td><td>Adaptive Sampling</td><td>自适应采样</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02103</td><td>Admet Evaluation</td><td>毒性评估</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00251/978-1-78801-789-3">[1]</a></td><td>化学</td></tr><tr class="even"><td>AITD-02104</td><td>Alexnet</td><td>AlexNet</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02105</td><td>Alphago</td><td>阿尔法狗</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[2]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02106</td><td>Adaptive Neuro Fuzzy Inference System</td><td>自适应神经模糊推理系统</td><td>ANFIS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02107</td><td>Approximate Probabilistic Models</td><td>近似概率模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02108</td><td>Artificial Neurons</td><td>人工神经元</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02109</td><td>Artificial Synapses</td><td>人工突触</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02110</td><td>Attention-Based</td><td>基于注意力（机制）的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02111</td><td>Automating Synthetic Planning</td><td>自动化综合规划</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02112</td><td>Automation</td><td>自动化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02113</td><td>Autonomous Decision-Making</td><td>自主决策</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02114</td><td>B-Clustering Algorithms</td><td>B树聚类算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02115</td><td>Balanced Accuracy</td><td>平衡精度</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02116</td><td>Bandgap Energy</td><td>带隙能量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>物理</td></tr><tr class="odd"><td>AITD-02117</td><td>Baseline Test</td><td>基准测试</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02118</td><td>Basin Hopping</td><td>盆地跳跃（算法）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02119</td><td>Bayesian Approach</td><td>贝叶斯方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="even"><td>AITD-02120</td><td>Bayesian Induction</td><td>贝叶斯归纳</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="odd"><td>AITD-02121</td><td>Bayesian Mcmc Methods</td><td>贝叶斯马尔可夫链蒙特卡洛方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="even"><td>AITD-02122</td><td>Bayesian Methods</td><td>贝叶斯方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="odd"><td>AITD-02123</td><td>Bayesian Molecular</td><td>贝叶斯分子（设计方法）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td>统计，机器学习，化学</td></tr><tr class="even"><td>AITD-02124</td><td>Bayesian Prior</td><td>贝叶斯先验</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="odd"><td>AITD-02125</td><td>Bayesian Program Learning</td><td>贝叶斯程序学习</td><td>BPL</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="even"><td>AITD-02126</td><td>Bayesian Regularized Neural Network</td><td>贝叶斯正则化神经网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td>统计，机器学习</td></tr><tr class="odd"><td>AITD-02127</td><td>Beam-Scanning</td><td>波束扫描</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td>物理</td></tr><tr class="even"><td>AITD-02128</td><td>Best Separates</td><td>最优分离</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02129</td><td>Biased Dataset</td><td>有偏数据集</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02130</td><td>Bit Collisions</td><td>字节碰撞/冲突</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td>数据库</td></tr><tr class="odd"><td>AITD-02131</td><td>Black Box</td><td>黑盒子</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02132</td><td>Black-Box Attack</td><td>黑盒攻击</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02133</td><td>Bonding Environments</td><td>成键环境</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02134</td><td>Bonferroni Correction</td><td>邦弗朗尼校正</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-02135</td><td>Bootstrap Aggregation</td><td>引导聚合</td><td>bagging</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02136</td><td>Broyden–Fletcher–Goldfarb–Shanno</td><td>BFGS（算法）</td><td>BFGS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td>一种拟牛顿法，数学计算</td></tr><tr class="odd"><td>AITD-02137</td><td>Buchwald−Hartwig Cross-Coupling</td><td>Buchwald–Hartwig 偶联（反应）</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>化学</td></tr><tr class="even"><td>AITD-02138</td><td>C4.5 Algorithm</td><td>C4.5 算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>一种决策树算法，数据挖掘</td></tr><tr class="odd"><td>AITD-02139</td><td>Calculation Uncertainties</td><td>计算不确定性</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02140</td><td>Canonical Ml Methods</td><td>经典机器学习方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02141</td><td>Cartesian Distance Vector</td><td>笛卡尔距离向量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02142</td><td>CASP</td><td>国际蛋白质结构预测竞赛</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td>生物</td></tr><tr class="odd"><td>AITD-02143</td><td>Categorical Data</td><td>分类数据</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02144</td><td>Categorization Algorithms</td><td>分类算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02145</td><td>ChemDataExtractor</td><td>化学数据提取器</td><td>CDE</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02146</td><td>Chi-Squared</td><td>卡方（分布）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02147</td><td>Classification Model</td><td>分类模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02148</td><td>Cluster Resolution Feature Selection</td><td>聚类分辨率特征选择</td><td>CR-FS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02149</td><td>Cluster-Based Splitting</td><td>基于聚类的分离方法</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02150</td><td>Clustering Methods</td><td>聚类方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02151</td><td>Code Pipeline</td><td>代码流水线</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02152</td><td>Coefficient of Determination</td><td>决定系数</td><td>r^2 or R^2</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-02153</td><td>Combined Gradient</td><td>组合梯度（算法）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02154</td><td>Complex Data</td><td>复合数据</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02155</td><td>Computational Cost</td><td>计算成本</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02156</td><td>Computational Optimisation</td><td>计算优化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02157</td><td>Computational Science</td><td>计算科学</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02158</td><td>Computational Toxicology</td><td>计算毒理学</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02159</td><td>Computer Science</td><td>计算机科学</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02160</td><td>Computer Simulations</td><td>计算机模拟</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00512/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02161</td><td>Computer-Aided</td><td>计算机辅助</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02162</td><td>Constraint</td><td>约束</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02163</td><td>Core-Loss Spectrum</td><td>（电子能量损失谱中的）高能区域</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02164</td><td>Coulomb Matrix</td><td>库仑矩阵</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02165</td><td>Coupled-Cluster Predictions</td><td>耦合簇预测</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02166</td><td>Cross-Validated Coefficient of Determination</td><td>交叉验证的决定系数</td><td>q^2 or Q^2</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02167</td><td>Cross-Validation</td><td>交叉验证</td><td>CV</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-02168</td><td>Crowd-Sourcing</td><td>众包</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>商业模式</td></tr><tr class="odd"><td>AITD-02169</td><td>Cut-Points</td><td>切点</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02170</td><td>Cutoff Radial Function</td><td>截断径向函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02171</td><td>Data Availability</td><td>数据可用性</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02172</td><td>Data Cleaning</td><td>数据清洗</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-02173</td><td>Data Collection</td><td>数据采集</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-02174</td><td>Data Considerations</td><td>数据注意事项</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02175</td><td>Data Curation</td><td>数据监管</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02176</td><td>Data Disparity</td><td>数据差异</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02177</td><td>Data Dredging</td><td>数据挖掘</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02178</td><td>Data Imputation</td><td>数据填补</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02179</td><td>Data Labels</td><td>数据标签</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02180</td><td>Data Leakage</td><td>数据泄露</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02181</td><td>Data Pre-Processing</td><td>数据预处理</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02182</td><td>Data Processing</td><td>数据处理</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02183</td><td>Data Quality</td><td>数据质量</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02184</td><td>Data Reduction</td><td>数据缩减</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-02185</td><td>Data Representation</td><td>数据表示</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02186</td><td>Data Selection</td><td>数据选择</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02187</td><td>Data Sources</td><td>数据源</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02188</td><td>Data Splitting</td><td>数据拆分</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02189</td><td>Data Transformation</td><td>数据转换</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02190</td><td>Data-Driven</td><td>数据驱动</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-02191</td><td>Data-Driven Decision-Making</td><td>数据驱动的决策</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02192</td><td>Data-Driven Methods</td><td>数据驱动的方法</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02193</td><td>Data-Driven Spectral Analysis</td><td>数据驱动的光谱分析</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02194</td><td>Data-Mining</td><td>数据挖掘</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02195</td><td>Database</td><td>数据库</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02196</td><td>DE Algorithm</td><td>差分进化算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02197</td><td>Deeplift</td><td>DeepLift模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02198</td><td>Dendrogram</td><td>树状图</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02199</td><td>Density Functional Theory</td><td>密度泛函理论</td><td>DFT</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00512/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[3]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[4]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[5]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[6]</a></td><td></td></tr><tr class="even"><td>AITD-02200</td><td>Density-Based Spatial Clustering Of Applications With Noise</td><td>DBSCAN密度聚类</td><td>DBSCAN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02201</td><td>Descriptor</td><td>描述符</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02202</td><td>DFT Calculations</td><td>DFT计算</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02203</td><td>Dice Similarity</td><td>戴斯相似度</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02204</td><td>Differential Evolution</td><td>差分进化</td><td>DE</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02205</td><td>Dimensionality Reduction</td><td>降维</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02206</td><td>Direct Neural Network Modeling</td><td>正向神经网络建模</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02207</td><td>Discrete Manner</td><td>离散方式</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02208</td><td>Discrete Quanta</td><td>离散量子</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02209</td><td>Discretization</td><td>离散化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02210</td><td>Distillation</td><td>蒸馏</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02211</td><td>Dynamic Datasets</td><td>动态数据集</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02212</td><td>Dynamic Filter Networks</td><td>动态过滤网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02213</td><td>Dynamic Sampling</td><td>动态采样</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02214</td><td>Dynamics Simulations</td><td>动力学模拟</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02215</td><td>Eigenfunction</td><td>特征函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02216</td><td>Electronegativity</td><td>电负性</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02217</td><td>Elman</td><td>埃尔曼</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02218</td><td>Empirical Models</td><td>经验模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02219</td><td>Energy Derivatives</td><td>能源衍生品</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>在DP模型中：能量的导数</td></tr><tr class="even"><td>AITD-02220</td><td>Energy Potentials</td><td>能量潜力</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02221</td><td>Ensemble Methods</td><td>集成方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://www.nature.com/articles/s41557-021-00716-z">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02222</td><td>Entity Normalisation</td><td>实体规范化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02223</td><td>Ethical Considerations</td><td>道德考虑</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02224</td><td>Euclidean Distances</td><td>欧几里得距离</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00512/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02225</td><td>Evolutionary Algorithms</td><td>进化算法</td><td>EA</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02226</td><td>Evolutionary Method</td><td>进化方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02227</td><td>Exchange–Correlation</td><td>交换关联（的能量/泛函）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02228</td><td>Excited-State Potentials</td><td>激发态能量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02229</td><td>Expected Reduction In Distortion</td><td>符合预期的失真减少</td><td>ERD</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02230</td><td>Experimental Validation Data</td><td>实验验证数据</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02231</td><td>Expert Systems</td><td>专家系统</td><td>ESS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02232</td><td>Extended-Connectivity Circular Fingerprint</td><td>扩展连接环形指纹</td><td>ECFP</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02233</td><td>Extraction Techniques</td><td>提取技术</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02234</td><td>Faber-Christensen-Huang-Lilienfeld</td><td>Faber-Christensen-Huang-Lilienfeld</td><td>FCHL</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>四个人提出的化学结构量子机器学习方法</td></tr><tr class="odd"><td>AITD-02235</td><td>Facial Recognition</td><td>面部识别</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02236</td><td>FAIR Data Principles</td><td>FAIR数据原则</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td>Findability可找寻 Accessibility可访问 Interoperability可交互Reuse可再用</td></tr><tr class="odd"><td>AITD-02237</td><td>False Negatives</td><td>假阴性</td><td>FNs</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02238</td><td>False Positives</td><td>假阳性</td><td>FPs</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02239</td><td>Fchl Representation</td><td>Fchl 表示</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02240</td><td>Feature Binarization</td><td>特征二值化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02241</td><td>Feature Transform</td><td>特征变换</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02242</td><td>Feature Vectors</td><td>特征向量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02243</td><td>Features</td><td>特征</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02244</td><td>Feed Back</td><td>反馈</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02245</td><td>Feed-Forward Neural Networks</td><td>前馈神经网络</td><td>FFNN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-02246</td><td>Feedback Structure</td><td>反馈结构</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02247</td><td>Final Evaluation</td><td>最终评估</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02248</td><td>Findable, Accessible, Interoperable, Reusable</td><td>可查找、可访问、可互操作、可重用</td><td>FAIR</td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02249</td><td>First-Principles</td><td>第一性原理</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02250</td><td>Flow Rate</td><td>流速</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02251</td><td>Forward Cross-Validation</td><td>前向交叉验证</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02252</td><td>Forward Prediction</td><td>前向预测</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02253</td><td>Forward Reaction Prediction</td><td>前向反应预测</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02254</td><td>Fuzzy Logic</td><td>模糊逻辑</td><td>FL</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02255</td><td>Fuzzy Neural Networks</td><td>模糊神经网络</td><td>FNN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02256</td><td>Ga-Based Approaches</td><td>基于遗传算法的方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02257</td><td>Garbage In, Garbage Out</td><td>无用数据入、无用数据出</td><td>GIGO</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02258</td><td>Gas-Phase Networks</td><td>气相网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02259</td><td>Gaussian Kernels</td><td>高斯核</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02260</td><td>Gaussian-Type Structure Descriptors</td><td>高斯型结构描述符</td><td>GTSD</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02261</td><td>General Intelligence</td><td>通用智能</td><td>GI</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02262</td><td>Generalized Gradient Approximation</td><td>广义梯度近似</td><td>GGA</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02263</td><td>Generative Adversarial Networks</td><td>生成对抗网络</td><td>GAN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[2]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02264</td><td>Gradient Boosting Decision Tree</td><td>梯度提升决策树</td><td>GBDT</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02265</td><td>Gradient-Based</td><td>基于梯度的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02266</td><td>Grain-Surface Networks</td><td>粒面网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02267</td><td>Graph Convolutional</td><td>图卷积</td><td>GC</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02268</td><td>Graph Models</td><td>图模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02269</td><td>Graph Neural Networks</td><td>图神经网络</td><td>GNNS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02270</td><td>Graph-Based</td><td>基于图形</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02271</td><td>Graph-Based Models</td><td>基于图的模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02272</td><td>Graph-Based Neural Networks</td><td>基于图的神经网络</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02273</td><td>Graph-Based Representation</td><td>基于图的表示</td><td>GB-GA</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02274</td><td>Graph-Convolutional Neural Network</td><td>图卷积神经网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-02275</td><td>Graphics Processing Units</td><td>图形处理器</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02276</td><td>Gravimetric Polymerization Degree</td><td>比重聚合度</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02277</td><td>Hamiltonian Matrix</td><td>哈密顿矩阵</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>物理</td></tr><tr class="even"><td>AITD-02278</td><td>Hamiltonian Operator</td><td>哈密顿算符</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td>物理</td></tr><tr class="odd"><td>AITD-02279</td><td>Heterogeneous Data</td><td>异构数据</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00398/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[2]</a></td><td></td></tr><tr class="even"><td>AITD-02280</td><td>Hidden Layers</td><td>隐藏层</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02281</td><td>High Data Throughput</td><td>高数据吞吐量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02282</td><td>High Throughput</td><td>高通量</td><td>HT</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02283</td><td>High Throughput Screening</td><td>高通量筛选</td><td>HTS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02284</td><td>High Variance Models</td><td>高方差模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02285</td><td>High-Dimensional Data</td><td>高维数据</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02286</td><td>High-Dimensional NN</td><td>高维神经网络</td><td>HDNN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02287</td><td>High-Dimensional Objects</td><td>高维对象</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02288</td><td>High-Throughput</td><td>高通量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02289</td><td>Higher-Dimensional Space</td><td>高维空间</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>数学</td></tr><tr class="even"><td>AITD-02290</td><td>Higher-Dimensional Spectral Space</td><td>高维光谱空间</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02291</td><td>Homogenization</td><td>同质化</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02292</td><td>Homomorphic Encryption</td><td>同态加密</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02293</td><td>Human Face Recognition</td><td>人脸识别</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02294</td><td>Human-Encoded</td><td>人工编码的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02295</td><td>Hybrid Model</td><td>混合模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02296</td><td>Hybrid Technique</td><td>混合技术</td><td>HM</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02297</td><td>Hybrid-Neural Model</td><td>混合神经模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02298</td><td>Hyperparameter Opimization</td><td>超参数优化</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02299</td><td>Hyperparameters</td><td>超参数</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[3]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02300</td><td>Hyperplanes Separate</td><td>超平面分离</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02301</td><td>Id3 Algorithm</td><td>Id3 算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02302</td><td>Image And Speech Recognition</td><td>图像和语音识别</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02303</td><td>Image Classification</td><td>图像分类</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02304</td><td>Image Classifier</td><td>图像分类器</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02305</td><td>Image Recognition</td><td>图像识别</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02306</td><td>Informative Priors</td><td>信息先验</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02307</td><td>Input-Output Pairs</td><td>输入输出对</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02308</td><td>Instance-Based</td><td>基于实例的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02309</td><td>Intelligent Machine</td><td>智能机器</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02310</td><td>Intermediate Neurons</td><td>中间神经元</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02311</td><td>Internet Of Things</td><td>物联网</td><td>IoT</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02312</td><td>Interpolation Coordinate</td><td>插值坐标</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02313</td><td>Interpretability</td><td>可解释性</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02314</td><td>Inverse Neural Modeling</td><td>逆神经建模</td><td>INN</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02315</td><td>Inverse Neural Network Modeling</td><td>逆神经网络建模</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02316</td><td>Iterative Learning</td><td>迭代学习</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02317</td><td>Joint Distribution</td><td>联合分布</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02318</td><td>Jordan-Elman Neural Networks</td><td>Jordan-Elman 神经网络</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02319</td><td>K Clusters</td><td>K聚类</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02320</td><td>K Nearest Points</td><td>K 最近点</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-02321</td><td>K-1 Folds</td><td>K-1 折</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02322</td><td>K-Edge (O-K Edge)</td><td>K-边缘（O-K 边缘）</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02323</td><td>K-Means</td><td>K-均值</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02324</td><td>Kendall’S Tau</td><td>肯德尔等级相关系数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02325</td><td>Kernel Ridge Regression</td><td>核岭回归</td><td>KRR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[3]</a></td><td></td></tr><tr class="even"><td>AITD-02326</td><td>Kernels</td><td>内核</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02327</td><td>Kinetic Curve</td><td>动力学曲线</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02328</td><td>KNN Model</td><td>K 近邻模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02329</td><td>Knowledge Extraction</td><td>知识提取</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02330</td><td>Knowledge Gradient</td><td>知识梯度</td><td>KG</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02331</td><td>L1 And L2 Regularization</td><td>L1与L2正则化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02332</td><td>Laboratory Level</td><td>实验室级别</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02333</td><td>Language Processing</td><td>语言处理</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02334</td><td>Laplacian Prior</td><td>拉普拉斯先验</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02335</td><td>Large-Scale Data Storage</td><td>大规模数据存储</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02336</td><td>Lasers</td><td>激光器</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02337</td><td>Lasso Regression</td><td>拉索回归</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02338</td><td>LBP</td><td>局部二值模式</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02339</td><td>Least Absolute Shrinkage And Selection Operator</td><td>Lasso回归</td><td>LASSO</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02340</td><td>Least Square Support Vector Machine</td><td>最小二乘支持向量机</td><td>LSSVM</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02341</td><td>Ligand-Field</td><td>配位场</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02342</td><td>Linear</td><td>线性的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[2]</a></td><td>数学</td></tr><tr class="odd"><td>AITD-02343</td><td>Linear Dimension Reduction Methods</td><td>线性降维方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02344</td><td>Linear Vibronic Coupling Model</td><td>线性振子耦合模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02345</td><td>Local Recurrent</td><td>本地卷积</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02346</td><td>Logic And Heuristics Applied To Synthetic Analysis</td><td>LHASA 程序</td><td>LHASA</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02347</td><td>Long-Range Prediction</td><td>长期预测</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02348</td><td>Long-Range Prediction Models</td><td>长期预测模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02349</td><td>Long-Term Planning</td><td>长期规划</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02350</td><td>Long-Term Reward</td><td>长期回报</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02351</td><td>Machine-Readable Data</td><td>机器可读的数据</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02352</td><td>Mae</td><td>平均绝对误差</td><td>MAE</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02353</td><td>Mahalanobis Distances</td><td>马氏距离</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02354</td><td>Matrices</td><td>矩阵</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>数学</td></tr><tr class="odd"><td>AITD-02355</td><td>Matthews Correlation Coefficient</td><td>马修斯相关系数</td><td>MCC</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02356</td><td>Maximum Likelihood Methods</td><td>最大似然法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-02357</td><td>Maximum Likelihood Procedures</td><td>最大似然估计法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02358</td><td>MCTS Method</td><td>蒙特卡洛树搜索方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02359</td><td>Mean-Squared Error</td><td>均方误差</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>统计、机器学习</td></tr><tr class="even"><td>AITD-02360</td><td>Mechanical Sympathy</td><td>机械同感，软硬件协同编程</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02361</td><td>Merging</td><td>合并</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02362</td><td>Message Passing Neural Networks</td><td>消息传递神经网络</td><td>MPNNS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02363</td><td>Microarray Data</td><td>微阵列数据</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02364</td><td>Mini Batch</td><td>小批次</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02365</td><td>Mining</td><td>挖掘</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02366</td><td>Mining Out</td><td>挖掘</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02367</td><td>Missing Values</td><td>缺失值</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02368</td><td>ML Algorithm</td><td>机器学习算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02369</td><td>ML Modelling</td><td>机器学习建模</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00206/978-1-83916-023-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02370</td><td>ML Potentials</td><td>机器学习势能</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02371</td><td>ML-Driven</td><td>机器学习驱动的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02372</td><td>ML-Driven Optimization</td><td>机器学习驱动的最优化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02373</td><td>MLP Neural Model</td><td>多层感知机神经模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02374</td><td>Model Construction</td><td>模型构建</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02375</td><td>Model Evaluation</td><td>模型评估</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02376</td><td>Model Performance</td><td>模型性能</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02377</td><td>Model Statistics</td><td>模型统计</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02378</td><td>Model Training</td><td>模型训练</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02379</td><td>Model Validation</td><td>模型验证</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02380</td><td>Model-Based Iterative Reconstruction</td><td>基于模型的迭代重建</td><td>MBIR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00450/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02381</td><td>Model-Construction</td><td>模型构建</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02382</td><td>Modelling Scenario</td><td>建模场景</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02383</td><td>Molecular Graph Theory</td><td>分子图论</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02384</td><td>Molecular Modelling</td><td>分子建模</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02385</td><td>Monte Carlo Tree Search</td><td>蒙特卡洛树搜索</td><td>MCTS</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[2]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[3]</a></td><td>数学</td></tr><tr class="even"><td>AITD-02386</td><td>Moore’S Law</td><td>摩尔定律</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00512/978-1-78801-789-3">[1]</a></td><td>计算机</td></tr><tr class="odd"><td>AITD-02387</td><td>ms-QSBER-EL Model</td><td>基于人工神经网络组合的结构生物学效应定量关系多尺度模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00398/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02388</td><td>Multi-Agent Control System</td><td>多智能体控制系统</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02389</td><td>Multi-Core Desktop Computer</td><td>多核台式计算机</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td>计算机</td></tr><tr class="even"><td>AITD-02390</td><td>Multi-Dimensional Big Data Analysis</td><td>多维度大数据分析</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00424/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02391</td><td>Multi-Layer Feed-Forward</td><td>多层前馈</td><td>MLFF</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02392</td><td>Multi-Objective Genetic Algorithm</td><td>多目标遗传算法</td><td>MOGA</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02393</td><td>Multi-Objective Optimization</td><td>多目标优化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02394</td><td>Multi-Reaction Synthesis</td><td>多反应合成</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02395</td><td>Multilayer Perceptron</td><td>多层感知机</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00227/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02396</td><td>Multivariate Regression</td><td>多变量回归</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02397</td><td>N-Dimensional Space</td><td>N维空间</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00372/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02398</td><td>Naive Bayesian</td><td>朴素贝叶斯</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00251/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="odd"><td>AITD-02399</td><td>Naive Bayesian Methods</td><td>朴素贝叶斯方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00251/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02400</td><td>Named Entity Recognition，NER</td><td>命名实体识别</td><td>NER</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00280/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02401</td><td>Nearest Neighbors</td><td>近邻</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02402</td><td>Nearest Neighbour Model</td><td>近邻模型</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02403</td><td>Negative Predictive Value</td><td>阴性预测值</td><td>NPV</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02404</td><td>Network Architecture</td><td>网络结构</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02405</td><td>Network Geometry</td><td>网络几何</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02406</td><td>Neural Turing Machines</td><td>神经图灵机</td><td>NTM</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[2]</a></td><td></td></tr><tr class="odd"><td>AITD-02407</td><td>Neural-Network-Based Function</td><td>基于神经网络的函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00251/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02408</td><td>Neurons</td><td>神经元</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02409</td><td>Nuclear Magnetic Resonance</td><td>核磁共振</td><td>NMR</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02410</td><td>Noise Filters</td><td>噪声过滤器</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02411</td><td>Noise-Free</td><td>无噪的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02412</td><td>Non-Linear</td><td>非线性</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>数学、统计</td></tr><tr class="odd"><td>AITD-02413</td><td>Non-Linear Correlation</td><td>非线性相关</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00195/978-1-83916-023-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02414</td><td>Non-Linearity</td><td>非线性</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02415</td><td>Non-Parametric Algorithm</td><td>非参数化学习算法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00311/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02416</td><td>Non-Safety-Critical Applications</td><td>非安全关键型应用</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02417</td><td>Non-Steady-State</td><td>非稳态</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02418</td><td>Non-Stochastic</td><td>非随机的</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00398/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02419</td><td>Non-Template</td><td>非模板</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02420</td><td>Non-Template Methods</td><td>非模板方法</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02421</td><td>Non-Zero Weight</td><td>非零权重</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02422</td><td>On-The-Fly Optimization</td><td>运行中优化</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td>计算机</td></tr><tr class="odd"><td>AITD-02423</td><td>One-Hot Vector</td><td>独热向量</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00136/978-1-78801-789-3">[1]</a></td><td>整个矢量中之后一个数为1 其余为0</td></tr><tr class="even"><td>AITD-02424</td><td>Open-Source</td><td>开源</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>软件工程</td></tr><tr class="odd"><td>AITD-02425</td><td>Open-Source Dataset</td><td>开源数据集</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00169/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02426</td><td>Predicted Label</td><td>预测值</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02427</td><td>Prediction</td><td>预测</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02428</td><td>Prediction Accuracy</td><td>预测准确率</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02429</td><td>Predictor</td><td>预测器/决策函数</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00251/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="even"><td>AITD-02430</td><td>Protein Folding</td><td>蛋白折叠</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[2]</a></td><td>生物</td></tr><tr class="odd"><td>AITD-02431</td><td>Quantum Chemistry</td><td>量子化学</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00076/978-1-78801-789-3">[1]</a></td><td>化学</td></tr><tr class="even"><td>AITD-02432</td><td>Quantum Theory</td><td>量子理论</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td>物理</td></tr><tr class="odd"><td>AITD-02433</td><td>Random Selection</td><td>随机选择</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00037/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02434</td><td>Raw Datasets</td><td>原始数据集</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02435</td><td>Root Mean Square Errors</td><td>均方根</td><td>RMSE</td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00488/978-1-78801-789-3">[1]</a></td><td>统计</td></tr><tr class="even"><td>AITD-02436</td><td>Scaling</td><td>缩放</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00109/978-1-78801-789-3">[1]</a></td><td>图像处理</td></tr><tr class="odd"><td>AITD-02437</td><td>Simulation</td><td>仿真</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00340/978-1-78801-789-3">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02438</td><td>The Global Minimum</td><td>全局最小值</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00016/978-1-78801-789-3">[1]</a></td><td>机器学习</td></tr><tr class="odd"><td>AITD-02439</td><td>Turing Test</td><td>图灵测试</td><td></td><td><ahref="https://pubs.rsc.org/en/content/chapter/bk9781788017893-00001/978-1-78801-789-3">[1]</a></td><td>AI，CS</td></tr><tr class="even"><td>AITD-02440</td><td>Version Control</td><td>版本控制</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="odd"><td>AITD-02441</td><td>Workflow</td><td>工作流</td><td></td><td><ahref="https://www.nature.com/articles/s41557-021-00716-z">[1]</a></td><td></td></tr><tr class="even"><td>AITD-02442</td><td>Sequence-Function</td><td>序列-功能</td><td></td><td>[1]</td><td></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>人工智能</tag>
      
      <tag>AI</tag>
      
      <tag>专业名词</tag>
      
      <tag>基础概念</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【原创小诗】完整</title>
    <link href="/%E3%80%90%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F%E3%80%91-%20%E5%AE%8C%E6%95%B4.html"/>
    <url>/%E3%80%90%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F%E3%80%91-%20%E5%AE%8C%E6%95%B4.html</url>
    
    <content type="html"><![CDATA[<center><p>我们本是完整的一个，但是分开了<br></p><p>于是开始有了期待，有了思念 <br></p><p>笑声很轻，眼泪也无声 <br></p><p>对天空诉说着爱是永恒 <br></p><p>跌跌撞撞寻找属于我们的完整 <br></p><p>未来的那一天在心里很重 <br></p><p>两只手里藏着全世界的星星 <br></p><p>在彼此的眼睛里看到了 <br></p><p>海洋陆地，银河苍穹 <br></p><p>北极光在脚下划过 <br></p><p>猎户座的虹手中缤纷 <br></p><p>你说那斑驳的星尘好像我们 <br></p><p>后来所有的时间空间都消失了 <br></p><p>拥抱里我们变成宇宙的最初 <br></p><p>完整 <br></p></center>]]></content>
    
    
    <categories>
      
      <category>生活感悟</category>
      
    </categories>
    
    
    <tags>
      
      <tag>生活感悟</tag>
      
      <tag>原创诗歌</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI行业技能点含金量统计分析</title>
    <link href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%A1%8C%E4%B8%9A%E7%9A%84%E4%B8%8D%E5%90%8C%E6%8A%80%E8%83%BD%E6%A0%91%E5%90%AB%E9%87%91%E9%87%8F%E5%88%86%E6%9E%90.html"/>
    <url>/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%A1%8C%E4%B8%9A%E7%9A%84%E4%B8%8D%E5%90%8C%E6%8A%80%E8%83%BD%E6%A0%91%E5%90%AB%E9%87%91%E9%87%8F%E5%88%86%E6%9E%90.html</url>
    
    <content type="html"><![CDATA[<p>在人工智能领域，有很多热议的技能选择，如CV还是NLP，TensorFlow还是PyTorch，python还是C++……<br />话题有争议，但是数据非常客观，让我们拭目以待吧~ <span id="more"></span></p><h3 id="数据说明">1.数据说明</h3><p><strong>数据来源：</strong>为BOSS直聘北京地区算法工程师相关岗位,数据时间是2022年五月,有效样本总量为2200个.<br /><strong>数据内容：</strong>招聘标题,薪资,福利待遇,关键词,岗位描述,公司,地址,招聘网址<br /><strong>统计方法：</strong>对样本数据通过相关的岗位关键词进行筛选,并统计筛选结果的薪资均值,岗位数量等信息,汇总为下表。</p><h3 id="ai技能点含金量排名">2.AI技能点含金量排名</h3><div id="container0" style="height: 500px;"></div><script type="text/javascript" src="https://registry.npmmirror.com/echarts/5.5.0/files/dist/echarts.min.js"></script><script type="text/javascript">var dom = document.getElementById('container0');var myChart = echarts.init(dom, null, {  renderer: 'canvas',  useDirtyRect: false});var app = {};var option;option = {  xAxis: {  type: 'category',  data: [    "视觉|cv|视频|图像",    "NLP|自然语言|LLM",    "多模态|大模型",    "机器学习",    "深度学习",    "软件开发",    "控制算法",    "推荐算法",    "数据挖掘|数据分析",    "地图|路径算法"  ],  axisLabel: {    rotate: 45, // 旋转标签以适应显示    interval: 0 // 设置为0表示显示全部标签  }  },  yAxis: {  type: 'value'  },  series: [  {    data: [378.43, 414.87, 439.42, 396.63, 395.89, 359.30, 379.71, 435.72, 358.50, 415.83],    type: 'bar',    showBackground: true,    backgroundStyle: {      color: 'rgba(180, 180, 180, 0.2)'    },  label: {      show: true, // 开启数据标签显示      position: 'top', // 数据标签的位置，这里是顶部      formatter: '{c}' // 格式化函数，这里使用默认的'{c}'表示显示数值    }}  ]  };if (option && typeof option === 'object') {  myChart.setOption(option);}window.addEventListener('resize', myChart.resize);</script><p><strong>多模态大模型</strong>以均值439k的平均年薪拔得头筹，<strong>推荐算法</strong>以436k紧随其后，<strong>NLP自然语言处理与地图路径算法工程师</strong>以415K的薪资并列第三。说起薪资较低的，分别是<strong>AI软件开发岗、数据挖掘分析岗</strong>，将近360K，也是难能可贵了。</p><h3id="ai技能点的需求量与含金量分布">3.AI技能点的需求量与含金量分布</h3><div id="container" style="height: 500px;"></div><script type="text/javascript" src="https://registry.npmmirror.com/echarts/5.5.0/files/dist/echarts.min.js"></script><script type="text/javascript">  var dom = document.getElementById('container');  var myChart = echarts.init(dom, null, {    renderer: 'canvas',    useDirtyRect: false  });  var app = {};  var option;  option = {    dataset: {      source: [        ['平均年薪(k)', '岗位数量', '职业技能'],        [378.43, 708, "视觉|cv|视频|图像"],        [414.87, 350, "NLP|自然语言|LLM"],        [439.42, 545, "多模态|大模型"],        [396.63, 691, "机器学习"],        [395.89, 785, "深度学习"],        [359.3, 154, "软件开发"],        [379.71, 98, "控制算法"],        [435.72, 171, "推荐算法"],        [358.5, 100, "数据挖掘|数据分析"],        [415.83, 36, "地图|路径算法"],        [384.27, 1032, "python"],        [396.68, 1225, "C++"],        [384.61, 206, "TensorFlow"],        [390.4, 193, "PyTorch"],      ]    },    grid: { containLabel: true },    xAxis: { name: '岗位数量' },    yAxis: { type: 'category' },    visualMap: {      orient: 'horizontal',      left: 'center',      min: 350,      max: 450,      text: ['High 平均年薪(k)', 'Low 平均年薪(k)'],      // Map the 平均年薪(k) column to color      dimension: 0,      inRange: {        color: ['#65B581', '#FFCE34', '#FD665F']      }    },    series: [      {        type: 'bar',        encode: {          // Map the "岗位数量" column to X axis.          x: '岗位数量',          // Map the "职业技能" column to Y axis          y: '职业技能'        }      }    ]  };  if (option && typeof option === 'object') {    myChart.setOption(option);  }  window.addEventListener('resize', myChart.resize);</script><p><strong>计算机视觉CV与自然语言NLP</strong>：视觉（CV）与图像、视频打交道，年薪约378k，岗位多；而自然语言处理（NLP）年薪诱人达415k，但岗位少。想多赚钱选NLP，想稳就业选CV。</p><p><strong>多模态与大模型</strong>：新兴的多模态与大模型领域，年薪高达439k，岗位也不少。想站风口就选它！</p><p><strong>机器学习与深度学习</strong>：机器学习年薪约397k，岗位稳定；深度学习略低但需求多。两者薪资相近，看需求选。</p><p><strong>软件开发与控制算法</strong>：软件开发年薪359k但岗位少；控制算法稍好，年薪380k。两者传统但重要。</p><p><strong>推荐算法与数据挖掘</strong>：推荐算法年薪高达436k但岗位少；数据挖掘年薪359k。喜欢数据处理就选它们。</p><p><strong>地图与路径算法</strong>：小众但高薪的地图与路径算法，年薪416k但竞争大。适合专长者挑战。</p><p><strong>编程语言：Python与C++</strong>Python年薪384k岗位多，C++年薪略高且岗位更多。两者都是AI开发利器。</p><p><strong>框架选择：TensorFlow与PyTorch</strong>TensorFlow年薪385k，PyTorch年薪390k。两者差距小，选谁看心情和项目需求。</p><h3id="技能点与教育程度工作经验及薪资的关系">4.技能点与教育程度，工作经验及薪资的关系</h3><h4id="技能点和教育程度对薪资的影响单位k">4.1技能点和教育程度对薪资的影响（单位：K）</h4><table><thead><tr class="header"><th></th><th>专科</th><th>本科</th><th>985/211</th><th>硕士</th><th>博士</th></tr></thead><tbody><tr class="odd"><td>地图/路径</td><td>-</td><td>481</td><td>330</td><td>470</td><td>1260</td></tr><tr class="even"><td>数据挖掘/数据分析</td><td>-</td><td>394</td><td>383</td><td>358</td><td>277</td></tr><tr class="odd"><td>推荐算法</td><td>-</td><td>378</td><td>456</td><td>397</td><td>397</td></tr><tr class="even"><td>PyTorch</td><td>360</td><td>370</td><td>427</td><td>383</td><td>365</td></tr><tr class="odd"><td>控制算法</td><td>-</td><td>364</td><td>390</td><td>400</td><td>-</td></tr><tr class="even"><td>c++/C++</td><td>315</td><td>359</td><td>395</td><td>418</td><td>420</td></tr><tr class="odd"><td>多模态/大模型</td><td>-</td><td>352</td><td>367</td><td>465</td><td>459</td></tr><tr class="even"><td>TensorFlow</td><td>360</td><td>343</td><td>367</td><td>383</td><td>365</td></tr><tr class="odd"><td>机器学习</td><td>360</td><td>343</td><td>395</td><td>434</td><td>433</td></tr><tr class="even"><td>深度学习</td><td>315</td><td>339</td><td>408</td><td>423</td><td>429</td></tr><tr class="odd"><td>python</td><td>315</td><td>330</td><td>361</td><td>411</td><td>394</td></tr><tr class="even"><td>NLP/自然语言/LLM</td><td>-</td><td>328</td><td>373</td><td>480</td><td>556</td></tr><tr class="odd"><td>软件/开发</td><td>360</td><td>327</td><td>252</td><td>394</td><td>393</td></tr><tr class="even"><td>视觉/cv/视频/图像</td><td>360</td><td>320</td><td>434</td><td>411</td><td>514</td></tr></tbody></table><h4id="技能点和教育程度对工作岗位数量的影响单位个">4.2技能点和教育程度对工作岗位数量的影响（单位：个）</h4><table><thead><tr class="header"><th></th><th>专科</th><th>本科</th><th>985/211</th><th>硕士</th><th>博士</th></tr></thead><tbody><tr class="odd"><td>c++/C++</td><td>2</td><td>248</td><td>23</td><td>255</td><td>42</td></tr><tr class="even"><td>python</td><td>2</td><td>223</td><td>22</td><td>212</td><td>39</td></tr><tr class="odd"><td>深度学习</td><td>2</td><td>157</td><td>25</td><td>166</td><td>25</td></tr><tr class="even"><td>机器学习</td><td>1</td><td>144</td><td>23</td><td>117</td><td>29</td></tr><tr class="odd"><td>视觉/cv/视频/图像</td><td>1</td><td>126</td><td>16</td><td>159</td><td>29</td></tr><tr class="even"><td>多模态/大模型</td><td>-</td><td>115</td><td>21</td><td>111</td><td>26</td></tr><tr class="odd"><td>NLP/自然语言/LLM</td><td>-</td><td>91</td><td>21</td><td>82</td><td>11</td></tr><tr class="even"><td>推荐算法</td><td>-</td><td>50</td><td>11</td><td>31</td><td>5</td></tr><tr class="odd"><td>TensorFlow</td><td>1</td><td>41</td><td>7</td><td>40</td><td>9</td></tr><tr class="even"><td>PyTorch</td><td>1</td><td>39</td><td>7</td><td>38</td><td>9</td></tr><tr class="odd"><td>软件/开发</td><td>1</td><td>38</td><td>3</td><td>20</td><td>3</td></tr><tr class="even"><td>数据挖掘/数据分析</td><td>-</td><td>21</td><td>5</td><td>17</td><td>4</td></tr><tr class="odd"><td>地图/路径</td><td>-</td><td>17</td><td>1</td><td>11</td><td>1</td></tr><tr class="even"><td>控制算法</td><td>-</td><td>13</td><td>3</td><td>19</td><td>-</td></tr></tbody></table><h4id="技能点和工作经验对平均年薪的影响单位k">4.3技能点和工作经验对平均年薪的影响（单位：K）</h4><table><thead><tr class="header"><th></th><th>应届</th><th>一年</th><th>两年</th><th>三年</th><th>四年</th><th>五年及以上</th></tr></thead><tbody><tr class="odd"><td>推荐算法</td><td>351</td><td>261</td><td>433</td><td>433</td><td>-</td><td>462</td></tr><tr class="even"><td>TensorFlow</td><td>272</td><td>343</td><td>324</td><td>415</td><td>360</td><td>427</td></tr><tr class="odd"><td>PyTorch</td><td>285</td><td>350</td><td>318</td><td>409</td><td>360</td><td>517</td></tr><tr class="even"><td>c++/C++</td><td>373</td><td>356</td><td>389</td><td>407</td><td>383</td><td>438</td></tr><tr class="odd"><td>多模态/大模型</td><td>409</td><td>355</td><td>427</td><td>397</td><td>423</td><td>428</td></tr><tr class="even"><td>控制算法</td><td>360</td><td>-</td><td>402</td><td>397</td><td>-</td><td>338</td></tr><tr class="odd"><td>NLP/自然语言/LLM</td><td>544</td><td>359</td><td>392</td><td>392</td><td>442</td><td>416</td></tr><tr class="even"><td>软件/开发</td><td>-</td><td>339</td><td>325</td><td>386</td><td>216</td><td>344</td></tr><tr class="odd"><td>机器学习</td><td>330</td><td>392</td><td>383</td><td>383</td><td>454</td><td>472</td></tr><tr class="even"><td>python</td><td>304</td><td>356</td><td>396</td><td>382</td><td>425</td><td>366</td></tr><tr class="odd"><td>深度学习</td><td>357</td><td>368</td><td>399</td><td>381</td><td>442</td><td>420</td></tr><tr class="even"><td>视觉/cv/视频/图像</td><td>406</td><td>360</td><td>454</td><td>379</td><td>397</td><td>505</td></tr><tr class="odd"><td>地图/路径</td><td>-</td><td>406</td><td>375</td><td>350</td><td>927</td><td>-</td></tr><tr class="even"><td>数据挖掘/数据分析</td><td>242</td><td>415</td><td>294</td><td>308</td><td>-</td><td>530</td></tr></tbody></table><h4id="技能点和工作经验对工作岗位数量的影响单位个">4.4技能点和工作经验对工作岗位数量的影响（单位：个）</h4><table><thead><tr class="header"><th></th><th>应届</th><th>一年</th><th>两年</th><th>三年</th><th>四年</th><th>五年及以上</th></tr></thead><tbody><tr class="odd"><td>c++/C++</td><td>38</td><td>70</td><td>142</td><td>211</td><td>17</td><td>92</td></tr><tr class="even"><td>python</td><td>35</td><td>49</td><td>143</td><td>187</td><td>14</td><td>70</td></tr><tr class="odd"><td>深度学习</td><td>19</td><td>44</td><td>99</td><td>146</td><td>9</td><td>58</td></tr><tr class="even"><td>视觉/cv/视频/图像</td><td>18</td><td>32</td><td>89</td><td>125</td><td>8</td><td>59</td></tr><tr class="odd"><td>机器学习</td><td>26</td><td>32</td><td>85</td><td>120</td><td>10</td><td>41</td></tr><tr class="even"><td>多模态/大模型</td><td>13</td><td>25</td><td>71</td><td>116</td><td>9</td><td>39</td></tr><tr class="odd"><td>NLP/自然语言/LLM</td><td>7</td><td>16</td><td>58</td><td>78</td><td>4</td><td>42</td></tr><tr class="even"><td>推荐算法</td><td>6</td><td>4</td><td>40</td><td>33</td><td>-</td><td>14</td></tr><tr class="odd"><td>PyTorch</td><td>5</td><td>16</td><td>19</td><td>32</td><td>1</td><td>21</td></tr><tr class="even"><td>TensorFlow</td><td>7</td><td>18</td><td>21</td><td>32</td><td>1</td><td>19</td></tr><tr class="odd"><td>软件/开发</td><td>-</td><td>6</td><td>22</td><td>25</td><td>1</td><td>11</td></tr><tr class="even"><td>数据挖掘/数据分析</td><td>3</td><td>4</td><td>18</td><td>16</td><td>-</td><td>6</td></tr><tr class="odd"><td>控制算法</td><td>1</td><td>-</td><td>13</td><td>13</td><td>-</td><td>8</td></tr><tr class="even"><td>地图/路径</td><td>-</td><td>9</td><td>5</td><td>9</td><td>7</td><td>-</td></tr></tbody></table><h3 id="高性价比工作岗位排名">5高性价比工作岗位排名</h3><h4id="加权工作经验工作岗位数量与薪资计算技能点的得分及排名情况">加权工作经验,工作岗位数量与薪资,计算技能点的得分及排名情况</h4><ul><li>基本原则：学历要求越低，工作经验要求越低，平均年薪越高的技能点越好，其评分会越高</li><li>学历，工作经验数据划分五个等级，然后将三个特征数据归一化处理，彼此相乘，再乘上百分系数，得到最终评分</li></ul><div id="container2" style="height: 400px;"></div><script type="text/javascript" src="https://registry.npmmirror.com/echarts/5.5.0/files/dist/echarts.min.js"></script><script type="text/javascript">  var dom = document.getElementById('container2');  var myChart = echarts.init(dom, null, {    renderer: 'canvas',    useDirtyRect: false  });  var app = {};  var option;  option = {    dataset: [      {        dimensions: ['name','score'],        source: [          ["NLP/自然语言/LLM",30.16],          ["PyTorch",14.78],          ["TensorFlow",15.56],          ["c++/C++",83.54],          ["python",74.84],          ["地图/路径",15.25],          ["多模态/大模型",45.56],          ["控制算法",10.59],          ["推荐算法",29.53],          ["数据挖掘/数据分析",5.26],          ["机器学习",46.19],          ["深度学习",52.13],          ["视觉/cv/视频/图像",42.48],          ["软件/开发",13.56]        ]      },      {        transform: {          type: 'sort',          config: { dimension: 'score', order: 'desc' }        }      }    ],    xAxis: {      type: 'category',      axisLabel: { interval: 0, rotate: 30 }    },    yAxis: {},    series: {      type: 'bar',      encode: { x: 'name', y: 'score' },            datasetIndex: 1    }  };  if (option && typeof option === 'object') {    myChart.setOption(option);  }  window.addEventListener('resize', myChart.resize);</script>]]></content>
    
    
    <categories>
      
      <category>Data Visualization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ECharts</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>北京人工智能行业薪资大揭秘</title>
    <link href="/%E5%8C%97%E4%BA%AC%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%A1%8C%E4%B8%9A%E8%96%AA%E8%B5%84%E5%A4%A7%E6%8F%AD%E7%A7%98.html"/>
    <url>/%E5%8C%97%E4%BA%AC%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%A1%8C%E4%B8%9A%E8%96%AA%E8%B5%84%E5%A4%A7%E6%8F%AD%E7%A7%98.html</url>
    
    <content type="html"><![CDATA[<p><img src="/images/ai_salary/1714717993428.png" />BOSS直聘数据，含北京市各区[<code>算法工程师|人工智能</code>]岗位数据7534条<span id="more"></span> # <strong>北京2024人工智能行业薪资大揭秘</strong></p><h3 id="数据说明">1.数据说明</h3><p>数据时间:<code>2024年5月</code></p><p>数据来源:**BOSS直聘,爬取北京市各区[<code>算法工程师|人工智能</code>]岗位数据7534条(多次爬取结果)</p><p><strong>数据清洗:</strong>提取岗位内容中包含<code>[人工智能|算法|nlp|cv]</code>的内容,并执行去重操作,得到岗位数据2208个.</p><p><img src="/images/ai_salary/1714721994550.png" /></p><h3 id="薪资分析">2.薪资分析</h3><p><img src="/images/ai_salary/1714716697686.png" /></p><p><strong>薪资上限，星辰大海般的梦想</strong>：首先，让人眼前一亮的是薪资上限——竟然高达<strong>1800k（年薪）</strong>！这意味着在这个行业，如果你拥有出色的才华和丰富的经验，那么年薪百万的梦想并非遥不可及。当然，这样的高薪也对应着极高的工作要求和挑战。</p><p><strong>薪资下限，无良公司真没下限</strong>：而对于那些刚刚步入人工智能行业的新人或者初入这个领域的小伙伴们来说，薪资下限为24k（年薪）,在北京还不够房租的,试问这些无良公司,你们的良心不会痛吗。</p><p><strong>平均年薪，舒适圈的魅力</strong>：说到最吸引人的部分，莫过于平均年薪了。北京人工智能行业的平均年薪高达<strong>400k</strong>左右，这真是一个赏心悦目的数字,另外年薪的众数和中位数都是<strong>360k</strong>,不知道屏幕前的你达到平均水平没有。</p><p><strong>人工智能岗位平均年薪与下限年薪对比:</strong></p><p><img src="/images/ai_salary/1714717993428.png" /></p><h3 id="岗位要求">3.岗位要求</h3><p>人工智能行业这么卷,是不是得<code>985\211起步,研究生占半数</code>呢?我们用数据来说话:</p><p><img src="/images/ai_salary/1714721621417.png" /></p><p>根据统计的2208个岗位数据来看,研究生占比30.4%,反而是<strong>本科生占据了大多数</strong>,占比达<strong>64.9%</strong>,本科生才是人工智能产业的中坚力量.不过AI行业的起步门槛是真高,大专和学历不限的岗位占比仅<strong>2.4%.</strong></p><p>在岗位经验来看,<strong>人工智能行业的包容性还是比较大的</strong>,经验不限的占到了17.91%(越缺人才的行业,这个指标越高),3-5年的岗位占比超过一半(鲜明的新兴行业).现在来看,又是招兵买马又是百模大战,<strong>人工智能的时代才刚开始.</strong></p><h3 id="薪资与学历和经验的关系">4.薪资与学历和经验的关系</h3><h4 id="学历vs薪资">4.1 学历VS薪资</h4><p><strong>大专小鲜肉</strong>：虽然起步稍低，但凭借着一股不服输的劲头，也能拿到251k的薪资，证明了在人工智能领域，实力非常的重要。</p><p><strong>本科高手</strong>：他们像是中流砥柱，稳稳地占据了薪资的中上游，379k的薪资，是对他们扎实基础和广泛知识的认可。</p><p><strong>硕士精英</strong>：他们在学历上更上一层楼，薪资也随之水涨船高，416k的薪资，是他们辛勤付出的回报。</p><p><strong>博士大佬</strong>：一出场就自带光环，稳稳地站在了薪资的金字塔尖，462k的薪资，仿佛在告诉大家：“知识就是力量，学历就是金钱！”</p><p><strong>学历不限</strong>：这个神秘的角色，似乎不受学历的束缚，凭借着自己的独特技能和经验，也能轻松拿到385k的薪资，可谓是“英雄不问出处”。</p><p><img src="/images/ai_salary/1714719207889.png" /></p><h3 id="经验vs薪资">4.2 经验VS薪资</h3><p><strong>1-3年新鲜人儿</strong>：初出茅庐的你，薪资322k，够你喝不少星巴克了！但别停步，未来更精彩！</p><p><strong>1年以内小鲜肉</strong>：应届生们，你们薪资333k，起点不错！不过这只是起点，挑战还在后头哦！</p><p><strong>3-5年小有成就</strong>：404k的薪资，帝都<strong>租房</strong>没问题！继续加油，成为公司顶梁柱！</p><p><strong>5-10年资深玩家</strong>：资深大佬，458k薪资，生活舒适还能追梦！多年打拼，果然值得！</p><p><strong>10年以上大佬级人物</strong>：传奇大佬，467k薪资，人生赢家！人脉经验都丰富，这钱你应得！</p><p><strong>在校/应届小白</strong>：小白们，150k只是开始，努力学习，未来可期！</p><p><strong>经验不限的小伙伴</strong>：无门槛岗位，378k薪资，虽有挑战，但你有实力，定能闯出一片天！</p><p><img src="/images/ai_salary/1714719746033.png" /></p><hr /><p>在北京,人工智能行业以平均年薪<strong>400k</strong>的高薪,<strong>经验不限</strong>的要求,让无数人心生向往。尽管如此,本科学历只是<strong>入行地板砖</strong>,稳妥些确实得硕士学历.但长远来看,AI行业是一个不断发展的增量市场,它注定要成为推动社会变革的新质生产力,你<strong>准备好迎接这个崭新的时代了吗</strong>?</p>]]></content>
    
    
    
    <tags>
      
      <tag>可视化</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo博客搭建教程</title>
    <link href="/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B.html"/>
    <url>/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B.html</url>
    
    <content type="html"><![CDATA[<p>hexo + github 搭建你的静态博客</p><span id="more"></span><h1id="一搭建前的软件准备gitnode">一，搭建前的软件准备（git，node）</h1><blockquote><p>搭建之前需要准备的软件： Git：官网下载：https://git-scm.com/ Node.js官网下载：http://nodejs.cn/</p></blockquote><h1 id="二-安装hexo完成简单本地页面展示">二，安装hexo，完成简单本地页面展示</h1><p>1.进入cmd窗口输入指令：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">npm install -g hexo-<span class="hljs-keyword">cli</span><br></code></pre></td></tr></table></figure><figure><img src="/images/hexo博客搭建教程/d6d9c791b8f449fea0b64b1a72bd32b2.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><p>2.你可以先创建一个文件夹myblog，然后cd到这个文件夹下（或者在这个文件夹下直接右键gitbash打开）。 <imgsrc="/images/hexo博客搭建教程/5b5554d54f20471098768040624585ba.png"alt="在这里插入图片描述" /></p><p>接下来初始化一下hexo</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs csharp">hexo <span class="hljs-keyword">init</span><br></code></pre></td></tr></table></figure><figure><img src="/images/hexo博客搭建教程/6010660448004f25871ce6b5a479f832.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><p>3.查看是否能启动成功</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clike">hexo s<br></code></pre></td></tr></table></figure><figure><img src="/images/hexo博客搭建教程/4df56b5dc3ce40a2a2c9dc99585fd8ed.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><blockquote><p>新建完成后，指定文件夹目录下有： node_modules: 依赖包public：存放生成的页面 scaffolds：生成文章的一些模板source：用来存放你的文章 themes：主题 **_config.yml:博客的配置文件**</p></blockquote><p>4.复制网址打开</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clike">http://localhost:4000/<br></code></pre></td></tr></table></figure><figure><img src="/images/hexo博客搭建教程/2bcb9a6a09024ce68d095901dc1ca203.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><p>这是初始界面，我们需要部署到github上。</p><p>ctrl+C可以停止；</p><h1 id="三将hexo部署到github">三，将Hexo部署到Github</h1><h2 id="github创建个人仓库">1.Github创建个人仓库</h2><blockquote><p>首先，需要有一个github账号。登上账号后建一个仓库：仓库名为你的用户名.github.io，举例如下： 创建一个和你用户名相同的仓库，后面加.github.io，只有这样，将来要部署到GitHub的时候，才会被识别，也就是xxxx.github.io，其中xxx就是你注册GitHub的用户名.</p></blockquote><figure><img src="/images/hexo博客搭建教程/a697d02a363e48e08d07854051642860.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><h2 id="生成ssh添加到github">2.生成ssh添加到Github</h2><blockquote><p>在Github上创建仓库完成之后，需要设置ssh免密登录</p></blockquote><p>1.打开cmd窗口：执行如下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clike">git config --global user.name &quot;yourname&quot;<br>git config --global user.email &quot;youremail&quot;<br></code></pre></td></tr></table></figure><p>这里的yourname输入你的GitHub用户名，youremail输入你GitHub的邮箱。这样GitHub才能知道你是不是对应它的账户。用户名为仓库的名称，邮箱为注册github的邮箱，举例如下：</p><figure><img src="/images/hexo博客搭建教程/ef3ce50ba8ce4e39bb4dd1387a9da316.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><p>防止输错可以检查：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clike">git config user.name<br>git config user.email<br></code></pre></td></tr></table></figure><p>2.接着进入到家目录：C:，右击打开git bash 。 输入：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clike">ssh-keygen -t rsa -C 2412757158@qq.com<br></code></pre></td></tr></table></figure><p>后面是自己注册github的邮箱，然后敲三次回车，</p><figure><img src="/images/hexo博客搭建教程/b07cadba4a484a7eac9c19884ea6f3b5.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><p>3.接着就会发现C:.ssh目录，打开后有一个公钥，一个私钥。id_rsa.pub是公钥，我们需要打开它，复制里面的内容。</p><p>然后进入github：</p><p>点击setings <imgsrc="/images/hexo博客搭建教程/2f3217c541b94d59bc17c3d8119e8801.png"alt="在这里插入图片描述" /></p><p>进行以下操作</p><p><imgsrc="/images/hexo博客搭建教程/a1def242038c4c77b125d0c0b597f987.png"alt="在这里插入图片描述" />发现我们需要一个密钥，把我们刚刚复制的密钥粘进去，title随便起</p><p><imgsrc="/images/hexo博客搭建教程/821106b4621d4a1a91cfc2f1510abd99.png"alt="在这里插入图片描述" /> 点击 Add SSH Key</p><h2 id="进行部署">3.进行部署</h2><blockquote><p>这一步，我们就可以将hexo和GitHub关联起来，也就是将hexo生成的文章部署到GitHub上，打开站点配置文件_config.yml，翻到最后，修改为 YourgithubName就是你的GitHub账户</p></blockquote><p>1.修改配置文件 <imgsrc="/images/hexo博客搭建教程/c87432a9b49c4552b931c51e0e94e61d.png"alt="在这里插入图片描述" /></p><p>修改内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs clike">deploy:<br>  type: git<br>  repo: git@github.com:goubin18/goubin18.github.io.git<br>  branch: main<br></code></pre></td></tr></table></figure><figure><img src="/images/hexo博客搭建教程/7955e295748647388285871fcf65b511.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><p><strong>注意：后面有空格</strong></p><p><strong>repo：获取步骤如下</strong></p><p><strong>点进自己刚刚创建的仓库，复制</strong></p><p><strong><imgsrc="/images/hexo博客搭建教程/a8b5f30ed44448b88f759faf8f104ecb.png"alt="在这里插入图片描述" /></strong></p><p><strong>2.找到自己的博客路径打开</strong></p><p><strong><imgsrc="/images/hexo博客搭建教程/fa09bd6a0d7448deb1ce16a424e0c987.png"alt="在这里插入图片描述" /></strong></p><p><strong>这个时候需要先安装deploy-git，也就是部署的命令,这样你才能用命令部署到GitHub。</strong></p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">npm install hexo-deployer-git <span class="hljs-comment">--save</span><br></code></pre></td></tr></table></figure><p><strong><imgsrc="/images/hexo博客搭建教程/a4ff5a3aed8443d6b98b366fa63e724d.png"alt="在这里插入图片描述" /></strong></p><p><strong>2.然后依次执行以下命令：</strong></p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog">hexo c   #清除缓存文件 db<span class="hljs-variable">.json</span> 和已生成的静态文件 public<br>hexo g       #生成网站静态文件到默认设置的 public 文件夹(hexo <span class="hljs-keyword">generate</span> 的缩写)<br>hexo d       #自动生成网站静态文件，并部署到设定的仓库(hexo deploy 的缩写)<br></code></pre></td></tr></table></figure><p><strong>注意deploy时会让输个yes</strong></p><p><strong><em>*最后回到github上查看自己的仓库：*</em></strong></p><p><imgsrc="/images/hexo博客搭建教程/5a62c4630f164385831ad449065b5b03.png"alt="在这里插入图片描述" /> 这就表示上传成功。</p><p>现在就可以使用xxx.github.io来访问你的博客啦例如：我的用户名是linxkon，那么我的博客地址就是<code>linxkon.github.io</code></p><p>举例如下：</p><figure><img src="/images/hexo博客搭建教程/9eefc08e36464040bc8fbe8d9716073b.png"alt="在这里插入图片描述" /><figcaption aria-hidden="true">在这里插入图片描述</figcaption></figure><h1 id="写在最后">写在最后：</h1><blockquote><p>现在简单的博客已经搭建完成了 现在你的个人网站的地址是xxx.github.io，如果觉得这个网址配不上帅气多金的你，你就可以设置个人域名了。但是需要花钱。小提示： 操作要细心，如果出现了问题可以私信留言，大家一起想办法！</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>categories</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客搭建</tag>
      
      <tag>知识管理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一文读懂Bert预训练模型</title>
    <link href="/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html"/>
    <url>/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html</url>
    
    <content type="html"><![CDATA[<p>BERT模型作为自然语言处理领域的重大突破，其核心优势在于创新性地采用了双向注意力机制和大规模无监督预训练方法。该模型通过深度双向上下文编码，有效捕捉了语言的复杂语义关系和长程依赖，显著提升了对语言理解的深度和广度。<span id="more"></span></p><h3 id="一.-关于bert">一. 关于Bert</h3><p>BERT是一种革命性的自然语言处理模型,全称为"Bidirectional EncoderRepresentations fromTransformers"(来自Transformer的双向编码器表示)。以下是BERT的简要介绍:</p><ol type="1"><li><p>开发背景:由Google AI团队在2018年开发。</p></li><li><p>核心技术:基于Transformer架构,使用双向训练。</p></li><li><p>预训练方法:采用掩码语言模型(MLM)和下一句预测(NSP)任务。</p></li><li><p>主要优势: &gt; - 捕捉更丰富的上下文信息 &gt; - 适用于多种NLP任务&gt; - 性能优异,在多个基准测试中取得突破</p></li><li><p>应用领域:问答系统、情感分析、文本分类等。</p></li><li><p>影响:推动了NLP领域的快速发展,催生了许多基于BERT的改进模型。</p></li></ol><h3 id="二.-bert的发展与衍生">二. Bert的发展与衍生</h3><table><thead><tr class="header"><th><strong>模型名称</strong></th><th><strong>优化点</strong></th><th><strong>发布时间</strong></th></tr></thead><tbody><tr class="odd"><td><strong>RoBERTa</strong></td><td><strong>更大的训练数据</strong>：使用了更大规模的数据进行预训练。<strong>longer训练时间</strong>：延长了模型的训练时间和迭代次数。<strong>移除NextSentencePrediction(NSP)任务</strong>：发现NSP任务对模型性能影响不大,因此将其移除。<strong>动态掩码</strong>：每次输入序列时动态生成掩码,而不是静态掩码。<strong>更大的batchsize</strong>：使用更大的batchsize进行训练。<strong>字节对编码</strong>(Byte-PairEncoding)：使用更大的词表</td><td>2019年7月</td></tr><tr class="even"><td><strong>ALBERT</strong></td><td>轻量级BERT变体 , 通过参数共享来减少模型大小，同时保持性能</td><td>2019年9月</td></tr><tr class="odd"><td><strong>DistilBERT</strong></td><td>轻量级版本，保留BERT 97%的性能，但体积减小40%，速度提高60%</td><td>2019年10月</td></tr><tr class="even"><td><strong>XLNet</strong></td><td>使用置换语言建模来解决BERT的一些局限性</td><td>2019年6月</td></tr><tr class="odd"><td><strong>ELECTRA</strong></td><td>使用替换检测而不是掩码语言建模进行预训练</td><td>2020年3月</td></tr><tr class="even"><td><strong>ERNIE</strong></td><td>加入了额外的知识信息</td><td>2019年3月</td></tr><tr class="odd"><td><strong>T5</strong></td><td><strong>统一框架：</strong>T5将所有NLP任务转化为文本到文本的格式，包括分类、翻译、摘要等。<strong>编码器-解码器架构</strong>：与BERT的编码器结构不同，T5采用了编码器-解码器架构。<strong>更大的模型和数据集</strong>：T5使用了更大规模的模型参数和训练数据。<strong>新的预训练任务</strong>：T5使用了"spancorruption"作为预训练任务，不同于BERT的掩码语言模型。<strong>多任务学习</strong>：在预训练阶段就引入了多任务学习。<strong>改进的位置编码</strong>：使用相对位置编码而非绝对位置编码。</td><td>2019年10月</td></tr><tr class="even"><td><strong>BART</strong></td><td>结合了BERT的双向编码器和GPT的自回归解码器</td><td>2019年10月</td></tr><tr class="odd"><td><strong>DeBERTa</strong></td><td>使用解耦注意力机制和增强的掩码解码器</td><td>2020年1月</td></tr></tbody></table><h3 id="三.-模型架构">三. 模型架构</h3><p>BERT模型的整体架构可以分为输入（Input）、编码器（Encoder）和输出（Output）三个层面。</p><h4 id="输入层input-layer">1. 输入层（Input Layer）</h4><p>BERT模型的输入层负责将文本数据转化为模型可以处理的格式。</p><h4 id="输入层主要分为三大部分">输入层主要分为三大部分：</h4><p><strong>词嵌入</strong>(Word Embeddings)</p><blockquote><ul><li><strong>Tokenization（分词）</strong>：将输入的文本字符串拆分为更小的单元，通常是词（words）或子词（subwords）。BERT使用的是WordPiecetokenizer。</li><li><strong>Adding SpecialTokens（添加特殊标记）</strong>：在每个输入序列的开头添加<code>[CLS]</code>标记，在两个句子之间添加<code>[SEP]</code>标记。</li><li><strong>Token IDs</strong>：将每个token映射到词汇表中的唯一ID。</li></ul></blockquote><p><strong>分段嵌入</strong>(Segment Embeddings)</p><blockquote><p><strong>SegmentIDs（分段ID）</strong>：在NSP任务中用于区分不同的句子。第一个句子的tokenIDs标记为0，第二个句子的token IDs标记为1。</p></blockquote><p><strong>位置嵌入</strong>(Position Embeddings): 完成词嵌入操作后,模型自动执行位置嵌入</p><p><strong>AttentionMask</strong>：用于区分填充（padding）部分和实际的token。在批处理时，将所有输入序列填充到相同的长度，填充值通常为0，实际token的attentionmask为1。</p><p>例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer<br><br><span class="hljs-comment"># 加载预训练的BERT tokenizer</span><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&#x27;bert-base-chinese&#x27;</span>)<br><br><span class="hljs-comment"># 输入文本</span><br>text = [<span class="hljs-string">&quot;Hello, how are you?&quot;</span>, <span class="hljs-string">&quot;I am fine, thank you!&quot;</span>]<br><br><span class="hljs-comment"># 使用tokenizer对输入文本进行编码</span><br>encoded_input = tokenizer(text, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(encoded_input)<br></code></pre></td></tr></table></figure><h4 id="编码器层encoder-layer">2. 编码器层（Encoder Layer）</h4><p>BERT的编码器层是由多个Transformer编码器堆叠而成的。每个Transformer编码器层包括以下几个部分：</p><ul><li><strong>Self-AttentionMechanism（自注意力机制）</strong>：每个token可以在序列中与其他token进行交互，从而捕捉句子中的全局依赖关系。BERT使用多头自注意力机制（Multi-HeadSelf-Attention），使得模型能够同时关注不同位置的信息。</li><li><strong>Feed-Forward NeuralNetwork（前馈神经网络）</strong>：每个自注意力层之后接一个前馈神经网络，进一步处理和变换注意力机制的输出。</li><li><strong>Add &amp;Norm（加和归一化）</strong>：每个子层（自注意力和前馈神经网络）都有一个残差连接，并进行层归一化（LayerNormalization）。</li><li><strong>Position-wise Feed-ForwardNetworks（逐位置前馈神经网络）</strong>：每个token在自注意力机制处理后，通过一个逐位置的前馈神经网络进行非线性变换。</li></ul><h4 id="输出层output-layer">3. 输出层（Output Layer）</h4><p>BERT的输出层根据具体任务的不同而有所变化，常见的任务包括：</p><ul><li><strong>分类任务</strong>：使用第一个token（<code>[CLS]</code>）的输出表示整个序列的特征，然后通过一个分类层进行分类。</li><li><strong>序列标注任务</strong>：对每个token的输出进行处理，通过一个分类层对每个token进行标注。</li><li><strong>问答任务</strong>：预测答案的起始和结束位置，使用的是序列中每个token的输出表示。</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel<br><br><span class="hljs-comment"># 加载预训练的BERT模型</span><br>model = BertModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-chinese&#x27;</span>)<br><br><span class="hljs-comment"># 使用模型进行推理</span><br>output = model(**encoded_input)<br><br><span class="hljs-comment"># 输出结果</span><br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><p><code>output</code>包含两个部分： -<code>last_hidden_state</code>：最后一个隐藏层的输出，可以用于各种下游任务。-<code>pooler_output</code>：对应于<code>[CLS]</code>标记的输出，通常用于分类任务。</p><hr /><p>BERT模型作为自然语言处理领域的重大突破，其核心优势在于创新性地采用了双向注意力机制和大规模无监督预训练方法。该模型通过深度双向上下文编码，有效捕捉了语言的复杂语义关系和长程依赖，显著提升了对语言理解的深度和广度。BERT的预训练-微调范式不仅大幅降低了特定任务的训练成本，还实现了模型在多种NLP任务上的卓越迁移能力。其强大的特征表示能力和灵活的架构设计，为下游任务提供了高质量的语言表征基础。</p>]]></content>
    
    
    <categories>
      
      <category>transformer</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>transformer</tag>
      
      <tag>预训练模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GPU版pytorch安装指南</title>
    <link href="/pytorch%20%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.html"/>
    <url>/pytorch%20%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.html</url>
    
    <content type="html"><![CDATA[<h4 id="安装或更新nvida显卡驱动">1. 安装或更新NVIDA显卡驱动</h4><p>官方驱动下载地址：https://www.nvidia.cn/Download/index.aspx?lang=cn</p><figure><imgsrc="/images/gpu版torch安装/v2-530262e6bd5b221121ebef91fe86b351_1440w.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h4 id="安装cuda-toolkit-cudnn">2.安装<code>CUDA Toolkit + cudnn</code>：</h4><h5 id="cuda安装">1）CUDA安装</h5><p>在<code>CUDA Toolkit</code>安装前用以下命令查询机器上显卡最高支持的CUDA 版本：</p><p>终端输入：</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">nvidia-smi</span><br></code></pre></td></tr></table></figure><p>下图中CUDA Version是12.2。</p><blockquote><p>如果你没有安装<code>cuda toolkit</code>或者需要升级，可以去官网下载：https://developer.nvidia.com/cuda-toolkit-archive</p></blockquote><figure><imgsrc="/images/gpu版torch安装/v2-976094b4950297cb63db4d8938179a01_1440w.jpg"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h5 id="cudnn安装">2）CUDNN安装</h5><p>NVIDIA CUDA深度神经网络库 (cuDNN) 是一个 <strong>GPU加速</strong>的<strong>深度神经网络基元库</strong>，能够以高度优化的方式实现标准例程（如前向和反向卷积、池化层、归一化和激活层）。</p><p>全球的深度学习研究人员和框架开发者都依赖 cuDNN 来实现高性能 GPU加速。借助cuDNN，研究人员和开发者可以专注于训练神经网络及开发软件应用，而不必花时间进行低层级的GPU 性能调整。cuDNN 可加速广泛应用的深度学习框架，包括Caffe2、Keras、MATLAB、MxNet、PaddlePaddle、PyTorch和 TensorFlow。</p><p><strong>下载地址：</strong><ahref="https://developer.nvidia.com/rdp/cudnn-archive">cuDNN Archive |NVIDIA Developer</a></p><p><strong>（1）下载并解压文件</strong></p><figure><img src="/images/gpu版torch安装/7429c11c55ca4e268719b103fbe72547.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>（2）复制内容到CUDA安装路径</strong></p><p>CUDA安装默认路径：</p><ul><li>Windows：<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA</code></li><li>Linux：<code>/usr/local/cuda</code></li></ul><figure><img src="/images/gpu版torch安装/e7b791a3d7bc454a9fc6a2373e33dddb.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h4 id="安装pytorch">3. 安装Pytorch</h4><p><strong>（1）在线安装</strong></p><p>打开<ahref="https://pytorch.org/get-started/locally/">pytorch安装指导网站</a>，选择合适的系统平台，关键是在<code>compute platform</code>选择一个不高于你电脑上的<code>CUDA Version</code>，复制命令安装。</p><ul><li>pip install torch==版本号</li><li>conda install torch==版本号</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 使用conda安装</span><br>conda install python pytorch torchvision torchaudio pytorch-cuda=<span class="hljs-number">11.7</span> -c pytorch -c nvidia<br><span class="hljs-comment"># 使用pip安装</span><br>pip install torch torchvision torchaudio --index-url https:<span class="hljs-regexp">//</span>download.pytorch.org<span class="hljs-regexp">/whl/</span>cu117<br>或者<br>pip install torch==<span class="hljs-number">2.0</span>.<span class="hljs-number">0</span>+cu118 torchvision==<span class="hljs-number">0.15</span>.<span class="hljs-number">0</span>+cu118 torchaudio==<span class="hljs-number">2.0</span>.<span class="hljs-number">1</span>+cu118 -f https:<span class="hljs-regexp">//</span>download.pytorch.org<span class="hljs-regexp">/whl/</span>torch_stable.html<br></code></pre></td></tr></table></figure><figure><img src="/images/gpu版torch安装/image-20240522173540087.png"alt="image-20240522173540087" /><figcaption aria-hidden="true">image-20240522173540087</figcaption></figure><p><strong>（2）离线安装</strong></p><ul><li>离线包下载地址：<ahref="https://download.pytorch.org/whl/torch_stable.html">download.pytorch.org/whl/torch_stable.html</a></li><li>安装方式</li></ul><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install torch-<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>+cu118-cp310-cp310-win_amd64.whl<br></code></pre></td></tr></table></figure><p>注意：</p><h5id="pytorch与torchvision版本对应问题">1）PYTORCH与TORCHVISION版本对应问题</h5><p><ahref="https://gitcode.com/pytorch/vision/overview?utm_source=csdn_blog_hover">Pytorch与torchvision版本配套</a></p><table><thead><tr class="header"><th>torch</th><th>torchaudio</th><th>python</th></tr></thead><tbody><tr class="odd"><td>main / nightly</td><td>main / nightly</td><td>&gt;=3.8, &lt;=3.10</td></tr><tr class="even"><td>2.1.0</td><td>2.1.0</td><td>&gt;=3.8, &lt;=3.11</td></tr><tr class="odd"><td>2.0.1</td><td>2.0.2</td><td>&gt;=3.8, &lt;=3.11</td></tr><tr class="even"><td>2.0.0</td><td>2.0.1</td><td>&gt;=3.8, &lt;=3.11</td></tr><tr class="odd"><td>1.13.1</td><td>0.13.1</td><td>&gt;=3.7, &lt;=3.10</td></tr><tr class="even"><td>1.13.0</td><td>0.13.0</td><td>&gt;=3.7, &lt;=3.10</td></tr><tr class="odd"><td>1.12.1</td><td>0.12.1</td><td>&gt;=3.7, &lt;=3.10</td></tr><tr class="even"><td>1.12.0</td><td>0.12.0</td><td>&gt;=3.7, &lt;=3.10</td></tr><tr class="odd"><td>1.11.0</td><td>0.11.0</td><td>&gt;=3.7, &lt;=3.9</td></tr><tr class="even"><td>1.10.1</td><td>0.10.1</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="odd"><td>1.10.0</td><td>0.10.0</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="even"><td>1.9.1</td><td>0.9.1</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="odd"><td>1.9.0</td><td>0.9.0</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="even"><td>1.8.2</td><td>0.8.2</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="odd"><td>1.8.1</td><td>0.8.1</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="even"><td>1.8.0</td><td>0.8.0</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="odd"><td>1.7.1</td><td>0.7.2</td><td>&gt;=3.6, &lt;=3.9</td></tr><tr class="even"><td>1.7.0</td><td>0.7.0</td><td>&gt;=3.6, &lt;=3.8</td></tr><tr class="odd"><td>1.6.0</td><td>0.6.0</td><td>&gt;=3.6, &lt;=3.8</td></tr><tr class="even"><td>1.5.0</td><td>0.5.0</td><td>&gt;=3.5, &lt;=3.8</td></tr><tr class="odd"><td>1.4.0</td><td>0.4.0</td><td>==2.7, &gt;=3.5, &lt;=3.8</td></tr></tbody></table><figure><img src="/images/gpu版torch安装/3eb20f49e5f547b0b87853b2ed5430c9.png"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><blockquote><p>如果你的conda解决环境很慢，可以试一试pip安装。</p></blockquote><h5 id="使用镜像源">2）使用镜像源</h5><ul><li>使用镜像源：</li><li>pip install torch -i [镜像源]</li><li>conda install torch -c [镜像源]</li><li>常用镜像源</li><li>清华源：https://pypi.tuna.tsinghua.edu.cn/simple</li><li>豆瓣源：https://pypi.doubanio.com/simple/</li></ul><h5 id="安装验证">3）安装验证</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import torch<br><span class="hljs-comment"># 打印出正在使用的PyTorch和CUDA版本。</span><br><span class="hljs-built_in">print</span>(torch.__version__)<br><span class="hljs-built_in">print</span>(torch.version.cuda)<br><br><span class="hljs-comment"># 测试GPU是否生效</span><br><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br></code></pre></td></tr></table></figure><h3 id="导入pytoch">（3）导入PyToch</h3><p>导入 PyTorch 并检查正在使用的版本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>torch.__version__<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-string">&#x27;2.0.1&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="pycharm配置anaconda环境">（4）Pycharm配置Anaconda环境</h3><ol type="1"><li>打开Pycharm，点击File--&gt;NewProject，例如新建项目工程名字为：Pycharm_conda</li></ol><figure><img src="/images/gpu版torch安装/image-20240530094628328.png"alt="image-20240530094628328" /><figcaption aria-hidden="true">image-20240530094628328</figcaption></figure><ol type="1"><li>选择新建工程所在文件位置，并命名，点击create。选择New Window。</li></ol><figure><img src="/images/gpu版torch安装/image-20240530094449673.png"alt="image-20240530094449673" /><figcaption aria-hidden="true">image-20240530094449673</figcaption></figure><ol type="1"><li>在创建好的新工程窗口下，点击File--&gt;Settings</li></ol><figure><img src="/images/gpu版torch安装/image-20240530094835776.png"alt="image-20240530094835776" /><figcaption aria-hidden="true">image-20240530094835776</figcaption></figure><ol type="1"><li>Settings--&gt;Project :Pycharm_conda--&gt;Python Interpreter,然后点击右边齿轮状图标或者"Add Interpreter"，点击Add ，添加解释器。</li></ol><figure><img src="/images/gpu版torch安装/image-20240530095248878.png"alt="image-20240530095248878" /><figcaption aria-hidden="true">image-20240530095248878</figcaption></figure><ol type="1"><li>打开后选择Conda Environment，然后选中Existingenvironment，选择自己创建的环境，点击OK，低版本可勾选Make available toall projects。</li></ol><figure><img src="/images/gpu版torch安装/image-20240530095810448.png"alt="image-20240530095810448" /><figcaption aria-hidden="true">image-20240530095810448</figcaption></figure><ol type="1"><li>等待加载完毕后，会看到在PythonInterpreter页面多了许多包。表示在该环境下创建的工程就可以使用anaconda中已有的库了。</li></ol><figure><img src="/images/gpu版torch安装/image-20240530100118494.png"alt="image-20240530100118494" /><figcaption aria-hidden="true">image-20240530100118494</figcaption></figure><ol type="1"><li>点击OK，配置完成，在主界面的右下角会显示当前环境处于刚配置好的环境中，等待加载完毕后即可正常使用</li></ol><figure><img src="/images/gpu版torch安装/image-20240530100154229.png"alt="image-20240530100154229" /><figcaption aria-hidden="true">image-20240530100154229</figcaption></figure><ol type="1"><li>使用terminal安装依赖</li></ol><figure><img src="/images/gpu版torch安装/image-20240530100803248.png"alt="image-20240530100803248" /><figcaption aria-hidden="true">image-20240530100803248</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>环境搭建</tag>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分类问题与回归问题的损失函数</title>
    <link href="/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E4%B8%8E%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.html"/>
    <url>/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E4%B8%8E%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.html</url>
    
    <content type="html"><![CDATA[<h2 id="分类问题损失函数">分类问题损失函数</h2><h3 id="多分类交叉熵损失softmax">多分类交叉熵损失Softmax</h3><figure><imgsrc="data:image/png;base64,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"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>其中:</strong></p><p>1.y 是样本 x 属于某一个类别的真实概率[用0,1表示]</p><p>2.而 f(x) 是样本属于某一类别的预测分数</p><p>3.S 是 softmax激活函数,将属于某一类别的预测分数转换成<strong>概率</strong></p><p>4.L 用来衡量真实值 y 和预测值 f(x) 之间差异性的损失结果</p><p>公式鼓励模型对正确类别给出高概率,对错误类别给出低概率。当预测完全正确时,损失为0;当预测错误时,损失会变大。</p><h3id="二分类损失----对数似然损失log-loss"><strong>二分类损失</strong>----对数似然损失(LogLoss)</h3><p>在处理二分类任务时，我们不再使用softmax激活函数，而是使用sigmoid激活函数，那损失函数也相应的进行调整，使用二分类的交叉熵损失函数：</p><figure><imgsrc="data:image/png;base64,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"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>其中:</strong></p><ol type="1"><li>y 是样本x属于某一个类别的真实概率</li><li>而y^是样本属于某一类别的预测概率</li><li>L用来衡量真实值y与预测值y^之间差异性的损失结果。</li></ol><h3 id="焦点损失-focal-loss"><strong>焦点损失</strong> <strong>(FocalLoss)</strong></h3><p>它是交叉熵损失的改进版本 ,由何恺明等人在2017年提出，最初用于解决目标检测中的前景-背景类别不平衡问题。</p><p><strong>FL(pt) = -α(1-pt)^γ * log(pt)</strong></p><p>其中：</p><ul><li><p>pt 是模型预测的概率</p></li><li><p>α 是平衡因子（用于平衡正负样本）</p></li><li><p>γ 是聚焦参数（用于调节简单样本的权重）</p></li><li><p>原理：</p><ul><li>焦点损失通过降低容易分类的样本（高置信度预测）的权重，使模型更关注难以分类的样本。</li><li>(1-pt)^γ项使得易分样本(pt接近1）的损失贡献较小，而难分样本的损失贡献较大。</li></ul></li><li><p>优点：</p><ul><li>有效解决类别不平衡问题，特别是在极度不平衡的情况下。</li><li>自动降低简单样本的权重，让模型更专注于难样本。</li><li>不需要进行硬性的样本挖掘。</li></ul></li><li><p>应用：</p><ul><li>目标检测</li><li>图像分类</li><li>其他存在类别不平衡的分类问题</li></ul></li><li><p>参数调节：</p><ul><li>γ 通常设置为0到5之间。γ 越大，对易分样本的抑制越强。</li><li>α 可以设置为类别频率的倒数，也可以通过交叉验证调整。</li></ul></li></ul><h2 id="回归问题损失函数">回归问题损失函数</h2><blockquote><p>又称loss function/cost function 目标函数 成本函数</p></blockquote><p>以下公式中, h(x^i )为拟合函数,y^i 为真实值</p><h4 id="最小二乘损失计算"><strong>最小二乘损失计算</strong>:</h4><figure><imgsrc="data:image/png;base64,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"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h4id="均方误差-mean-square-error-mse-又叫l2损失"><strong>均方误差</strong>(Mean-Square Error, <strong>MSE</strong>) 又叫L2损失</h4><figure><imgsrc="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUYAAABDCAIAAABvDzugAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAABBGSURBVHhe7Z0PVBNHHseHUwhV4XpqsC3Fw0ZBq2JRpFQ8NVZFlKvBs/ho5RTR3sGpRz3xKv0jbR+1hb4K1nf0yh/b04pSRBQlFSz/ChT5I4IiDTaKIH0ChgqokETL7c4OEJJsspuEhMT5PN8zv0kmbHb3OzO/2d9vxqqvrw9gMBhL4XfofwwGYxFgSWMwFgWWtGnoqE56faqtlf36Ey3y5tzIJQ62VrZTI4u6eq9+EzzL3ooy0GcxGBZgSZuCOwVfnnrq4ytZYd3nkrdt2ndv63dttQlzxPsiBSEHx7xXKak7MEf82ZlL6NMYDAuwpE3BxCVvRfk5tdysAb29q/fG+0+xBaNGWwOOzWvQsH4o7QS+81zRpzEYFmBJm4yu+qISTui7G12skcHdFU0Z4vJMkfdqj0nwYxgMK7CkTcalojQQ8PI8UsMA/FT1HVjpNRMarZVnS1wFnjz4BgbDDixpU1FbflrqucDFnjKKUtu9F82gjKtlmWDRrCltubt3nroDSzAYxmBJm4jGqmwRd9Vcl0FjuRvql10WBtglCnhb6wPfWTORKsJgmIKjxzAYiwL30hiMRYElrTO9d8u+ufiSfXU+sjGYkQCWtA5QYnaoeWlDd1k3KsNgRgZY0qz59ciG+tNjnj4lWZgThoowmBEDljRr/rAh/aWP/J92sB412gYVaabx0FIrA/AmHuFjGIAlPfw4b/giwRu95giO3epjgayrISPECVXGYLSDJW0ErF1CUhL5HPKlNHNjUFKDHBYzwdpumn/CmdjZyMRgtIElbRSsXbakpwdRos7fujmZhaiJym7+O/p7eYyhkLfVnfxo7VwHW8KnsXVYEpnbzOaajGCwpI3FeL84YTg1hC4JXfY2q2xonssC2BxgDIb467XzPrfZfaapt6+nJf3Vq/tW7MhoRe+ZN1jSxmM8PyY9ihJ1c+yGvfkd8CUjFsX09u3nIwNjAHhbinvzdnk9YwuA7TN+614HoL37HnrPvMGSNibWnpHnkVPdHOcbfoaFqDHDh7y26nsOP4RvGblvWNLGhXCqExPQTNnhdevYzJTRIm+rTAqe+2JcDbJZoVdlkjsngp/1ifzuRi+yRxAXY+fODU6qbNN4juVtubvXfrFSmB5sKdms6GEJhjWy2wneBQD8mCB6iEqYIslDTjXg8BNFMlSqG5K8CJ4dLzTjeg8qYIOulX9O9AaciEJkyVorYvkcO58UPX+KIRh6ZH091zNCnDi8iDwJKlBC1pQVwnOPKqV52yzBkmbPjdQKV9diRztCz9S/IkfXYtfA+hvofQYMihrMjq3RWQmyC4Rv7hROd8NqRo/KeeEA8FMUf69MRDgUdiHZptaG6pHBc83xiFc9yzLRsQBL0zOBgSVNNNhHtq/gBaY2o4Jh5lqKH2/FnowrrabvH1giEw2En+ilSW54XieyWaFXZbXADjIoawQKpDMvnKvSdHYWRjgNnnlZTezs8DzqtZljSElLSqPcdR4DauBCFJe694Oy1NyAxNgqlGdnho0t7NioH6aTqG8dE3CA7xHVYLTbxwTU17rG1qAiFWgra4MULgE36gIqGKQzO4QDnKIumKh51XBkfXXxs5UC96qilWPyPBNE6D3zhq2kRQme6AwAMKRVIxs9nfsbbfRUfOCqMqBSAI6t9HZLjY8kiwo/YR8oSt2ldKKUtaatJ75z0KdURlNlbchywgAnPE/NuZaVvs0FnJBsw/X87KA/sr5bR3wJHye+DpmWDPteWpJB3C0AeB+oU+iM4TBOH69QC2RHraHPGf4DGC50nimDfZJ34s/IVOJGCp9mUAPRXFkLZKsuOHYbWUOQ5YVz6ERlBDQcmX4/2axgL2myKVS+XW6nB+g2jGMIeT203SlkO2zCHkJnYGNE4Z3AWNRwcK12jEkCrxH9/au5shbIyrRjVL2+WV80HhnlvtEJ3pJg/1y6vuZ7wu/oX9oS0lpwJE3qvdbLEdmGhlzkGvh6PU+tj0uDo9dab2nyl0Jzi+pTCD9hESgqqhICMGuyAzKVIK/R4PKEKmiurJmuirOZA8sgqjDp6Wkc0F5Y14hsY6L5yIDD5FkACKtEyLRcWEu6tb5EBIaeOXltUSbgLHAZcgd1nfkrzPKd/mktKgGg9tPpCmm/+W/CD1iFZGsLxCNXvPb0cR/f9kP8WnLDKPtZwcdVYzRgILQ5XjOF8BOmgaKN4kopAHOcnZE9FHLBUfDqAveO6qRgMi/B1mHNIYXzpalyx48fUftz7UaH0Xs1aQ1R4HbgKjThguMujk+2VR748NtmqkgRRxcPAErrm5BpIORtP6DDCs1uQWUD98/KI7egreXInJ3nACCtFJuitTEqbCUN5QtWzpuObJKmmzUAeLgM7aPt/b6Ec1qiFgkqoVoDUCEWUyY/5uI+V2KsvG7hOKqADnLFa+5yu5I3ou+8cvSKpDVtVd1XG2POq3Rn5O0kLW1AX69K/z2gCROtM8ALTkc5Hc1xpxkEcj16JCO8b+tRyByK/FplPhDM7ti7RTg1urTtlwxB++nNCcXoXU2Vr6WEnZyf1iQ6tFQc++GpRiBvSBLsfLivqbevdsfz1Ecc5//ZqWTbwoAc978JlOeMCUaNsiGEI3+ETMNw7fCOLOKwymNdxF/sTO3vIqj7B/gG8Z+FtpYjA6OsiVZT9siwhzYSQQNwpkCPRGnqmXbmgXzuP+h1w0lHxWcF5GQKgxkt6J9x7HwGZo/o/p6Zz4C0pvkTp4fDT2HwAzT+VHiNFEKm4GVQeDyh/TzBT4Sl5YR7sX6EofzHDElNLCFhBXeY+KEsZk/M/PZgDMteurGusB1wF89UP+BTZoIjcQmu324nX8vLk/ZcEQg8QbkIDZ06zh06ERr/hptGD5moeLVMCDi+iclb4H5RpqHQyortP1STKfLyhH+dBJygdL1jjcW1ucQ1Ck18hz8e2g2iUkIIXqiXZQTPbTkXJAeFPhkfg77EIIiTFqLBED0Lk2hHWWDGnJcV3eHaolSXg3t8FSZ1MATsJN11JZ8YmBJeGrK1YD/hGQDu3L1PvBR/vXPfkv8cCCE03thGzmB1FX0c3h27i6/1gtRXCaUgIMR3YFwvv15dAsBzT6H4E6OwuK+P7T9Ukxkd+bvXRTU7hQvj/JhLqLJhwK9UAM4lcv8R2H9mW6vPlQPVTfPUV+5nqttSIJ2zK9CTbSva2KjBbeBtKUY9CT3FW+hbNOtpHvwBd7gr/9DRwM82Mm//Whoq0SvLhp2kyRkIwPeYNvRCT/7jHPW3CJyRIJ3pluO7dtok7PVzGjuBykvtyN+7+Vr0wfXa58jhVI9g9fwB6XedP55MeOCBi1Qag6Y6QurzebQXecT60i3HQ3zjmmfHnmHcJ2pwWeE1Gmx1yXlgpdlvrf6uvPzzd7PtQHlpA+td6zU6+XrjPHMxF02+idMOyD7ZzqbJeSSXAmAzapgObeTAStINF7PbgeuqeUrDbmu3RQL181KOrp4ASJqP7tnaGZ9IDijJgsqG+tx3N0rikhkIGo0LnB36+xh5w9HoZKnTnjeWqSi6lnw0o2mAyd+PegINGH+dAXlDUtDGTMBPTP+nNh9kEGeeBweAmkbV6Vt4jRRaXSWFk9BXhhAjhvfGHi18zxWkfV/FNvcTdoULZkxGpqGZPm8l7KZbjkeWhXy4nI1TAMcPHA8eM5/RnEG3MhM6s4KICmE5qvNZdKEmMIhJccqHmuri8NTMuqifV4FTPShUTdZVeyTAiS7MCobxml2oCZkuQJwR1tkOdDEd8BoplHef3QxjvckEyL/8O78bFmoICOmpS/CBE5EwEIy7u6iHKBmoqBUN32wYyBkyriDAJ4R1eshjE2rCRtKFEUTjrv6kwBAoNRH7pE6H3K9kgfpIcLWSvpHiw4/NF8b5z7Qjmwauu390TpO6KXIYXmx2AaFUOKhOkfE087fwGim2urfSA4hTx+Eu3qNw4tRWhm0i77VjqL2UiVJ8iJp2Mzf1l2hn+ANCYVycLifscZnvZiVp+AiBNtBa37QNeK10jauHaRu8aFPlAOkIlbShazukT+aFfpVpMULahkS4dXZEIfs/gNM21ADvAo0nRZ/kSklOGFe3BsFMkyup1Ep90sdgfqSu/Y5elWkY9uRK4pxRXgFr4AiEdbKbecJM0oQXS0YsatecrPVKxh4dlkC4tH9FaJbaEbVmmlMDzXIJBORC63eT6bWKgV6V1UIObYdlCQTCCw7L6WmtiH/llQTF9D/GqF0CwWLRKmnoHmnyYjGs0cOFHgo1haHj9+hVWRk46DDUlw0FesFKkwFsMNdkel1hMz32GPOwtaJu08wiAIp8DrcRN/B1YfVibiFhekU3Enex5GLdJvciDiiw86q9oK3fo1xoQw1QTbKc4FBkRAfqYzcylhNUgvLK6JcTtESwpJlw5fLqUNH1ntsJngUgXHQxvio6/9eevnsZ6wsAuJBwrNo/WtzS0yfJKAegQHN8s/4utCqEpBI3ubvHVCGbFXpVJmlP3+S4Yo/Q0KtTGYKqGHf3TYkV5rcwnV5gSbMASppbGpV3j7IvRBH9doFTuBj1AXkXtUhadxeafKpqKYtjYYYVtsmVjzOtv54rB5yVE7fzx0K788al3wBn3H/ff46KYhKLpQA8QR++1pG/2y/islO4kFHc3BBgKob1aIsPZsToD5Y0Y+RXe4TAKjQYCRjIJWVCwN01sT80tbPyrBR4j1POj+in40y4b1yzU1S6DslNLWUZJQBw7bQklmMwWNIsqK96IAVjXp7X31XW3xdKwUovBxRN3dUG8yPGqc0akTckrVt3GPATz0eyTW6Sd1/+atubQuLVYKQ7BkMLljRT2sszHwLvMTP600Uaqx6IgM0ClyeQ/dMDmB+hbkgtb0jevDVfSm4t7WqDUr4YY2PvFpxJppwPW34TxqLAkmZI110yDXmwE350rbIXcMcMrsF2/7d2MHrKJNBWeXnNzusKy6kRLvSyUGLcrC/KS0FhMOrAkmbIpXtp5JprA+sutJR+S9hjBtdgc7H7O+9RhGdpQMaYg588p+D11pyOU7O6HQYzPFj19bFbfwODwYxkcC+NwVgUWNIYjEWBJW1MyNXPlh6y+MXhMaYES9qIiMUVbFa/kjfnRpJ7TMDtRZKqGWzCgcHg6bERi7z8fd6LuRF157dP6yr+YNmfYl/I+uV/LJYExjym4F7aSKAVh/2PM9yGT16cuq856K2Nz9sCa4eF294WSA8n55rbFn4YE4AlbST4+8ndjweXyKffeYJaSrxJXCEFE8aiWLVJU17ggpKfblIWBkMPlrSxkN+8XK6wRD79zhPUUuLkPgOergPxYhMcXUA73LcEg9EIlrSxqC79lvnWQwBuYjCwfRgA9+/eAa6OE5CFwdCCJW0kaotS2wWLBvfT0DbwfurZge3DCLqaakXAc7rl7xSB0RssaeMA99Z2dvj9jZNRn5eROR3aBt72iwJDOJnRB4vb5KD36tcfH3aK2KK6DRgGowyWtHEYP2OJOydujccHDwK2ejFaycDeN+bHxHknV02ysXpyyYlFOSXRWNEYBuDn0hiMBQHA/wHZu8qNrXdoywAAAABJRU5ErkJggg=="alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h4id="平均绝对误差-mean-absolute-error-mae-又叫l1损失"><strong>平均绝对误差</strong>(Mean Absolute Error , <strong>MAE</strong>) 又叫L1损失</h4><figure><imgsrc="data:image/png;base64,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"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><em>注MSE与MAE既能在模型训练阶段作为损失函数求解拟合函数最优解 ,又可作为模型评估阶段, 衡量已有模型误差大小</em></p><h4 id="smooth-l1-lose"><strong>smooth L1 lose</strong></h4><p>平滑后的L1lose,分段函数</p><figure><imgsrc="data:image/png;base64,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"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p>其中：𝑥 = f(x) − y 为真实值和预测值的差值。</p><p>从下图中可以看出，该函数实际上就是一个分段函数</p><ol type="1"><li>在[-1,1]之间实际上就是L2损失，这样解决了L1的不光滑问题</li><li>在[-1,1]区间外，实际上就是L1损失，这样就解决了离群点梯度爆炸的问题</li></ol><p><img src="/images/神经网络图解/lossfunction.png" /></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>机器学习</tag>
      
      <tag>损失函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>爬虫与反爬虫技术点梳理</title>
    <link href="/%E7%88%AC%E8%99%AB%E4%B8%8E%E5%8F%8D%E7%88%AC%E6%94%BB%E9%98%B2%E7%9A%8412%E5%B1%82%E5%A2%83%E7%95%8C.html"/>
    <url>/%E7%88%AC%E8%99%AB%E4%B8%8E%E5%8F%8D%E7%88%AC%E6%94%BB%E9%98%B2%E7%9A%8412%E5%B1%82%E5%A2%83%E7%95%8C.html</url>
    
    <content type="html"><![CDATA[<h2 id="爬虫与反爬攻防的12层境界">1 爬虫与反爬攻防的12层境界</h2><table><thead><tr class="header"><th><strong>步骤</strong></th><th><strong>攻击者</strong></th><th><strong>防守者</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr class="odd"><td><strong>1. 初学者</strong></td><td>不管三七二十一，直接用 requests模块开始抓取，不作任何反爬措施。</td><td>发现同一 IP 和 UA 都是 Python 程序，开始限制访问。</td><td>初学者不了解反爬技术，直接用简单方法抓取。网站会检测到这种异常访问并限制。</td></tr><tr class="even"><td><strong>2. 小白入门</strong></td><td>学会设置 UA 模拟浏览器，并设置代理 IP。</td><td>网站仍发现异常，开始设置登录限制。</td><td>攻击者稍微提高技术，模仿真实用户访问。网站会进一步检测异常。</td></tr><tr class="odd"><td><strong>3. 需要登录</strong></td><td>注册账号，带 cookie 抓取数据。</td><td>限制单账号访问速度，发现异常访问。</td><td>攻击者注册账号后模拟正常用户行为。网站开始检测账号行为并限制速度。</td></tr><tr class="even"><td><strong>4. 多账号抓取</strong></td><td>购买多个账号，用多个 cookie 抓取。</td><td>开始 IP 频繁访问限制，可能误封现象。</td><td>攻击者通过多个账号分散访问。网站开始加强 IP 层面的限制。</td></tr><tr class="odd"><td><strong>5. 模拟人类请求</strong></td><td>利用多账号，多线程，不同时间段抓取。</td><td>设置验证码，对访问频率快的 IP 验证。</td><td>攻击者模仿更真实的人类行为，使用多线程等手段。网站加强验证机制。</td></tr><tr class="even"><td><strong>6. 打码平台</strong></td><td>通过打码平台识别验证码，研究机器学习识别。</td><td>开始将重要数据通过 Ajax 加载。</td><td>攻击者利用技术手段破解验证码。网站改用更复杂的动态数据加载方式。</td></tr><tr class="odd"><td><strong>7. 完全模拟</strong></td><td>通过 selenium 完全模拟浏览器操作。</td><td>动态内容内容加载</td><td>攻击者使用高级工具模拟完整浏览器操作。网站防守难度增大，甚至无奈放弃。</td></tr><tr class="even"><td><strong>8. 绕过动态内容</strong></td><td>使用 Puppeteer 或 Playwright 等工具处理动态内容抓取。</td><td>使用更复杂的动态加载和懒加载技术。</td><td>攻击者利用现代工具处理 JavaScript渲染的网站。网站尝试通过更复杂的加载策略增加抓取难度。</td></tr><tr class="odd"><td><strong>9. 深度伪装</strong></td><td>利用抗检测浏览器，使用指纹伪装和环境模拟技术。</td><td>实施浏览器指纹识别和行为分析技术。</td><td>攻击者使用技术来伪装浏览器指纹和环境。网站则通过指纹识别和用户行为分析来检测异常。</td></tr><tr class="even"><td><strong>10. 分布式爬虫</strong></td><td>使用分布式系统，如 Scrapy Cloud 或自建集群，分散 IP 和流量。</td><td>部署 WAF（Web 应用防火墙）和 CDN，进行流量分析和阻断。</td><td>攻击者通过分布式系统减轻单点访问压力。网站则利用防火墙和内容分发网络来监控和阻止恶意流量。</td></tr><tr class="odd"><td><strong>11. AI 模拟</strong></td><td>采用深度学习算法模拟真实用户行为，以躲避检测。</td><td>使用 AI 和机器学习检测异常行为模式。</td><td>攻击者利用 AI 技术模拟真实用户交互。网站同样采用 AI来识别和应对复杂的异常行为。</td></tr><tr class="even"><td><strong>12. 复杂验证码破解</strong></td><td>结合计算机视觉和机器学习自动破解复杂验证码。</td><td>实施更复杂的验证码，如行为验证码和多因素验证。</td><td>攻击者使用先进技术破解验证码。网站则采用更复杂和多层次的验证手段。</td></tr></tbody></table><ol type="1"><li><ul><li><h2 id="爬虫与反爬虫对抗">爬虫与反爬虫对抗</h2><h3 id="初学者阶段">初学者阶段</h3><ul><li><strong>攻击者</strong>：直接使用简单的 <code>requests</code>库进行抓取，不考虑反爬策略。</li><li><strong>防守者</strong>：由于请求过于简单和单一，服务器能够快速检测到大量请求来自同一IP 和 UA（User Agent），并进行限制。</li></ul><h3 id="小白入门">小白入门</h3><ul><li><strong>攻击者</strong>：学习伪装浏览器的 UA 和使用代理IP，以规避基本的反爬策略。</li><li><strong>防守者</strong>：若发现网站访问压力仍然很大，可能会启动登录限制，要求用户登录才能访问更多数据。</li></ul><h3 id="需要登录">需要登录</h3><ul><li><strong>攻击者</strong>：创建账号，使用登录后的 Cookie进行数据抓取。</li><li><strong>防守者</strong>：监控账号的使用情况，限制单个账号的访问频率，并检查异常访问模式。</li></ul><h3 id="多账号抓取">多账号抓取</h3><ul><li><strong>攻击者</strong>：购买多个账号以绕过单个账号的限制，使用多个Cookie 进行数据抓取。</li><li><strong>防守者</strong>：实施 IP频率限制，尝试阻止过于频繁的访问，但这可能导致误封正常用户。</li></ul><h3 id="模拟人类请求">模拟人类请求</h3><ul><li><strong>攻击者</strong>：模拟人类的行为，使用多线程和多账号，在不同时间段进行抓取以避免被检测。</li><li><strong>防守者</strong>：使用验证码，并对访问频繁的 IP进行更严格的验证。</li></ul><h3 id="打码平台">打码平台</h3><ul><li><strong>攻击者</strong>：借助打码平台自动识别验证码，甚至研究使用机器学习技术来识别复杂验证码。</li><li><strong>防守者</strong>：将数据通过 Ajax动态加载，以增加抓取难度和反爬虫能力。</li></ul><h3 id="完全模拟">完全模拟</h3><ul><li><strong>攻击者</strong>：使用 Selenium等工具模拟完整的浏览器操作，几乎无法与真实用户行为区分。</li><li><strong>防守者</strong>：在这种情况下，防守难度极大，维护成本高，甚至可能放弃小部分数据的保护。</li></ul><h3 id="绕过动态内容">绕过动态内容</h3><ul><li><strong>攻击者</strong>：使用 Puppeteer 和 Playwright等工具渲染并抓取需要 JavaScript 执行的动态内容。</li><li><strong>防守者</strong>：通过懒加载和动态加载技术增加爬取难度，确保数据不易被抓取。</li></ul><h3 id="深度伪装">深度伪装</h3><ul><li><strong>攻击者</strong>：使用反检测浏览器和环境模拟技术，伪装浏览器的指纹和操作环境。</li><li><strong>防守者</strong>：通过浏览器指纹识别和行为分析，检测异常的访问行为和指纹伪造。</li></ul><h3 id="分布式爬虫">分布式爬虫</h3><ul><li><strong>攻击者</strong>：使用分布式爬虫框架分散请求，避免集中 IP导致的封禁。</li><li><strong>防守者</strong>：通过 Web 应用防火墙和 CDN监测并阻止异常流量。</li></ul><h3 id="ai-模拟">AI 模拟</h3><ul><li><strong>攻击者</strong>：利用 AI模拟人类用户的复杂交互和行为，以规避传统检测手段。</li><li><strong>防守者</strong>：使用 AI进行行为分析，识别并阻止异常的用户行为模式。</li></ul></li></ul></li></ol><h2 id="playwright-相比-selenium-具有一些显著的优势">2.Playwright 相比Selenium 具有一些显著的优势：</h2><p><strong>1. 更高效的页面加载和渲染：</strong> Playwright使用浏览器原生的 API进行交互，能够更快地加载和渲染页面，从而提高爬取效率。</p><p><strong>2. 更强大的浏览器控制能力：</strong> Playwright提供了更细粒度的浏览器控制能力，例如拦截网络请求、模拟用户输入、处理JavaScript 执行等，可以更灵活地处理复杂的爬虫场景。</p><p><strong>3. 更强的反检测能力：</strong> Playwright可以更好地模拟真实用户的行为，例如鼠标移动、页面滚动等，从而降低被目标网站识别为爬虫的风险。</p><p><strong>4. 更易于处理动态内容：</strong> Playwright可以等待页面加载完成并执行 JavaScript渲染，从而更轻松地获取动态加载的内容。</p><p><strong>5. 更简洁的代码实现：</strong> Playwright 的 API更简洁易懂，可以减少代码量，提高开发效率。</p><p><strong>总结：</strong></p><table><thead><tr class="header"><th>特性</th><th>Playwright</th><th>Selenium</th></tr></thead><tbody><tr class="odd"><td>页面加载和渲染速度</td><td>更快</td><td>相对较慢</td></tr><tr class="even"><td>浏览器控制能力</td><td>更强</td><td>相对较弱</td></tr><tr class="odd"><td>反检测能力</td><td>更强</td><td>相对较弱</td></tr><tr class="even"><td>处理动态内容</td><td>更易于</td><td>相对较难</td></tr><tr class="odd"><td>代码实现</td><td>更简洁</td><td>相对复杂</td></tr></tbody></table><p><strong>举例说明：</strong></p><p>假设您需要爬取一个使用 AJAX 加载数据的网站。使用Selenium，您需要手动等待 AJAX 请求完成并更新页面内容，而使用Playwright，您可以使用 <code>waitForResponse</code>方法自动等待特定的网络请求完成，从而更方便地获取数据。</p>]]></content>
    
    
    <categories>
      
      <category>数据获取</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据工程</tag>
      
      <tag>爬虫</tag>
      
      <tag>数据挖掘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>半小时速通正则表达式</title>
    <link href="/%E5%8D%8A%E5%B0%8F%E6%97%B6%E9%80%9F%E9%80%9A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F.html"/>
    <url>/%E5%8D%8A%E5%B0%8F%E6%97%B6%E9%80%9F%E9%80%9A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F.html</url>
    
    <content type="html"><![CDATA[<p>正则表达式在文本范式处理时有者非常重要的应用，快来一起巩固一下正则的相关知识吧！<span id="more"></span> ### 正则表达式应用场景(Regular Expression)</p><ul><li>数据验证（表单验证、如手机、邮箱、IP地址）</li><li>爬虫功能</li><li>数据检索（数据检索、数据抓取）</li><li>数据隐藏（135****6235王先生）</li><li>数据过滤（论坛敏感关键词过滤）</li></ul><h3 id="正则--match">正则--match</h3><p><strong>re.match(pattern, string, flags=0)</strong></p><table><thead><tr class="header"><th><strong>参数</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr class="odd"><td>pattern</td><td>匹配的正则表达式</td></tr><tr class="even"><td>string</td><td>要匹配的字符串。</td></tr><tr class="odd"><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<ahref="https://www.runoob.com/python/python-reg-expressions.html#flags">正则表达式修饰符- 可选标志</a></td></tr></tbody></table><p>re.match 尝试从字符串的<strong>起始位置匹配</strong>一个模式，匹配成功 re.match 方法返回一个匹配的对象，否则返回 None。</p><h3 id="正则--search">正则--search</h3><p><strong>re.search(pattern, string, flags=0)</strong></p><table><thead><tr class="header"><th><strong>参数</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr class="odd"><td>pattern</td><td>匹配的正则表达式</td></tr><tr class="even"><td>string</td><td>要匹配的字符串。</td></tr><tr class="odd"><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<ahref="https://www.runoob.com/python/python-reg-expressions.html#flags">正则表达式修饰符- 可选标志</a></td></tr></tbody></table><p>re.match尝试从字符串的<strong>任意位置匹配</strong>一个模式，(常用于全词匹配)匹配成功 re.search 方法返回一个匹配的对象，否则返回 None。</p><p>re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</p><h3id="re.compile正则表达式.sub用来替换的内容要被替换的内容">re.compile（正则表达式）.sub（用来替换的内容，要被替换的内容）</h3><p>compile 函数用于编译正则表达式，生成一个正则表达式（ Pattern）对象，供 match() 和 search() 这两个函数使用。 ### ###re.sub(正则,替换字符,被替换的内容)</p><h3 id="正则常用符号释义">正则常用符号释义</h3><table><thead><tr class="header"><th><strong>符号</strong></th><th><strong>解释</strong></th><th><strong>示例</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr class="odd"><td>.</td><td><strong>匹配任意字符</strong></td><td>b.t</td><td>可以匹配bat / but / b#t / b1t等</td></tr><tr class="even"><td><a href="file://w"></a></td><td><strong>匹配字母/数字/下划线/汉字</strong></td><td>b</td><td>可以匹配bat / b1t / b_t等&lt;br&gt;但不能匹配b#t</td></tr><tr class="odd"><td><a href="file://s"></a></td><td>**匹配空白字符（包括、*）</td><td>love</td><td>可以匹配love you</td></tr><tr class="even"><td>[(file://d)</td><td><strong>匹配数字</strong></td><td>[(file://d/d)</td><td>可以匹配01 / 23 / 99等</td></tr><tr class="odd"><td>[(file://b)</td><td>匹配单词的边界</td><td>[(file://bThe/b)</td><td></td></tr><tr class="even"><td>^</td><td><strong>匹配字符串的开始</strong></td><td>^The</td><td>可以匹配The开头的字符串</td></tr><tr class="odd"><td>$</td><td><strong>匹配字符串的结束</strong></td><td>.exe$</td><td>可以匹配.exe结尾的字符串</td></tr><tr class="even"><td><a href="file://W"></a></td><td>匹配非字母/数字/下划线</td><td>b</td><td>可以匹配b#t / b@t等&lt;br&gt;但不能匹配but / b1t / b_t等</td></tr><tr class="odd"><td><a href="file://S"></a></td><td>匹配非空白字符</td><td>love</td><td>可以匹配love#you等&lt;br&gt;但不能匹配love you</td></tr><tr class="even"><td><a href="file://D"></a></td><td>匹配非数字</td><td><a href="file://d/D"></a></td><td>可以匹配9a / 3# / 0F等</td></tr><tr class="odd"><td><a href="file://B"></a></td><td>匹配非单词边界</td><td><a href="file://Bio/B"></a></td><td></td></tr><tr class="even"><td>[]</td><td>匹配来自字符集的任意单一字符</td><td>[aeiou]</td><td>可以匹配任一元音字母字符</td></tr><tr class="odd"><td><strong>[^]</strong></td><td>匹配不在字符集中的任意单一字符</td><td>[^aeiou]</td><td>可以匹配任一非元音字母字符</td></tr><tr class="even"><td><strong>*</strong></td><td><strong>匹配0次或多次</strong></td><td><a href="file://w*">*</a></td><td></td></tr><tr class="odd"><td><strong>+</strong></td><td><strong>匹配1次或多次</strong></td><td><a href="file://w+">+</a></td><td></td></tr><tr class="even"><td><strong>?</strong></td><td><strong>匹配0次或1次</strong></td><td><a href="file://w">?</a></td><td></td></tr><tr class="odd"><td><strong>{N}</strong></td><td><strong>匹配N次</strong></td><td></td><td></td></tr><tr class="even"><td><strong>{M,}</strong></td><td><strong>匹配至少M次</strong></td><td></td><td></td></tr><tr class="odd"><td><strong>{M,N}</strong></td><td><strong>匹配至少M次至多N次</strong></td><td></td><td></td></tr><tr class="even"><td><strong>\</strong></td><td>分支</td><td>foo\bar</td><td>可以匹配foo或者bar</td></tr><tr class="odd"><td><strong>(?#)</strong></td><td>注释</td><td></td><td></td></tr><tr class="even"><td><strong>(exp)</strong></td><td>匹配exp并捕获到自动命名的组中</td><td></td><td></td></tr><tr class="odd"><td><strong>(?&lt;name&gt;exp)</strong></td><td>匹配exp并捕获到名为name的组中</td><td></td><td></td></tr><tr class="even"><td><strong>(?:exp)</strong></td><td>匹配exp但是不捕获匹配的文本</td><td></td><td></td></tr><tr class="odd"><td><strong>(?=exp)</strong></td><td>匹配exp前面的位置</td><td><a href="file://b/w+(%3f=ing)">+(?=ing)</a></td><td>可以匹配I'm dancing中的danc</td></tr><tr class="even"><td><strong>(?&lt;=exp)</strong></td><td>匹配exp后面的位置</td><td>[(?&lt;=)+(file://bdanc)/w+/b)</td><td>可以匹配I love dancing and reading中的第一个ing</td></tr><tr class="odd"><td><strong>(?!exp)</strong></td><td>匹配后面不是exp的位置</td><td></td><td></td></tr><tr class="even"><td><strong>(?&lt;!exp)</strong></td><td>匹配前面不是exp的位置</td><td></td><td></td></tr><tr class="odd"><td><strong>*?</strong></td><td>重复任意次，但尽可能少重复</td><td>a.\b&lt;br&gt;a.\?b</td><td>将正则表达式应用于aabab，前者会匹配整个字符串aabab，后者会匹配aab和ab两个字符串</td></tr><tr class="even"><td><strong>+?</strong></td><td>重复1次或多次，但尽可能少重复</td><td></td><td></td></tr><tr class="odd"><td><strong>??</strong></td><td>重复0次或1次，但尽可能少重复</td><td></td><td></td></tr><tr class="even"><td><strong>{M,N}?</strong></td><td>重复M到N次，但尽可能少重复</td><td></td><td></td></tr><tr class="odd"><td><strong>{M,}?</strong></td><td>重复M次以上，但尽可能少重复</td><td></td><td></td></tr></tbody></table><p>说明：如果需要匹配的字符是正则表达式中的特殊字符，那么可以使用\进行转义处理，例如想匹配小数点可以写成\.就可以了，因为直接写.会匹配任意字符；同理，想匹配圆括号必须写成\(和\)，否则圆括号被视为正则表达式中的分组。</p>]]></content>
    
    
    
    <tags>
      
      <tag>正则表达式</tag>
      
      <tag>基础语法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>矩阵乘法、点乘、点积与bmm</title>
    <link href="/%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E3%80%81%E7%82%B9%E4%B9%98%E3%80%81%E7%82%B9%E7%A7%AF%E4%B8%8Ebmm.html"/>
    <url>/%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E3%80%81%E7%82%B9%E4%B9%98%E3%80%81%E7%82%B9%E7%A7%AF%E4%B8%8Ebmm.html</url>
    
    <content type="html"><![CDATA[<p>在机器学习和深度学习中，向量和矩阵运算是核心的数学操作。PyTorch作为一个流行的深度学习框架，提供了高效的张量操作接口，包括点乘、点积和矩阵乘法。下面详细讲解这些概念及其在PyTorch中的实现和应用。</p><h3 id="点乘-element-wise-product">点乘 (Element-wise Product)</h3><p><strong>概念</strong>: -点乘是指两个相同形状的向量或矩阵对应元素逐个相乘，得到一个相同形状的向量或矩阵。- 也称为哈达玛积（Hadamard Product）。</p><p><strong>公式</strong>: - 如果 ( ) 和 ( )是形状相同的矩阵（或向量），则点乘的结果是一个矩阵 ( )，其中 ( C_{ij} =A_{ij} B_{ij} )。</p><p><strong>PyTorch实现</strong>: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 创建两个相同形状的张量</span><br>a = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>b = torch.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>])<br><br><span class="hljs-comment"># 进行点乘（元素级别相乘）</span><br>elementwise_product = a * b<br><span class="hljs-built_in">print</span>(elementwise_product)  <span class="hljs-comment"># 输出: tensor([4, 10, 18])</span><br></code></pre></td></tr></table></figure></p><h3 id="点积-dot-product">点积 (Dot Product)</h3><p><strong>概念</strong>: -点积是两个相同长度的向量间的运算，结果是一个标量。 -在几何上，点积可以用于计算两个向量的夹角和相似度。</p><p><strong>公式</strong>: - 如果 ( ) 和 ( ) 是两个向量，点积 ( ) 为： [= _{i=1}^{n} a_i b_i ]</p><p><strong>PyTorch实现</strong>: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建两个相同长度的向量</span><br>a = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>b = torch.tensor([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>])<br><br><span class="hljs-comment"># 计算点积</span><br>dot_product = torch.dot(a, b)<br><span class="hljs-built_in">print</span>(dot_product)  <span class="hljs-comment"># 输出: tensor(32)</span><br></code></pre></td></tr></table></figure></p><h3 id="矩阵乘法-matrix-multiplication">矩阵乘法 (MatrixMultiplication)</h3><p><strong>概念</strong>: -矩阵乘法是线性代数中的基本运算，将两个矩阵相乘以得到一个新矩阵。 - 矩阵( ) 的列数必须等于矩阵 ( ) 的行数。 -在机器学习中，矩阵乘法用于计算神经网络的加权和。</p><p><strong>公式</strong>: - 如果 ( ) 是一个 ( m n ) 矩阵，( ) 是一个 ( np ) 矩阵，则乘积矩阵 ( ) 是一个 ( m p ) 矩阵，且 [ C_{ij} =<em>{k=1}^{n} A</em>{ik} B_{kj} ]</p><p><strong>PyTorch实现</strong>: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建两个可相乘的矩阵</span><br>A = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>B = torch.tensor([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br><br><span class="hljs-comment"># 进行矩阵乘法</span><br>matrix_product = torch.mm(A, B)<br><span class="hljs-built_in">print</span>(matrix_product)<br><span class="hljs-comment"># 输出: tensor([[19, 22],</span><br><span class="hljs-comment">#               [43, 50]])</span><br></code></pre></td></tr></table></figure></p><h3 id="bmm计算">bmm计算</h3><p>在PyTorch中，<code>bmm</code>是用于执行批量矩阵乘法的函数。方法是<code>torch.bmm</code>，适用于形状为<code>(b, n, m)</code> 和 <code>(b, m, p)</code>的张量的批量矩阵乘法运算，输出为 <code>(b, n, p)</code>形状的张量。其中，<code>b</code>是批次大小，<code>n</code>、<code>m</code>、<code>p</code>是矩阵的维度。</p><p><code>torch.bmm</code> 主要用于对一批 2D矩阵进行乘法操作，这对需要在多个样本上同时进行线性代数运算的情况特别有用。</p><blockquote><p><code>torch.bmm</code> 在以下场景中特别有用：</p><ol type="1"><li><strong>神经网络的批处理操作</strong>：在神经网络中，处理多个样本的批量数据时，使用<code>bmm</code> 可以高效地进行矩阵乘法。</li><li><strong>时间序列数据的处理</strong>：处理时间序列数据时，常常需要对时间步长上的数据进行操作，这也可以通过<code>bmm</code> 来实现。</li><li><strong>多元线性代数计算</strong>：在对多对矩阵进行线性代数运算时，<code>bmm</code>提供了一种简洁而高效的实现方式。</li></ol></blockquote><h3 id="应用场景">应用场景</h3><ol type="1"><li><strong>神经网络中的线性变换</strong>:<ul><li>在神经网络的全连接层（Fully ConnectedLayer）中，输入和权重矩阵的乘法用于线性变换。</li></ul></li><li><strong>损失函数的计算</strong>:<ul><li>矩阵乘法用于批量计算预测值和真实值之间的差异，特别是在训练期间。</li></ul></li><li><strong>数据的相似度计算</strong>:<ul><li>在自然语言处理（NLP）等领域，<strong>点积</strong>用于计算词向量之间的相似性。</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>categories</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>笔记整理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tensor基础3——张量的索引与变形</title>
    <link href="/Tensor%E5%9F%BA%E7%A1%803--%E5%BC%A0%E9%87%8F%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%8F%98%E5%BD%A2.html"/>
    <url>/Tensor%E5%9F%BA%E7%A1%803--%E5%BC%A0%E9%87%8F%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%8F%98%E5%BD%A2.html</url>
    
    <content type="html"><![CDATA[<h4 id="张量的索引操作">1. 张量的索引操作</h4><ul><li>在操作张量时，经常要去获取某些元素进行处理或者修改操作，在这里需要了解torch中的索引操作。</li></ul><p><strong>准备数据：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-comment"># 随机生成数据</span><br>data = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<br><span class="hljs-built_in">print</span>(data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>, <span class="hljs-number">9</span>],<br>            [<span class="hljs-number">6</span>, <span class="hljs-number">8</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>            [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>],<br>            [<span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>]])<br></code></pre></td></tr></table></figure><h5 id="简单行列索引的使用">1）简单行列索引的使用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(data[<span class="hljs-number">0</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>, <span class="hljs-number">9</span>])<br><br><span class="hljs-built_in">print</span>(data[:, <span class="hljs-number">0</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">0</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure><h5 id="列表索引的使用">2）列表索引的使用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 返回 (0, 1)、(1, 2) 两个位置的元素</span><br><span class="hljs-built_in">print</span>(data[[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">7</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-comment"># 返回 0、1 行的 1、2 列共4个元素</span><br><span class="hljs-built_in">print</span>(data[[[<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>]], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">7</span>, <span class="hljs-number">6</span>],<br>            [<span class="hljs-number">8</span>, <span class="hljs-number">3</span>]])<br></code></pre></td></tr></table></figure><h5 id="范围索引的使用">3）范围索引的使用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 前3行的前2列数据</span><br><span class="hljs-built_in">print</span>(data[:<span class="hljs-number">3</span>, :<span class="hljs-number">2</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">7</span>],<br>            [<span class="hljs-number">6</span>, <span class="hljs-number">8</span>],<br>            [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>]])<br><br><span class="hljs-comment"># 第2行到最后的前2列数据</span><br><span class="hljs-built_in">print</span>(data[<span class="hljs-number">2</span>:, :<span class="hljs-number">2</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],<br>            [<span class="hljs-number">4</span>, <span class="hljs-number">9</span>]])<br></code></pre></td></tr></table></figure><h5 id="布尔索引的使用">4）布尔索引的使用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第三列大于5的行数据</span><br><span class="hljs-built_in">print</span>(data[data[:, <span class="hljs-number">2</span>] &gt; <span class="hljs-number">5</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>, <span class="hljs-number">9</span>],<br>            [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>]])<br><br><span class="hljs-comment"># 第二行大于5的列数据</span><br><span class="hljs-built_in">print</span>(data[:, data[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">5</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">7</span>],<br>            [<span class="hljs-number">6</span>, <span class="hljs-number">8</span>],<br>            [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],<br>            [<span class="hljs-number">4</span>, <span class="hljs-number">9</span>]])<br></code></pre></td></tr></table></figure><h5 id="多维索引的使用">5）多维索引的使用</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python">data = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<br><span class="hljs-built_in">print</span>(data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[[<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>             [<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>],<br>             [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>],<br>             [<span class="hljs-number">7</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">9</span>, <span class="hljs-number">9</span>]],<br><br>            [[<span class="hljs-number">9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>             [<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">6</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>             [<span class="hljs-number">6</span>, <span class="hljs-number">9</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br>             [<span class="hljs-number">9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>]],<br><br>            [[<span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>],<br>             [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>],<br>             [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>],<br>             [<span class="hljs-number">9</span>, <span class="hljs-number">6</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>]]])<br><br><span class="hljs-comment"># 获取0轴上的第一个数据</span><br><span class="hljs-built_in">print</span>(data[<span class="hljs-number">0</span>, :, :])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>            [<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>],<br>            [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>],<br>            [<span class="hljs-number">7</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">9</span>, <span class="hljs-number">9</span>]])<br><br><span class="hljs-comment"># 获取1轴上的第一个数据</span><br><span class="hljs-built_in">print</span>(data[:, <span class="hljs-number">0</span>, :])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>],<br>            [<span class="hljs-number">9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>            [<span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br><br><span class="hljs-comment"># 获取2轴上的第一个数据</span><br><span class="hljs-built_in">print</span>(data[:, :, <span class="hljs-number">0</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>],<br>            [<span class="hljs-number">9</span>, <span class="hljs-number">8</span>, <span class="hljs-number">6</span>, <span class="hljs-number">9</span>],<br>            [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">9</span>]])<br></code></pre></td></tr></table></figure><h4 id="张量的形状操作">2. 张量的形状操作</h4><p>有重塑、堆叠、挤压和解压：</p><table><thead><tr class="header"><th style="text-align: left;">方法</th><th style="text-align: left;">单行描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">torch.reshape(input, shape)</td><td style="text-align: left;">重塑 input 到 shape（如果兼容），也可以使用 torch.Tensor.reshape()。</td></tr><tr class="even"><td style="text-align: left;">tensor.view(shape)</td><td style="text-align: left;">返回不同 shape中的原始张量视图，但与原始张量共享相同的数据。</td></tr><tr class="odd"><td style="text-align: left;">tensor.contiguous()</td><td style="text-align: left;">将张量转换到整块内存上</td></tr><tr class="even"><td style="text-align: left;">torch.stack(tensors, dim=0)</td><td style="text-align: left;">沿着新的维度（dim）连接 tensors的序列，所有 tensors 必须具有相同的大小。</td></tr><tr class="odd"><td style="text-align: left;">torch.squeeze(input)</td><td style="text-align: left;">挤压 input 以移除值为 1 的所有尺寸。</td></tr><tr class="even"><td style="text-align: left;">torch.unsqueeze(input, dim)</td><td style="text-align: left;">返回在 dim 处添加了维度值 1 的input。</td></tr><tr class="odd"><td style="text-align: left;">torch.transpose(input,dim1,dim2)</td><td style="text-align: left;">实现交换张量形状的指定维度</td></tr><tr class="even"><td style="text-align: left;">torch.permute(input, dims)</td><td style="text-align: left;">返回原始 input的视图，其尺寸被置换（重新排列）为 dims。</td></tr></tbody></table><p>深度学习模型（神经网络）都是以某种方式操纵张量。由于矩阵乘法的规则，如果形状不匹配，就会遇到错误。这些方法可帮助您确保张量的正确元素与其他张量的正确元素混合。</p><p>举例说明：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import torch<br>x = torch<span class="hljs-selector-class">.arange</span>(<span class="hljs-number">1</span>., <span class="hljs-number">8</span>.)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(x)</span></span><br>&gt;&gt;&gt; <span class="hljs-built_in">tensor</span>(<span class="hljs-selector-attr">[1., 2., 3., 4., 5., 6., 7.]</span>)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(x.shape)</span></span><br>&gt;&gt;&gt; torch<span class="hljs-selector-class">.Size</span>(<span class="hljs-selector-attr">[7]</span>)<br></code></pre></td></tr></table></figure><h5 id="reshape">1）RESHAPE</h5><p>reshape函数可以在保证张量数据不变的前提下改变数据的维度，将其转换成指定的形状。</p><p>使用 <code>torch.reshape()</code> 增加一个维度。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs lua"># 增加一个维度<br>x_reshaped = x.reshape(<span class="hljs-number">1</span>, <span class="hljs-number">7</span>)<br><span class="hljs-built_in">print</span>(x_reshaped)<br>&gt;&gt;&gt; tensor(<span class="hljs-string">[[1., 2., 3., 4., 5., 6., 7.]]</span>)<br><br><span class="hljs-built_in">print</span>(x_reshaped.shape)<br>&gt;&gt;&gt; torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">7</span>])<br></code></pre></td></tr></table></figure><p>使用 <code>torch.reshape()</code> 改变张量的形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>data = torch.tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>], [<span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>]])<br><span class="hljs-comment"># 1. 使用 shape 属性或者 size 方法都可以获得张量的形状</span><br><span class="hljs-built_in">print</span>(data.shape, data.shape[<span class="hljs-number">0</span>], data.shape[<span class="hljs-number">1</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]) <span class="hljs-number">2</span> <span class="hljs-number">3</span><br><br><span class="hljs-built_in">print</span>(data.size(), data.size(<span class="hljs-number">0</span>), data.size(<span class="hljs-number">1</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]) <span class="hljs-number">2</span> <span class="hljs-number">3</span><br><br><span class="hljs-comment"># 2. 使用 reshape 函数修改张量形状</span><br>new_data = data.reshape(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>)<br><span class="hljs-built_in">print</span>(new_data.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6</span>])<br></code></pre></td></tr></table></figure><h5 id="view-contiguous">2）VIEW / CONTIGUOUS</h5><ul><li>view函数也可以用于修改张量的形状，只能用于<strong>存储在整块内存中的张量</strong>。</li><li>在 PyTorch中，有些张量是由不同的数据块组成的，它们并没有存储在整块的内存中，view函数无法对这样的张量进行变形处理。例如: 一个张量经过了 transpose 或者permute 函数的处理之后，就无法使用 view 函数进行形状操作。</li><li>此时需要先<strong>使用 contiguous函数转换为整块内存的张量</strong>，再使用 view 函数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1 一个张量经过了 transpose 或者 permute 函数的处理之后，就无法使用 view 函数进行形状操作</span><br><span class="hljs-comment">#   若要使用view函数, 需要使用contiguous() 变成连续以后再使用view函数</span><br><span class="hljs-comment"># 2 判断张量是否使用整块内存</span><br>data = torch.tensor( [[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>],[<span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;data---&gt;&#x27;</span>, data, data.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>data---&gt; tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>],<br>                     [<span class="hljs-number">40</span>, <span class="hljs-number">50</span>, <span class="hljs-number">60</span>]]) torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-comment"># 1 判断是否使用整块内存</span><br><span class="hljs-built_in">print</span>(data.is_contiguous())<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-literal">True</span><br><br><span class="hljs-comment"># 2 view</span><br>mydata2 = data.view(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata2---&gt;&#x27;</span>, mydata2, mydata2.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata2---&gt; tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">20</span>],<br>                        [<span class="hljs-number">30</span>, <span class="hljs-number">40</span>],<br>                        [<span class="hljs-number">50</span>, <span class="hljs-number">60</span>]]) torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>])<br><br><span class="hljs-comment"># 3 判断是否使用整块</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata2.is_contiguous()---&gt;&#x27;</span>, mydata2.is_contiguous())<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata2.is_contiguous()---&gt; <span class="hljs-literal">True</span><br><br><br><span class="hljs-comment"># 4 使用 transpose 函数修改形状</span><br>mydata3 = torch.transpose(data, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata3---&gt;&#x27;</span>, mydata3, mydata3.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata3---&gt; tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">40</span>],<br>                        [<span class="hljs-number">20</span>, <span class="hljs-number">50</span>],<br>                        [<span class="hljs-number">30</span>, <span class="hljs-number">60</span>]]) torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata3.is_contiguous()---&gt;&#x27;</span>, mydata3.is_contiguous())<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata3.is_contiguous()---&gt; <span class="hljs-literal">False</span><br><br><span class="hljs-comment"># 5 需要先使用 contiguous 函数转换为整块内存的张量，再使用 view 函数</span><br><span class="hljs-built_in">print</span> (mydata3.contiguous().is_contiguous())<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-literal">True</span><br><br>mydata4 = mydata3.contiguous().view(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata4---&gt;&#x27;</span>, mydata4.shape, mydata4)<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata4---&gt; torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]) tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">40</span>, <span class="hljs-number">20</span>],<br>                                           [<span class="hljs-number">50</span>, <span class="hljs-number">30</span>, <span class="hljs-number">60</span>]])<br></code></pre></td></tr></table></figure><h5 id="stack">3）STACK</h5><p>如果想将新张量堆叠五次，使用 <code>torch.stack()</code> 来实现。</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs inform7"># Stack tensors on top <span class="hljs-keyword">of</span> each other<br>x_stacked = torch.stack(<span class="hljs-comment">[x, x, x, x]</span>, dim=0) # 同pandas的axis，按行堆叠<br>&gt;&gt;&gt;tensor(<span class="hljs-comment">[<span class="hljs-comment">[5., 2., 3., 4., 5., 6., 7.]</span>,</span><br><span class="hljs-comment">           <span class="hljs-comment">[5., 2., 3., 4., 5., 6., 7.]</span>,</span><br><span class="hljs-comment">           <span class="hljs-comment">[5., 2., 3., 4., 5., 6., 7.]</span>,</span><br><span class="hljs-comment">           <span class="hljs-comment">[5., 2., 3., 4., 5., 6., 7.]</span>]</span>)<br></code></pre></td></tr></table></figure><h5 id="squeeze-unsqueeze">4）SQUEEZE / UNSQUEEZE</h5><p>squeeze 函数删除形状为 1 的维度（降维），unsqueeze函数添加形状为1的维度（升维）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python">mydata1 = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>])             <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata1---&gt;&#x27;</span>, mydata1.shape, mydata1) <span class="hljs-comment"># 一个普通的数组 1维数据</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata1---&gt; torch.Size([<span class="hljs-number">5</span>]) tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<br><br>mydata2 = mydata1.unsqueeze(dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;在0维度上 拓展维度：&#x27;</span>, mydata2, mydata2.shape)  <span class="hljs-comment">#1*5</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>在<span class="hljs-number">0</span>维度上 拓展维度： tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]]) torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">5</span>])<br><br>mydata3 = mydata1.unsqueeze(dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;在1维度上 拓展维度：&#x27;</span>, mydata3, mydata3.shape)  <span class="hljs-comment">#5*1</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>在<span class="hljs-number">1</span>维度上 拓展维度： tensor([[<span class="hljs-number">1</span>],<br>                              [<span class="hljs-number">2</span>],<br>                              [<span class="hljs-number">3</span>],<br>                              [<span class="hljs-number">4</span>],<br>                              [<span class="hljs-number">5</span>]]) torch.Size([<span class="hljs-number">5</span>, <span class="hljs-number">1</span>])<br><br><br>mydata4 = mydata1.unsqueeze(dim=-<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;在-1维度上 拓展维度：&#x27;</span>, mydata4, mydata4.shape) <span class="hljs-comment">#5*1</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>在-<span class="hljs-number">1</span>维度上 拓展维度： tensor([[<span class="hljs-number">1</span>],<br>                               [<span class="hljs-number">2</span>],<br>                               [<span class="hljs-number">3</span>],<br>                               [<span class="hljs-number">4</span>],<br>                               [<span class="hljs-number">5</span>]]) torch.Size([<span class="hljs-number">5</span>, <span class="hljs-number">1</span>])<br><br>mydata5 = mydata4.squeeze()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;压缩维度：&#x27;</span>, mydata5, mydata5.shape)  <span class="hljs-comment">#1*5</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>压缩维度： tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]) torch.Size([<span class="hljs-number">5</span>])<br></code></pre></td></tr></table></figure><h5 id="transpose-permute">5）TRANSPOSE/ PERMUTE</h5><p>transpose 函数可以实现交换张量形状的指定维度, 例如: 一个张量的形状为(2, 3, 4) 可以通过 transpose 函数把 3 和 4 进行交换, 将张量的形状变为(2, 4, 3) 。 permute 函数可以一次交换更多的维度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">data = torch.tensor(np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;data shape:&#x27;</span>, data.size())<br><span class="hljs-meta">&gt;&gt;&gt; </span>data shape: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<br><br><span class="hljs-comment"># 1 交换1和2维度</span><br>mydata2 = torch.transpose(data, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata2.shape---&gt;&#x27;</span>, mydata2.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata2.shape---&gt; torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>])<br><br><span class="hljs-comment"># 2 将data 的形状修改为 (4, 5, 3), 需要变换多次</span><br>mydata3 =  torch.transpose(data, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>mydata4 = torch.transpose(mydata3, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata4.shape---&gt;&#x27;</span>, mydata4.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata4.shape---&gt; torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-comment"># 3 使用 permute 函数将形状修改为 (4, 5, 3)</span><br><span class="hljs-comment"># 3-1 方法1</span><br>mydata5 = torch.permute(data, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata5.shape---&gt;&#x27;</span>, mydata5.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata5.shape---&gt; torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-comment"># 3-2 方法2</span><br>mydata6 = data.permute([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;mydata6.shape---&gt;&#x27;</span>, mydata6.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>mydata6.shape---&gt; torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure><h5 id="总结">6）总结</h5><p>&lt;1&gt; reshape函数可以在保证张量数据不变的前提下改变数据的维度</p><p>&lt;2&gt; squeeze 和 unsqueeze 函数可以用来增加或者减少维度</p><p>&lt;3&gt; transpose 函数可以实现交换张量形状的指定维度, permute可以一次交换更多的维度</p><p>&lt;4&gt; view 函数也可以用于修改张量的形状,但是它要求被转换的张量内存必须连续，所以一般配合 contiguous 函数使用</p><h4 id="张量的拼接操作">3. 张量的拼接操作</h4><ul><li>torch.cat()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>data1 = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br>data2 = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><span class="hljs-built_in">print</span>(data1)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">7</span>],<br>         [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>]]])<br><br><br><br><span class="hljs-built_in">print</span>(data2)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[[<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>],<br>         [<span class="hljs-number">7</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>]]])<br><br><br><span class="hljs-comment"># 1. 按0维度拼接</span><br>new_data = torch.cat([data1, data2], dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(new_data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">7</span>],<br>             [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>]],<br><br>            [[<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>],<br>             [<span class="hljs-number">7</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>]]])<br><br><span class="hljs-built_in">print</span>(new_data.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-comment"># 2. 按1维度拼接</span><br>new_data = torch.cat([data1, data2], dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(new_data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">7</span>],<br>             [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>],<br>             [<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>],<br>             [<span class="hljs-number">7</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>]]])<br><br><span class="hljs-built_in">print</span>(new_data.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-comment"># 3. 按2维度拼接</span><br>new_data = torch.cat([data1, data2], dim=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(new_data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[[<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">7</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>],<br>             [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>]]])<br><br><span class="hljs-built_in">print</span>(new_data.shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>张量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tensor基础2——张量的计算</title>
    <link href="/Tensor%E5%9F%BA%E7%A1%802--%E5%BC%A0%E9%87%8F%E7%9A%84%E8%AE%A1%E7%AE%97.html"/>
    <url>/Tensor%E5%9F%BA%E7%A1%802--%E5%BC%A0%E9%87%8F%E7%9A%84%E8%AE%A1%E7%AE%97.html</url>
    
    <content type="html"><![CDATA[<h4 id="张量的数值计算">1. 张量的数值计算</h4><h5 id="张量基本运算">1）张量基本运算</h5><ul><li>加减乘除取负号：</li><li>add、sub、mul、div、neg</li><li>add_（其中带下划线的版本会修改原数据）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python">data = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<br><span class="hljs-built_in">print</span>(data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">3</span>, <span class="hljs-number">7</span>, <span class="hljs-number">4</span>],<br>            [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">6</span>]])<br><br><span class="hljs-comment"># 1. 不修改原数据</span><br>new_data = data.add(<span class="hljs-number">10</span>)  <span class="hljs-comment"># 等价 new_data = data + 10</span><br><span class="hljs-built_in">print</span>(new_data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">13</span>, <span class="hljs-number">17</span>, <span class="hljs-number">14</span>],<br>            [<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">16</span>]])<br><br><span class="hljs-comment"># 2. 直接修改原数据 注意: 带下划线的函数为修改原数据本身</span><br>data.add_(<span class="hljs-number">10</span>)  <span class="hljs-comment"># 等价 data += 10</span><br><span class="hljs-built_in">print</span>(data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">13</span>, <span class="hljs-number">17</span>, <span class="hljs-number">14</span>],<br>            [<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">16</span>]])<br><br><span class="hljs-comment"># 3. 其他函数</span><br><span class="hljs-built_in">print</span>(data.sub(<span class="hljs-number">100</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[-<span class="hljs-number">87</span>, -<span class="hljs-number">83</span>, -<span class="hljs-number">86</span>],<br>            [-<span class="hljs-number">90</span>, -<span class="hljs-number">90</span>, -<span class="hljs-number">84</span>]])<br><br><span class="hljs-built_in">print</span>(data.mul(<span class="hljs-number">100</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">1300</span>, <span class="hljs-number">1700</span>, <span class="hljs-number">1400</span>],<br>            [<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">1600</span>]])<br><br><span class="hljs-built_in">print</span>(data.div(<span class="hljs-number">100</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">0.1300</span>, <span class="hljs-number">0.1700</span>, <span class="hljs-number">0.1400</span>],<br>            [<span class="hljs-number">0.1000</span>, <span class="hljs-number">0.1000</span>, <span class="hljs-number">0.1600</span>]])<br><br><span class="hljs-built_in">print</span>(data.neg())<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[-<span class="hljs-number">13</span>, -<span class="hljs-number">17</span>, -<span class="hljs-number">14</span>],<br>            [-<span class="hljs-number">10</span>, -<span class="hljs-number">10</span>, -<span class="hljs-number">16</span>]])<br></code></pre></td></tr></table></figure><h5 id="张量点乘运算">2）张量点乘运算</h5><ul><li>点乘指（Hadamard）的是两个同维矩阵对应位置的元素相乘，使用mul和运算符 * 实现。</li></ul><figure><img src="assets/image-20240528102236446.png"alt="image-20240528102236446" /><figcaption aria-hidden="true">image-20240528102236446</figcaption></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs lua">data1 = torch.tensor(<span class="hljs-string">[[1, 2], [3, 4]]</span>)<br>data2 = torch.tensor(<span class="hljs-string">[[5, 6], [7, 8]]</span>)<br># 第一种方式<br>data = torch.mul(data1, data2)<br><span class="hljs-built_in">print</span>(data)<br>&gt;&gt;&gt; tensor(<span class="hljs-string">[[ 5, 12],</span><br><span class="hljs-string">            [21, 32]]</span>)<br><br># 第二种方式<br>data = data1 * data2<br><span class="hljs-built_in">print</span>(data)<br>&gt;&gt;&gt; tensor(<span class="hljs-string">[[ 5, 12],</span><br><span class="hljs-string">            [21, 32]]</span>)<br></code></pre></td></tr></table></figure><h5 id="张量矩阵乘法运算">3）张量矩阵乘法运算</h5><ul><li>矩阵乘法运算要求第一个矩阵 shape: (n, m)，第二个矩阵 shape: (m, p),两个矩阵点积运算 shape 为: (n, p)。</li><li>运算符 @ 用于进行两个矩阵的乘积运算</li><li>torch.matmul 对进行乘积运算的两矩阵形状没有限定.对数输入的 shape不同的张量, 对应的最后几个维度必须符合矩阵运算规则</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 点积运算</span><br>data1 = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br>data2 = torch.tensor([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br><span class="hljs-comment"># 方式一:</span><br>data3 = data1 @ data2<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;data3--&gt;&quot;</span>, data3)<br><span class="hljs-meta">&gt;&gt;&gt; </span>data3--&gt; tensor([[<span class="hljs-number">19</span>, <span class="hljs-number">22</span>],<br>                     [<span class="hljs-number">43</span>, <span class="hljs-number">50</span>],<br>                     [<span class="hljs-number">67</span>, <span class="hljs-number">78</span>]])<br><br><span class="hljs-comment"># 方式二:</span><br>data4 = torch.matmul(data1, data2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;data4--&gt;&quot;</span>, data4)<br><span class="hljs-meta">&gt;&gt;&gt; </span>data4--&gt; tensor([[<span class="hljs-number">19</span>, <span class="hljs-number">22</span>],<br>                     [<span class="hljs-number">43</span>, <span class="hljs-number">50</span>],<br>                     [<span class="hljs-number">67</span>, <span class="hljs-number">78</span>]])<br></code></pre></td></tr></table></figure><h5 id="总结">4）总结</h5><p><strong>&lt;1&gt; 张量基本运算函数</strong></p><ul><li>add、sub、mul、div、neg等函数</li><li>add_、sub_、mul_、div_、neg_等函数</li></ul><p><strong>&lt;2&gt; 张量的点乘运算</strong></p><ul><li>mul 和运算符 *</li></ul><p><strong>&lt;3&gt; 点积运算</strong></p><ul><li>运算符@用于进行两个矩阵的点乘运算</li><li>torch.matmul 对进行点乘运算的两矩阵形状没有限定，对数输入的 shape不同的张量, 对应的最后几个维度必须符合矩阵运算规则</li></ul><h4 id="张量的运算函数">2. 张量的运算函数</h4><p>PyTorch 为每个张量封装很多实用的计算函数：</p><ul><li>均值</li><li>平方根</li><li>求和</li><li>指数计算</li><li>对数计算等等</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>data = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], dtype=torch.float64)<br><span class="hljs-built_in">print</span>(data)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">4.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">7.</span>],<br>            [<span class="hljs-number">6.</span>, <span class="hljs-number">3.</span>, <span class="hljs-number">5.</span>]], dtype=torch.float64)<br><br><span class="hljs-comment"># 1. 计算均值</span><br><span class="hljs-comment"># 注意: tensor 必须为 Float 或者 Double 类型</span><br><span class="hljs-built_in">print</span>(data.mean())<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor(<span class="hljs-number">4.1667</span>, dtype=torch.float64)<br><br><span class="hljs-built_in">print</span>(data.mean(dim=<span class="hljs-number">0</span>))  <span class="hljs-comment"># 按列计算均值</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">5.0000</span>, <span class="hljs-number">1.5000</span>, <span class="hljs-number">6.0000</span>], dtype=torch.float64)<br><br><span class="hljs-built_in">print</span>(data.mean(dim=<span class="hljs-number">1</span>))  <span class="hljs-comment"># 按行计算均值</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">3.6667</span>, <span class="hljs-number">4.6667</span>], dtype=torch.float64)<br><br><span class="hljs-comment"># 2. 计算总和</span><br><span class="hljs-built_in">print</span>(data.<span class="hljs-built_in">sum</span>())<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor(<span class="hljs-number">25.</span>, dtype=torch.float64)<br><br><span class="hljs-built_in">print</span>(data.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">0</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">10.</span>,  <span class="hljs-number">3.</span>, <span class="hljs-number">12.</span>], dtype=torch.float64)<br><br><span class="hljs-built_in">print</span>(data.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">11.</span>, <span class="hljs-number">14.</span>], dtype=torch.float64)<br><br><span class="hljs-comment"># 3. 计算平方</span><br><span class="hljs-built_in">print</span>(torch.<span class="hljs-built_in">pow</span>(data，<span class="hljs-number">2</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">16.</span>,  <span class="hljs-number">0.</span>, <span class="hljs-number">49.</span>],<br>            [<span class="hljs-number">36.</span>,  <span class="hljs-number">9.</span>, <span class="hljs-number">25.</span>]], dtype=torch.float64)<br><br><span class="hljs-comment"># 4. 计算平方根</span><br><span class="hljs-built_in">print</span>(data.sqrt())<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">2.0000</span>, <span class="hljs-number">0.0000</span>, <span class="hljs-number">2.6458</span>],<br>            [<span class="hljs-number">2.4495</span>, <span class="hljs-number">1.7321</span>, <span class="hljs-number">2.2361</span>]], dtype=torch.float64)<br><br><span class="hljs-comment"># 5. 指数计算, e^n 次方</span><br><span class="hljs-built_in">print</span>(data.exp())<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">5.4598e+01</span>, <span class="hljs-number">1.0000e+00</span>, <span class="hljs-number">1.0966e+03</span>],<br>            [<span class="hljs-number">4.0343e+02</span>, <span class="hljs-number">2.0086e+01</span>, <span class="hljs-number">1.4841e+02</span>]], dtype=torch.float64)<br><br><span class="hljs-comment"># 6. 对数计算</span><br><span class="hljs-built_in">print</span>(data.log())  <span class="hljs-comment"># 以 e 为底</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">1.3863</span>,   -inf, <span class="hljs-number">1.9459</span>],<br>            [<span class="hljs-number">1.7918</span>, <span class="hljs-number">1.0986</span>, <span class="hljs-number">1.6094</span>]], dtype=torch.float64)<br><br><span class="hljs-built_in">print</span>(data.log2())<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">2.0000</span>,   -inf, <span class="hljs-number">2.8074</span>],<br>            [<span class="hljs-number">2.5850</span>, <span class="hljs-number">1.5850</span>, <span class="hljs-number">2.3219</span>]], dtype=torch.float64)<br><br><span class="hljs-built_in">print</span>(data.log10())<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">0.6021</span>,   -inf, <span class="hljs-number">0.8451</span>],<br>            [<span class="hljs-number">0.7782</span>, <span class="hljs-number">0.4771</span>, <span class="hljs-number">0.6990</span>]], dtype=torch.float64)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>张量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ROC曲线原理及绘制</title>
    <link href="/ROC%E6%9B%B2%E7%BA%BF%E7%BB%98%E5%88%B6.html"/>
    <url>/ROC%E6%9B%B2%E7%BA%BF%E7%BB%98%E5%88%B6.html</url>
    
    <content type="html"><![CDATA[<p>ROC曲线（Receiver Operating CharacteristicCurve）是一种用于评价二分类模型性能的图形工具。它展示了模型在不同阈值下的分类性能，通过绘制假阳性率（FPR）和真阳性率（TPR）之间的关系来表现。</p><span id="more"></span><h3 id="混淆矩阵">1.混淆矩阵</h3><p><strong>混淆矩阵</strong>是对<strong>预测正例</strong>样本的进一步分析,而<strong>准确率</strong>是综合了正例与反例的比例.</p><table><thead><tr class="header"><th></th><th>预测值</th><th>预测值</th><th></th></tr></thead><tbody><tr class="odd"><td></td><td><strong>正例</strong> (positive)</td><td><strong>假例</strong> (negtive)</td><td></td></tr><tr class="even"><td><strong>真实正例</strong></td><td>真正例TP</td><td><strong>伪反例</strong>FN</td><td>TPR=TP/真实正例</td></tr><tr class="odd"><td><strong>真实假例</strong></td><td><strong>伪正例</strong> FP</td><td>真反例TN</td><td>FPR=FP/真实假例</td></tr></tbody></table><h3 id="roc曲线的含义">2.ROC曲线的含义</h3><p>ROC曲线（Receiver Operating CharacteristicCurve）是一种用于评价二分类模型性能的图形工具。它展示了模型在不同阈值下的分类性能，通过绘制假阳性率（FPR）和真阳性率（TPR）之间的关系来表现。</p><ul><li><p><strong>真阳性率（TPR, True PositiveRate）</strong>：也称为灵敏度（sensitivity）或召回率（recall），表示真正被分类为正类的比例。公式为：<span class="math display">\[\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}\]</span></p></li><li><p><strong>假阳性率（FPR, False PositiveRate）</strong>：表示被错误分类为正类的负类样本比例。公式为： <spanclass="math display">\[\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}\]</span></p></li></ul><h3 id="roc曲线的绘制步骤">3.ROC曲线的绘制步骤</h3><ol type="1"><li><strong>计算预测概率</strong>：使用二分类模型对数据进行预测，得到每个样本属于正类的概率。</li><li><strong>确定阈值</strong>：从0到1选择一系列阈值，对每个阈值进行如下操作：<ul><li>将预测概率与当前阈值比较，得到分类结果（大于等于阈值为正类，小于阈值为负类）。</li><li>计算对应的TPR和FPR。</li></ul></li><li><strong>绘制曲线</strong>：以FPR为横坐标，TPR为纵坐标，绘制曲线。</li></ol><h3 id="实例说明">4.实例说明</h3><p>假设有一个简单的二分类问题，以下是一些预测结果及对应的实际标签：</p><table><thead><tr class="header"><th>实际标签</th><th>预测概率</th></tr></thead><tbody><tr class="odd"><td>1</td><td>0.9</td></tr><tr class="even"><td>0</td><td>0.8</td></tr><tr class="odd"><td>1</td><td>0.7</td></tr><tr class="even"><td>1</td><td>0.6</td></tr><tr class="odd"><td>0</td><td>0.4</td></tr><tr class="even"><td>1</td><td>0.3</td></tr><tr class="odd"><td>0</td><td>0.2</td></tr><tr class="even"><td>0</td><td>0.1</td></tr></tbody></table><p>我们使用这些数据来绘制ROC曲线。</p><h4 id="步骤1计算tpr和fpr">步骤1：计算TPR和FPR</h4><p>我们选择几个阈值来计算TPR和FPR：</p><ul><li>阈值 = 0.9</li><li>阈值 = 0.7</li><li>阈值 = 0.5</li><li>阈值 = 0.3</li><li>阈值 = 0.1</li></ul><p>对于每个阈值，计算TPR和FPR：</p><ol type="1"><li><p><strong>阈值 = 0.9</strong>:</p><ul><li>预测结果：1 0 0 0 0 0 0 0</li><li>TPR = 1/4 = 0.25</li><li>FPR = 0/4 = 0</li></ul></li><li><p><strong>阈值 = 0.7</strong>:</p><ul><li>预测结果：1 1 1 0 0 0 0 0</li><li>TPR = 2/4 = 0.5</li><li>FPR = 1/4 = 0.25</li></ul></li><li><p><strong>阈值 = 0.4</strong>:</p><ul><li>预测结果：1 1 1 1 1 0 0 0</li><li>TPR = 3/4 = 0.75</li><li>FPR = 2/4 = 0.5</li></ul></li><li><p><strong>阈值 = 0.3</strong>:</p><ul><li>预测结果：1 1 1 1 1 1 0 0</li><li>TPR = 4/4 = 1</li><li>FPR = 2/4 = 0.5</li></ul></li><li><p><strong>阈值 = 0.2</strong>:</p><ul><li>预测结果：1 1 1 1 1 1 1 0</li><li>TPR = 4/4 = 1</li><li>FPR = 3/4 = 0.75</li></ul><p><img src="/images/roc/image-20240526220530303.png" /></p></li></ol><h4 id="python绘制曲线">5.python绘制曲线</h4><p>我们将这些TPR和FPR值在图上绘制出来，得到ROC曲线。</p><p>下面用Python代码实现绘制ROC曲线：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve<br><br><span class="hljs-comment"># 实际标签</span><br>y_true = [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># 预测概率</span><br>y_scores = [<span class="hljs-number">0.9</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.1</span>]<br><br><span class="hljs-comment"># 计算FPR和TPR</span><br>fpr, tpr, thresholds = roc_curve(y_true, y_scores)<br><br><span class="hljs-comment"># 绘制ROC曲线</span><br>plt.figure()<br>plt.plot(fpr, tpr, marker=<span class="hljs-string">&#x27;o&#x27;</span>)<br>plt.plot([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], linestyle=<span class="hljs-string">&#x27;--&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;False Positive Rate&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;True Positive Rate&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;ROC Curve&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>这段代码将绘制出对应的数据的ROC曲线。ROC曲线越靠近左上角，表示模型性能越好。曲线下面积（AUC,Area Under theCurve）可以用来量化模型的整体性能，AUC值越大表示模型性能越好。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ROC曲线</tag>
      
      <tag>模型评估</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tensor基础1——张量的创建与转换</title>
    <link href="/Tensor%E5%9F%BA%E7%A1%801-%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%BD%AC%E6%8D%A2.html"/>
    <url>/Tensor%E5%9F%BA%E7%A1%801-%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%BD%AC%E6%8D%A2.html</url>
    
    <content type="html"><![CDATA[<h4 id="张量的创建">1. 张量的创建</h4><h5 id="张量的基本创建方式">1）张量的基本创建方式</h5><ul><li>torch.tensor 根据指定数据创建张量</li><li>torch.Tensor 根据形状创建张量, 其也可用来创建指定数据的张量</li><li>torch.IntTensor、torch.FloatTensor、torch.DoubleTensor创建指定类型的张量</li></ul><p><strong>1、torch.tensor() 根据指定数据创建张量</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-meta"># 1. 创建张量标量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.tensor(10)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor(<span class="hljs-number">10</span>)<br><br><span class="hljs-meta"># 2. numpy 数组, 由于 data 为 float64, 下面代码也使用该类型</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = np.random.randn(2, 3)</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.tensor(<span class="hljs-title">data</span>)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[ <span class="hljs-number">0.1345</span>,  <span class="hljs-number">0.1149</span>,  <span class="hljs-number">0.2435</span>],<br>            [ <span class="hljs-number">0.8026</span>, -<span class="hljs-number">0.6744</span>, -<span class="hljs-number">1.0918</span>]], dtype=torch.float64)<br><br><span class="hljs-meta"># 3. 列表, 下面代码使用默认元素类型 float32</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = [[10., 20., 30.], [40., 50., 60.]]</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.tensor(<span class="hljs-title">data</span>)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">10</span>., <span class="hljs-number">20</span>., <span class="hljs-number">30</span>.],<br>            [<span class="hljs-number">40</span>., <span class="hljs-number">50</span>., <span class="hljs-number">60</span>.]])<br></code></pre></td></tr></table></figure><p><strong>2、torch.Tensor()根据指定形状创建张量，也可以用来创建指定数据的张量</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 1. 创建2行3列的张量, 默认 dtype 为 float32</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">Tensor</span>(2, 3)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">0.0000e+00</span>, <span class="hljs-number">3.6893e+19</span>, <span class="hljs-number">2.2018e+05</span>],<br>            [<span class="hljs-number">4.6577e-10</span>, <span class="hljs-number">2.4158e-12</span>, <span class="hljs-number">1.1625e+33</span>]])<br><br><span class="hljs-meta"># 2. 注意: 如果传递列表, 则创建包含指定元素的张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">Tensor</span>([10])</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([<span class="hljs-number">10</span>.])<br><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">Tensor</span>([10, 20])</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([<span class="hljs-number">10</span>., <span class="hljs-number">20</span>.])<br></code></pre></td></tr></table></figure><p><strong>3、torch.IntTensor()、torch.FloatTensor()、torch.DoubleTensor()创建指定类型的张量</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 1. 创建2行3列, dtype 为 int32 的张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">IntTensor</span>(2, 3)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[ <span class="hljs-number">0</span>, <span class="hljs-number">1610612736</span>, <span class="hljs-number">1213662609</span>],<br>            [ <span class="hljs-number">805308409</span>,  <span class="hljs-number">156041223</span>,  <span class="hljs-number">1</span>]], dtype=torch.int32)<br><br><span class="hljs-meta"># 2. 注意: 如果传递的元素类型不正确, 则会进行类型转换</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">IntTensor</span>([2.5, 3.3])</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], dtype=torch.int32)<br><br><span class="hljs-meta"># 3. 其他的类型</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">ShortTensor</span>()  # int16</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">LongTensor</span>()   # int64</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">FloatTensor</span>()  # float32</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.<span class="hljs-type">DoubleTensor</span>() # float64</span><br></code></pre></td></tr></table></figure><h5 id="创建线性张量和随机张量">2）创建线性张量和随机张量</h5><ul><li>torch.arange 和 torch.linspace 创建线性张量</li><li>torch.random.init_seed 和 torch.random.manual_seed 随机种子设置</li><li>torch.randn 创建随机张量</li></ul><p><strong>1、torch.arange()、torch.linspace() 创建线性张量</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 1. 在指定区间按照步长生成元素 [start, end, step)</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.arange(0, 10, 2)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">8</span>])<br><br><span class="hljs-meta"># 2. 在指定区间按照元素个数生成 [start, end, steps]</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.linspace(0, 11, 10)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([<span class="hljs-number">0.0000</span>, <span class="hljs-number">1.2222</span>, <span class="hljs-number">2.4444</span>, <span class="hljs-number">3.6667</span>, <span class="hljs-number">4.8889</span>, <span class="hljs-number">6.1111</span>, <span class="hljs-number">7.3333</span>, <span class="hljs-number">8.5556</span>, <span class="hljs-number">9.7778</span>,                     <span class="hljs-number">11.0000</span>])<br></code></pre></td></tr></table></figure><p><strong>2、随机种子操作</strong></p><ul><li>torch.random.initial_seed()查看随机种子</li><li>torch.random.manual_seed() 设置随机数种子</li><li>torch.randn() 创建随机张量</li></ul><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs lua"># <span class="hljs-number">1.</span> 创建随机张量<br>data = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)  # 创建<span class="hljs-number">2</span>行<span class="hljs-number">3</span>列张量<br><span class="hljs-built_in">print</span>(data)<br>&gt;&gt;&gt; tensor(<span class="hljs-string">[[-0.5209, -0.2439, -1.1780],</span><br><span class="hljs-string">            [ 0.8133,  1.1442,  0.6790]]</span>)<br><br># <span class="hljs-number">2.</span>查看随机数种子<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;随机数种子:&#x27;</span>, torch.<span class="hljs-built_in">random</span>.initial_seed())<br>&gt;&gt;&gt; 随机数种子: <span class="hljs-number">4508475192273306739</span><br><br># <span class="hljs-number">3.</span>设置随机数种子 <br>torch.<span class="hljs-built_in">random</span>.manual_seed(<span class="hljs-number">100</span>)<br>data = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;随机数种子:&#x27;</span>, torch.<span class="hljs-built_in">random</span>.initial_seed())<br>&gt;&gt;&gt; tensor(<span class="hljs-string">[[ 0.3607, -0.2859, -0.3938],</span><br><span class="hljs-string">            [ 0.2429, -1.3833, -2.3134]]</span>)<br>    随机数种子: <span class="hljs-number">100</span><br></code></pre></td></tr></table></figure><h5 id="创建0-1张量">3）创建0-1张量</h5><ul><li>torch.ones 和 torch.ones_like 创建全1张量</li><li>torch.zeros 和 torch.zeros_like 创建全0张量</li><li>torch.full 和 torch.full_like 创建全为指定值张量</li></ul><p><strong>1、torch.ones()、torch.ones_like() 创建全1张量</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 1. 创建指定形状全0张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.zeros(2, 3)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">0</span>., <span class="hljs-number">0</span>., <span class="hljs-number">0</span>.],<br>            [<span class="hljs-number">0</span>., <span class="hljs-number">0</span>., <span class="hljs-number">0</span>.]])<br><br><span class="hljs-meta"># 2. 根据张量形状创建全0张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.zeros_like(<span class="hljs-title">data</span>)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">0</span>., <span class="hljs-number">0</span>., <span class="hljs-number">0</span>.],<br>            [<span class="hljs-number">0</span>., <span class="hljs-number">0</span>., <span class="hljs-number">0</span>.]])<br></code></pre></td></tr></table></figure><p><strong>2、torch.zeros()、torch.zeros_like() 创建全0张量</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 1. 创建指定形状全1张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.ones(2, 3)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">1</span>., <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>            [<span class="hljs-number">1</span>., <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.]])<br><br><span class="hljs-meta"># 2. 根据张量形状创建全1张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.ones_like(<span class="hljs-title">data</span>)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">1</span>., <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.],<br>            [<span class="hljs-number">1</span>., <span class="hljs-number">1</span>., <span class="hljs-number">1</span>.]])<br></code></pre></td></tr></table></figure><p><strong>3、torch.full()、torch.full_like()创建全为指定值张量</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 1. 创建指定形状指定值的张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.full([2, 3], 10)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>],<br>            [<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>]])<br><br><span class="hljs-meta"># 2. 根据张量形状创建指定值的张量</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.full_like(<span class="hljs-title">data</span>, 20)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>&gt;&gt;&gt; tensor([[<span class="hljs-number">20</span>, <span class="hljs-number">20</span>, <span class="hljs-number">20</span>],<br>            [<span class="hljs-number">20</span>, <span class="hljs-number">20</span>, <span class="hljs-number">20</span>]])<br></code></pre></td></tr></table></figure><h5 id="张量元素类型转换">4）张量元素类型转换</h5><ul><li>data.type(torch.DoubleTensor)</li><li>data.double()</li></ul><p><strong>1、data.type(torch.DoubleTensor)</strong></p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">data</span> = torch.full([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], <span class="hljs-number">10</span>)<br><span class="hljs-title">print</span>(data.d<span class="hljs-keyword">type</span>)<br>&gt;&gt;&gt; torch.int64<br><br># 将 data 元素类型转换为 float64 类型<br><span class="hljs-title">data</span> = data.<span class="hljs-keyword">type</span>(torch.<span class="hljs-type">DoubleTensor</span>)<br><span class="hljs-title">print</span>(data.d<span class="hljs-keyword">type</span>)<br>&gt;&gt;&gt; torch.float64<br><br># 转换为其他类型<br># data = data.<span class="hljs-keyword">type</span>(torch.<span class="hljs-type">ShortTensor</span>)   # int16<br># data = data.<span class="hljs-keyword">type</span>(torch.<span class="hljs-type">IntTensor</span>)    # int32<br># data = data.<span class="hljs-keyword">type</span>(torch.<span class="hljs-type">LongTensor</span>)   # int64<br># data = data.<span class="hljs-keyword">type</span>(torch.<span class="hljs-type">FloatTensor</span>)  # float32<br></code></pre></td></tr></table></figure><p><strong>2、data.double()</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.full([2, 3], 10)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>.dtype)</span><br>&gt;&gt;&gt; torch.int64<br><br><span class="hljs-meta"># 将 data 元素类型转换为 float64 类型</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = <span class="hljs-keyword">data</span>.double()</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>.dtype)</span><br>&gt;&gt;&gt; torch.float64<br><br><span class="hljs-meta"># 转换为其他类型</span><br><span class="hljs-meta"># data = data.short()</span><br><span class="hljs-meta"># data = data.int()</span><br><span class="hljs-meta"># data = data.long()</span><br><span class="hljs-meta"># data = data.float()</span><br></code></pre></td></tr></table></figure><h5 id="总结">5）总结</h5><p><strong>&lt;1&gt; 创建张量的方式</strong></p><ul><li>torch.tensor() 根据指定数据创建张量</li><li>torch.Tensor() 根据形状创建张量, 其也可用来创建指定数据的张量</li><li>torch.IntTensor()、torch.FloatTensor()、torch.DoubleTensor()创建指定类型的张量</li></ul><p><strong>&lt;2&gt; 创建线性和随机张量</strong></p><ul><li>torch.arrange() 和 torch.linspace() 创建线性张量</li><li>torch.random.initial_seed() 和 torch.random.manual_seed()随机种子设置</li><li>torch.randn() 创建随机张量</li></ul><p><strong>&lt;3&gt; 创建01张量</strong></p><ul><li>torch.ones() 和 torch.ones_like() 创建全1张量</li><li>torch.zeros() 和 torch.zeros_like() 创建全0张量</li><li>torch.full() 和 torch.full_like() 创建全为指定值张量</li></ul><p><strong>&lt;4&gt; 张量元素类型转换</strong></p><ul><li>data.type(torch.DoubleTensor)</li><li>data.double()</li></ul><h4 id="张量的类型转换">2. 张量的类型转换</h4><h5 id="张量转换为numpy数组">1）张量转换为NUMPY数组</h5><ul><li>使用 Tensor.numpy 函数可以将张量转换为 ndarray数组，但是共享内存，可以使用 copy 函数避免共享。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1. 将张量转换为 numpy 数组</span><br>data_tensor = torch.tensor([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br><span class="hljs-comment"># 使用张量对象中的 numpy 函数进行转换</span><br>data_numpy = data_tensor.numpy()<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(data_tensor))<br><span class="hljs-meta">&gt;&gt;&gt; </span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;torch.Tensor&#x27;</span>&gt;<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(data_numpy))<br><span class="hljs-meta">&gt;&gt;&gt; </span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;numpy.ndarray&#x27;</span>&gt;<br><br><span class="hljs-comment"># 注意: data_tensor 和 data_numpy 共享内存</span><br><span class="hljs-comment"># 修改其中的一个，另外一个也会发生改变</span><br><span class="hljs-comment"># data_tensor[0] = 100</span><br>data_numpy[<span class="hljs-number">0</span>] = <span class="hljs-number">100</span><br><span class="hljs-built_in">print</span>(data_tensor)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">100</span>,   <span class="hljs-number">3</span>,   <span class="hljs-number">4</span>])<br><br><span class="hljs-built_in">print</span>(data_numpy)<br><span class="hljs-meta">&gt;&gt;&gt; </span>[<span class="hljs-number">100</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span>]<br><br><span class="hljs-comment"># 2. 对象拷贝避免共享内存</span><br>data_tensor = torch.tensor([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br><span class="hljs-comment"># 使用张量对象中的 numpy 函数进行转换，通过copy方法拷贝对象</span><br>data_numpy = data_tensor.numpy().copy()<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(data_tensor))<br><span class="hljs-meta">&gt;&gt;&gt; </span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;torch.Tensor&#x27;</span>&gt;<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(data_numpy))<br><span class="hljs-meta">&gt;&gt;&gt; </span>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;numpy.ndarray&#x27;</span>&gt;<br><br><span class="hljs-comment"># 注意: data_tensor 和 data_numpy 此时不共享内存</span><br><span class="hljs-comment"># 修改其中的一个，另外一个不会发生改变</span><br><span class="hljs-comment"># data_tensor[0] = 100</span><br>data_numpy[<span class="hljs-number">0</span>] = <span class="hljs-number">100</span><br><span class="hljs-built_in">print</span>(data_tensor)<br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br><br><span class="hljs-built_in">print</span>(data_numpy)<br><span class="hljs-meta">&gt;&gt;&gt; </span>[<span class="hljs-number">100</span>   <span class="hljs-number">3</span>   <span class="hljs-number">4</span>]<br></code></pre></td></tr></table></figure><h5 id="numpy数组转换为张量">2）NUMPY数组转换为张量</h5><ul><li>使用 <strong>from_numpy</strong> 可以将 ndarray 数组转换为Tensor，默认<strong>共享内存</strong>，使用 copy 函数避免共享。</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros">data_numpy = np.array([2, 3, 4])<br><span class="hljs-comment"># 将 numpy 数组转换为张量类型</span><br><span class="hljs-comment"># 1. from_numpy</span><br><span class="hljs-comment"># 2. torch.tensor(ndarray)</span><br>data_tensor = torch.from_numpy(data_numpy)<br><span class="hljs-comment"># nunpy 和 tensor 共享内存</span><br><span class="hljs-comment"># data_numpy[0] = 100</span><br>data_tensor[0] = 100<br><span class="hljs-built_in">print</span>(data_tensor)<br>&gt;&gt;&gt; tensor([100,   3,   4], <span class="hljs-attribute">dtype</span>=torch.int32)<br><br><span class="hljs-built_in">print</span>(data_numpy)<br>&gt;&gt;&gt; [100   3   4]<br></code></pre></td></tr></table></figure><ul><li>使用 <strong>torch.tensor</strong> 可以将 ndarray 数组转换为Tensor，默认<strong>不共享内存</strong>。</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs routeros">data_numpy = np.array([2, 3, 4])<br>data_tensor = torch.tensor(data_numpy)<br><span class="hljs-comment"># nunpy 和 tensor 不共享内存</span><br><span class="hljs-comment"># data_numpy[0] = 100</span><br>data_tensor[0] = 100<br><span class="hljs-built_in">print</span>(data_tensor)<br>&gt;&gt;&gt; tensor([100,   3,   4], <span class="hljs-attribute">dtype</span>=torch.int32)<br><br><span class="hljs-built_in">print</span>(data_numpy)<br>&gt;&gt;&gt; [2 3 4]<br></code></pre></td></tr></table></figure><h5 id="标量张量和数字转换">3）标量张量和数字转换</h5><ul><li>对于只有一个元素的张量，使用item()函数将该值从张量中提取出来</li></ul><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-meta"># 当张量只包含一个元素时, 可以通过 item() 函数提取出该值</span><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.tensor([30,])</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>.item())</span><br>&gt;&gt;&gt; <span class="hljs-number">30</span><br><br><span class="hljs-class"><span class="hljs-keyword">data</span> = torch.tensor(30)</span><br><span class="hljs-title">print</span>(<span class="hljs-class"><span class="hljs-keyword">data</span>.item())</span><br>&gt;&gt;&gt; <span class="hljs-number">30</span><br></code></pre></td></tr></table></figure><h5 id="总结-1">4）总结</h5><p><strong>1. 张量转换为 numpy 数组</strong></p><ul><li>data_tensor.numpy()</li><li>data_tensor.numpy().copy()</li></ul><p><strong>2. numpy 转换为张量</strong></p><ul><li>torch.from_numpy(data_numpy)</li><li>torch.tensor(data_numpy)</li></ul><p><strong>3. 标量张量和数字转换</strong></p><ul><li>data.item()</li></ul>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>张量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CatBoost简明教程</title>
    <link href="/CatBoost%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.html"/>
    <url>/CatBoost%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B.html</url>
    
    <content type="html"><![CDATA[<h2 id="一-catboost简介"><strong>一 CatBoost简介</strong></h2><p>CatBoost和XGBoost、LightGBM并称为GBDT的三大主流神器，都是在GBDT算法框架下的一种改进实现。</p><p>正如其名字所说那样，CatBoost主要是在类别特征上的处理上做了很多的改进。</p><span id="more"></span><p>从用户使用角度来看，相比XGBoost和LightGBM，CatBoost具有如下特点。</p><ul><li>模型精度：XGBoost和LightGBM相当，CatBoost往往略好一些，无需调参即可获取很好的结果。</li><li>训练速度：LightGBM远快于XGBoost，CatBoost快于XGBoost但比LightGBM慢。</li><li>预测速度：LightGBM与XGBoost相当，CatBoost远快于LightGBM与XGBoost，是它们的几十分之一。</li><li>内存消耗：LightGBM远小于XGBoost，CatBoost小于XGBoost，但大于LightGBM。</li><li>类别特征：XGBoost不支持类别特征，需要OneHot编码预处理。LightGBM支持类别特征，需转换成整数编码。CatBoost提供更强大的对类别特征的支持，直接支持字符串类型的类别特征，无需预处理。</li><li>缺失值特征：XGBoost和LightGBM都可以自动处理特征缺失值，CatBoost不能自动处理缺失值(或者将缺失值视为最小值/最大值)。</li><li>GPU支持：LightGBM与CatBoost支持GPU训练，XGBoost不支持GPU训练。</li><li>可视化：CatBoost还自带一套可视化工具，可以在JupyterNotebook或者TensorBoard中实时看到指标变化。</li></ul><p>CatBoost主要创新点如下：</p><ul><li>类别特征的 Ordered Target Statistics 数值编码方法。</li><li>基于贪心策略的特征组合方法。</li><li>避免预测偏移的 Ordered Boosting 方法。</li><li>使用对称二叉树作为基模型，有正则作用且预测极快。</li></ul><figure><img src="/images/catboost/v2-98453423ce486634a73c57943fd8737f.jpg"alt="v2-98453423ce486634a73c57943fd8737f" /><figcaptionaria-hidden="true">v2-98453423ce486634a73c57943fd8737f</figcaption></figure><h2 id="二-原理说明"><strong>二 原理说明</strong></h2><h3 id="类别特征的ordered-target-statistics-数值编码方法"><strong>1,类别特征的Ordered Target Statistics 数值编码方法</strong></h3><p>对于类别特征，如果类别数目不多，可以使用onehot编码。</p><p>但如果类别数量成百上千，使用onehot编码会导致特征数量爆炸。</p><p>CatBoost设计了一种基于预测目标统计值的方法可以将类别特征转化为数值特征。</p><p>以风控领域的预测信贷用户是否会违约为例，假设有一个类别特征是根据身份证号码解析出来的用户所出生的城市。</p><p>全国有几百个城市，转化为onehot编码会造成特征维数爆炸。</p><p>一种非常make sense的方式是我们用某个城市用户的平均逾期率来作为该城市的数值特征编码。</p><p>简而言之,我们用如下方式将 city = "上海" 这一类别特征取值代替为如下值。</p><p>city_numeric("上海") = sample_count(city="上海" and label=1(逾期)) /sample_count(city="上海")</p><p>这就是所谓的 Target Statistics 编码方法。</p><p>但是考虑到有一些小城市，比如黑龙江鹤岗市，可能在训练样本中数量很少甚至没有，这时候用训练样本中鹤岗市的用户平均逾期率来估计会比较不靠谱。</p><p>例如鹤岗市只有1个样本，并且这个样本是逾期的，那么数值编码</p><p>city_numeric("鹤岗") = sample_count(city="鹤岗" and label=1(逾期)) /sample_count(city="鹤岗") = 1.0</p><p>我们可以考虑加入先验值来抑制这种小样本的波动。</p><p>假设不区分城市，全部训练样本中用户的 逾期率 为 P = 0.1,我们可以在分子分母上分别加入 a = 100个 逾期率为P 的先验样本。</p><p>city_numeric("鹤岗") = (sample_count(city="鹤岗" and label=1(逾期)) +a·P) / （sample_count(city="鹤岗")+ a） = 11/101</p><p>这样就合理多了。</p><p>这种数值编码方式虽然好，但是会造成训练集中label的泄露，因为对于某个样本来说，其数值编码计算过程中已经把这个样本的label值纳入了计算过程中。</p><p>未来要预测的验证集的数据分布未必与训练集相同，例如训练集中 上海市用户的平均逾期率为0.12，但是验证集中上海市用户的平均逾期率可能只有0.04，在训练集中这个city_numeric特征可能会特别好用，特别重要，但是在验证集中可能会变得没有那么好用，没有那么重要。</p><p>为了让模型正确地评估 city_numeric特征的真实有效性和重要程度，我们可以拿出一部分数据来计算这个特征编码，用另外一部分数据来训练。但是这样会造成可用数据的减少。</p><p>CatBoost巧妙地设计了如下trick，来缓解这个问题。先将样本随机打乱，然后每个样本只使用它排序在它前面的样本来计算其类别特征的数值编码。这样就防止了label的泄露，并且能够较为合理地评估这个特征的真实有效性。</p><p>不过这种方式会造成排在前面的样本的类别特征的数值编码估计不是很准，为了减少这个影响，CatBoost会设计多个样本随机排列(默认4个)，在每次建树前从中随机取一个排列。</p><p>以上就是所谓的 Ordered Target Statistics编码方法，也是CatBoost最重要的创新。</p><figure><img src="/images/catboost/v2-90cfdd4e26bbcdc3825abe0a84e727a5.jpg"alt="v2-90cfdd4e26bbcdc3825abe0a84e727a5" /><figcaptionaria-hidden="true">v2-90cfdd4e26bbcdc3825abe0a84e727a5</figcaption></figure><h3id="基于贪心策略的特征交叉方法"><strong>2，基于贪心策略的特征交叉方法</strong></h3><p>使用Ordered Target Statistics方法将类别特征转化成为数值特征以后，会影响到特征交叉，因为数值特征无法有效地进行交叉。</p><p>依然以风控领域的预测信贷用户是否会违约为例，假设 city="北京市" 且job="保安"的用户信用特别好，但不是北京市所有的用户都信用好，也不是所有的保安都信用特别好。只有北京市的保安这个群体才信用好。</p><p>如果我们将city转换为数值编码，也将保安转换为数值编码之后，我们得到两个数，这两个数相乘是没有意义的，我们无法表示北京市的保安这个群体。</p><p>为了有效地利用特征交叉，CatBoost在将类别特征转换为数值编码的同时，会自动生成 交叉特征。</p><p>如果让全部的类别特征之间都进行交叉，两两交叉，三三交叉，四四交叉，这个复杂度是指数级的，特征维度一定会爆炸。</p><p>CatBoost使用一种贪心的策略来进行特征交叉。生成tree的第一次分裂，CatBoost不使用任何交叉特征。在后面的分裂中，CatBoost会使用生成tree所用到的全部原始特征和交叉特征跟 数据集中的全部 类别特征进行交叉。</p><p>在定义CatBoost模型时，我们可以用'max_ctr_complexity'来控制允许的特征交叉的最大特征数量，如果设置为3，那么生成tree时所用到的交叉特征最多只会来自3个特征的交叉，也就是我们只能表示city='北京市' 且 job='保安' 且education='高中'这样的三阶交叉特征，而无法表示 city='北京市' 且job='保安' 且 education='高中' 且 hobby='抽烟' 这样的四阶交叉特征。</p><h3 id="避免预测偏移的-ordered-boosting-方法"><strong>3，避免预测偏移的Ordered Boosting 方法。</strong></h3><p>使用XGBoost或者LightGBM做模型时，我们可能经常会发现模型在训练集上拟合的很好，train_auc甚至达到了1.0,但是在验证集上却差了很多, va_auc可能只有0.7。这当然有可能是因为tree的数量太多了，或者是每棵tree的leaves太多了，总之模型太复杂了造成了过拟合。</p><p>但也有一些XGBoost和LightGBM自身算法的缺陷因素。我们知道LightGBM在训练下一棵tree的时候，需要计算前面这些tree构成的加法模型在所有样本上的一阶梯度和二阶梯度(Loss对模型预测结果的导数)，然后用这些梯度来决定下一棵树的结构和叶子节点取值。</p><p>但是我们计算的这些一阶梯度和二阶梯度值是问题的。前面的这些tree都是在这些样本上训练的，现在我们又在这些样本上估计模型预测结果的一阶和二阶梯度。我们应该换一些新的样本才更合理。但是我们从哪里找这些新的样本呢？</p><p>CatBoost的作者故伎重演。先将样本随机打乱，然后每个样本只使用排序在它前面的样本来训练模型。用这样的模型来估计这个样本预测结果的一阶和二阶梯度。然后用这些梯度构建一棵tree的结构，最终tree的每个叶子节点的取值，是使用全体样本进行计算的。</p><p>这就是OrderedBoosting的主要思想。可以有效地减少梯度估计的误差，缓解预测偏移。但是会增加较多的计算量，影响训练速度。</p><p>在定义CatBoost模型时，我们可以用'boosting_type'这个参数来设置是使用OrderedBoosting 还是 LightGBM那样的 PlainBoosting。如果不显式设置，CatBoost会根据样本和特征数量自己决定。</p><figure><img src="/images/catboost/v2-7dbcacde377b5172a666fb1d981efbbb.jpg"alt="v2-7dbcacde377b5172a666fb1d981efbbb" /><figcaptionaria-hidden="true">v2-7dbcacde377b5172a666fb1d981efbbb</figcaption></figure><h3id="使用对称二叉树作为基模型有正则作用且预测极快"><strong>4，使用对称二叉树作为基模型，有正则作用且预测极快</strong></h3><p>XGBoost和LightGBM采用的基模型是普通的二叉树，但是CatBoost采用的是对称的二叉树。</p><p>这种对树结构上的约束有一定的正则作用。更为重要的是，它可以让CatBoost模型的推断过程极快。</p><p>对于CatBoost的tree的预测过程来说，每个特征的分裂都是独立的，不分先后顺序，多个样本可以一起预测。</p><figure><img src="/images/catboost/v2-e99a44ac409aa702ed46dd07f1136cdb.jpg"alt="v2-e99a44ac409aa702ed46dd07f1136cdb" /><figcaptionaria-hidden="true">v2-e99a44ac409aa702ed46dd07f1136cdb</figcaption></figure><h2 id="三-使用范例"><strong>三 使用范例</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!pip install catboost </span><br><span class="hljs-keyword">import</span> catboost <span class="hljs-keyword">as</span> cb <br><span class="hljs-built_in">print</span>(cb.__version__)<br></code></pre></td></tr></table></figure><p>1.0.4</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> display <br><br><span class="hljs-keyword">import</span> datetime,json<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> catboost <span class="hljs-keyword">as</span> cb <br><span class="hljs-keyword">from</span> catboost.datasets <span class="hljs-keyword">import</span> titanic<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedKFold<br><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score,roc_auc_score,accuracy_score<br><span class="hljs-keyword">import</span> plotly.graph_objs <span class="hljs-keyword">as</span> go <br><span class="hljs-keyword">import</span> plotly.express <span class="hljs-keyword">as</span> px <br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">printlog</span>(<span class="hljs-params">info</span>):<br>    nowtime = datetime.datetime.now().strftime(<span class="hljs-string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\n&quot;</span>+<span class="hljs-string">&quot;==========&quot;</span>*<span class="hljs-number">8</span> + <span class="hljs-string">&quot;%s&quot;</span>%nowtime)<br>    <span class="hljs-built_in">print</span>(info+<span class="hljs-string">&#x27;...\n\n&#x27;</span>)<br>     <br><span class="hljs-comment">#================================================================================</span><br><span class="hljs-comment"># 一，准备数据</span><br><span class="hljs-comment">#================================================================================</span><br>printlog(<span class="hljs-string">&quot;step1: preparing data...&quot;</span>)<br><br>dfdata,dftest = titanic()<br><br>display(dfdata.head()) <br><br>label_col = <span class="hljs-string">&quot;Survived&quot;</span><br><br><span class="hljs-comment"># 填充空值特征</span><br>dfnull = pd.DataFrame(dfdata.isnull().<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>),columns = [<span class="hljs-string">&quot;null_cnt&quot;</span>]).query(<span class="hljs-string">&quot;null_cnt&gt;0&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;null_features:&quot;</span>) <br><span class="hljs-built_in">print</span>(dfnull)<br><br>dfdata.fillna(-<span class="hljs-number">9999</span>, inplace=<span class="hljs-literal">True</span>)<br>dftest.fillna(-<span class="hljs-number">9999</span>, inplace=<span class="hljs-literal">True</span>)<br><br><br><span class="hljs-comment"># 刷选类别特征</span><br>cate_cols = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> dfdata.columns <br>             <span class="hljs-keyword">if</span> dfdata[x].dtype <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [np.float32,np.float64] <span class="hljs-keyword">and</span> x!=label_col]<br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> cate_cols:<br>    dfdata[col] = pd.Categorical(dfdata[col]) <br>    dftest[col] = pd.Categorical(dftest[col]) <br><br><span class="hljs-comment"># 分割数据集</span><br>dftrain,dfvalid = train_test_split(dfdata, train_size=<span class="hljs-number">0.75</span>, random_state=<span class="hljs-number">42</span>)<br>Xtrain,Ytrain = dftrain.drop(label_col,axis = <span class="hljs-number">1</span>),dftrain[label_col]<br>Xvalid,Yvalid = dfvalid.drop(label_col,axis = <span class="hljs-number">1</span>),dfvalid[label_col]<br>cate_cols_indexs = np.where(Xtrain.columns.isin(cate_cols))[<span class="hljs-number">0</span>]<br><br><br><span class="hljs-comment"># 整理成Pool</span><br>pool_train = cb.Pool(data = Xtrain, label = Ytrain, cat_features=cate_cols)<br>pool_valid = cb.Pool(data = Xvalid, label = Yvalid, cat_features=cate_cols)<br><br><br><span class="hljs-comment">#================================================================================</span><br><span class="hljs-comment"># 二，设置参数</span><br><span class="hljs-comment">#================================================================================</span><br>printlog(<span class="hljs-string">&quot;step2: setting parameters...&quot;</span>)<br>                               <br>iterations = <span class="hljs-number">1000</span><br>early_stopping_rounds = <span class="hljs-number">200</span><br><br>params = &#123;<br>    <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">0.05</span>,<br>    <span class="hljs-string">&#x27;loss_function&#x27;</span>: <span class="hljs-string">&quot;Logloss&quot;</span>,<br>    <span class="hljs-string">&#x27;eval_metric&#x27;</span>: <span class="hljs-string">&quot;Accuracy&quot;</span>,<br>    <span class="hljs-string">&#x27;depth&#x27;</span>: <span class="hljs-number">6</span>,<br>    <span class="hljs-string">&#x27;min_data_in_leaf&#x27;</span>: <span class="hljs-number">20</span>,<br>    <span class="hljs-string">&#x27;random_seed&#x27;</span>: <span class="hljs-number">42</span>,<br>    <span class="hljs-string">&#x27;logging_level&#x27;</span>: <span class="hljs-string">&#x27;Silent&#x27;</span>,<br>    <span class="hljs-string">&#x27;use_best_model&#x27;</span>: <span class="hljs-literal">True</span>,<br>    <span class="hljs-string">&#x27;one_hot_max_size&#x27;</span>: <span class="hljs-number">5</span>,   <span class="hljs-comment">#类别数量多于此数将使用ordered target statistics编码方法,默认值为2。</span><br>    <span class="hljs-string">&#x27;boosting_type&#x27;</span>:<span class="hljs-string">&quot;Ordered&quot;</span>, <span class="hljs-comment">#Ordered 或者Plain,数据量较少时建议使用Ordered,训练更慢但能够缓解梯度估计偏差。</span><br>    <span class="hljs-string">&#x27;max_ctr_complexity&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-comment">#特征组合的最大特征数量，设置为1取消特征组合，设置为2只做两个特征的组合,默认为4。</span><br>    <span class="hljs-string">&#x27;nan_mode&#x27;</span>: <span class="hljs-string">&#x27;Min&#x27;</span> <br>&#125;<br><br><br><span class="hljs-comment">#================================================================================</span><br><span class="hljs-comment"># 三，训练模型</span><br><span class="hljs-comment">#================================================================================</span><br>printlog(<span class="hljs-string">&quot;step3: training model...&quot;</span>)<br><br><br>model = cb.CatBoostClassifier(<br>    iterations = iterations,<br>    early_stopping_rounds = early_stopping_rounds,<br>    train_dir=<span class="hljs-string">&#x27;catboost_info/&#x27;</span>,<br>    **params<br>)<br><br><br><span class="hljs-comment">#直接训练</span><br>model.fit(<br>    pool_train,<br>    eval_set=pool_valid,<br>    plot=<span class="hljs-literal">True</span><br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;model.get_all_params():&quot;</span>)<br><span class="hljs-built_in">print</span>(model.get_all_params() )<br><br><br><span class="hljs-comment">#5折交叉验证</span><br>cv_data= cb.cv(<br>    cb.Pool(dfdata.drop(label_col,axis = <span class="hljs-number">1</span>), dfdata[label_col], cat_features=cate_cols_indexs),<br>    params,<br>    fold_count = <span class="hljs-number">3</span>,<br>    plot=<span class="hljs-literal">True</span><br>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Best validation accuracy score: &#123;:.2f&#125;±&#123;:.2f&#125; on step &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>    np.<span class="hljs-built_in">max</span>(cv_data[<span class="hljs-string">&#x27;test-Accuracy-mean&#x27;</span>]),<br>    cv_data[<span class="hljs-string">&#x27;test-Accuracy-std&#x27;</span>][np.argmax(cv_data[<span class="hljs-string">&#x27;test-Accuracy-mean&#x27;</span>])],<br>    np.argmax(cv_data[<span class="hljs-string">&#x27;test-Accuracy-mean&#x27;</span>])<br>))<br><br><br><span class="hljs-comment">#================================================================================</span><br><span class="hljs-comment"># 四，评估模型</span><br><span class="hljs-comment">#================================================================================</span><br>printlog(<span class="hljs-string">&quot;step4: evaluating model ...&quot;</span>)<br><br><br>y_pred_train = model.predict(Xtrain)<br>y_pred_valid = model.predict(Xvalid)<br><br>train_score = f1_score(Ytrain,y_pred_train)<br>valid_score = f1_score(Yvalid,y_pred_valid)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;train f1_score: &#123;:.5&#125; &#x27;</span>.<span class="hljs-built_in">format</span>(train_score))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;valid f1_score: &#123;:.5&#125; \n&#x27;</span>.<span class="hljs-built_in">format</span>(valid_score))   <br><br><br><br><span class="hljs-comment">#feature importance </span><br>dfimportance = model.get_feature_importance(prettified=<span class="hljs-literal">True</span>) <br>dfimportance = dfimportance.sort_values(by = <span class="hljs-string">&quot;Importances&quot;</span>).iloc[-<span class="hljs-number">20</span>:]<br>fig_importance = px.bar(dfimportance,x=<span class="hljs-string">&quot;Importances&quot;</span>,y=<span class="hljs-string">&quot;Feature Id&quot;</span>,title=<span class="hljs-string">&quot;Feature Importance&quot;</span>)<br><br>display(dfimportance)<br>display(fig_importance)<br><br><br><span class="hljs-comment">#score distribution</span><br>y_test_prob = model.predict_proba(dftest)[:,-<span class="hljs-number">1</span>]<br>trace1 = go.Histogram(x = y_test_prob,histnorm = <span class="hljs-string">&#x27;probability&#x27;</span>,nbinsx=<span class="hljs-number">50</span>)<br>layout = go.Layout(title = <span class="hljs-string">&quot;Score Distribution&quot;</span>,xaxis=&#123;<span class="hljs-string">&quot;title&quot;</span>:<span class="hljs-string">&quot;score&quot;</span>&#125;,yaxis = &#123;<span class="hljs-string">&quot;title&quot;</span>:<span class="hljs-string">&quot;frequecy&quot;</span>&#125;)<br>fig_distribution = go.Figure(data = [trace1])<br>fig_distribution.update_layout(layout)<br>display(fig_distribution)<br><br><br><span class="hljs-comment">#================================================================================</span><br><span class="hljs-comment"># 五，使用模型</span><br><span class="hljs-comment">#================================================================================</span><br>printlog(<span class="hljs-string">&quot;step5: using model ...&quot;</span>)<br><br>y_pred_test = model.predict(dftest)<br>y_pred_test_prob = model.predict_proba(dftest)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y_pred_test:\n&quot;</span>,y_pred_test[:<span class="hljs-number">10</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y_pred_test_prob:\n&quot;</span>,y_pred_test_prob[:<span class="hljs-number">10</span>])<br><br><br><br><span class="hljs-comment">#================================================================================</span><br><span class="hljs-comment"># 六，保存模型</span><br><span class="hljs-comment">#================================================================================</span><br>printlog(<span class="hljs-string">&quot;step6: saving model ...&quot;</span>)<br><br>model_dir = <span class="hljs-string">&#x27;catboost_model&#x27;</span><br>model.save_model(model_dir)<br>model_loaded = cb.CatBoostClassifier()<br>model.load_model(model_dir)<br></code></pre></td></tr></table></figure><figure><img src="/images/catboost/v2-c657c93122dd4eefaa9023a7ef49b495.jpg"alt="v2-c657c93122dd4eefaa9023a7ef49b495" /><figcaptionaria-hidden="true">v2-c657c93122dd4eefaa9023a7ef49b495</figcaption></figure><figure><img src="/images/catboost/v2-d451da5658789992a0a910062972049b.jpg"alt="v2-d451da5658789992a0a910062972049b" /><figcaptionaria-hidden="true">v2-d451da5658789992a0a910062972049b</figcaption></figure><figure><img src="/images/catboost/v2-86df3c443efed79653479c614bd73b4d.jpg"alt="v2-86df3c443efed79653479c614bd73b4d" /><figcaptionaria-hidden="true">v2-86df3c443efed79653479c614bd73b4d</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>集成学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>模型框架</tag>
      
      <tag>集成学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>XGBoost参数调优</title>
    <link href="/XGB%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98.html"/>
    <url>/XGB%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98.html</url>
    
    <content type="html"><![CDATA[<p>在机器学习中，参数调优是一门玄学，因为模型的最优参数可能依赖于许多场景。因此，不可能为参数调优创建一个全面的指南。本文尝试为XGBoost中的参数提供一些指导。</p><span id="more"></span><h2 id="一.-思路概述">一. 思路概述</h2><h3 id="理解偏差-方差权衡bias-variance-tradeoff">1.1理解偏差-方差权衡(Bias-Variance Tradeoff)</h3><p>如果你参加过机器学习或统计学课程，这可能是最重要的概念之一。当我们允许模型变得更加复杂（例如，增加深度）时，模型具有更好的拟合训练数据的能力，从而获得偏差较小的模型。然而，这种复杂的模型需要更多的数据来进行拟合。</p><p>XGBoost中的大多数参数都涉及偏差和方差的权衡。最好的模型应该在模型复杂度和预测能力之间进行仔细权衡。参数文档会告诉你每个参数是否会使模型更保守。这可以帮助你在复杂模型和简单模型之间进行调整。</p><h3 id="控制过拟合">1.2 控制过拟合</h3><p>当你观察到训练准确率高但测试准确率低时，很可能遇到了过拟合问题。</p><p>在XGBoost中，一般有两种方法可以控制过拟合：</p><blockquote><ul><li><p>第一种方法是直接控制模型复杂度。</p><p><code>这包括max_depth、min_child_weight和gamma。</code></p></li><li><p>第二种方法是增加随机性，使训练对噪声具有鲁棒性。</p></li></ul><p>​ <code>这包括subsample和colsample_bytree。</code></p></blockquote><p>你还可以减少步长eta。记住在这样做时增加num_round。</p><h3 id="处理数据集不平衡">1.3 处理数据集不平衡</h3><p>对于诸如广告点击日志等常见情况，数据集极度不平衡。这会影响XGBoost模型的训练，有两种方法可以改进。</p><blockquote><p>如果你只关心预测的整体性能指标（AUC）</p><ul><li><p>通过scale_pos_weight平衡正负样本的权重</p></li><li><p>使用AUC作为评估标准</p></li></ul><p>如果你关心预测的正确概率</p><ul><li><p>在这种情况下，你不能重新平衡数据集</p></li><li><p>将参数max_delta_step设置为一个有限的数值（例如1）以帮助收敛</p></li></ul></blockquote><h3 id="减少内存使用">1.4 减少内存使用</h3><p>如果你使用类似sklearn.model_selection.GridSearchCV的HPO库，请控制它可以使用的线程数。最好让XGBoost并行运行，而不是让GridSearchCV同时运行多个实验。例如，为交叉验证创建一个数据折叠可以消耗大量内存：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 这会创建数据集的副本。X和X_train同时存在于内存中。</span><br><span class="hljs-comment"># 如果你在n_jobs大于1的情况下运行`GridSearchCV`，每个线程都会同时发生这种情况。</span><br>X_train, X_test, y_train, y_test = train_test_split(X, y)<br><br>df = pd.DataFrame()<br><span class="hljs-comment"># 这会创建数据框的新副本，即使你指定了inplace参数</span><br>new_df = df.drop(...)<br><br>array = np.array(...)<br><span class="hljs-comment"># 这可能会也可能不会复制数据，具体取决于数据类型</span><br>array.astype(np.float32)<br><br><span class="hljs-comment"># np默认使用双精度，你真的需要吗？</span><br>array = np.array(...)<br></code></pre></td></tr></table></figure><p>你可以在文档中找到一些更具体的减少内存使用的实践。例如：与Dask的分布式XGBoost、XGBoostGPU支持。然而，在深入研究这些之前，要意识到数据副本的创建是一个好的起点。它通常消耗的内存比人们预期的要多得多</p><h2 id="二.-xgb参数详解">二. XGB参数详解</h2><p>在运行 XGBoost 之前, 我们必须设置三种类型的参数: 常规参数,提升器参数和任务参数.</p><ul><li>常规参数与我们用于提升的提升器有关，通常是树模型或线性模型</li><li>提升器参数取决于你所选择的提升器</li><li>学习任务的参数决定了学习场景,例如回归任务可以使用不同的参数进行排序相关的任务</li><li>命令行参数的行为与 xgboost 的 CLI 版本相关</li></ul><h3 id="常规参数">2.1 常规参数</h3><h4 id="booster-默认gbtree">booster [默认=gbtree]</h4><p>选择使用哪种booster，可以是gbtree、gblinear或dart。gbtree和dart使用基于树的模型，而gblinear使用线性函数。</p><h4 id="silent-默认0">silent [默认=0]</h4><p>0表示打印运行信息，1表示静默模式。</p><h4 id="nthread-默认值为可用的最大线程数如果未设置">nthread[默认值为可用的最大线程数，如果未设置]</h4><p>用于运行xgboost的并行线程数。</p><h4 id="num_pbuffer-由xgboost自动设置无需用户设置">num_pbuffer[由xgboost自动设置，无需用户设置]</h4><p>预测缓冲区的大小，通常设置为训练实例的数量。缓冲区用于保存上一次boosting步骤的预测结果。</p><h4 id="num_feature-由xgboost自动设置无需用户设置">num_feature[由xgboost自动设置，无需用户设置]</h4><p>boosting过程中使用的特征维度，设置为特征的最大维度。</p><h3 id="用于-tree-提升的参数">2.2 用于 Tree 提升的参数</h3><h4 id="eta-默认0.3">⭐eta [默认=0.3]</h4><p>用于更新的步长缩减，以防止过拟合。在每个提升步骤之后，我们可以直接获得新特征的权重。eta实际上是缩小了特征权重，使提升过程更加保守。 范围: [0,1]</p><h4 id="gamma-默认0">⭐gamma [默认=0]</h4><p>在树的叶节点上进行进一步分区所需的最小损失减少量。值越大，算法越保守。范围: [0,∞]</p><h4 id="max_depth-默认6">⭐max_depth [默认=6]</h4><p>树的最大深度，增加此值将使模型更加复杂/更容易过拟合。 范围: [1,∞]</p><h4 id="min_child_weight-默认1">⭐min_child_weight [默认=1]</h4><p>子节点所需的实例权重（赫西安矩阵）的最小和。如果树分区步骤导致叶节点的实例权重和小于min_child_weight，那么构建过程将放弃进一步分区。在线性回归模式下，这仅对应于每个节点所需的最小实例数。值越大，算法越保守。范围: [0,∞]</p><h4 id="max_delta_step-默认0">max_delta_step [默认=0]</h4><p>每棵树的权重估计允许的最大步长。如果设置为0，则表示没有约束。如果设置为正值，可以帮助使更新步骤更加保守。通常不需要此参数，但在类极不平衡的逻辑回归中可能会有所帮助。设置为1-10的值可能有助于控制更新。范围: [0,∞]</p><h4 id="subsample-默认1">subsample [默认=1]</h4><p>训练实例的子采样比例。设置为0.5表示XGBoost随机收集一半的数据实例来生长树，这将防止过拟合。范围: (0,1]</p><h4 id="colsample_bytree-默认1">colsample_bytree [默认=1]</h4><p>构建每棵树时的列的子采样比例。 范围: (0,1]</p><h4 id="colsample_bylevel-默认1">colsample_bylevel [默认=1]</h4><p>在每个层次上分割时的列的子采样比例。 范围: (0,1]</p><h4 id="lambda-默认1">⭐lambda [默认=1]</h4><p>权重上的L2正则化项，增加此值将使模型更加保守。</p><h4 id="alpha-默认0">alpha [默认=0]</h4><p>权重上的L1正则化项，增加此值将使模型更加保守。</p><h4 id="tree_method-string-默认auto">tree_method, string[默认=‘auto’]</h4><p>XGBoost中使用的树构建算法（参见参考文献中的描述）。分布式和外部存储版本仅支持近似算法。 选择：{‘auto’, ‘exact’,‘approx’}</p><blockquote><p>‘auto’: 使用启发式方法选择更快的算法。对于中小型数据集，将使用精确贪婪算法。对于非常大的数据集，将选择近似算法。由于旧行为始终在单机上使用精确贪婪算法，因此在选择近似算法时用户将收到通知。‘exact’: 精确贪婪算法。 ‘approx’: 使用素描和直方图的近似贪婪算法。</p></blockquote><h4 id="sketch_eps-默认0.03">sketch_eps, [默认=0.03]</h4><p>仅用于近似贪婪算法。 这大致转换为 O(1 / sketch_eps)个箱子的数量。相比于直接选择箱子的数量，这种方法带有理论上的素描准确性保证。通常用户不需要调整此参数，但可以考虑设置为较低的值以获得更准确的枚举。范围: (0, 1)</p><h4 id="scale_pos_weight-默认0">⭐scale_pos_weight, [默认=0]</h4><p>控制正负权重的平衡，对不平衡类别有用。一个典型的考虑值是：sum(负例) /sum(正例)。详见参数调优中的更多讨论。参见 Higgs Kaggle 比赛的示例：R,py1, py2, py3</p><h3 id="学习任务的参数">2.3 学习任务的参数</h3><p>指定学习任务及相应的学习目标。可选的目标如下：</p><h4 id="objective-默认值reglinear">objective [默认值=reg:linear]</h4><blockquote><ul><li><p>“reg:linear” – 线性回归</p></li><li><p>“reg:logistic” – 逻辑回归</p></li><li><p>“binary:logistic” – 用于二分类的逻辑回归，输出概率</p></li><li><p>“binary:logitraw” –用于二分类的逻辑回归，输出逻辑变换前的得分</p></li><li><p>“count:poisson” – 计数数据的泊松回归，输出泊松分布的均值泊松回归中max_delta_step默认设为0.7（用于保障优化过程）</p></li><li><p>“multi:softmax” –使用softmax目标设置XGBoost进行多类分类，还需要设置num_class（类别数）</p></li><li><p>“multi:softprob” – 与softmax相同，但输出一个ndata *nclass的向量，可以进一步重塑为ndata,nclass矩阵。结果包含每个数据点属于每个类别的预测概率。</p></li><li><p>“rank:pairwise” –设置XGBoost通过最小化成对损失来执行排序任务</p></li><li><p>“reg:gamma” –用于严重度数据的伽玛回归，输出伽玛分布的均值</p></li></ul></blockquote><h4 id="base_score-默认值0.5">base_score [默认值=0.5]</h4><p>所有实例的初始预测得分，全局偏差对于足够多的迭代次数，改变这个值不会有太大影响。</p><h4 id="eval_metric-默认值根据objective确定">⭐eval_metric[默认值根据objective确定]</h4><p>验证数据的评估指标，将根据objective分配一个默认指标（回归任务为rmse，分类任务为error，排序任务为平均精度）用户可以添加多个评估指标，对于Python用户，请记住将指标作为参数对的列表传递，而不是映射，这样后面的‘eval_metric’不会覆盖前面的。</p><p>可选的评估指标如下：</p><blockquote><ul><li><p>“rmse”：均方根误差</p></li><li><p>“mae”：平均绝对误差</p></li><li><p>“logloss”：负对数似然</p></li><li><p>“error”：二分类错误率。计算方法为#(错误案例)/#(所有案例)。对于预测，评估会将预测值大于0.5的实例视为正例，其余视为负例。</p></li><li><p>“merror”：多类分类错误率。计算方法为#(错误案例)/#(所有案例)。</p></li><li><p>“mlogloss”：多类对数损失</p></li><li><p>“auc”：用于排序评估的曲线下面积</p></li><li><p>“ndcg”：归一化折扣累积增益</p></li><li><p>“map”：平均精度</p></li><li><p>“ndcg@n”，“map@n”：n可以设为一个整数，用于截断评估列表中的前n个位置。</p></li><li><p>“ndcg-”，“map-”，“ndcg@n-”，“map@n-”：在XGBoost中，NDCG和MAP将评估没有任何正样本的列表的得分为1。通过在评估指标中添加“-”，XGBoost将在某些条件下将这些得分评估为0。</p></li><li><p>“gamma-deviance”： [伽玛回归的残差偏差]</p></li></ul></blockquote><h4 id="seed-默认值0">seed [默认值=0]</h4><p>随机数种子。</p><h3 id="用于-dart-booster-的其它参数">2.4 用于 Dart Booster的其它参数</h3><h4 id="sample_type-默认值uniform"><code>sample_type</code>[默认值=”uniform”]</h4><p>采样算法的类型。<br />“uniform”：均匀选择丢弃的树。<br />“weighted”：按权重比例选择丢弃的树。</p><h4 id="normalize_type-默认值tree"><code>normalize_type</code>[默认值=”tree”]</h4><p>归一化算法的类型。<br />“tree”：新树的权重与每棵丢弃的树相同。<br />新树的权重为 1 / (k + 学习率)<br />丢弃的树按 k / (k + 学习率) 进行缩放。<br />“forest”：新树的权重与丢弃树（森林）的权重总和相同。<br />新树的权重为 1 / (1 + 学习率)<br />丢弃的树按 1 / (1 + 学习率) 进行缩放。</p><h4 id="rate_drop-默认值0.0"><code>rate_drop</code> [默认值=0.0]</h4><p>丢弃率。<br />范围：[0.0, 1.0]</p><h3 id="用于-linear-booster-的参数">2.5 用于 Linear Booster 的参数</h3><h4 id="skip_drop-默认值0.0"><code>skip_drop</code> [默认值=0.0]</h4><p>跳过丢弃的概率。<br />如果跳过丢弃，新树将以与 gbtree 相同的方式添加。<br />范围：[0.0, 1.0]</p><h4 id="lambda-默认值0">lambda [默认值=0]</h4><p>权重的L2正则化项，增加这个值会使模型更加保守。</p><p>alpha [默认值=0] 权重的L1正则化项，增加这个值会使模型更加保守。</p><h4 id="lambda_bias">lambda_bias</h4><p>偏置的L2正则化项，默认值为0（没有偏置的L1正则化，因为它不重要）。</p><h2 id="三.-xgb代码示例">三. XGB代码示例</h2><p>此代码用于二分类问题,使用XGB建模,并输出评估报告,绘制AUC曲线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xgboost <span class="hljs-keyword">as</span> xgb<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_auc_score,roc_curve<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br><span class="hljs-comment"># 参数设置</span><br>params=&#123;<br><span class="hljs-string">&#x27;booster&#x27;</span>:<span class="hljs-string">&#x27;gblinear&#x27;</span>,<br><span class="hljs-string">&#x27;objective&#x27;</span>:<span class="hljs-string">&#x27;binary:logistic&#x27;</span>,<br><span class="hljs-string">&#x27;metric&#x27;</span>:<span class="hljs-string">&#x27;auc&#x27;</span>,<br><span class="hljs-string">&#x27;eval_metric&#x27;</span>:<span class="hljs-string">&#x27;auc&#x27;</span>,<br><span class="hljs-string">&#x27;eta&#x27;</span>:<span class="hljs-number">0.0425</span>,<br><span class="hljs-string">&#x27;max_depth&#x27;</span>:<span class="hljs-number">15</span>,<br><span class="hljs-string">&#x27;min_child_weight&#x27;</span>:<span class="hljs-number">20</span>,<br><span class="hljs-string">&#x27;gamma&#x27;</span>:<span class="hljs-number">0</span>,<br><span class="hljs-string">&#x27;subsample&#x27;</span>:<span class="hljs-number">1</span>,<br><span class="hljs-string">&#x27;colsample_bytree&#x27;</span>:<span class="hljs-number">1</span>,<br><span class="hljs-string">&#x27;scale_pos_weight&#x27;</span>:<span class="hljs-number">1</span><br>&#125;<br><br>dtrain = xgb.DMatrix(x, y)<br><br>lr_class_weight = xgb.train(params=params,dtrain=dtrain,num_boost_round=<span class="hljs-number">165</span>)<br><span class="hljs-comment"># 加载测试数据</span><br>data_test = test_slct3<br><br>data_test_encoding = pd.get_dummies(data_test)<br>y_test = data_test_encoding[<span class="hljs-string">&#x27;Attrition&#x27;</span>]<br>x_test = transfer.transform(data_test_encoding.drop(<span class="hljs-string">&#x27;Attrition&#x27;</span>, axis=<span class="hljs-number">1</span>))<br><br><span class="hljs-comment"># 使用xgb.DMatrix进行预测</span><br>y_pre_prob = lr_class_weight.predict(xgb.DMatrix(x_test))<br>y_pre = (y_pre_prob &gt;= <span class="hljs-number">0.70</span>).astype(<span class="hljs-built_in">int</span>)  <span class="hljs-comment"># 将概率转换为0或1</span><br><br>train_y_pre_prob = lr_class_weight.predict(xgb.DMatrix(x))<br>train_y_pre = (train_y_pre_prob &gt;= <span class="hljs-number">0.70</span>).astype(<span class="hljs-built_in">int</span>)  <span class="hljs-comment"># 将概率转换为0或1</span><br><br><span class="hljs-comment"># 计算并打印ROC AUC得分</span><br>roc_auc = roc_auc_score(y_test, y_pre_prob)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ROC AUC Score: <span class="hljs-subst">&#123;roc_auc&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 计算并打印ROC AUC得分</span><br>roc_auc = roc_auc_score(y_test, y_pre_prob)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ROC AUC Score: <span class="hljs-subst">&#123;roc_auc&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 生成并打印classification_report</span><br>report = classification_report(y_test, y_pre)<br><span class="hljs-built_in">print</span>(report)<br><span class="hljs-comment"># 绘制ROC曲线</span><br>fpr, tpr, _ = roc_curve(y_test, y_pre_prob)<br>fpr_train, tpr_train,_=roc_curve(y, train_y_pre_prob)<br>plt.plot(fpr, tpr, label=<span class="hljs-string">&#x27;evl ROC&#x27;</span>)<br>plt.plot(fpr_train, tpr_train, label=<span class="hljs-string">&#x27;Train ROC&#x27;</span>)<br>plt.plot([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;k--&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;False Positive Rate&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;True Positive Rate&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;ROC Curve&#x27;</span>)<br>plt.legend(loc=<span class="hljs-string">&#x27;best&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>集成学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>回归模型</tag>
      
      <tag>参数调优</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模型调优指南--过拟合</title>
    <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B0%83%E4%BC%98%E6%8C%87%E5%8D%97--%E8%BF%87%E6%8B%9F%E5%90%88.html"/>
    <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%B0%83%E4%BC%98%E6%8C%87%E5%8D%97--%E8%BF%87%E6%8B%9F%E5%90%88.html</url>
    
    <content type="html"><![CDATA[<p>过拟合是机器学习模型在训练数据上表现很好，但在新数据上表现不佳的一种现象。它的发生通常是由于模型过于复杂，以至于能够记住训练数据的噪声和细节，而不是学习到数据的普遍模式和特征。以下是导致过拟合的常见原因以及相应的解决方法：<span id="more"></span></p><h3 id="过拟合的原因">过拟合的原因</h3><ol type="1"><li><strong>模型复杂度过高</strong>：模型参数过多（如深层神经网络的层数和节点数过多），导致模型具有很强的表达能力，能够拟合训练数据中的噪声。</li><li><strong>训练数据不足</strong>：训练数据量太少，使得模型只能依赖于有限的数据，容易记住而不是泛化。</li><li><strong>数据噪声</strong>：训练数据中包含大量噪声或异常值，模型在训练时会把这些噪声也当作有效模式来学习。</li><li><strong>训练次数过多</strong>：模型在训练数据上迭代次数过多，导致模型对训练数据的拟合过于精细。</li></ol><h3 id="解决过拟合的方法">解决过拟合的方法</h3><ol type="1"><li><strong>增加训练数据量</strong>：通过收集更多的数据或使用数据增强技术来扩展训练集，可以帮助模型学习到更加普遍的特征。<ul><li><strong>数据增强</strong>：对于图像数据，可以使用翻转、旋转、缩放等技术来生成更多的训练样本。</li></ul></li><li><strong>简化模型</strong>：减少模型的参数数量，选择一个较为简单的模型结构。<ul><li><strong>正则化</strong>：在损失函数中加入正则化项，如L1正则化（Lasso）和L2正则化（Ridge），可以防止模型参数过大，减小模型的复杂度。</li></ul></li><li><strong>使用交叉验证</strong>：将数据集划分为多个子集，进行交叉验证，以确保模型在不同数据子集上的表现一致，帮助发现和防止过拟合。<ul><li><strong>K折交叉验证</strong>：将数据集分成K个子集，每次用K-1个子集训练模型，剩下的一个子集测试，循环K次，综合评估模型表现。</li></ul></li><li><strong>提前停止（EarlyStopping）</strong>：在训练过程中监控验证集的误差，当验证误差不再降低时，停止训练，避免模型在训练集上过度拟合。</li><li><strong>集成方法</strong>：使用多种模型的组合来降低单一模型过拟合的风险。<ul><li><strong>袋装（Bagging）</strong>：如随机森林，通过对数据进行多次采样并训练多个模型，最后进行投票或平均来得到最终结果。</li><li><strong>提升（Boosting）</strong>：如梯度提升决策树（GradientBoosting Decision Trees,GBDT），通过逐步训练多个弱模型，每次针对前一轮模型的错误进行改进。</li></ul></li><li><strong>正则化技术</strong>：<ul><li><strong>Dropout</strong>：在神经网络训练中随机将一部分神经元输出设置为0，以防止模型过于依赖某些特定的路径。</li><li><strong>数据标准化</strong>：对输入数据进行归一化处理，使其均值为0，标准差为1，帮助模型更快收敛，并减少过拟合的可能。</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>AI基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>模型训练</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>进栈与出栈-递归案例演示</title>
    <link href="/%E8%BF%9B%E6%A0%88%E4%B8%8E%E5%87%BA%E6%A0%88-%E9%80%92%E5%BD%92%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA.html"/>
    <url>/%E8%BF%9B%E6%A0%88%E4%B8%8E%E5%87%BA%E6%A0%88-%E9%80%92%E5%BD%92%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA.html</url>
    
    <content type="html"><![CDATA[<p>栈作为一种基本的数据结构，其简单性和高效性使得它在各种计算和编程任务中具有广泛的应用。理解和掌握栈的原理和操作，对于编写高效、可靠的代码至关重要。</p><span id="more"></span><h3 id="什么是栈">什么是栈</h3><p>栈是一种特殊的线性表，仅允许在表的一端进行插入和删除运算。这一端被称为栈顶（top），相对地，把另一端称为栈底（bottom）。向一个栈插入新元素又称作进栈、入栈或压栈（push），它是把新元素放到栈顶元素的上面，使之成为新的栈顶元素；从一个栈删除元素又称作出栈或退栈（pop），它是把栈顶元素删除掉，使其相邻的元素成为新的栈顶元素。所以栈具有“后入先出”的特点（LIFO）。</p><h3 id="栈的作用">栈的作用</h3><p>在程序执行过程中，函数调用是通过栈来管理的。每当一个函数被调用时，会将当前的执行环境（例如局部变量、参数和返回地址）压入栈中。当函数执行完毕后，这些信息会从栈中弹出，恢复之前的执行环境。</p><p>同时在一些回溯算法中，如深度优先搜索、迷宫求解等，使用栈来保存回溯路径，便于在需要时返回上一步。</p><h3 id="递归函数中栈的内存演示">递归函数中栈的内存演示</h3><blockquote><p>这里演示了一个爬台阶的案例，题目要求是有jieshu阶台阶，要求每次可以爬1阶或2阶，求解一共有多少爬法。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">stairs</span>(<span class="hljs-params">jieshu</span>):<br>    <span class="hljs-keyword">if</span> jieshu ==<span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> jieshu==<span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">2</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> (jieshu-<span class="hljs-number">1</span>)+stairs(jieshu-<span class="hljs-number">2</span>)<br><br>stairs(<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure><p>上述代码中</p><h4 id="进栈的过程图示为">进栈的过程图示为：</h4><figure><img src="/images/递归进出栈内存图/递归可视化_进栈.png"alt="递归可视化_进栈" /><figcaption aria-hidden="true">递归可视化_进栈</figcaption></figure><h4 id="出栈的过程为">出栈的过程为：</h4><figure><img src="/images/递归进出栈内存图/递归可视化_出栈.png"alt="递归可视化_出栈" /><figcaption aria-hidden="true">递归可视化_出栈</figcaption></figure><h4 id="总的流程示意">总的流程示意：</h4><figure><img src="/images/递归进出栈内存图/递归可视化.png" alt="递归可视化" /><figcaption aria-hidden="true">递归可视化</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记整理</tag>
      
      <tag>栈</tag>
      
      <tag>递归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git的原理及常用指令</title>
    <link href="/Git%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8.html"/>
    <url>/Git%E7%9A%84%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8.html</url>
    
    <content type="html"><![CDATA[<p>Git是一种分布式版本控制系统，用于跟踪项目中的更改，并允许多个开发者协作，本文介绍了Git的版本管理特点及常用指令。</p><span id="more"></span><h2 id="git的版本控制要点">Git的版本控制要点</h2><p>git与传统的集中式版本控制系统（如 Subversion 和CVS）有显著不同。分布式版本控制系统（DVCS）提供了更高的灵活性和可靠性。下面是关于Git 分布式管理的一些关键点：</p><p><img src="/images/git/git版本管理模式.png" /></p><h3 id="分布式架构">1. 分布式架构</h3><p>在 Git中，每个开发者的工作目录都包含了整个项目的完整版本库。这意味着每个开发者都有一个项目的完整副本，包括所有的历史记录和分支。这样，即使中央服务器出现问题，开发者仍然可以继续工作并且不会丢失任何数据。</p><h3 id="本地操作">2. 本地操作</h3><p>Git的大部分操作都是在本地完成的，例如提交（commit）、创建分支（branching）、合并（merging）等。这使得Git 操作非常快速，因为不需要与远程仓库通信。</p><h3 id="分支和合并">3. 分支和合并</h3><p>Git的分支和合并功能非常强大且灵活。创建和合并分支的操作都是本地的，效率高并且不会影响其他开发者的工作。分支在Git 中是轻量级的，这鼓励开发者频繁使用分支来进行独立开发和实验。</p><h3 id="协作工作流">4. 协作工作流</h3><p>Git 支持多种协作工作流，例如：</p><ul><li><strong>集中式工作流</strong>：所有的开发者都从中央仓库中拉取（pull）和推送（push）代码。</li><li><strong>功能分支工作流</strong>：每个新功能都有一个单独的分支，开发完成后合并回主分支。</li><li><strong>Forking 工作流</strong>：开发者从主仓库 fork出自己的仓库，在自己的仓库中工作，完成后向主仓库提交 pull request。</li></ul><h3 id="远程仓库">5. 远程仓库</h3><p>虽然 Git是分布式的，但它仍然支持通过远程仓库来进行团队协作。远程仓库通常托管在GitHub、GitLab 或 Bitbucket等平台上。开发者可以将本地的更改推送到远程仓库，也可以从远程仓库拉取其他开发者的更改。</p><h3 id="数据完整性">6. 数据完整性</h3><p>Git 使用 SHA-1哈希函数来确保数据的完整性。每一个文件、提交和标记都由一个唯一的哈希值标识，这些哈希值在版本库中是唯一的，可以确保数据不会被意外篡改。</p><h3 id="离线工作">7. 离线工作</h3><p>由于 Git的分布式特性，开发者可以在没有网络连接的情况下进行大部分操作。所有的操作都是在本地完成的，等到有网络连接时，再将更改推送到远程仓库。</p><h2 id="git的常用命令">Git的常用命令</h2><h3 id="配置">配置</h3><ol type="1"><li><p><strong>配置用户信息</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">git config --global user.name <span class="hljs-string">&quot;Your Name&quot;</span><br>git config --global user.email <span class="hljs-string">&quot;your.email@example.com&quot;</span><br></code></pre></td></tr></table></figure></p></li><li><p><strong>查看配置</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git config --list<br></code></pre></td></tr></table></figure></p></li></ol><h3 id="基本操作">基本操作</h3><ol type="1"><li><p><strong>初始化仓库</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git init<br></code></pre></td></tr></table></figure>在当前目录中创建一个新的 Git 仓库。</p></li><li><p><strong>克隆仓库</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">clone</span> &lt;repository_url&gt;<br></code></pre></td></tr></table></figure>从远程仓库克隆一个副本到本地。</p></li><li><p><strong>查看状态</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git status<br></code></pre></td></tr></table></figure>显示工作目录和暂存区的状态。</p></li><li><p><strong>添加文件到暂存区</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git add &lt;file&gt;<br></code></pre></td></tr></table></figure>将文件添加到暂存区。使用 <code>git add .</code>可以添加所有更改的文件。</p></li><li><p><strong>提交更改</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git commit -m <span class="hljs-string">&quot;Commit message&quot;</span><br></code></pre></td></tr></table></figure>提交暂存区的更改并附带提交信息。</p></li><li><p><strong>查看日志</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git <span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure>查看提交历史记录。</p></li></ol><h3 id="分支操作">分支操作</h3><ol type="1"><li><p><strong>创建新分支</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git branch &lt;branch_name&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>切换分支</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git checkout &lt;branch_name&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>创建并切换到新分支</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git checkout -b &lt;branch_name&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>合并分支</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git merge &lt;branch_name&gt;<br></code></pre></td></tr></table></figure>将指定分支合并到当前分支。</p></li><li><p><strong>删除分支</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git branch -d &lt;branch_name&gt;<br></code></pre></td></tr></table></figure>删除指定的分支。</p></li></ol><h4 id="要将-dev-分支的更改合并到-master-分支可以按照以下步骤操作">要将<code>dev</code> 分支的更改合并到 <code>master</code>分支，可以按照以下步骤操作：</h4><ol type="1"><li><p><strong>切换到 <code>master</code> 分支：</strong> 首先，确保你在<code>master</code> 分支上。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">git checkout <span class="hljs-literal">master</span><br></code></pre></td></tr></table></figure></li><li><p><strong>更新 <code>master</code> 分支：</strong> 确保你的<code>master</code> 分支是最新的。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">git pull origin <span class="hljs-literal">master</span><br></code></pre></td></tr></table></figure></li><li><p><strong>合并 <code>dev</code> 分支到 <code>master</code>分支：</strong> 将 <code>dev</code> 分支的更改合并到 <code>master</code>分支。</p><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cos">git <span class="hljs-keyword">merge</span> dev<br></code></pre></td></tr></table></figure></li><li><p><strong>解决冲突（如果有）：</strong>如果在合并过程中遇到冲突，Git会提示你解决冲突。你需要手动编辑冲突的文件，解决冲突后，添加解决冲突的文件。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">git <span class="hljs-built_in">add</span> &lt;conflicted_file&gt;<br></code></pre></td></tr></table></figure></li><li><p><strong>完成合并：</strong>如果有冲突需要解决，解决完冲突并添加文件后，完成合并。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">git commit</span><br></code></pre></td></tr></table></figure></li><li><p><strong>推送更改到远程 <code>master</code> 分支：</strong>将合并后的 <code>master</code> 分支推送到远程仓库。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs maxima">git <span class="hljs-built_in">push</span> <span class="hljs-built_in">origin</span> master<br></code></pre></td></tr></table></figure></li></ol><h3 id="远程操作">远程操作</h3><ol type="1"><li><p><strong>添加远程仓库</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git remote add &lt;remote_name&gt; &lt;url&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>查看远程仓库</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git remote -v<br></code></pre></td></tr></table></figure></p></li><li><p><strong>从远程仓库拉取更改</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git pull &lt;remote_name&gt; &lt;branch_name&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>推送更改到远程仓库</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git push &lt;remote_name&gt; &lt;branch_name&gt;<br></code></pre></td></tr></table></figure></p></li></ol><h3 id="撤销操作">撤销操作</h3><ol type="1"><li><p><strong>撤销工作目录中的更改</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git checkout -- &lt;file&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>重置暂存区的更改</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git reset &lt;file&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>撤销提交</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git revert &lt;commit&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>强制重置分支</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git reset --hard &lt;commit&gt;<br></code></pre></td></tr></table></figure></p></li></ol><h3 id="标签">标签</h3><ol type="1"><li><p><strong>创建标签</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git tag &lt;tag_name&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>查看标签</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git tag<br></code></pre></td></tr></table></figure></p></li><li><p><strong>推送标签到远程仓库</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git push &lt;remote_name&gt; &lt;tag_name&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>删除标签</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git tag -d &lt;tag_name&gt;<br></code></pre></td></tr></table></figure></p></li></ol><h3 id="比较">比较</h3><ol type="1"><li><p><strong>比较文件</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git diff &lt;file&gt;<br></code></pre></td></tr></table></figure></p></li><li><p><strong>比较分支</strong> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">git diff &lt;branch1&gt; &lt;branch2&gt;<br></code></pre></td></tr></table></figure></p></li></ol><p>这些 Git的基本操作，熟练使用可以极大地提升管理代码和协作开发的工作效率。</p>]]></content>
    
    
    <categories>
      
      <category>编程基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
      <tag>代码管理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SQL数据库基础知识</title>
    <link href="/SQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html"/>
    <url>/SQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html</url>
    
    <content type="html"><![CDATA[<p>数据库操作在日常工作非常常见，以下知识点你都掌握了吗？<span id="more"></span></p><h2 id="内容大纲">内容大纲</h2><ul><li>SQL的相关概述</li><li>环境搭建</li><li>SQL语句分类<ul><li>DDL</li><li>DML</li><li>DCL</li><li>DQL</li></ul></li><li>DDL语句之操作数据库</li><li>DDL语句之操作数据表</li><li>DML语句之操作表数据(增删改)</li><li>DQL语句之操作表数据(查)</li></ul><hr /><h2 id="sql概念">1.SQL概念</h2><p>结构化查询语言(Structured QueryLanguage)简称SQL，是<strong>关系型数据库</strong>管理系统都需要遵循的规范，是数据库认识的语句。不同的数据库生产厂商都支持SQL语句，但都有自己特有内容.</p><h3 id="数据库概念">1.1数据库概念</h3><p>数据库就是存储数据的仓库，其本质是一个文件系统，按照特定的格式将数据存储起来，用户可以对数据库中的数据进行增加，修改，删除及查询(<strong>CURD)</strong>操作。</p><ul><li><p>C: Create, 增</p></li><li><p>U: Update, 改</p></li><li><p>R: Read, 查</p></li><li><p>D: Delete, 删</p></li></ul><h3id="关系型数据库与非关系型数据库">1.2关系型数据库与非关系型数据库</h3><h4 id="关系型数据">关系型数据</h4><p>指采用了<strong>关系模型</strong>来组织数据的数据库。关系模型指的就是<strong>二维表格</strong>模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。</p><h4 id="非关系型数据">非关系型数据</h4><p>又被称为NoSQL（Not Only SQL)，<strong>意为不仅仅是SQL</strong>，对NoSQL最普遍的定义是“非关联型的”，强调 <strong>Key-Value</strong>的方式存储数据。</p><h3 id="sql常用数据类型">1.3 SQL常用数据类型</h3><p>-- SQL 根据每列值的不同, 数据类型也不同, 常用的如下.</p><ul><li><p>整数: int</p></li><li><p>小数; decimal, float, double</p></li><li><p>字符串: varchar(长度), char(长度)</p></li><li><p>日期: date, datetime</p></li></ul><h2 id="mysql基础语法">2.MySql基础语法</h2><ul><li><p>建议先通过小皮安装MySql数据库,并将mysql.exe的路径添加到path</p></li><li><p>建议通过Pycharm专业版或DataGrip运行MySql相关命令及可视化</p></li></ul><h3 id="sql通用语法">2.1 SQL通用语法</h3><ul><li><ol type="1"><li>SQL语句可以写单行, 也可以写多行, 最后以 分号; 结尾.</li></ol></li><li><ol start="2" type="1"><li>为了阅读方便, 我们可以用 者 空格来隔开SQL语句.</li></ol></li><li><ol start="3" type="1"><li>SQL语句不区分大小写, 为了阅读方便, 建议: 关键字大写, 其它小写.</li></ol></li><li><ol start="4" type="1"><li>SQL的注释写法如下 -- 单行注释 '# 单行注释' /<em> 多行 注释</em>/</li></ol></li></ul><p>-- 5. 我们目前在PyCharm或者DataGrip中写SQL语句, 是选中执行的, 即:不要漏选, 防止出错.</p><h3 id="sql语句分类">2.2 SQL语句分类</h3><ul><li><p><strong>DDL</strong>语句, DataBase Definition Language,数据定义语言</p><blockquote><p>作用对象: <strong>数据库, 数据表, 列的</strong>, 进行: CURD.</p><p><strong>关键字: create, drop, alter, show</strong></p></blockquote></li><li><p><strong>DML</strong>语句, DataBase Manipulation Language,数据操作语言.</p><blockquote><p>作用对象: <strong>表数据的, 进行: 增删改操作</strong>, 统称为:<strong>更新语句</strong></p><p><strong>关键字: insert, delete, update</strong></p></blockquote></li><li><p><strong>DQL</strong>语句, DataBase Query Language,数据查询语言.</p><blockquote><p>作用对象: <strong>表数据的, 进行: 查询操作</strong>.</p><p><strong>关键字: select, from, where...</strong></p></blockquote></li><li><p><strong>DCL</strong>语句, DataBase Control Language,数据控制语言.</p><blockquote><p>作用对象: 设置权限, 访问级别(隔离级别), 创建用户等的...</p></blockquote></li></ul><h2 id="ddl语句">3.DDL语句</h2><h3 id="ddl操作数据库">3.1DDL操作数据库</h3><ul><li><ol type="1"><li><strong>查看</strong>所有的<strong>数据库</strong>.<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">show databases;         # ctrl + 回车, 执行该行代.<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="2" type="1"><li><strong>创建</strong>数据库. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">create database day01 character set &#x27;utf8&#x27;;                 # 创建day01数据库, 采用: utf8 码表.  库不存在就创建, 存在就: 报错.<br>create database if not exists day01 character set &#x27;utf8&#x27;;   # 创建day01数据库, 采用: utf8 码表.  库不存在就创建, 存在就: 啥也不做.<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">上述格式, 语法糖1: character <span class="hljs-built_in">set</span> =&gt; 可以写成 charset</span><br>create database day02 charset &#x27;utf8&#x27;;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="3" type="1"><li><strong>查看</strong>对象数据库. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">show create database day01;     # utf8<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="4" type="1"><li><strong>修改</strong>数据库码表. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">alter database day03 charset =&#x27;gbk&#x27;;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="5" type="1"><li><strong>删除</strong>数据库. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">drop database day01;            # 删除数据库, 如果数据库存在就删除, 不存在就: 报错.<br>drop database if exists day01;  # 删除数据库, 如果数据库存在就删除, 不存在就: 啥也不做.<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="6" type="1"><li><strong>应用</strong>数据库. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">use day01; #之后: 建表, 查表, 查数据等操作, 都是基于数据库完成的.<br></code></pre></td></tr></table></figure> ### 3.2DDL操作数据表</li></ol></li><li><ol type="1"><li>查看当前库中, 所有的数据表. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">show tables;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="2" type="1"><li>查看表结构. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">show create table student;      # 查看建表的详细过程.<br>describe student;               # 语法糖,  desc student;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="3" type="1"><li>创建数据表. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">create table if not exists student(<br>    sid int primary key,        # 学生id, primary key: 主键约束, 特点为: 唯一, 非空.<br>    name varchar(20) not null,  # 学生姓名, 非空约束(即: 不能为空)<br>    gender varchar(2),          # 学生性别<br>    age int                     # 学生年龄, 整数.<br>);<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="4" type="1"><li>删除数据表. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">drop table if exists student;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="5" type="1"><li>修改表(名字) <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">格式: rename table 旧表名 to 新表名;</span><br>rename table student to stu;<br></code></pre></td></tr></table></figure> ### 3.3 DDL操作列</li></ol></li><li><ol type="1"><li>查看表结构. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">desc stu;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="2" type="1"><li>给表新增一列, desc varchar(200), 非空约束. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">alter table stu add `desc` varchar(200) not null;       # 如果列名和关键字重名, 记得用 反引号包裹.<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="3" type="1"><li>修改表的字段(列), 只修改: 数据类型, 约束. 将desc列改为: int类型..<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">alter table stu modify `desc` int;      # 因为没有加非空约束, 所以本次会认为, 不要非空约束了, 即: 会删除它.<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="4" type="1"><li>修改表的字段(列), 修改: 列名, 数据类型, 约束. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">-- 格式: alter table 表名 change 旧列名 新列名 数据类型 约束;<br>alter table stu change `desc` address varchar(10) not null;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="5" type="1"><li>删除表的字段 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">格式: alter table 表名 drop 旧列名;</span><br>alter table stu drop address;<br></code></pre></td></tr></table></figure> ## 4 DML语句 ### 4.1添加数据</li></ol></li><li><ol type="1"><li>查看表数据, 这个数据DQL语句, 先用一下, 稍后详解. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">select * from stu;<br><span class="hljs-meta prompt_"># </span><span class="language-bash">查看表结构.</span><br>desc stu;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="2" type="1"><li>添加表数据. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">场景1: 添加单条数据, 格式为: insert into 表名(列名1, 列名2, 列名3...) values(值1, 值2, 值3...);</span><br>insert into stu(sid, name, gender, age) values (1, &#x27;乔峰&#x27;, null, 38);<br><br>insert into stu(sid, name, gender, age) values (2, null, null, 38);     # 报错, name列有非空约束, 不能为null<br>场景2:添加多条数据, 格式为: insert into 表名(列名1, 列名2, 列名3...) values(值1, 值2, 值3...), (...), (...);<br>insert into stu(sid, name, gender, age)<br>values<br>    (2, &#x27;虚竹&#x27;, null, 26),<br>    (3, &#x27;段誉&#x27;, &#x27;男&#x27;, 21),<br>    (4, &#x27;阿朱&#x27;, &#x27;女&#x27;, 35),<br>    (5, &#x27;梦姑&#x27;, &#x27;女&#x27;, 23),<br>    (6, &#x27;钟灵儿&#x27;, &#x27;女&#x27;, 19);<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="3" type="1"><li>上述格式的变形版. 不一定非得是全列名, 只要值的个数, 类型 和列名的个数, 类型保持一致即可. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">insert into stu(sid, name) values (7, &#x27;木婉清&#x27;);<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="4" type="1"><li>上述格式的语法糖, 掌握, 实际开发一般是用这个.. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">insert into stu values (8, &#x27;鸠摩智&#x27;, &#x27;男&#x27;, 49);      # 如果不写列名, 则默认是: 全列名, 需要给每一个列都要传入值.<br></code></pre></td></tr></table></figure> ###4.2DML修改数据</li></ol></li><li><ol type="1"><li>修改 sid为3的数据, 姓名为: 段氏小王子, 渣男 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">update stu set name=&#x27;段氏小王子&#x27;, gender=&#x27;渣男&#x27; where sid = 3;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="2" type="1"><li>危险操作, 修改数据时, 没有写 where条件,则会一次性修改表中所有的数据. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">update stu set name=&#x27;段氏小王子&#x27;, gender=&#x27;渣男&#x27;;<br></code></pre></td></tr></table></figure> ### 4.3DML删除数据</li></ol></li><li><ol type="1"><li>正常删除数据, 删除id &gt; 3的数据.(主键ID不变) <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">delete from stu where sid &gt; 3;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="2" type="1"><li>删除数据, 删除id &gt; 3的数据.(主键ID改变) <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">truncate table stu where sid &gt; 3;<br></code></pre></td></tr></table></figure> ##5.备份表数据</li></ol></li><li><ol type="1"><li>场景1: 备份表不存在. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">create table stu_tmp select * from stu;<br></code></pre></td></tr></table></figure></li></ol></li><li><ol start="2" type="1"><li>场景1: 备份表存在. <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">insert into hero_tmp select * from hero;<br></code></pre></td></tr></table></figure></li></ol></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>SQL</tag>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SQL之DQL详解</title>
    <link href="/SQL%E4%B9%8BDQL%E8%AF%A6%E8%A7%A3.html"/>
    <url>/SQL%E4%B9%8BDQL%E8%AF%A6%E8%A7%A3.html</url>
    
    <content type="html"><![CDATA[<p>SQL数据库中的查询语句整理 <span id="more"></span></p><img src="/images/00194-3462269573.jpeg" /><table><thead><tr class="header"><th><h3 id="基础查询">基础查询</h3></th><th></th></tr></thead><tbody><tr class="odd"><td>Select * from 数据表;</td><td>查看所有数据</td></tr><tr class="even"><td>Select 字段1,字段2 from 数据表;</td><td>查看字段</td></tr><tr class="odd"><td>select 地段名 as 字段别名 from 数据表;</td><td>别名查询</td></tr><tr class="even"><td>select distinct 地段名 from 数据表;</td><td>去重查询</td></tr><tr class="odd"><td><h3 id="运算符筛选">运算符筛选</h3></td><td></td></tr><tr class="even"><td>select * from 表名 where 字段名 = '字段值';</td><td>筛选某字段值的行信息</td></tr><tr class="odd"><td>select * from 表名 where 字段名 != '字段值';</td><td>筛选不含某字段值的行信息</td></tr><tr class="even"><td>select * from 表名 where 字段名 &gt; 字段值;</td><td>筛选显示大于字段值的行</td></tr><tr class="odd"><td>select * from 表名 where 字段名 in (a,b);</td><td>筛选显示包含a,b值的行</td></tr><tr class="even"><td>select * from 表名 where 字段名 <strong>between</strong> 20<strong>and</strong> 80;</td><td>筛选显示介于20 - 80之间的行</td></tr><tr class="odd"><td>select * from 表名 where 字段名=a <strong>and</strong> 字段名&gt;b;</td><td>交集条件</td></tr><tr class="even"><td>select * from 表名 where 字段名=a <strong>or</strong> 字段名&gt;b;</td><td>并集条件</td></tr><tr class="odd"><td>select * from 表名 where 字段名 like '_值%';</td><td>近似查询,_占位符,%任意字符</td></tr><tr class="even"><td>select * from 表名 where 字段名 is null;</td><td>空字段查询</td></tr><tr class="odd"><td>select * from 表名 where 字段名 is not null;</td><td>非空字段查询</td></tr><tr class="even"><td><h3 id="排序">排序</h3></td><td></td></tr><tr class="odd"><td>select * from 表名 order by 字段名 asc | desc;</td><td>排序</td></tr><tr class="even"><td>select * from 表名 order by 字段名1 asc,字段名2 desc</td><td>多重排序</td></tr><tr class="odd"><td><h3 id="聚合与分组">聚合与分组</h3></td><td></td></tr><tr class="even"><td><p>select 聚合函数 from 表名 where 字段名xxx;</p><p>聚合函数为:count(),max(),min(),sum(),avg()</p><p>xxx为筛选条件</p></td><td>相关条件值下的统计值</td></tr><tr class="odd"><td><p></p><p>select</p><p><strong>分组字段</strong>, 聚合函数(<strong>count(*)</strong>)...</p><p>from</p><p>数据表名</p><p>where</p><p>组前筛选</p><p><strong>group by</strong></p><p><strong>分组字段</strong></p><p>having</p><p>组后筛选;</p></td><td><p>分组查询</p><p>一般结合聚合函数一起用, 否则: 无意义</p><p></p><p>where: 组前筛选, 后边不能跟: 聚合函数.</p><p>having: 组后筛选, 后边可以跟: 聚合函数.</p></td></tr><tr class="even"><td><h3 id="分页查询">分页查询</h3></td><td></td></tr><tr class="odd"><td><p>select * from 表名 limit 起始索引, 数据条数;</p><p>注:索引从0开始,从0开始则0可以省略不写</p><p>经验:总页数:=(总条数 + 每页的数据条数 - 1) // 每页的数据条数</p></td><td>分页查询较为常用,有效减少服务器/用户压力</td></tr><tr class="even"><td><h3 id="重分类查询">重分类查询</h3></td><td></td></tr><tr class="odd"><td><p>select case</p><p>when 条件1 then 重命名值</p><p>when 条件2 then 重命名值2</p><p>.....</p><p>else 重命名值3</p><p>end as 字段名,</p><p>from 数据表</p></td><td></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>SQL</tag>
      
      <tag>查询语句</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux常用命令整理</title>
    <link href="/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86.html"/>
    <url>/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86.html</url>
    
    <content type="html"><![CDATA[<p>整理了一下linux常用的一些命令 <span id="more"></span> ## 基本格式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>命令名 [-选项] [参数]# 有些命令要选项和参数, 有些不需要. 这里的[]表示可选项. <br></code></pre></td></tr></table></figure><h2 id="文件目录操作">文件目录操作</h2><h4 id="ls命令">2.ls命令</h4><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">ls</span>命令, 来源于: list(列表)  即: 查看指定目录下所有的子级(不包括子级的子级)</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>ls [-a -l -h] [Linux的路径]<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">参数解释</span><br>-a显示所有(包括隐藏的) all<br>-l以行的形式展示详细信息 line<br>-h以人性化的方式展示.   human<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">例如:</span> <br>ls# 查看当前目录的子级, 不包括隐藏.<br>ls /# 查看根目录(/)下的内容.<br>ls -a # 查看当前目录的子级, 包括隐藏.<br>ls -l# 以行的方式, 查看当前目录的子级. 简写形式: ll<br>ls -h# 以人性化的方式展示当前目录的内容, 但是: 无效果.<br>ls -lh# 行的方式, 人性化展示当前目录下的内容. 简写形式:  ll -h<br>ls -al# 以行的形式, 展示当前目录下所有子级(包括 隐藏)<br>ls -alh # 以行, 人性化的方式展示当前目录下所有子级(包括 隐藏)<br></code></pre></td></tr></table></figure></p><h4 id="cd命令">3.cd命令</h4><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">cd</span>命令, 来源于: change directory, 改变目录</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>cd 要切换到的目录的路径<br></code></pre></td></tr></table></figure></p><h4 id="pwd命令">4.pwd命令</h4><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">来源于 Print Work Directory</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>pwd # 查看当前所在的工作目录,  即: 当前在Linux的哪个路径下. <br></code></pre></td></tr></table></figure></p><h4 id="linux中的路径写法">5.Linux中的路径写法</h4><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">路径介绍</span><br>就是用来描述文件 或者 文件夹(目录)的路径的, 有: 绝对路径 和 相对路径两种写法.<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">绝对路径</span><br>以 / 根目录开头.   <br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">相对路径</span><br>默认是相对于当前路径来写的. <br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">例如: 当前目录是在 /aa/bb  如果相切换到 /aa/bb/cc目录, 有如下两种写法.</span><br>绝对路径:   cd /aa/bb/cc<br>相对路径:   cd cc<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">几个特殊的路径写法</span><br>./# 代表当前路径, 例如: 上述的 cd cc 还可以写成 cd ./cc<br>..# 代表上级路径<br>../..# 代表上上级路径<br>~# 代表: 回到家目录, root账号的家 /root,  其它账号的家 /home/账号名<br><span class="hljs-meta prompt_"># </span><span class="language-bash">语法糖, 可以直接写 <span class="hljs-built_in">cd</span> 也是回家命令.</span><br>-# 代表: 在最近的两个目录之间做切换.<br></code></pre></td></tr></table></figure></p><h4 id="mkdir命令">6.mkdir命令</h4><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">来源于 make directory, 创建目录(文件夹)的.</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>mkdir [-p] 文件夹路径# -p表示parent, 即: 父目录不存在, 也会自动创建.<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">简单理解, 假设: 目前只有 /root/aa 文件夹</span><br>mkdir /root/aa/bb/cc# 报错, 因为不写-p, 只能创建单级文件夹.<br>mkdir -p /root/aa/bb/cc# 不报错, 加上-p可以创建多级目录.<br></code></pre></td></tr></table></figure></p><h4 id="文件相关">7.文件相关</h4><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">touch</span>创建文件的.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>touch 文件路径1 文件路径2...# 可以同时创建多个文件.<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">cat</span>查看文件内容的</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>cat文件路径# 一次性查看文件所有内容, 如果内容较多, 会翻页, 只留最后一页.<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">more查看文件内容的, 可以分页查看.</span><br>more 文件路径# 以分页的形式查看文件内容.<br><span class="hljs-meta prompt_"># </span><span class="language-bash">空格向下翻一页</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">d  down的意思, 向下翻半页</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">enter 向下翻一行</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">b  back, 向上翻一页.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">q     quit, 表示退出.  也可以按下 ctrl + 字母C</span><br></code></pre></td></tr></table></figure></p><h2 id="文件和文件夹相关命令">文件和文件夹相关命令</h2><h4 id="cp命令-来源于-copy单词-可以拷贝-文件-文件夹">8.cp命令, 来源于copy单词, 可以拷贝 文件, 文件夹</h4><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"> # </span><span class="language-bash">格式</span><br>cp [-r] 数据源 目的地# -r表示recursive(递归), 即: 拷贝文件夹时, 要写. <br>cp -r /root/aa /root/test<br><br>[root@linxkon ~]# cd /root/<br>[root@linxkon ~]# ls<br>2.avi  3.jpg  4.mp3  aa  anaconda-ks.cfg  a.txt<br>[root@linxkon ~]# mkdir lk<br>[root@linxkon ~]# <br>[root@linxkon ~]# cp a.txt lk# 拷贝<br>[root@linxkon ~]# ls<br>2.avi  3.jpg  4.mp3  aa  anaconda-ks.cfg  a.txt  lk<br>[root@linxkon ~]# ls lk/<br>a.txt<br>[root@linxkon ~]# <br>[root@linxkon ~]# cp 2.avi lk/abc.avi# 拷贝, 并改名<br>[root@linxkon ~]# ls lk/<br>abc.avi  a.txt<br>[root@linxkon ~]# cp aa lk# 报错, 拷贝文件夹必须夹-r, 递归拷贝.<br>cp: 略过目录&quot;aa&quot;<br>[root@linxkon ~]# cp -r aa lk# 拷贝文件夹<br>[root@linxkon ~]# ls lk/<br>aa  abc.avi  a.txt<br></code></pre></td></tr></table></figure></p><h4 id="mvmove剪切移动重命名">9.mv（move）剪切移动/重命名</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">格式</span><br>mv 数据源 目的地# 注意: 如果是同级路径, 就是改名.<br><br>[root@linxkon ~]# ls<br>2.avi  3.jpg  4.mp3  aa  anaconda-ks.cfg  a.txt  lk<br>[root@linxkon ~]# ls lk/<br>aa  abc.avi  a.txt<br>[root@linxkon ~]# <br>[root@linxkon ~]# mv 3.jpg lk/# 剪切文件<br>[root@linxkon ~]# ls lk/<br>3.jpg  aa  abc.avi  a.txt<br>[root@linxkon ~]# ls<br>2.avi  4.mp3  aa  anaconda-ks.cfg  a.txt  lk<br>[root@linxkon ~]# <br>[root@linxkon ~]# <br>[root@linxkon ~]# mv 4.mp3 lk/好日子.xyz# 剪切(文件)并改名<br>[root@linxkon ~]# ls<br>2.avi  aa  anaconda-ks.cfg  a.txt  lk<br>[root@linxkon ~]# ls lk/<br>3.jpg  aa  abc.avi  a.txt  好日子.xyz<br><br>[root@linxkon ~]# mkdir xyz<br>[root@linxkon ~]# ls<br>2.avi  aa  anaconda-ks.cfg  a.txt  lk  xyz<br>[root@linxkon ~]# mv aa xyz# 剪切文件夹, 无需加: -r<br>[root@linxkon ~]# ls<br>2.avi  anaconda-ks.cfg  a.txt  lk  xyz<br>[root@linxkon ~]# ls xyz/<br>aa<br><br><br>[root@linxkon ~]# ls<br>[root@linxkon ~]# touch 1.txt<br>[root@linxkon ~]# <br>[root@linxkon ~]# mv 1.txt abc.txt# 改名操作<br>[root@linxkon ~]# ls<br>abc.txt<br></code></pre></td></tr></table></figure><h4 id="rm命令-来源于-remove单词-可以删除-文件-文件夹">10.rm命令, 来源于remove单词, 可以删除 文件, 文件夹</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">rm [-r -f] 要删除的文件或者文件夹路径# -r:递归,  -f: force(强制)<br><br>[root@linxkon ~]# rm -rf lk# 强制删除 lk文件夹, 且不询问<br>[root@linxkon ~]# ls<br>anaconda-ks.cfg  xyz<br>[root@linxkon ~]# touch 1.txt 2.txt 3.avi 4.avi 5.jpg<br>[root@linxkon ~]# ls<br>1.txt  2.txt  3.avi  4.avi  5.jpg  anaconda-ks.cfg  xyz<br>[root@linxkon ~]# rm -rf *.txt<br>[root@linxkon ~]# ls<br>3.avi  4.avi  5.jpg  anaconda-ks.cfg  xyz<br>[root@linxkon ~]# rm -rf *# 清空当前文件夹<br>[root@linxkon ~]# ls<br>[root@linxkon ~]# rm -rf /*  ^C# 慎用<br></code></pre></td></tr></table></figure><h4 id="一个坐牢命令">11.一个坐牢命令</h4><figure class="highlight shell"><figcaption><span>rm -rf</span><a href="/*">link</a></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">rm -rf /* #删除系统<br></code></pre></td></tr></table></figure><h2 id="查找命令">查找命令</h2><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">### 12.which命令,  查找Linux可执行命令 的路径的.</span></span> <br>  which ls# /usr/bin/ls<br>  which pwd# /usr/bin/pwd<br>  <br>  which ifconfig# /usr/sbin/ifconfig<br>  <br><span class="hljs-meta prompt_">  </span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment">### 13.find命令, 根据文件名, 或者 文件大小查找指定文件.</span></span><br><span class="hljs-meta prompt_">  # </span><span class="language-bash">格式</span><br>  find 要被检索的目录路径 -name &#x27;要检索的文件名&#x27;<br>  <br>  find / -name &#x27;abc*&#x27;# 查找Linux中, 以abc开头的内容.<br>  <br><span class="hljs-meta prompt_">  # </span><span class="language-bash">格式</span><br>  find 要被检索的目录路径 -size +100M# 超过100MB,  -10K, 小于10KB<br>  <br>  find / -size +100M# 查找Linux中, 文件大小超过100M的文件.<br></code></pre></td></tr></table></figure></p><p>—————————————————华丽的分割线—————————————————<img src="/images/2024年5月10日genk.jpg" title="毕加索" alt="dolor"></p>]]></content>
    
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>基础命令</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer：开启AI大模型时代的神奇之匙</title>
    <link href="/Transformer%EF%BC%9A%E4%BA%BA%E7%B1%BB%E8%BF%9B%E5%85%A5AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3%E7%9A%84%E9%92%A5%E5%8C%99.html"/>
    <url>/Transformer%EF%BC%9A%E4%BA%BA%E7%B1%BB%E8%BF%9B%E5%85%A5AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3%E7%9A%84%E9%92%A5%E5%8C%99.html</url>
    
    <content type="html"><![CDATA[<p><img src="/images/transformer/transformer.png" /></p><hr /><p>在人工智能的长河中，2017年如同一颗璀璨的明珠，闪耀着非凡的光芒。这一年，Vaswani等学者发表了题为《AttentionIs All YouNeed》的论文，如同智慧的种子，播撒在科技的沃土上，孕育出了Transformer这一革命性的架构。自此，AI的未来如同一幅巨大的画卷被徐徐展开，世界迎来了一个由ScaleLaw主宰的大模型时代。Transformer，这把神奇的智慧之匙，开启了通向无尽可能的大门，为人工智能注入了前所未有的力量与灵性。</p><p><strong>注意力机制：智慧之灯，照亮认知的殿堂</strong></p><p>Transformer的灵魂，是那璀璨夺目的<strong>自注意力机制</strong>（Self-AttentionMechanism）。如同一位洞悉一切的智者，它让模型在捕捉每个信息元素的精髓时，都能与序列中的其他元素进行深入的对话，汲取它们的智慧。这种机制赋予了模型超凡的洞察力，使其能够如阅读一部复杂的哲学巨作般，全方位地理解和诠释信息的深邃意涵。</p><p>自注意力机制的引入，不仅如同一道光芒穿透了传统神经网络的重重迷雾，还为Transformer披上了并行计算的战袍。这意味着模型可以如同一位全能的指挥家，同时指挥整个交响乐团，让每一个音符都在最恰当的时刻奏响，极大地提升了训练的韵律与效率。更为神奇的是，自注意力机制让模型如同牵起一条无形的丝线，轻松地跨越时空，捕捉远隔千里的语义关联，这在自然语言处理的艺术中，恰如画龙点睛之笔。</p><p>而<strong>多头注意力机制</strong>（Multi-HeadAttention）则是Transformer皇冠上最耀眼的明珠。通过同时编织多个注意力之网，模型如同一位集合了毕加索、莫奈、梵高等大师才华的艺术家，能从多个视角、多个维度解读信息的画卷。这种方法不仅丰富了模型表达的调色盘，还让其作品更加精准、更具生命力。</p><p>多头注意力机制的引入，使得Transformer模型如同一位文艺复兴时期的全才，既能解读复杂的哲学论题，又能创作出震撼人心的艺术杰作，每一个思考，每一次创作，都闪烁着智慧的金光。</p><p><strong>位置编码：时空之罗盘，引领未来航程</strong></p><p>在Transformer的殿堂中，<strong>位置编码</strong>（PositionalEncoding）扮演着时空导航者的角色。由于Transformer如同一位自由的思想家，不受限于顺序的束缚，它需要位置编码这一时空罗盘，为每一个信息元素标注其在序列中的坐标。这一机制确保了模型能如同一位通晓古今的学者，精准把握语言中每一个词语的位置意义，使其在处理语言这一时序敏感的艺术时，依然能够演绎出令人叹服的华章。</p><p>位置编码的引入，如同为AI模型配备了一只刻度精密的时空罗盘，引领它们在信息的汪洋大海中乘风破浪，找到真知灼见的宝藏之岛。</p><p><strong>大规模预训练：开启智慧宝库，启迪无尽可能</strong></p><p>Transformer架构的这些特性，使其成为大规模预训练模型的理想之选。通过在浩如烟海的未标注数据中遨游，模型如同一位勤奋的学者，在知识的海洋中汲取丰富的语言精华，然后在具体任务的画布上点染出精妙的色彩。这种预训练-微调的艺术，已经在自然语言处理的殿堂中谱写了辉煌的乐章，而BERT、GPT等模型便是其中最动听的音符。</p><p>大规模预训练模型的成功，如同一道曙光，照亮了AI研究的新纪元。模型的通用性和迁移能力，使它们如同一位身怀绝技的大师，在不同的舞台上都能演绎出惊艳世人的表演，推动了无数实际应用从理论的云端落地生根。从搜索引擎到对话系统，从自动翻译到内容生成，AI的智慧之手已经春风化雨的地浸润着我们生活的每一个角落。</p><p><strong>影响和未来：智慧之树，枝叶繁茂</strong></p><p>Transformer架构及其相关技术的突破，如同一阵春风，不仅在自然语言处理的园地里催生了革命性的变化，也开始在计算机视觉、语音识别等领域播撒希望的种子。而这些智慧的嫩芽，在人工智能的广袤大地上破土而出，迅速长成枝叶繁茂的大树，结出累累硕果。Transformer，这把开启大模型时代的神奇之匙，不仅象征着技术的飞跃，更预示着人类智慧之树将会枝繁叶茂，根系深广，为未来世界投射下智慧的清凉绿荫。让我们以诗人的热情与哲学家的沉思，拥抱这个智慧的新纪元，共同见证AI这部人类智慧的壮丽史诗。</p><blockquote><p>主创：linxkon</p><p>二作：GPT4</p><p>润色：Claude</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>transformer</tag>
      
      <tag>宣传介绍</tag>
      
      <tag>claude，chatGPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>集成学习常见模型比对</title>
    <link href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A6%81%E7%82%B9%E5%AF%B9%E6%AF%94.html"/>
    <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A6%81%E7%82%B9%E5%AF%B9%E6%AF%94.html</url>
    
    <content type="html"><![CDATA[<p>集成学习的基础思想是通过组合多个基学习器形成整体强学习器,使基学习器在预测准确性、降低过拟合风险、增强模型的鲁棒性等方面获得明显提升,集成学习主要包含Bagging和Boosting两大分类。本文对比总结了四种集成学习常见模型。</p><span id="more"></span><p>Bagging是一种并行式的集成学习方法，其特点包括通过有放回的抽样产生不同的训练集，从而训练多个不同的学习器，并通过平均投票或多数表决的方式决定预测结果。此外，Bagging允许弱学习器并行训练，代表算法包括随机森林算法。</p><p>Boosting是一种串行式的集成学习方法，其特点是随着学习的积累从弱到强，每加入一个弱学习器，整体能力会得到提升。Boosting对学习器进行加权投票，采用串行方式进行学习，具有明确的先后顺序。代表算法包括Adaboost、GBDT、XGBoost以及LightGBM。</p><p><img src="/images/集成学习常见模型对比/集成学习对比示意.png" /></p><table><thead><tr class="header"><th>模型</th><th>核心要点</th><th>模型优缺点</th><th>模型应用</th></tr></thead><tbody><tr class="odd"><td>Bagging随机森林</td><td>1. 随机有放回的抽样产生不同的训练集(boostrap)<br>2.基于不同抽样训练多个基学习器（如决策树）<br>3.通过投票或平均组合预测结果</td><td>优点:<br>- 泛化错误率低<br>-易于并行训练<br>缺点:<br>-性能上限低</td><td>1. 分类问题<br>2. 回归问题</td></tr><tr class="even"><td>Adaptive Boosting</td><td>1. 迭代构建弱学习器<br>2.聚焦错误样本,每轮根据分类结果调整样本及模型权重<br>3.组合加权弱学习器成强学习器</td><td>优点:<br>- 泛化能力强<br>- 易于处理多种数据<br>缺点:<br>-对离群点敏感<br>- 需要预处理高维或不平衡数据</td><td>1. 分类问题<br>2. 图像识别</td></tr><tr class="odd"><td>GBDT (梯度提升树)</td><td>1. 迭代构建决策树<br>2. 拟合损失函数的负梯度训练新树<br>3.累加方式构建最终模型</td><td>优点:<br>- 准确性高<br>- 可以适应多种损失函数<br>缺点:<br>-容易过拟合<br>- 计算量大</td><td>1. 回归问题<br>2. 排名问题<br>3. 分类问题</td></tr><tr class="even"><td>XGBoost</td><td>1. 基于GBDT的高效实现<br>2. 加入正则化项解决GBDT过拟合问题<br>3.损失函数泰勒二阶近似优化拟合函数<br/>4.支持并行化和缺失值处理</td><td>优点:<br>- 速度快<br>- 准确性高,防止过拟合<br>-支持多种目标函数和评估指标<br>缺点:<br>- 参数调整复杂<br>-可能需要更多的内存</td><td>1. 赢取竞赛的首选算法<br>2. 排名问题<br>3. 分类和回归问题</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>categories</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>集成学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>总结归纳</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客上云 纵享丝滑</title>
    <link href="/%E5%8D%9A%E5%AE%A2%E4%B8%8A%E4%BA%91%E7%BA%B5%E4%BA%AB%E4%B8%9D%E6%BB%91.html"/>
    <url>/%E5%8D%9A%E5%AE%A2%E4%B8%8A%E4%BA%91%E7%BA%B5%E4%BA%AB%E4%B8%9D%E6%BB%91.html</url>
    
    <content type="html"><![CDATA[<p>让你的博客上云，体验丝般顺滑~</p><span id="more"></span><h1 id="一工作原理">一、工作原理</h1><p>使用Hexo搭建个人博客并自动部署到阿里云ECS服务器的原理如下图所示：</p><p><a href="/images/hexo_aliyun/Hexo_ALiYun.jpg"><imgsrc="/images/hexo_aliyun/Hexo_ALiYun.jpg"alt="基于Hexo的博客搭建和阿里云部署原理" /></a></p><p>简单来说就是在本地计算机搭建Hexo环境，Hexo通过generate命令将*.md文件渲染成静态的html页面，然后Hexo通过deploy命令触发git用户通过公钥免密登陆服务器，进而将静态页面推送到服务器的git仓库（repository）中。然后，服务器再通过钩子（git-hooks）将静态页面checkout到网站的根目录下，进而实现博客的自动部署。具体过程如图中实线箭头所示。</p><h1 id="二搭建步骤">二、搭建步骤</h1><h2 id="在本地计算机安装hexo环境">1、在本地计算机安装Hexo环境</h2><p>首先需要说明的是：我本地使用的是Win10（64位）操作系统。更权威的安装过程可以参照<ahref="https://hexo.io/zh-cn/">Hexo官方主页</a>。</p><h3 id="安装node.js">1.1 安装Node.js</h3><p>去<a href="https://nodejs.org/en/">Node.js官网</a>下载Windows(x64)长期支持版 Long Term Support (LTS)schedule。按提示逐步安装即可，安装完成后打开cmd查看版本号验证是否安装成功。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">C:\Users\tangcl&gt; <span class="hljs-keyword">node</span> <span class="hljs-title">-v</span><br>v12.<span class="hljs-number">13.1</span><br></code></pre></td></tr></table></figure><p>Node.js中自带了npm包管理工具，在cmd中查看npm版本。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">C</span>:\Users\tangcl&gt; npm -v<br><span class="hljs-attribute">6</span>.<span class="hljs-number">12</span>.<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h3 id="安装git">1.2 安装Git</h3><p>git是一个版本控制工具，国外镜像下载巨慢，建议前往<ahref="https://npm.taobao.org/mirrors/git-for-windows/">淘宝 Git forWindows 镜像</a>下载 git安装包。按提示逐步安装即可，安装完成后右键菜单中出现Git Bash和GitGUI菜单表明安装成功，如下图所示。 <ahref="/images/hexo_aliyun/git_menu.png"><imgsrc="/images/hexo_aliyun/git_menu.png" alt="git右键菜单" /></a></p><p>注：git和github是两个东西。github是基于git二次开发的，git是github的核心，git负责与github相关的所有本地工作。</p><h3 id="安装hexo">1.3 安装Hexo</h3><p>在D盘新建MyHexoBlogs文件夹用来存放个人博客，进入该文件夹，右键打开GitBash，使用 npm 安装 Hexo。</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">npm install -g hexo-<span class="hljs-keyword">cli</span><br></code></pre></td></tr></table></figure><p>运行结果如下： <a href="/images/hexo_aliyun/installHexo.png"><imgsrc="/images/hexo_aliyun/installHexo.png" alt="安装Hexo" /></a>Hexo安装完成后，在MyHexoBlogs文件夹下新建myblogs项目，并对其进行初始化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo init myblogs<br><span class="hljs-built_in">cd</span> myblogs<br>npm install<br></code></pre></td></tr></table></figure><p>此时，会在MyHexoBlogs文件夹下新建myblogs文件夹，并在其内部生成相应的项目文件。如下图所示：<a href="/images/hexo_aliyun/files.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="文件" /></a> 在myblogs文件夹下启动hexo服务。</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta">hexo <span class="hljs-keyword">server</span><br></code></pre></td></tr></table></figure><p>此时在本地打开浏览器，通过 http://localhost:4000/便可访问基于Hexo的个人博客主页了。如下图所示： <ahref="/images/hexo_aliyun/hexo.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="个人博客本地主页" /></a></p><h2 id="服务端准备工作">2、服务端准备工作</h2><h3 id="域名注册">2.1 域名注册</h3><p>网站搭建之前我们需要注册自己的域名，因为我们不可能让用户通过“公网IP+端口”的方式访问我们的服务器，这样太不方便记忆了。</p><p>因为万网已被阿里收购，所以对于阿里云用户，我们可以直接在<ahref="https://wanwang.aliyun.com/?spm=5176.12825654.eofdhaal5.9.3dbd2c4anS0SLJ&amp;aly_as=SIqz0Gsr">阿里云域名注册官网</a>上直接注册购买。<a href="/images/hexo_aliyun/yuming.png"><imgsrc="/images/hexo_aliyun/yuming.png" alt="域名注册" /></a>由于域名可以交易，所以域名注册应当有点战略性眼光，应简单直观、方便记忆。域名格式参考是<ahref="http://www.xxxxxx.com/">www.xxxxxx.com</a>。</p><h3 id="域名实名认证">2.2 域名实名认证</h3><p>域名注册过程中，必须进行邮箱和身份证实名认证才可以继续购买，我们只需按提示进行操作即可。</p><h3 id="购买阿里云ecs服务器">2.3 购买阿里云ECS服务器</h3><p>阿里的云服务产品有很多种，如阿里云主机、ECS服务器等。我这里购买的是阿里云ECS服务器。所谓ECS，即弹性计算服务。</p><p>进入阿里云官网的ECS专区购买即可。 <ahref="/images/hexo_aliyun/aliyunECS.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="阿里云ECS" /></a>如下图所示，我这里购买的是双十二入门级活动套餐：实例1核1G（预装CentOS7.4） + 40G高效云盘 + 1M带宽，小白用户选择此配置足以。</p><p><a href="/images/hexo_aliyun/myECS.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="我的ECS配置" /></a>付款成功后，你就拥有一个属于自己的ECS服务器实例了。所谓实例，就是一台装了CentOS的电脑。接下来就是对该实例进行设置，并在它上面搭建相应的部署环境了。</p><h3 id="ecs服务器备案">2.4 ECS服务器备案</h3><p>备案需要有服务器和域名。</p><p>国家法律规定，使用中国大陆境内服务器托管你的网站时，你必须对你的网站进行备案申请。当你使用阿里云中国大陆境内节点的服务器时，你可以直接在<ahref="https://beian.aliyun.com/">阿里云备案管理系统</a>中提交ICP备案申请。<a href="/images/hexo_aliyun/beian.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="备案" /></a>ICP备案申请审核通过后，管局（工信部）会给我们一个ICP备案号，我们需要将备案号在网站底部标明。网站在工信部备案成功后，还需要在网站开通之日起30日内登录<ahref="http://beian.gov.cn/portal/index">全国公安机关互联网站安全管理服务平台</a>提交公安联网备案申请。</p><h3 id="阿里云服务器设置">2.5 阿里云服务器设置</h3><h4 id="重置实例密码">（1）重置实例密码</h4><p>点击阿里云首页的控制台按钮，登录到云服务器管理控制台，便可以查看自己购买的实例了。<a href="/images/hexo_aliyun/control.png"><imgsrc="/images/hexo_aliyun/control.png" alt="登录控制台" /></a>新买的ECS服务器实例对root用户是没有设置初始密码的,ECS服务器的root密码需要重置才能用。重置步骤如下：选中ECS服务器实例，点击下面的重置密码按钮即可重置root用户的密码，密码在实例重启后生效。（该密码必须是字母、数字和其它字符组成的8位以上字符串。）</p><p><a href="/images/hexo_aliyun/shili.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="实例" /></a></p><h4 id="远程连接linux实例">（2）远程连接Linux实例</h4><p>远程连接服务器的方法都很多。我们既可以通过阿里云自带的VNC（VirtualNetworkConsole，虚拟网络控制台）远程连接Linux实例，也可以通过远程连接软件（例如PuTTY、Xshell、SecureCRT等）连接Linux实例。</p><p>我这里用到是VNC方法。需要说明的是：使用阿里云自带的VNC远程连接Linux实例，登录VNC窗口时还要输入一个6位数的远程连接密码，用于连接ECS管理控制台的管理终端，注意不要与root密码混淆。</p><p>注：</p><ul><li>远程连接密码用于连接ECS管理控制台的管理终端，而实例登录密码（root密码）用于登录实例。</li><li>远程连接密码仅在第一次连接管理终端时显示一次，建议启用后立即修改远程连接密码。</li></ul><p>具体连接步骤如下： a.在实例列表中选中当前实例，点击右侧按钮：远程连-&gt;VNC。 b.输入远程连接密码。 <a href="/images/hexo_aliyun/connect.png"><imgsrc="/images/hexo_aliyun/connect.png" alt="远程连接密码" /></a> c.在控制台中输入用户名：root，及其root密码（实例密码）。回车即可进入阿里云ECS服务器的后台，如下图所示。<a href="/images/hexo_aliyun/aliyunServer.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="ECS服务器后台" /></a></p><p>后面，我们主要就是利用此终端在ECS上部署网站运行环境了。</p><h4 id="配置安全组">（3）★ 配置安全组</h4><p>由于我们要通过80端口访问nginx服务，而阿里云默认是禁止80端口访问权限的，所以我们要为实例手动添加安全组，让阿里云给相应的端口和IP放行。该步骤非常重要，若不手动配置，我们将无法通过“公网IP+端口”的方式访问我们的ECS服务器。</p><p>具体操作步骤如下： a.打开阿里云服务管理控制台，点击左侧菜单中的“安全组”按钮，查看安全组列表。b. 点击右上角的“创建安全组”按钮，创建一个新的安全组。 c.立即为新建的安全组添加安全组规则，在入方向解除端口和IP限制，具体参数设置如下图所示。<a href="/images/hexo_aliyun/safe.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="添加安全规则" /></a> d. 在实例列表中为实例添加安全组。</p><p><a href="/images/hexo_aliyun/add.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="为实例添加安全组" /></a></p><p>这样就完成了安全组的配置。<em>注：安全组出方向默认允许所有访问，即从安全组内ECS访问外部都是放行的。</em></p><h2 id="hexo博客的阿里云部署">3、Hexo博客的阿里云部署</h2><p><em>该步骤是整个博客搭建过程中最重要的一步，实现过程中一定要注意是在服务端操作还是在本地计算机上操作。若在服务器上操作，还要注意是使用root用户进行操作还是使用git用户进行操作。</em></p><h3 id="安装nginx">3.1 ★ 安装nginx</h3><p>因为我们用nginx作Web服务器，所以我们需要先安装nginx服务。具体步骤如下：</p><p>使用root用户远程登录阿里云服务器，使用yum命令进行安装。</p><ol type="a"><li>安装nginx依赖环境，安装期间有提示一律选yes。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#yum install gcc-c++</span><br><span class="hljs-meta">#yum install -y pcre pcre-devel</span><br><span class="hljs-meta">#yum install -y zlib zlib-devel</span><br><span class="hljs-meta">#yum install -y openssl openssl-devel</span><br></code></pre></td></tr></table></figure><ol start="2" type="a"><li>下载nginx安装包。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#wget -c https:<span class="hljs-comment">//nginx.org/download/nginx-1.10.1.tar.gz</span></span><br></code></pre></td></tr></table></figure><ol start="3" type="a"><li>将安装包解压到/usr/local目录下。</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-id">#tar</span> -xvf nginx-<span class="hljs-number">1.10</span>.<span class="hljs-number">1</span><span class="hljs-selector-class">.tar</span><span class="hljs-selector-class">.gz</span> -C /usr/local<br></code></pre></td></tr></table></figure><ol start="4" type="a"><li>进入/usr/local目录，确认nginx解压到该目录下。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">cd</span> /usr/local</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">ls</span></span><br></code></pre></td></tr></table></figure><ol start="5" type="a"><li>进入nginx-1.10.1目录，会发现该目录下有一个configure文件，执行该配置文件。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">cd</span> nginx-1.10.1/</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">ls</span></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">./configure</span><br></code></pre></td></tr></table></figure><ol start="6" type="a"><li>编译并安装nginx。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#make</span><br><span class="hljs-meta">#make install</span><br></code></pre></td></tr></table></figure><ol start="7" type="a"><li>查找nginx安装目录。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#whereis nginx</span><br></code></pre></td></tr></table></figure><p>h.进入安装目录。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">cd</span> /usr/local/nginx</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">ls</span></span><br></code></pre></td></tr></table></figure><ol type="i"><li>由于nginx默认通过80端口访问，而Linux默认情况下不会开发该端口号，因此需要开放linux的80端口供外部访问。</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">#/sbin/iptables -<span class="hljs-selector-tag">I</span> <span class="hljs-selector-tag">INPUT</span> -<span class="hljs-selector-tag">p</span> tcp <span class="hljs-attr">--dport</span> <span class="hljs-number">80</span> -j ACCEPT<br></code></pre></td></tr></table></figure><ol start="10" type="a"><li>进入/usr/local/nginx/sbin目录，启动nginx。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">cd</span> sbin</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">./nginx</span><br></code></pre></td></tr></table></figure><p>没有任何消息，代表启动成功。此时，便可以通过“公网IP+端口”的方式访问<a href="http://xx.xx.xxx.xxx/">http://xx.xx.xxx.xxx:80/</a>进入nginx欢迎页面了。 <strong>注：</strong> <strong>（1）可以使用./nginx-s stop命令停止服务；</strong><strong>（2）网站搭建成功后，若出现宕机现象，很有可能是nginx服务器挂了，此时应检查nginx服务器状态，并进行重启操作。</strong></p><h3 id="配置nginx服务器路由">3.2 配置nginx服务器路由</h3><ol type="a"><li>专门为hexo创建一个部署目录/home/www/hexo。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">mkdir</span> -p /home/www/hexo</span><br></code></pre></td></tr></table></figure><ol start="2" type="a"><li>进入/usr/local/nginx/conf目录，打开该文件夹下的nginx.conf配置文件。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">cd</span> /usr/local/nginx/conf</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">ls</span></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">vim nginx.conf</span><br></code></pre></td></tr></table></figure><p>进入后按i键由命令模式切换到编辑模式。</p><ul><li>将其中的部署根目录（root）修改为/home/www/hexo；</li><li>将域名（server_name）<ahref="http://xn--www-c88dx1fq77c.xxxxxx.com/">修改为www.xxxxxx.com</a>，如果暂时没有域名就填阿里云实例的公网ip，以后有了再改回来；</li><li>查看监听端口（listen）的系统默认值是否为80（不用修改）。</li></ul><p>完成以上修改后，先按Esc由编辑模式切换到命令模式，再输入:wq命令保存并退出编辑器。</p><h3 id="安装node.js-1">3.3 安装node.js</h3><ol type="a"><li>退回根目录，安装node.js。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">cd</span> ~</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">curl -sL https://rpm.nodesource.com/setup_10.x | bash -</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">yum install -y nodejs</span><br></code></pre></td></tr></table></figure><ol start="2" type="a"><li>查看安装结果，打印版本号即为安装成功。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#node -v</span><br><span class="hljs-meta">#npm -v</span><br></code></pre></td></tr></table></figure><h3 id="安装git-1">3.4 安装Git</h3><ol type="a"><li>使用yum命令安装Git，安装期间有提示一律选yes。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#yum install git</span><br></code></pre></td></tr></table></figure><ol start="2" type="a"><li>安装成功后，查看版本号。</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-id">#git</span> <span class="hljs-attr">--version</span><br></code></pre></td></tr></table></figure><h3 id="创建git用户">3.5 创建git用户</h3><p>为了实现博客的自动部署，我们后面要使用公钥免密登录服务器。为了安全起见，最好不要使用root用户免密登录。因此，我们要创建一个新的git用户，用于远程公钥免密登录服务器。</p><ol type="a"><li>创建git用户。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#adduser git</span><br></code></pre></td></tr></table></figure><ol start="2" type="a"><li>修改git用户的权限。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">chmod</span> 740 /etc/sudoers</span><br></code></pre></td></tr></table></figure><ol start="3" type="a"><li>打开文件。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">vim /etc/sudoers</span><br></code></pre></td></tr></table></figure><p>进入后按i键由命令模式切换到编辑模式。找到 root ALL=(ALL)ALL，在下面添加一行 <strong>git ALL=(ALL)ALL</strong>。修改完成后，先按Esc由编辑模式切换到命令模式，再输入:wq命令保存并退出编辑器。</p><ol start="4" type="a"><li>保存退出后改回权限。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">chmod</span> 400 /etc/sudoers</span><br></code></pre></td></tr></table></figure><ol start="5" type="a"><li>设置git用户的密码。</li></ol><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-meta">#sudo passwd git</span><br></code></pre></td></tr></table></figure><p>设置密码：************，这样我们就可以使用git用户远程登录阿里云服务器了。</p><h3 id="给git用户配置ssh免密公钥登录">3.6 ★给git用户配置ssh免密公钥登录</h3><p>该步骤是基于Hexo搭建个人博客的核心步骤，也是坑我时间最长的地方。它既需要在本地计算机上操作，也需要在服务器上进行操作，新手一定要搞清原理才不会弄错。</p><p>使用git用户免密公钥登录阿里云服务器的原理是：在本地计算机生成一个公钥文件和一个秘钥文件（类似于一个钥匙配一把锁)，然后使用FTP工具将公钥文件上传到阿里云服务器，并公钥安装到authorized_keys列表中去（即：将公钥文件的内容拷贝到authorized_keys文件中去）。这样本地计算机便可以通过ssh方式免密连接我们的阿里云服务器了。</p><p>具体操作步骤如下：</p><ol type="a"><li>在服务器端将登陆用户切换到git用户，然后在~目录(根目录)下创建.ssh文件夹，用来存放公钥。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">su git</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">cd</span> ~</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">mkdir</span> .ssh</span><br></code></pre></td></tr></table></figure><ol start="2" type="a"><li>在本地计算机桌面右键打开GitBash，在本地生成公钥/私钥对。</li></ol><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-meta"><span class="hljs-keyword">$cd</span> ~</span><br><span class="hljs-meta"><span class="hljs-keyword">$cd</span> .ssh</span><br><span class="hljs-meta"><span class="hljs-keyword">$ssh</span>-keygen</span><br></code></pre></td></tr></table></figure><p>接下来，碰见系统询问就直接按回车键。此时便会在本地计算机的用户根目录（C:）下自动生成.ssh（隐藏）文件夹，并在其中创建两个文件，分别为：id_rsa（私钥）和id_rsa.pub（公钥）。</p><ol start="3" type="a"><li>在本地计算机上给私钥设置权限。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chmod</span> 700 ~/.ssh<br><span class="hljs-built_in">chmod</span> 600 ~/.ssh/id_rsa <br></code></pre></td></tr></table></figure><ol start="4" type="a"><li><p>下载并安装FTP工具，我这里用的是阿里云官方提供的<ahref="https://help.aliyun.com/knowledge_detail/36243.html">FileZilla（Windows版本）</a>。</p></li><li><p>打开FileZilla，使用git用户通过22端口远程连接到阿里云服务器，将客服端生成的公钥上传到服务器的~/.ssh目录下。</p></li></ol><p><a href="/images/hexo_aliyun/ftp.png"><imgsrc="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"alt="FTP" /></a></p><ol start="6" type="a"><li>上传完成后切回服务器端，继续以git用户的身份进入服务器~/.ssh目录，新建一个authorized_keys文件，并将id_rsa.pub文件中公钥的内容拷贝到该文件中。<em>（注：该步骤既可以用命令行操作，也可使用FTP工具操作。）</em></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">cd</span> ~/.ssh</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">cp</span> id_rsa.pub authorized_keys</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">cat</span> id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></code></pre></td></tr></table></figure><ol start="7" type="a"><li>在服务器上设置文件权限：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">chmod</span> 600 ~/.ssh/authorized_keys</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">chmod</span> 700 ~/.ssh</span><br></code></pre></td></tr></table></figure><ol start="8" type="a"><li>确保设置了正确的SELinux上下文。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">restorecon -Rv ~/.ssh <br></code></pre></td></tr></table></figure><p>现在，当您使用ssh远程登录服务器时，将不会提示您输入密码（除非您在创建密钥对时输入了密码）。i. 接下来在本地计算机上使用ssh方式连接我们的云服务器。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-variable">$ssh</span> -v git@xxx<span class="hljs-selector-class">.xxx</span><span class="hljs-selector-class">.xxx</span>.xxx（阿里云公网IP）<br></code></pre></td></tr></table></figure><p>或</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-variable">$ssh</span> git@xxx<span class="hljs-selector-class">.xxx</span><span class="hljs-selector-class">.xxx</span>.xxx（阿里云公网IP）<br></code></pre></td></tr></table></figure><p>使用git用户ssh免密公钥登录成功界面如下图所示。 <ahref="/images/hexo_aliyun/ssh.png"><imgsrc="/images/hexo_aliyun/ssh.png" alt="ssh" /></a></p><h3 id="配置git仓库">3.7 配置Git仓库</h3><ol type="a"><li>在服务器上使用git用户创建一个Git仓库，并且在该仓库中新建一个post-receive钩子文件。</li></ol><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-meta"><span class="hljs-keyword">$cd</span> ~</span><br><span class="hljs-meta"><span class="hljs-keyword">$git</span> init --bare hexo.git</span><br><span class="hljs-meta"><span class="hljs-keyword">$vi</span> ~/hexo.git/hooks/post-receive</span><br></code></pre></td></tr></table></figure><ol start="2" type="a"><li>进入后按i键由命令模式切换到编辑模式。输入： <strong>git--work-tree=/home/www/hexo --git-dir=/home/git/hexo.git checkout-f</strong></li></ol><p>即：让钩子文件删除/home/www/hexo目录下原有的文件，然后从blog.git仓库clone 新的博客静态文件到/home/www/hexo目录下。</p><p>完成以上修改后，先按Esc由编辑模式切换到命令模式，再输入:wq命令保存并退出编辑器。</p><ol start="3" type="a"><li>授予钩子文件可执行权限。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">chmod</span> +x ~/hexo.git/hooks/post-receive</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash"><span class="hljs-built_in">cd</span> ~</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">sudo <span class="hljs-built_in">chmod</span> -R 777 /home/www/hexo</span><br></code></pre></td></tr></table></figure><ol start="4" type="a"><li>重启ECS服务器实例。</li></ol><p>至此我们就完成了所有关于服务器端的配置。</p><h2 id="其它配置">4、其它配置</h2><h3 id="客服端hexo配置">4.1 客服端hexo配置</h3><ol type="a"><li><p>在本地计算机hexo的工程目录下，找到_config.yml，对deploy参数进行修改，如下图所示。<a href="/images/hexo_aliyun/deploy.png"><imgsrc="/images/hexo_aliyun/deploy.png" alt="deploy" /></a></p></li><li><p>在本地计算机安装插件: hexo-deployer-git 和hexo-server。在myblogs文件夹下右键打开GitBash，输入以下命令：</p></li></ol><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-meta"><span class="hljs-keyword">$npm</span> install hexo-deployer-git --save</span><br><span class="hljs-meta"><span class="hljs-keyword">$npm</span> install hexo-server</span><br></code></pre></td></tr></table></figure><p><em>这俩插件的作用分别是使用Git自动部署，和hexo本地简单的服务器。</em></p><ol start="3" type="a"><li>在本地计算机配置Git全局变量。 输入以下命令：</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.email</span> <span class="hljs-string">&quot;xxxxxxxxxx@qq.com&quot;</span><br>git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.name</span> “tangcl”<br></code></pre></td></tr></table></figure><ol start="4" type="a"><li>使用Hexo生成、发布个人博客。</li></ol><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog">hexo clean<br>hexo <span class="hljs-keyword">generate</span><br>hexo deploy<br></code></pre></td></tr></table></figure><p>此时，便可以通过浏览器访问<ahref="http://xxx.xxx.xxx.xxx/">http://xxx.xxx.xxx.xxx:80/</a>进入hexo我的博客主页了。</p><h3 id="域名绑定">4.2 域名绑定</h3><p>待ECS服务器备案审核通过，在阿里云后台对域名解析进行设置，将域名的解析值修改为ECS实例的公网IP。进而完成域名与ECS服务器实例的公网IP进行绑定。</p><p><a href="/images/hexo_aliyun/jiexi.png"><imgsrc="/images/hexo_aliyun/jiexi.png" alt="解析" /></a></p><p>十分钟后，我们便可以通过浏览器访问http://www.xxxxx.com/进入hexo的博客主页了。</p><p><a href="/images/hexo_aliyun/success.png"><imgsrc="/images/hexo_aliyun/success.png" alt="success" /></a></p><h1 id="结束语">结束语</h1><p>新手搭建个人博客过程中难免会出一些小问题，千万不要害怕遇到问题。解决它，你就进步了</p>]]></content>
    
    
    <categories>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>服务器</tag>
      
      <tag>博客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo-fluid数学公式显示问题处理</title>
    <link href="/hexo_fluid%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86.html"/>
    <url>/hexo_fluid%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86.html</url>
    
    <content type="html"><![CDATA[<p>在此补充一下之前公式不显示的问题。</p><span id="more"></span><p>虽然<ahref="https://hexo.fluid-dev.com/docs/">Fluid</a>主题支持<strong>LaTeX数学公式</strong>，但是需要手动操作，而且我按照<ahref="https://hexo.fluid-dev.com/docs/guide/#latex-数学公式">教程</a>开启本功能<code>mathjax</code>没有成功，即公式在网页里并没有被渲染和转换。通过网上查找，发现解决这类问题的思路主要是换渲染引擎，例如<code>pandoc</code>、<code>mathjax</code>、<code>katex</code>。我目前使用<code>mathjax</code>，操作如下：</p><ul><li><p><strong>卸载</strong>默认引擎，并<strong>安装</strong>这个新的渲染引擎</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ada">$ npm uninstall hexo-renderer-marked <span class="hljs-comment">--save </span><br>$ npm install hexo-renderer-kramed <span class="hljs-comment">--saveCopy</span><br></code></pre></td></tr></table></figure></li><li><p>修改<code>/node_modules/hexo-renderer-kramed/lib/renderer.js</code></p><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs arcade"><span class="hljs-comment">// Change inline math rule</span><br><span class="hljs-keyword">function</span> <span class="hljs-title function_">formatText</span>(<span class="hljs-params">text</span>) &#123;<br>  <span class="hljs-comment">// Fit kramed&#x27;s rule: $$ + \1 + $$</span><br>  <span class="hljs-comment">// 直接返回text</span><br>  <span class="hljs-comment">// return text.replace(/`\$(.*?)\$`/g, &#x27;$$$$$1$$$$&#x27;);</span><br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">text</span>;<br>&#125;Copy<br></code></pre></td></tr></table></figure></li><li><p>修改hexo的渲染源码<code>/node_modules/kramed/lib/rules/inline.js</code></p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs r"><span class="hljs-operator">/</span><span class="hljs-operator">/</span> 去掉`\\`的额外转义，第<span class="hljs-number">11</span>行，将其修改为<br><span class="hljs-operator">/</span><span class="hljs-operator">/</span> escape<span class="hljs-operator">:</span> <span class="hljs-operator">/</span><span class="hljs-operator">^</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">\</span>`*&#123;&#125;\[\]()# +\-.!_&gt;])/, <br>escape: /^\\([`<span class="hljs-operator">*</span><span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">\</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">)</span><span class="hljs-comment"># +\-.!_&gt;])/,</span><br><span class="hljs-operator">/</span><span class="hljs-operator">/</span> 将em标签对应的符号中，去掉`_`，第<span class="hljs-number">20</span>行，将其修改为<br><span class="hljs-operator">/</span><span class="hljs-operator">/</span> em<span class="hljs-operator">:</span> <span class="hljs-operator">/</span><span class="hljs-operator">^</span><span class="hljs-punctuation">\</span>b_<span class="hljs-punctuation">(</span><span class="hljs-punctuation">(</span><span class="hljs-operator">?</span><span class="hljs-operator">:</span>__<span class="hljs-operator">|</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">\</span>s<span class="hljs-punctuation">\</span>S<span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-operator">+</span><span class="hljs-operator">?</span><span class="hljs-punctuation">)</span>_<span class="hljs-punctuation">\</span>b<span class="hljs-operator">|</span><span class="hljs-operator">^</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">(</span><span class="hljs-operator">?</span><span class="hljs-operator">:</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-operator">|</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">\</span>s<span class="hljs-punctuation">\</span>S<span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-operator">+</span><span class="hljs-operator">?</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">(</span><span class="hljs-operator">?</span><span class="hljs-operator">!</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">)</span><span class="hljs-operator">/</span><span class="hljs-punctuation">,</span>    <br>em<span class="hljs-operator">:</span> <span class="hljs-operator">/</span><span class="hljs-operator">^</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">(</span><span class="hljs-punctuation">(</span><span class="hljs-operator">?</span><span class="hljs-operator">:</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-operator">|</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">\</span>s<span class="hljs-punctuation">\</span>S<span class="hljs-punctuation">]</span><span class="hljs-punctuation">)</span><span class="hljs-operator">+</span><span class="hljs-operator">?</span><span class="hljs-punctuation">)</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">(</span><span class="hljs-operator">?</span><span class="hljs-operator">!</span><span class="hljs-punctuation">\</span><span class="hljs-operator">*</span><span class="hljs-punctuation">)</span><span class="hljs-operator">/</span><span class="hljs-punctuation">,</span>Copy<br></code></pre></td></tr></table></figure></li><li><p>停止使用 <code>hexo-math</code>，安装<code>hexo-renderer-mathjax</code></p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> npm uninstall hexo-math --save<br><span class="hljs-comment">// 不知道是不是必要的</span><br><span class="hljs-symbol">$</span> npm install hexo-renderer-mathjax --saveCopy<br></code></pre></td></tr></table></figure></li><li><p>更新 <code>Mathjax</code> 的 <code>CDN</code>链接，打开<code>/node_modules/hexo-renderer-mathjax/mathjax.html</code>，在最后一行添加js：</p><ul><li>网上推荐的上面这个，但我使用失败了</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xml">// <span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>Copy<br></code></pre></td></tr></table></figure><ul><li>推荐下面这个，亲测可行，不过偶尔出问题，需要多部署几次就ok</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">script</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>Copy<br></code></pre></td></tr></table></figure><ul><li><strong>更新于2020年6月6日</strong>：如果有人看到这，可以注意下<code>MathJax.js</code>版本已经到3.0.5了，参照mathjax<ahref="https://www.npmjs.com/package/mathjax#installation-and-use">文档</a>，那么现在的上面的一步可以自行修改，如果控制台报错可以到<ahref="https://cdn.jsdelivr.net/npm/mathjax@3/es5/">mathjax CDNfiles</a>下找到合适的js代替</li></ul><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs applescript">&lt;<span class="hljs-keyword">script</span> <span class="hljs-built_in">id</span>=<span class="hljs-string">&quot;MathJax-script&quot;</span> async<br>  src=<span class="hljs-string">&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js&quot;</span>&gt;<br>&lt;/<span class="hljs-keyword">script</span>&gt;Copy<br></code></pre></td></tr></table></figure><ul><li>当然，如果博客的<strong>内部静态</strong>文件<strong>第三方库</strong>包含了mathjax，上面的<code>MathJax.js</code>不用导入都行，导的不对甚至有冲突，虽然不影响公式的显示，但会在控制台报错。</li></ul></li></ul><p>经过<strong><ahref="https://github.com/Ningsir">Ningsir</a></strong>提醒，删除掉hexo-renderer-mathjax就行了，简单省事。</p><ul><li><p>按照<a href="https://hexo.fluid-dev.com/docs/">Fluid</a>的<ahref="https://hexo.fluid-dev.com/docs/guide/#快速开始">快速开始</a>，需要修改<strong>主题配置</strong>，打开<code>/source/_data/fluid_config.yml</code>文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">post:</span><br>  <span class="hljs-attr">math:</span>  <br>    <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span>  <br>    <span class="hljs-attr">specific:</span> <span class="hljs-literal">false</span>   <br>    <span class="hljs-attr">engine:</span> <span class="hljs-string">mathjaxCopy</span><br></code></pre></td></tr></table></figure></li><li><p>在根目录下修改<code>_config.yml</code>，添加</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">mathjax: <span class="hljs-literal">true</span>Copy<br></code></pre></td></tr></table></figure></li><li><p>在<code>Front-matter</code>中打开<code>MathJax</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br>  <span class="hljs-attr">layout:</span> <span class="hljs-string">post</span><br>  <span class="hljs-attr">title:</span> <span class="hljs-string">title</span><br>  <span class="hljs-attr">date:</span> <span class="hljs-string">date</span><br>  <span class="hljs-attr">categories:</span> <br>  <span class="hljs-bullet">-</span> <span class="hljs-string">categories</span><br>  <span class="hljs-attr">tags:</span> <br>  <span class="hljs-bullet">-</span> <span class="hljs-string">tags1</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">tags2</span><br>  <span class="hljs-attr">mathjax:</span> <span class="hljs-literal">true</span><br><span class="hljs-string">---Copy</span><br></code></pre></td></tr></table></figure></li><li><p>显示数学公式 <span class="math display">\[\Sigma({n} ;{p})=\left\{\left(\zeta_{1}, \ldots, \zeta_{r}\right) \in\mathbb{C}^{n_{1}} \times \cdots \times \mathbb{C}^{n_{r}}:\sum_{k=1}^{r}\left\|{\zeta}_{k}\right\|^{2 p_{k}} &lt;1\right\}\]</span></p></li></ul><p>最后如果公式还是乱码可以尝试重启电脑，然后先尝试部署一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hexo clean&amp;&amp;hexo g&amp;&amp;hexo d&amp;&amp;hexo s<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>categories</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客维护</tag>
      
      <tag>数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性回归知识点梳理</title>
    <link href="/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86.html"/>
    <url>/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86.html</url>
    
    <content type="html"><![CDATA[<p>🏠线性回归可以称得上最经典的回归模型，从房子值多少钱，再到股票价格的涨跌🌈，疾病与各种因素的关联，广告投放的收益等，都使它擅长的领域💼接下来让我们走进线性回归💖</p><span id="more"></span><h3 id="线性回归的概念">1.线性回归的概念</h3><h5id="利用-回归方程函数-对-一个或多个自变量特征值和因变量目标值之间-关系进行建模的一种分析方式.">利用回归方程(函数) 对 一个或多个自变量(特征值)和因变量(目标值)之间关系进行建模的一种分析方式.</h5><h5 id="yw1x1w2x2....wnb-wtb">y=w1x1+w2x2+....+w(n)+b= wT+b</h5><ul><li>w=weight</li><li>b=bias wT x为将权重系数转置并与x相乘,矩阵的乘法</li></ul><h5 id="常用于分类与回归问题">常用于分类与回归问题</h5><h3 id="损失函数">2.损失函数</h3><h5 id="loss-functioncost-function目标函数成本函数">loss function/costfunction/目标函数/成本函数</h5><h5 id="最小二乘损失计算">最小二乘损失计算:</h5><p><span class="math display">\[J(w,b)=\sum_{i=0}^m\bigl(h\bigl(x^i\bigr)-y^i\bigr)^2\]</span></p><h5 id="均方误差mse">均方误差MSE</h5><p><span class="math display">\[J(w,b)=\frac1m\sum_{i=0}^m\left(h\left(x^i\right)-y^i\right)^2\]</span></p><h5 id="平均绝对误差mae">平均绝对误差MAE</h5><h5id="注-mse与mae既能在模型训练阶段作为损失函数求解拟合函数最优解又可作为模型评估阶段衡量已有模型误差大小">注:MSE与MAE既能在模型训练阶段作为损失函数求解拟合函数最优解,又可作为模型评估阶段,衡量已有模型误差大小</h5><h3 id="损失函数推导_正规方程法">3.损失函数推导_正规方程法</h3><p><span class="math display">\[J(w) =∥Xw−y∥_2^2\]</span></p><p><span class="math display">\[w=(X^TX)^{-1}*X^Ty\]</span></p><h5 id="优点可以精确求解">优点:可以精确求解</h5><h5 id="缺点计算量极大xt-x的逆不存在时无解">缺点:计算量极大,X^TX的逆不存在时无解</h5><h3 id="梯度与导数">4.梯度与导数</h3><h5id="导数表征了函数在某点处的变化速率.">导数表征了函数在某点处的变化速率.</h5><h5 id="梯度gradient">梯度（gradient）</h5><ul><li>多元函数中，导数不再是一个单一的数值，而是一个向量，因为它涉及到函数对多个自变量的变化率。这个向量被称为梯度（gradient），它表示了函数在某一点上沿着各个自变量方向的变化率。</li></ul><h5 id="梯度的性质">梯度的性质</h5><ul><li>梯度的方向是函数在给定点增长最快的方向。</li><li>梯度的模（长度）是函数在给定点处沿最大增长方向的增长率</li><li>梯度是垂直于等值面的</li><li>对函数求导</li></ul><p><span class="math display">\[f(\theta)=\theta_0x_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\cdots+\theta_nx_n\]</span></p><p><span class="math display">\[\nabla f=\begin{bmatrix}\frac{\partialf}{\partial\theta_0}\\\frac{\partialf}{\partial\theta_1}\\\vdots\\\frac{\partialf}{\partial\theta_n}\end{bmatrix}=\begin{bmatrix}x_0\\x_1\\\vdots\\x_n\end{bmatrix}\]</span></p><h3 id="梯度下降">5.梯度下降</h3><h5 id="梯度下降公式"><strong>梯度下降公式</strong></h5><ul><li>循环迭代求当前点的梯度，更新当前的权重参数</li><li></li></ul><p><span class="math display">\[\theta_{i+1}=\theta_i-\alpha\frac\partial{\partial\theta_i}J(\theta)\]</span> - θ_i:初始位置 α:学习率(步长),一般取值范围0.001 ~ 0.01 ∂/(∂θ_i) J(θ) :损失函数在i处的导数</p><h5 id="梯度下降优化过程"><strong>梯度下降优化过程 </strong></h5><ul><li><p>给定学习率,步长,初始位置</p></li><li><p>计算该点梯度方向并取反</p></li><li><p>向梯度反方向移动</p></li><li><p>重复以上步骤</p></li><li><p>达到收敛条件</p><ul><li>两次差距小于指定的阈值 •</li><li>达到指定的迭代次数</li></ul></li></ul><h5 id="学习率"><strong>学习率</strong></h5><ul><li>步长决定了在梯度下降迭代过程中</li><li>学习率太小，下降的速度会慢</li><li>学习率太大：容易造成错过最低点、产生下降过程中的震荡、甚至梯度爆炸</li></ul><h5 id="推导过程">推导过程</h5><ul><li>已知</li></ul><p><span class="math display">\[h_{(\theta)}=\theta_{1}x_{1}+\theta_{2}x_{2}+\cdots+\theta_{\mathrm{m}}x_{\mathrm{m}}+b\\=\theta_{0}x_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+\cdots+\theta_{\mathrm{m}}x_{\mathrm{m}}\]</span> - 损失函数</p><p><span class="math display">\[J_{(\theta)}=\frac1{2m}\sum_{i=1}^m(h_\theta(x^i)-y^i)^2\]</span> - 梯度下降公式</p><p><span class="math display">\[\theta_{i+1}=\theta_i-\alpha\frac\partial{\partial\theta_i}J(\theta)\]</span></p><ul><li>对损失函数求导</li></ul><p><span class="math display">\[J&#39;_{(\theta)}=\frac{\partial\mathrm{J}(\theta)}{\partial\theta}=\frac{2*1}{2m}\sum_{i=1}^{m}(h_{\theta}\big(x^{i}\big)-y^{i})^{2-1}*h_{\theta}\big(x^{i}\big)^{\prime}\]</span> - <strong>带入梯度下降公式</strong></p><p><span class="math display">\[\theta_j=\theta_j-\alpha\frac1m\sum_{i=1}^m(h_\theta(x^i)-y^i)*x_j^i\]</span> - 参数说明</p><p>θ_j:当前损失函数的梯度位置/原函数的特征权重<br />m,n:行数,列数<br />i,j:列索引,行索引<br />x,y:特征向量与目标向量</p><h3 id="常见梯度下降算法">6.常见梯度下降算法</h3><h5 id="全梯度下降算法-fgd">全梯度下降算法 FGD</h5><ul><li>每次迭代使用全样本梯度<br /></li><li>(硬件要求极高,数据量大时无法实现)</li></ul><h5 id="随机梯度下降-sgd">随机梯度下降 SGD</h5><ul><li>每次迭代随机选择并使用一个样本梯度<br /></li><li>(容易受异常值影响)</li></ul><h5id="小批量梯度下降算法-mini-bantch-最常用"><strong>小批量梯度下降算法mini-bantch 最常用√</strong></h5><ul><li>每次迭代随机选择并使用小批量的样本梯度<br /></li><li>(在硬件性能满足的情况下,每批的量应该尽可能大)</li></ul><h5 id="随机平均梯度下降-sag">随机平均梯度下降 SAG</h5><ul><li>每次迭代随机选择并使用一个样本梯度并和以往样本梯度值做平均</li><li>(解决异常值影响问题,但训练初期受异常值影响较大)</li></ul><h3 id="回归问题的评估方法">7.回归问题的评估方法</h3><h5 id="平方误差mse">平方误差MSE</h5><p><span class="math display">\[=\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}\]</span></p><h5 id="平均绝对误差mae-1">平均绝对误差MAE</h5><p><span class="math display">\[=\frac{1}{n}\sum_{i=1}^{n}|y_{i}-\hat{y}_{i}|\]</span></p><h5 id="均方根误差">均方根误差</h5><p><span class="math display">\[RMSE=\sqrt{\frac1n\sum_{i=1}^n\left(y_i-\hat{y}_i\right)^2}\]</span></p><h3 id="模型拟合">8.模型拟合</h3><h5 id="过拟合"><strong>过拟合</strong></h5><ul><li><p>原因</p><ul><li>模型过于复杂,学习到了过多异常特征</li><li>数据噪声大</li></ul></li><li><p>解决方案</p><ul><li>数据清洗</li><li>正则化</li><li>精简特征维度</li><li>增加数据量</li></ul></li></ul><h5 id="欠拟合"><strong>欠拟合</strong></h5><ul><li><p>原因</p><ul><li>模型复杂度低</li><li>特征选择不当</li><li>数据量不足</li><li>正则化过度</li></ul></li><li><p>解决方案</p><ul><li>添加多项式特征项</li><li>添加其它特征</li><li>增加训练量</li></ul></li></ul><h3 id="正则化">9.正则化</h3><h5id="概念在模型训练时数据中有些特征影响模型复杂度或者某个特征的异常值较多-所以要尽量减少这个特征的影响甚至删除某个特征的影响这就是正则化正则化是添加在损失函数中的特殊项.">概念:在模型训练时，数据中有些特征影响模型复杂度、或者某个特征的异常值较多，所以要尽量减少这个特征的影响（甚至删除某个特征的影响），这就是正则化。正则化是添加在损失函数中的特殊项.</h5><h5 id="l1正则化"><strong>L1正则化:</strong></h5><p><span class="math display">\[J(w)=\mathrm{MSE}(w)+\alpha\sum_{i=1}^{n}\mid w_{i}\mid\]</span> - • α叫做惩罚系数，该值越大则权重调整的幅度就越大，即：表示对特征权重惩罚力度就越大- L1 正则化会使得权重趋向于 0，甚至等于0，使得某些特征失效，达到特征筛选的目的 - from sklearn.linear_modelimport Lasso</p><h5 id="l2正则化"><strong>L2正则化</strong></h5><ul><li></li></ul><p><span class="math display">\[J(w)=\mathrm{MSE}(w)+\alpha\sum_{i=1}^nw_i^2\]</span> - L2 正则化会使得权重趋向于 0，一般不等于 0 - fromsklearn.linear_model import Ridge - L2的线性回归又称为岭回归</p>]]></content>
    
    
    <categories>
      
      <category>categories</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>笔记整理</tag>
      
      <tag>回归模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
