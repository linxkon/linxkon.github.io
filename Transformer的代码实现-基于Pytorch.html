

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/linxkon_blog.png">
  <link rel="icon" href="/img/linxkon_blog.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="linxkon">
  <meta name="keywords" content="æŠ€æœ¯åˆ†äº«ï¼Œé¡¹ç›®å®æˆ˜ï¼Œç”Ÿæ´»è®°å½•">
  
    <meta name="description" content="æœ¬æ–‡æ˜¯Transfomrerçš„Pytorchç‰ˆæœ¬å®ç°. å®ç°çš„è¿‡ç¨‹ä¸­éå¸¸è€ƒéªŒç»´åº¦æ§åˆ¶çš„åŠŸåº•. æœ¬æ–‡å®ç°å‚è€ƒTransformer çš„ PyTorch å®ç°, æˆ‘å¯¹å…¶åœ¨ä¸ªåˆ«åœ°æ–¹è¿›è¡Œäº†ä¿®æ”¹, å¹¶å¯¹æ‰€æœ‰çš„æ•°æ®å…¨éƒ¨åŠ ä¸Šäº†ç»´åº¦æ³¨é‡Š. æœ¬æ–‡çš„ä»£ç å·²ç»æ”¾åˆ°äº†Colabä¸Š, æ‰“å¼€è®¾ç½®GPUå°±å¯ä»¥å¤ç°(éœ€è¦ç§‘å­¦ä¸Šç½‘).  å³é”®æˆ‘åœ¨COLABä¸­æ‰“å¼€!  å³é”®æˆ‘åœ¨COLABä¸­æ‰“å¼€! å¦‚æœä½ ä¸èƒ½ç§‘å­¦ä¸Šç½‘, åº”">
<meta property="og:type" content="article">
<meta property="og:title" content="Transformerçš„ä»£ç å®ç°-åŸºäºPytorch">
<meta property="og:url" content="https://linxkon.github.io/Transformer%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-%E5%9F%BA%E4%BA%8EPytorch.html">
<meta property="og:site_name" content="AIÂ·ä½ æ‰€çˆ±">
<meta property="og:description" content="æœ¬æ–‡æ˜¯Transfomrerçš„Pytorchç‰ˆæœ¬å®ç°. å®ç°çš„è¿‡ç¨‹ä¸­éå¸¸è€ƒéªŒç»´åº¦æ§åˆ¶çš„åŠŸåº•. æœ¬æ–‡å®ç°å‚è€ƒTransformer çš„ PyTorch å®ç°, æˆ‘å¯¹å…¶åœ¨ä¸ªåˆ«åœ°æ–¹è¿›è¡Œäº†ä¿®æ”¹, å¹¶å¯¹æ‰€æœ‰çš„æ•°æ®å…¨éƒ¨åŠ ä¸Šäº†ç»´åº¦æ³¨é‡Š. æœ¬æ–‡çš„ä»£ç å·²ç»æ”¾åˆ°äº†Colabä¸Š, æ‰“å¼€è®¾ç½®GPUå°±å¯ä»¥å¤ç°(éœ€è¦ç§‘å­¦ä¸Šç½‘).  å³é”®æˆ‘åœ¨COLABä¸­æ‰“å¼€!  å³é”®æˆ‘åœ¨COLABä¸­æ‰“å¼€! å¦‚æœä½ ä¸èƒ½ç§‘å­¦ä¸Šç½‘, åº”">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://linxkon.github.io/images/index_pic/Transformer.png">
<meta property="article:published_time" content="2023-01-11T12:21:13.000Z">
<meta property="article:modified_time" content="2024-06-12T10:20:03.595Z">
<meta property="article:author" content="linxkon">
<meta property="article:tag" content="ç¬”è®°æ•´ç†">
<meta property="article:tag" content="transformer">
<meta property="article:tag" content="ä»£ç å®ç°">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://linxkon.github.io/images/index_pic/Transformer.png">
  
  
  
  <title>Transformerçš„ä»£ç å®ç°-åŸºäºPytorch - AIÂ·ä½ æ‰€çˆ±</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"linxkon.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"enable":true,"app_id":"XLEbEr6BfzRRh34xJtmOEom0-MdYXbMMI","app_key":"3bwflR7evMRYC6JTohHAE31C","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>AIÂ·ä½ æ‰€çˆ± | Linxkon@gmail.com</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>å½’æ¡£</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>åˆ†ç±»</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>å…³äº</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/pursenight.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Transformerçš„ä»£ç å®ç°-åŸºäºPytorch"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-01-11 20:21" pubdate>
          2023å¹´1æœˆ11æ—¥ æ™šä¸Š
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.6k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          30 åˆ†é’Ÿ
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> æ¬¡
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Transformerçš„ä»£ç å®ç°-åŸºäºPytorch</h1>
            
            
              <div class="markdown-body">
                
                <p>æœ¬æ–‡æ˜¯Transfomrerçš„Pytorchç‰ˆæœ¬å®ç°. å®ç°çš„è¿‡ç¨‹ä¸­éå¸¸è€ƒéªŒ<strong>ç»´åº¦æ§åˆ¶</strong>çš„åŠŸåº•. æœ¬æ–‡å®ç°å‚è€ƒ<a target="_blank" rel="noopener" href="https://wmathor.com/index.php/archives/1455/">Transformer çš„ PyTorch å®ç°</a>, æˆ‘å¯¹å…¶åœ¨ä¸ªåˆ«åœ°æ–¹è¿›è¡Œäº†ä¿®æ”¹, å¹¶å¯¹æ‰€æœ‰çš„æ•°æ®<strong>å…¨éƒ¨</strong>åŠ ä¸Šäº†ç»´åº¦æ³¨é‡Š.</p>
<p>æœ¬æ–‡çš„ä»£ç å·²ç»æ”¾åˆ°äº†Colabä¸Š, æ‰“å¼€è®¾ç½®GPUå°±å¯ä»¥å¤ç°(éœ€è¦ç§‘å­¦ä¸Šç½‘).</p>
<figure>
<img src="https://colab.research.google.com/assets/colab-badge.svg" srcset="/img/loading.gif" lazyload alt="å³é”®æˆ‘åœ¨COLABä¸­æ‰“å¼€!" /><figcaption aria-hidden="true">å³é”®æˆ‘åœ¨COLABä¸­æ‰“å¼€!</figcaption>
</figure>
<p><strong>å³é”®æˆ‘åœ¨COLABä¸­æ‰“å¼€!</strong></p>
<p>å¦‚æœä½ ä¸èƒ½ç§‘å­¦ä¸Šç½‘, åº”è¯¥çœ‹ä¸åˆ°<code>Open in Colab</code>çš„å›¾æ ‡.</p>
<p>åœ¨å¼€å¤´éœ€è¦è¯´æ˜çš„æ˜¯:</p>
<ul>
<li>ç½‘ä¸Šçš„æ‰€æœ‰æµä¼ çš„ä»£ç , ä¸€èˆ¬éƒ½ä¼šæŠŠ<code>batch_size</code>æ”¾åœ¨ç¬¬0ç»´. å› ä¸ºæˆ‘ä»¬åŸºæœ¬ä¸Šä¸å¯¹batchç»´åšæ“ä½œ, æ”¾åœ¨æœ€å‰é¢æ¥é˜²æ­¢å½±å“åé¢æ€»éœ€è¦ä½¿ç”¨<code>transpose</code>ç§»åŠ¨.</li>
<li>å¦‚æœå¯¹Transformerä¸ç†Ÿæ‚‰, æœ€å¥½ç†Ÿæ‚‰åå†æ¥çœ‹è¿™ç¯‡æ–‡ç« .</li>
<li>æ³¨æ„<code>view</code>å’Œ<code>transpose</code>æ‹†ç»´åº¦æ—¶ä¸è¦ä¹±äº†.</li>
</ul>
<h2 id="preparing">Preparing</h2>
<p>æŒ‰ç…§æƒ¯ä¾‹, å…ˆå¯¼åŒ…:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data <span class="hljs-keyword">as</span> Data<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure>
<p>å› ä¸ºåé¢éœ€è¦ç”¨åˆ°ä¸€äº›å…³äºTransformerçš„è¶…å‚æ•°, æ‰€ä»¥åœ¨å¼€å¤´å°±å…ˆå…¨éƒ¨å®šä¹‰å‡ºæ¥:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">d_model = <span class="hljs-number">512</span> <span class="hljs-comment"># embedding size </span><br>max_len = <span class="hljs-number">1024</span> <span class="hljs-comment"># max length of sequence</span><br>d_ff = <span class="hljs-number">2048</span> <span class="hljs-comment"># feedforward nerual network  dimension</span><br>d_k = d_v = <span class="hljs-number">64</span> <span class="hljs-comment"># dimension of k(same as q) and v</span><br>n_layers = <span class="hljs-number">6</span> <span class="hljs-comment"># number of encoder and decoder layers</span><br>n_heads = <span class="hljs-number">8</span> <span class="hljs-comment"># number of heads in multihead attention</span><br>p_drop = <span class="hljs-number">0.1</span> <span class="hljs-comment"># propability of dropout</span><br></code></pre></td></tr></table></figure>
<p>å¦‚æœä½ å¯¹Transformerè¶³å¤Ÿç†Ÿæ‚‰, çœ‹å˜é‡åå’Œæ³¨é‡Šä¸€å®šèƒ½çœ‹å‡ºæ¥å®ƒä»¬çš„å«ä¹‰, å®ƒä»¬ä¾æ¬¡æ˜¯:</p>
<ul>
<li>d_model: Embeddingçš„å¤§å°.</li>
<li>max_len: è¾“å…¥åºåˆ—çš„æœ€é•¿å¤§å°.</li>
<li>d_ff: å‰é¦ˆç¥ç»ç½‘ç»œçš„éšè—å±‚å¤§å°, ä¸€èˆ¬æ˜¯d_modelçš„å››å€.</li>
<li>d_k, d_v: è‡ªæ³¨æ„åŠ›ä¸­Kå’ŒVçš„ç»´åº¦, Qçš„ç»´åº¦ç›´æ¥ç”¨Kçš„ç»´åº¦ä»£æ›¿, å› ä¸ºè¿™äºŒè€…å¿…é¡»å§‹ç»ˆç›¸ç­‰.</li>
<li>n_layers: Encoderå’ŒDecoderçš„å±‚æ•°.</li>
<li>n_heads: è‡ªæ³¨æ„åŠ›å¤šå¤´çš„å¤´æ•°.</li>
<li>p_drop: Dropoutçš„æ¦‚ç‡.</li>
</ul>
<h2 id="mask">Mask</h2>
<p>Maskåˆ†ä¸ºä¸¤ç§, ä¸€ç§æ˜¯å› ä¸ºåœ¨æ•°æ®ä¸­ä½¿ç”¨äº†padding, ä¸å¸Œæœ›padè¢«åŠ å…¥åˆ°æ³¨æ„åŠ›ä¸­è¿›è¡Œè®¡ç®—çš„Pad Mask for Attention, è¿˜æœ‰ä¸€ç§æ˜¯ä¿è¯Decoderè‡ªå›å½’ä¿¡æ¯ä¸æ³„éœ²çš„Subsequent Mask for Decoder.</p>
<h3 id="pad-mask-for-attention">Pad Mask for Attention</h3>
<p>ä¸ºäº†æ–¹ä¾¿, å‡è®¾<code>&lt;PAD&gt;</code>åœ¨å­—å…¸ä¸­çš„Indexæ˜¯0, é‡åˆ°è¾“å…¥ä¸º0ç›´æ¥å°†å…¶æ ‡ä¸ºTrue.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_attn_pad_mask</span>(<span class="hljs-params">seq_q, seq_k</span>):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  Padding, because of unequal in source_len and target_len.</span><br><span class="hljs-string"></span><br><span class="hljs-string">  parameters:</span><br><span class="hljs-string">  seq_q: [batch, seq_len]</span><br><span class="hljs-string">  seq_k: [batch, seq_len]</span><br><span class="hljs-string"></span><br><span class="hljs-string">  return:</span><br><span class="hljs-string">  mask: [batch, len_q, len_k]</span><br><span class="hljs-string"></span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  batch, len_q = seq_q.size()<br>  batch, len_k = seq_k.size()<br>  <span class="hljs-comment"># we define index of PAD is 0, if tensor equals (zero) PAD tokens</span><br>  pad_attn_mask = seq_k.data.eq(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, 1, len_k]</span><br><br>  <span class="hljs-keyword">return</span> pad_attn_mask.expand(batch, len_q, len_k) <span class="hljs-comment"># [batch, len_q, len_k]</span><br></code></pre></td></tr></table></figure>
<p>åœ¨Encoderå’ŒDecoderä¸­ä½¿ç”¨Maskçš„æƒ…å†µå¯èƒ½å„æœ‰ä¸åŒ:</p>
<ul>
<li>åœ¨Encoderä¸­ä½¿ç”¨Mask, æ˜¯ä¸ºäº†å°†<code>encoder_input</code>ä¸­æ²¡æœ‰å†…å®¹è€Œæ‰“ä¸ŠPADçš„éƒ¨åˆ†è¿›è¡ŒMask, æ–¹ä¾¿çŸ©é˜µè¿ç®—.</li>
<li>åœ¨Decoderä¸­ä½¿ç”¨Mask, å¯èƒ½æ˜¯åœ¨Decoderçš„è‡ªæ³¨æ„åŠ›å¯¹<code>decoder_input</code> çš„PADè¿›è¡ŒMask, ä¹Ÿæœ‰å¯èƒ½æ˜¯å¯¹Encoder - Decoderè‡ªæ³¨æ„åŠ›æ—¶å¯¹<code>encoder_input</code>å’Œ<code>decoder_input</code>çš„PADè¿›è¡ŒMask.</li>
</ul>
<h3 id="subsequent-mask-for-decoder">Subsequent Mask for Decoder</h3>
<p>è¯¥Maskæ˜¯ä¸ºäº†é˜²æ­¢Decoderçš„è‡ªå›å½’ä¿¡æ¯æ³„éœ²è€Œç”Ÿçš„Mask, ç›´æ¥ç”Ÿæˆä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µå³å¯:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_attn_subsequent_mask</span>(<span class="hljs-params">seq</span>):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  Build attention mask matrix for decoder when it autoregressing.</span><br><span class="hljs-string"></span><br><span class="hljs-string">  parameters:</span><br><span class="hljs-string">  seq: [batch, target_len]</span><br><span class="hljs-string"></span><br><span class="hljs-string">  return:</span><br><span class="hljs-string">  subsequent_mask: [batch, target_len, target_len] </span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  attn_shape = [seq.size(<span class="hljs-number">0</span>), seq.size(<span class="hljs-number">1</span>), seq.size(<span class="hljs-number">1</span>)] <span class="hljs-comment"># [batch, target_len, target_len]</span><br>  subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, target_len, target_len] </span><br>  subsequent_mask = torch.from_numpy(subsequent_mask)<br><br>  <span class="hljs-keyword">return</span> subsequent_mask <span class="hljs-comment"># [batch, target_len, target_len] </span><br></code></pre></td></tr></table></figure>
<p>å…¶ä¸­, ç”¨åˆ°äº†ç”Ÿæˆä¸Šä¸‰è§’çš„å‡½æ•°<code>np.triu</code>, å…¶ç”¨æ³•ä¸º:</p>
<p>python</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">np.triu(np.ones([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), k=<span class="hljs-number">1</span>)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">array([[0., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 0., 1., 1.],</span><br><span class="hljs-string">       [0., 0., 0., 1.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>np.triu(np.ones([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), k=<span class="hljs-number">0</span>)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">array([[1., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 0., 1., 1.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>np.triu(np.ones([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), k=-<span class="hljs-number">1</span>)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">array([[1., 1., 1., 1.],</span><br><span class="hljs-string">       [1., 1., 1., 1.],</span><br><span class="hljs-string">       [0., 1., 1., 1.]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure>
<p>å…¶ä¸­<code>k</code>èƒ½æ§åˆ¶ä¸Šä¸‰è§’çš„å¤§å°, è¶Šå¤§åˆ™ä¸Šä¸‰è§’èŒƒå›´è¶Šå°. ä¸ä¹‹å®Œå…¨<strong>ç›¸å</strong>çš„å‡½æ•°æ˜¯<code>np.tril</code>, èƒ½å¤Ÿç”Ÿæˆä¸‹ä¸‰è§’çŸ©é˜µ.</p>
<h2 id="positional-encoding">Positional Encoding</h2>
<p>åœ¨Transformerä¸­, ä½¿ç”¨çš„æ˜¯ç»å¯¹ä½ç½®ç¼–ç , ç”¨äºä¼ è¾“ç»™æ¨¡å‹Self - Attentionæ‰€ä¸èƒ½ä¼ è¾“çš„ä½ç½®ä¿¡æ¯, ç¼–ç ä½¿ç”¨æ­£ä½™å¼¦å…¬å¼å®ç°: ğ‘ƒğ¸(ğ‘ğ‘œğ‘ ,2ğ‘–)=sinâ¡(ğ‘ğ‘œğ‘ /100002ğ‘–ğ‘‘ğ‘šğ‘œğ‘‘ğ‘’ğ‘™)ğ‘ƒğ¸(ğ‘ğ‘œğ‘ ,2ğ‘–+1)=cosâ¡(ğ‘ğ‘œğ‘ /100002ğ‘–ğ‘‘ğ‘šğ‘œğ‘‘ğ‘’ğ‘™) åŸºäºä¸Šè¿°å…¬å¼, æˆ‘ä»¬æŠŠå®ƒå®ç°å‡ºæ¥:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionalEncoding</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, dropout=<span class="hljs-number">.1</span>, max_len=<span class="hljs-number">1024</span></span>):<br>    <span class="hljs-built_in">super</span>(PositionalEncoding, self).__init__()<br>    self.dropout = nn.Dropout(p=p_drop)<br><br>    positional_encoding = torch.zeros(max_len, d_model) <span class="hljs-comment"># [max_len, d_model]</span><br>    position = torch.arange(<span class="hljs-number">0</span>, max_len).<span class="hljs-built_in">float</span>().unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># [max_len, 1]</span><br><br>    div_term = torch.exp(torch.arange(<span class="hljs-number">0</span>, d_model, <span class="hljs-number">2</span>).<span class="hljs-built_in">float</span>() * <br>                         (-torch.log(torch.Tensor([<span class="hljs-number">10000</span>])) / d_model)) <span class="hljs-comment"># [max_len / 2]</span><br><br>    positional_encoding[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>] = torch.sin(position * div_term) <span class="hljs-comment"># even</span><br>    positional_encoding[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>] = torch.cos(position * div_term) <span class="hljs-comment"># odd</span><br><br>    <span class="hljs-comment"># [max_len, d_model] -&gt; [1, max_len, d_model] -&gt; [max_len, 1, d_model]</span><br>    positional_encoding = positional_encoding.unsqueeze(<span class="hljs-number">0</span>).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># register pe to buffer and require no grads</span><br>    self.register_buffer(<span class="hljs-string">&#x27;pe&#x27;</span>, positional_encoding)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-comment"># x: [seq_len, batch, d_model]</span><br>    <span class="hljs-comment"># we can add positional encoding to x directly, and ignore other dimension</span><br>    x = x + self.pe[:x.size(<span class="hljs-number">0</span>), ...]<br><br>    <span class="hljs-keyword">return</span> self.dropout(x)<br></code></pre></td></tr></table></figure>
<p>å®ç°1/100002ğ‘–ğ‘‘ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ æ—¶æ—¢å¯ä»¥åƒæˆ‘å†™å‡ºçš„é‚£æ ·ä½¿ç”¨å¹‚æŒ‡è¿ç®—, ä¹Ÿå¯ä»¥ç›´æ¥å†™å‡º.</p>
<p><code>register_buffer</code>èƒ½å¤Ÿç”³è¯·ä¸€ä¸ªç¼“å†²åŒºä¸­çš„<strong>å¸¸é‡</strong>, å¹¶ä¸”å®ƒä¸ä¼šè¢«åŠ å…¥åˆ°è®¡ç®—å›¾ä¸­, ä¹Ÿå°±ä¸ä¼šå‚ä¸åå‘ä¼ æ’­.</p>
<p>æ›´å¤šå…³äº<code>register</code>åœ¨<code>parameter</code>å’Œ<code>buffer</code>ä¸Šçš„åŒºåˆ«è¯·è§<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/89442276">Pytorchæ¨¡å‹ä¸­çš„parameterä¸buffer</a>.</p>
<h2 id="feed-forward-neural-network">Feed Forward Neural Network</h2>
<p>åœ¨Transformerä¸­, Encoderæˆ–è€…Decoderæ¯ä¸ªBlockéƒ½éœ€è¦ç”¨ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œæ¥æ·»åŠ <strong>éçº¿æ€§</strong>: FFN(ğ‘¥)=ReLU(ğ‘¥ğ‘Š1+ğ‘1)ğ‘Š2+ğ‘2 æ³¨æ„, è¿™é‡Œå®ƒä»¬éƒ½æ˜¯æœ‰åç½®çš„, è€Œä¸”è¿™ä¸¤ä¸ªLinearå¯ä»¥ç”¨ä¸¤ä¸ª1Ã—1 çš„å·ç§¯æ¥å®ç°:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeedForwardNetwork</span>(nn.Module):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  Using nn.Conv1d replace nn.Linear to implements FFN.</span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(FeedForwardNetwork, self).__init__()<br>    <span class="hljs-comment"># self.ff1 = nn.Linear(d_model, d_ff)</span><br>    <span class="hljs-comment"># self.ff2 = nn.Linear(d_ff, d_model)</span><br>    self.ff1 = nn.Conv1d(d_model, d_ff, <span class="hljs-number">1</span>)<br>    self.ff2 = nn.Conv1d(d_ff, d_model, <span class="hljs-number">1</span>)<br>    self.relu = nn.ReLU()<br><br>    self.dropout = nn.Dropout(p=p_drop)<br>    self.layer_norm = nn.LayerNorm(d_model)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-comment"># x: [batch, seq_len, d_model]</span><br>    residual = x<br>    x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, d_model, seq_len]</span><br>    x = self.ff1(x)<br>    x = self.relu(x)<br>    x = self.ff2(x)<br>    x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, seq_len, d_model]</span><br><br>    <span class="hljs-keyword">return</span> self.layer_norm(residual + x)<br></code></pre></td></tr></table></figure>
<p>ä½œä¸ºä¸€ä¸ªå­å±‚, ä¸è¦å¿˜è®°Transformerä¸­æåˆ°çš„Residual Connectionå’ŒLayer Norm.</p>
<p>æˆ‘é€‰æ‹©ç”¨ä¸¤ä¸ªå·ç§¯ä»£æ›¿Linear. åœ¨<code>nn.Conv1d</code>ä¸­, è¦æ±‚æ•°æ®çš„è§„æ ¼ä¸º<code>[batch, x, ...]</code>, æˆ‘ä»¬æ˜¯è¦å¯¹<code>d_model</code> ä¸Šçš„æ•°æ®è¿›è¡Œå·ç§¯, æ‰€ä»¥è¿˜æ˜¯éœ€è¦<code>transpose</code>ä¸€ä¸‹.</p>
<h2 id="multi---head-attention">Multi - Head Attention</h2>
<p>å…ˆè¯´å¤šå¤´æ³¨æ„åŠ›, å› ä¸ºå¤šå¤´æ³¨æ„åŠ›èƒ½å¤Ÿå†³å®šç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›çš„è¾“å…¥å¤§å°. ä½œä¸ºä¸€ä¸ªå­å±‚, å…¶ä¸­çš„Residual Connectionå’ŒLayer Normæ˜¯å¿…é¡»çš„.</p>
<p>å¤šå¤´æ³¨æ„åŠ›æ˜¯å¤šä¸ªä¸åŒçš„å¤´æ¥è·å–ä¸åŒçš„ç‰¹å¾, ç±»ä¼¼äºå¤šä¸ª<strong>å·ç§¯æ ¸</strong>æ‰€è¾¾åˆ°çš„æ•ˆæœ. åœ¨è®¡ç®—å®Œåé€šè¿‡ä¸€ä¸ªLinearè°ƒæ•´å¤§å°: MultiHead(ğ‘„,ğ¾,ğ‘‰)=Concat(head1,head2,â€¦,headâ„)ğ‘Šğ‘‚where headğ‘–=Attention(ğ‘„ğ‘Šğ‘–ğ‘„,ğ¾ğ‘Šğ‘–ğ¾,ğ‘‰ğ‘Šğ‘–ğ‘‰) å¤šå¤´æ³¨æ„åŠ›åœ¨Encoderå’ŒDecoderä¸­çš„ä½¿ç”¨ç•¥æœ‰åŒºåˆ«, ä¸»è¦åŒºåˆ«åœ¨äºMaskçš„ä¸åŒ. æˆ‘ä»¬å‰é¢å·²ç»å®ç°äº†ä¸¤ç§Maskå‡½æ•°, åœ¨è¿™é‡Œä¼šç”¨åˆ°.</p>
<p>å¤šå¤´æ³¨æ„åŠ›å®é™…ä¸Šä¸æ˜¯é€šè¿‡å¼„å‡ºå¾ˆå¤šå¤§å°ç›¸åŒçš„çŸ©é˜µç„¶åç›¸ä¹˜æ¥å®ç°çš„, åªéœ€è¦åˆå¹¶åˆ°ä¸€ä¸ªçŸ©é˜µè¿›è¡Œè®¡ç®—:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiHeadAttention</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_heads=<span class="hljs-number">8</span></span>):<br>    <span class="hljs-built_in">super</span>(MultiHeadAttention, self).__init__()<br>    <span class="hljs-comment"># do not use more instance to implement multihead attention</span><br>    <span class="hljs-comment"># it can be complete in one matrix</span><br>    self.n_heads = n_heads<br><br>    <span class="hljs-comment"># we can&#x27;t use bias because there is no bias term in formular</span><br>    self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=<span class="hljs-literal">False</span>)<br>    self.W_K = nn.Linear(d_model, d_k * n_heads, bias=<span class="hljs-literal">False</span>)<br>    self.W_V = nn.Linear(d_model, d_v * n_heads, bias=<span class="hljs-literal">False</span>)<br>    self.fc = nn.Linear(d_v * n_heads, d_model, bias=<span class="hljs-literal">False</span>)<br>    self.layer_norm = nn.LayerNorm(d_model)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_Q, input_K, input_V, attn_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    To make sure multihead attention can be used both in encoder and decoder, </span><br><span class="hljs-string">    we use Q, K, V respectively.</span><br><span class="hljs-string">    input_Q: [batch, len_q, d_model]</span><br><span class="hljs-string">    input_K: [batch, len_k, d_model]</span><br><span class="hljs-string">    input_V: [batch, len_v, d_model]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    residual, batch = input_Q, input_Q.size(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># [batch, len_q, d_model] -- matmul W_Q --&gt; [batch, len_q, d_q * n_heads] -- view --&gt; </span><br>    <span class="hljs-comment"># [batch, len_q, n_heads, d_k,] -- transpose --&gt; [batch, n_heads, len_q, d_k]</span><br><br>    Q = self.W_Q(input_Q).view(batch, -<span class="hljs-number">1</span>, n_heads, d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, n_heads, len_q, d_k]</span><br>    K = self.W_K(input_K).view(batch, -<span class="hljs-number">1</span>, n_heads, d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, n_heads, len_k, d_k]</span><br>    V = self.W_V(input_V).view(batch, -<span class="hljs-number">1</span>, n_heads, d_v).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># [batch, n_heads, len_v, d_v]</span><br><br>    attn_mask = attn_mask.unsqueeze(<span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, n_heads, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, n_heads, seq_len, seq_len]</span><br><br>    <span class="hljs-comment"># prob: [batch, n_heads, len_q, d_v] attn: [batch, n_heads, len_q, len_k]</span><br>    prob, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)<br><br>    prob = prob.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous() <span class="hljs-comment"># [batch, len_q, n_heads, d_v]</span><br>    prob = prob.view(batch, -<span class="hljs-number">1</span>, n_heads * d_v).contiguous() <span class="hljs-comment"># [batch, len_q, n_heads * d_v]</span><br><br>    output = self.fc(prob) <span class="hljs-comment"># [batch, len_q, d_model]</span><br><br>    <span class="hljs-keyword">return</span> self.layer_norm(residual + output), attn<br></code></pre></td></tr></table></figure>
<p>æä¸¤ä¸ªéå¸¸é‡è¦çš„ç‚¹:</p>
<ol type="1">
<li>åœ¨æ‹†ç»´åº¦æ—¶ä¸è¦ç ´åç»´åº¦åŸæ¥æœ¬èº«çš„æ„ä¹‰.</li>
<li>è™½ç„¶æ–°ç‰ˆæœ¬å·²ç»æœ‰<code>reshape</code>å‡½æ•°å¯ä»¥ç”¨äº†, ä½†æ˜¯ä»ç„¶ä¸è¦å¿˜è®°, <code>transpose</code>åå¦‚æœæ¥<code>permute</code>æˆ–è€…<code>view</code>å¿…é¡»è¦åŠ <code>contiguous</code>, è¿™æ˜¯<strong>æ•°æ®çœŸå®å­˜å‚¨è¿ç»­ä¸å¦</strong>çš„é—®é¢˜, è¯·å‚è§<a target="_blank" rel="noopener" href="https://adaning.github.io/posts/42255.html">Pytorchä¹‹å¼ é‡åŸºç¡€æ“ä½œ</a>ä¸­çš„<strong>ç»´åº¦å˜æ¢</strong>éƒ¨åˆ†.</li>
</ol>
<h2 id="scaled-dotproduct-attention">Scaled DotProduct Attention</h2>
<p>Tranformerä¸­éå¸¸é‡è¦çš„æ¦‚å¿µ, ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›, å…¬å¼å¦‚ä¸‹: Attention(ğ‘„,ğ¾,ğ‘‰)=softmax(ğ‘„ğ¾ğ‘‡ğ‘‘ğ‘˜)ğ‘‰ å®ç°èµ·æ¥éå¸¸ç®€å•, åªéœ€è¦æŠŠQ, Kä¸¤ä¸ªçŸ©é˜µä¸€ä¹˜, ç„¶åå†ç¼©æ”¾, è¿‡ä¸€æ¬¡Softmax, å†å’ŒVä¹˜ä¸‹:</p>
<p>python</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ScaledDotProductAttention</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(ScaledDotProductAttention, self).__init__()<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, Q, K, V, attn_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    Q: [batch, n_heads, len_q, d_k]</span><br><span class="hljs-string">    K: [batch, n_heads, len_k, d_k]</span><br><span class="hljs-string">    V: [batch, n_heads, len_v, d_v]</span><br><span class="hljs-string">    attn_mask: [batch, n_heads, seq_len, seq_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    scores = torch.matmul(Q, K.transpose(-<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>)) / np.sqrt(d_k) <span class="hljs-comment"># [batch, n_heads, len_q, len_k]</span><br>    scores.masked_fill_(attn_mask, -<span class="hljs-number">1e9</span>)<br><br>    attn = nn.Softmax(dim=-<span class="hljs-number">1</span>)(scores) <span class="hljs-comment"># [batch, n_heads, len_q, len_k]</span><br>    prob = torch.matmul(attn, V) <span class="hljs-comment"># [batch, n_heads, len_q, d_v]</span><br>    <span class="hljs-keyword">return</span> prob, attn<br></code></pre></td></tr></table></figure>
<p><code>masked_fill_</code>èƒ½æŠŠä¼ è¿›æ¥çš„Maskä¸ºTrueçš„åœ°æ–¹å…¨éƒ½å¡«å……ä¸ŠæŸä¸ªå€¼, è¿™é‡Œéœ€è¦ç”¨ä¸€ä¸ªå¾ˆå¤§çš„è´Ÿæ•°æ¥ä¿è¯ğ‘’ğ‘¥â†’0, ä½¿å¾—å…¶åœ¨Softmax ä¸­å¯ä»¥è¢«å¿½ç•¥.</p>
<h2 id="encoder-and-decoder">Encoder and Decoder</h2>
<h3 id="encoder">Encoder</h3>
<p>å…ˆå†™å‡ºEncoderçš„æ¯ä¸ªLayer, ç”±å¤šå¤´æ³¨æ„åŠ›å’ŒFFNç»„æˆ:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderLayer</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(EncoderLayer, self).__init__()<br>    self.encoder_self_attn = MultiHeadAttention()<br>    self.ffn = FeedForwardNetwork()<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_input, encoder_pad_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    encoder_input: [batch, source_len, d_model]</span><br><span class="hljs-string">    encoder_pad_mask: [batch, n_heads, source_len, source_len]</span><br><span class="hljs-string"></span><br><span class="hljs-string">    encoder_output: [batch, source_len, d_model]</span><br><span class="hljs-string">    attn: [batch, n_heads, source_len, source_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    encoder_output, attn = self.encoder_self_attn(encoder_input, encoder_input, encoder_input, encoder_pad_mask)<br>    encoder_output = self.ffn(encoder_output) <span class="hljs-comment"># [batch, source_len, d_model]</span><br><br>    <span class="hljs-keyword">return</span> encoder_output, attn<br></code></pre></td></tr></table></figure>
<p>å¯¹äºç»™å®šçš„<code>encoder_input</code>å’Œ<code>encoder_pad_pask</code>, Encoderåº”è¯¥èƒ½å¤Ÿå®Œæˆæ•´ä¸ªBlock(Layer)çš„è®¡ç®—æµç¨‹. ç„¶åå®ç°æ•´ä¸ªEncoder:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(Encoder, self).__init__()<br>    self.source_embedding = nn.Embedding(source_vocab_size, d_model)<br>    self.positional_embedding = PositionalEncoding(d_model)<br>    self.layers = nn.ModuleList([EncoderLayer() <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers)])<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_input</span>):<br>    <span class="hljs-comment"># encoder_input: [batch, source_len]</span><br>    encoder_output = self.source_embedding(encoder_input) <span class="hljs-comment"># [batch, source_len, d_model]</span><br>    encoder_output = self.positional_embedding(encoder_output.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, source_len, d_model]</span><br><br>    encoder_self_attn_mask = get_attn_pad_mask(encoder_input, encoder_input) <span class="hljs-comment"># [batch, source_len, source_len]</span><br>    encoder_self_attns = <span class="hljs-built_in">list</span>()<br>    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>      <span class="hljs-comment"># encoder_output: [batch, source_len, d_model]</span><br>      <span class="hljs-comment"># encoder_self_attn: [batch, n_heads, source_len, source_len]</span><br>      encoder_output, encoder_self_attn = layer(encoder_output, encoder_self_attn_mask)<br>      encoder_self_attns.append(encoder_self_attn)<br><br>    <span class="hljs-keyword">return</span> encoder_output, encoder_self_attns<br></code></pre></td></tr></table></figure>
<p>å¯¹äºæ•´ä¸ªEncoder, ç›´æ¥å°†Tokençš„Indexä¼ å…¥Embeddingä¸­, å†æ·»å…¥ä½ç½®ç¼–ç , ä¹‹åå°±ç»è¿‡å¤šå±‚Transformer Encoder. åœ¨ä¼ å…¥Blockå‰, å…ˆéœ€è¦è®¡ç®—Paddingçš„Mask, å†å°†ä¸Šå±‚çš„è¾“å‡ºä½œä¸ºä¸‹å±‚è¾“å…¥ä¾æ¬¡è¿­ä»£.</p>
<h3 id="decoder">Decoder</h3>
<p>å…¶å®å®ç°äº†Encoder, Decoderçš„å®ç°éƒ¨åˆ†éƒ½æ˜¯å¯¹åº”çš„. å…ˆå®ç°Decoderçš„Block:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DecoderLayer</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(DecoderLayer, self).__init__()<br>    self.decoder_self_attn = MultiHeadAttention()<br>    self.encoder_decoder_attn = MultiHeadAttention()<br>    self.ffn = FeedForwardNetwork()<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, decoder_input, encoder_output, decoder_self_mask, decoder_encoder_mask</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    decoder_input: [batch, target_len, d_mdoel]</span><br><span class="hljs-string">    encoder_output: [batch, source_len, d_model]</span><br><span class="hljs-string">    decoder_self_mask: [batch, target_len, target_len]</span><br><span class="hljs-string">    decoder_encoder_mask: [batch, target_len, source_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># masked mutlihead attention</span><br>    <span class="hljs-comment"># Q, K, V all from decoder it self</span><br>    <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>    <span class="hljs-comment"># decoder_self_attn: [batch, n_heads, target_len, target_len]</span><br>    decoder_output, decoder_self_attn = self.decoder_self_attn(decoder_input, decoder_input, decoder_input, decoder_self_mask)<br><br>    <span class="hljs-comment"># Q from decoder, K, V from encoder</span><br>    <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>    <span class="hljs-comment"># decoder_encoder_attn: [batch, n_heads, target_len, source_len]</span><br>    decoder_output, decoder_encoder_attn = self.encoder_decoder_attn(decoder_output, encoder_output, encoder_output, decoder_encoder_mask)<br>    decoder_output = self.ffn(decoder_output) <span class="hljs-comment"># [batch, target_len, d_model]</span><br><br>    <span class="hljs-keyword">return</span> decoder_output, decoder_self_attn, decoder_encoder_attn<br></code></pre></td></tr></table></figure>
<p>ä¸Encoderç›¸å¯¹åº”, åªä¸è¿‡å› ä¸ºå¤šäº†ä¸€ä¸ªEncoder - Decoderè‡ªæ³¨æ„åŠ›, æ‰€ä»¥éœ€è¦é¢å¤–è®¡ç®—ä¸€ä¸ªEncoder - Decoderçš„Mask. ç„¶åå†™å‡ºæ•´ä¸ªDecoder:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(Decoder, self).__init__()<br>    self.target_embedding = nn.Embedding(target_vocab_size, d_model)<br>    self.positional_embedding = PositionalEncoding(d_model)<br>    self.layers = nn.ModuleList([DecoderLayer() <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers)])<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, decoder_input, encoder_input, encoder_output</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    decoder_input: [batch, target_len]</span><br><span class="hljs-string">    encoder_input: [batch, source_len]</span><br><span class="hljs-string">    encoder_output: [batch, source_len, d_model]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    decoder_output = self.target_embedding(decoder_input) <span class="hljs-comment"># [batch, target_len, d_model]</span><br>    decoder_output = self.positional_embedding(decoder_output.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># [batch, target_len, d_model]</span><br>    decoder_self_attn_mask = get_attn_pad_mask(decoder_input, decoder_input) <span class="hljs-comment"># [batch, target_len, target_len]</span><br>    decoder_subsequent_mask = get_attn_subsequent_mask(decoder_input) <span class="hljs-comment"># [batch, target_len, target_len]</span><br><br>    decoder_encoder_attn_mask = get_attn_pad_mask(decoder_input, encoder_input) <span class="hljs-comment"># [batch, target_len, source_len]</span><br><br>    decoder_self_mask = torch.gt(decoder_self_attn_mask + decoder_subsequent_mask, <span class="hljs-number">0</span>)<br>    decoder_self_attns, decoder_encoder_attns = [], []<br><br>    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>      <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>      <span class="hljs-comment"># decoder_self_attn: [batch, n_heads, target_len, target_len]</span><br>      <span class="hljs-comment"># decoder_encoder_attn: [batch, n_heads, target_len, source_len]</span><br>      decoder_output, decoder_self_attn, decoder_encoder_attn = layer(decoder_output, encoder_output, decoder_self_mask, decoder_encoder_attn_mask)<br>      decoder_self_attns.append(decoder_self_attn)<br>      decoder_encoder_attns.append(decoder_encoder_attn)<br><br>    <span class="hljs-keyword">return</span> decoder_output, decoder_self_attns, decoder_encoder_attns<br></code></pre></td></tr></table></figure>
<p>å’ŒEncoderç›¸å¯¹åº”, ä½†Decoderå’ŒEncoderä½¿ç”¨äº†ä¸¤ä¸ªä¸åŒçš„Embedding. å¯¹äºMask, å¯ä»¥æŠŠè‡ªå›å½’Maskå’ŒPadding Maskç”¨<code>torch.gt</code>æ•´åˆæˆä¸€ä¸ªMask, é€å…¥å…¶ä¸­.</p>
<h2 id="transformer">Transformer</h2>
<p>ç»ˆäºåˆ°äº†è¿™ä¸€æ­¥, è™½ç„¶åé¢è¿˜æœ‰ä¸€äº›å°å°çš„å·¥ä½œ, ä½†ç°åœ¨ç»ˆäºèƒ½çœ‹åˆ°Transformerçš„<strong>å…¨è²Œ</strong>äº†:</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/transformer.jpg" srcset="/img/loading.gif" lazyload alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>é‡Œé¢æœ‰ä¸€ä¸ªEncoder, ä¸€ä¸ªDecoder, åœ¨Decoderç«¯è¿˜éœ€è¦åŠ ä¸ŠæŠ•å½±å±‚æ¥åˆ†ç±»:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transformer</span>(nn.Module):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(Transformer, self).__init__()<br><br>    self.encoder = Encoder()<br>    self.decoder = Decoder()<br>    self.projection = nn.Linear(d_model, target_vocab_size, bias=<span class="hljs-literal">False</span>)<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, encoder_input, decoder_input</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    encoder_input: [batch, source_len]</span><br><span class="hljs-string">    decoder_input: [batch, target_len]</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># encoder_output: [batch, source_len, d_model]</span><br>    <span class="hljs-comment"># encoder_attns: [n_layers, batch, n_heads, source_len, source_len]</span><br>    encoder_output, encoder_attns = self.encoder(encoder_input)<br>    <span class="hljs-comment"># decoder_output: [batch, target_len, d_model]</span><br>    <span class="hljs-comment"># decoder_self_attns: [n_layers, batch, n_heads, target_len, target_len]</span><br>    <span class="hljs-comment"># decoder_encoder_attns: [n_layers, batch, n_heads, target_len, source_len]</span><br>    decoder_output, decoder_self_attns, decoder_encoder_attns = self.decoder(decoder_input, encoder_input, encoder_output)<br>    decoder_logits = self.projection(decoder_output) <span class="hljs-comment"># [batch, target_len, target_vocab_size]</span><br><br>    <span class="hljs-comment"># decoder_logits: [batch * target_len, target_vocab_size]</span><br>    <span class="hljs-keyword">return</span> decoder_logits.view(-<span class="hljs-number">1</span>, decoder_logits.size(-<span class="hljs-number">1</span>)), encoder_attns, decoder_self_attns, decoder_encoder_attns<br></code></pre></td></tr></table></figure>
<p>æœ€åå¯¹logitsçš„å¤„ç†æ˜¯<code>view</code>æˆäº†<code>[batch * target_len, target_vocab_size]</code>, å‰é¢çš„å¤§å°å¹¶ä¸å½±å“æˆ‘ä»¬ä¸€ä¼šç”¨äº¤å‰ç†µè®¡ç®—æŸå¤±.</p>
<h2 id="input-data">Input Data</h2>
<p>è¾“å…¥æ•°æ®æ²¡ä»€ä¹ˆå¥½è¯´çš„, ä¸ºäº†æ–¹ä¾¿ç›´æ¥é‡‡ç”¨äº†ç¡¬ç¼–ç çš„æ–¹å¼æ„é€ <code>word2index</code>, è¿™æ ·æˆ‘ä»¬çš„è¾“å…¥åºåˆ—éƒ½è¢«è½¬æ¢ä¸ºäº†Tokençš„indexè¾“å…¥åˆ°Embeddingå±‚ä¸­, è‡ªåŠ¨è½¬åŒ–ä¸ºåµŒå…¥åœ¨ä½ç»´ç©ºé—´çš„ç¨ å¯†å‘é‡:</p>
<p>Decoderçš„è¾“å…¥æ„é€ è¿‡ç¨‹é‡‡ç”¨äº†<strong>Teaching Forcing</strong>, ä¿è¯äº†è®­ç»ƒè¿‡ç¨‹æ˜¯å¯ä»¥ä¿æŒ<strong>å¹¶è¡Œ</strong>çš„.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">sentences = [<br>        <span class="hljs-comment"># enc_input           dec_input         dec_output</span><br>        [<span class="hljs-string">&#x27;ich mochte ein bier P&#x27;</span>, <span class="hljs-string">&#x27;S i want a beer .&#x27;</span>, <span class="hljs-string">&#x27;i want a beer . E&#x27;</span>],<br>        [<span class="hljs-string">&#x27;ich mochte ein cola P&#x27;</span>, <span class="hljs-string">&#x27;S i want a coke .&#x27;</span>, <span class="hljs-string">&#x27;i want a coke . E&#x27;</span>]<br>]<br><br><span class="hljs-comment"># Padding Should be Zero</span><br>source_vocab = &#123;<span class="hljs-string">&#x27;P&#x27;</span> : <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;ich&#x27;</span> : <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;mochte&#x27;</span> : <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;ein&#x27;</span> : <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;bier&#x27;</span> : <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;cola&#x27;</span> : <span class="hljs-number">5</span>&#125;<br>source_vocab_size = <span class="hljs-built_in">len</span>(source_vocab)<br><br>target_vocab = &#123;<span class="hljs-string">&#x27;P&#x27;</span> : <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;i&#x27;</span> : <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;want&#x27;</span> : <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;a&#x27;</span> : <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;beer&#x27;</span> : <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;coke&#x27;</span> : <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;S&#x27;</span> : <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;E&#x27;</span> : <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;.&#x27;</span> : <span class="hljs-number">8</span>&#125;<br>idx2word = &#123;i: w <span class="hljs-keyword">for</span> i, w <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(target_vocab)&#125;<br>target_vocab_size = <span class="hljs-built_in">len</span>(target_vocab)<br>source_len = <span class="hljs-number">5</span> <span class="hljs-comment"># max length of input sequence</span><br>target_len = <span class="hljs-number">6</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_data</span>(<span class="hljs-params">sentences</span>):<br>  encoder_inputs, decoder_inputs, decoder_outputs = [], [], []<br>  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sentences)):<br>    encoder_input = [source_vocab[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentences[i][<span class="hljs-number">0</span>].split()]<br>    decoder_input = [target_vocab[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentences[i][<span class="hljs-number">1</span>].split()]<br>    decoder_output = [target_vocab[word] <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentences[i][<span class="hljs-number">2</span>].split()]<br>    encoder_inputs.append(encoder_input)<br>    decoder_inputs.append(decoder_input)<br>    decoder_outputs.append(decoder_output)<br><br>  <span class="hljs-keyword">return</span> torch.LongTensor(encoder_inputs), torch.LongTensor(decoder_inputs), torch.LongTensor(decoder_outputs)<br></code></pre></td></tr></table></figure>
<p>æ•°æ®é‡éå¸¸çš„å°‘, æ‰€ä»¥ç­‰ä¼šçš„è®­ç»ƒä¼šæ ¹æœ¬ä¸å……åˆ†.</p>
<h2 id="dataset">DataSet</h2>
<p>åˆ¶ä½œä¸€ä¸ªSeq2Seqçš„æ•°æ®é›†, åªéœ€è¦æŒ‰ç…§Indexè¿”å›Encoderçš„è¾“å‡º, Decoderçš„è¾“å…¥, Decoderçš„è¾“å‡º(label)å°±å¥½:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Seq2SeqDataset</span>(Data.Dataset):<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder_input, decoder_input, decoder_output</span>):<br>    <span class="hljs-built_in">super</span>(Seq2SeqDataset, self).__init__()<br>    self.encoder_input = encoder_input<br>    self.decoder_input = decoder_input<br>    self.decoder_output = decoder_output<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-keyword">return</span> self.encoder_input.shape[<span class="hljs-number">0</span>]<br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>    <span class="hljs-keyword">return</span> self.encoder_input[idx], self.decoder_input[idx], self.decoder_output[idx]<br></code></pre></td></tr></table></figure>
<h2 id="training">Training</h2>
<p>å¯¹è®­ç»ƒæ‰€éœ€çš„æ‰€æœ‰ä¸œè¥¿è¿›è¡Œå®šä¹‰:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">64</span><br>epochs = <span class="hljs-number">64</span><br>lr = <span class="hljs-number">1e-3</span><br><br>device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)<br>model = Transformer().to(device)<br>criterion = nn.CrossEntropyLoss(ignore_index=<span class="hljs-number">0</span>)<br>optimizer = optim.Adam(model.parameters(), lr=lr)<br>encoder_inputs, decoder_inputs, decoder_outputs = make_data(sentences)<br>dataset = Seq2SeqDataset(encoder_inputs, decoder_inputs, decoder_outputs)<br>data_loader = Data.DataLoader(dataset, <span class="hljs-number">2</span>, <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>è¿™é‡Œæœ‰ä¸ª<code>criterion = nn.CrossEntropyLoss(ignore_index=0)</code>, å…¶ä¸­<code>ignore_index=0</code>æŒ‡çš„æ˜¯PADåœ¨è®¡ç®—äº¤å‰ç†µæ—¶ä¸åº”è¯¥è¢«åŒ…æ‹¬è¿›å»(å‰é¢æåˆ°è¿‡PADæ‰€å¯¹åº”çš„Indexæ˜¯0).</p>
<p>æˆ‘ä»¬ä»å®šä¹‰å¥½çš„æ•°æ®é›†ä¸­å–å‡ºæ•°æ®åˆ°<code>device</code>, ç„¶åç”¨torchä¸‰ä»¶å¥—:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>  <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  encoder_input: [batch, source_len]</span><br><span class="hljs-string">  decoder_input: [batch, target_len]</span><br><span class="hljs-string">  decoder_ouput: [batch, target_len]</span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br>  <span class="hljs-keyword">for</span> encoder_input, decoder_input, decoder_output <span class="hljs-keyword">in</span> data_loader:<br>    encoder_input = encoder_input.to(device)<br>    decoder_input = decoder_input.to(device)<br>    decoder_output = decoder_output.to(device)<br><br>    output, encoder_attns, decoder_attns, decoder_encoder_attns = model(encoder_input, decoder_input)<br>    loss = criterion(output, decoder_output.view(-<span class="hljs-number">1</span>))<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch:&#x27;</span>, <span class="hljs-string">&#x27;%04d&#x27;</span> % (epoch + <span class="hljs-number">1</span>), <span class="hljs-string">&#x27;loss =&#x27;</span>, <span class="hljs-string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(loss))<br><br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br></code></pre></td></tr></table></figure>
<h2 id="attention-visualization">Attention Visualization</h2>
<p>è¿™å›æœ‰äº†è‡ªå·±é€ çš„Transformer, ç»è¿‡äº†<strong>æ ¹æœ¬ä¸å®Œå…¨çš„è®­ç»ƒ: )</strong>, æˆ‘ä»¬å¯ä»¥æŠŠå®ƒçš„AttentionçŸ©é˜µç”»å‡ºæ¥çœ‹çœ‹:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">batch 1:</span><br><span class="hljs-string">[[1, 2, 3, 5, 0],</span><br><span class="hljs-string">[1, 2, 3, 4, 0]]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>temp_batch = <span class="hljs-number">0</span><br>n_layers = <span class="hljs-number">4</span><br>plt.figure(figsize=(n_heads * <span class="hljs-number">3</span>, n_layers * <span class="hljs-number">3</span> + <span class="hljs-number">3</span>))<br><span class="hljs-comment"># encoder_attns: [n_layers, batch, n_heads, source_len, source_len]</span><br>i = <span class="hljs-number">0</span><br>tokens = sentences[temp_batch][<span class="hljs-number">0</span>].split()<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers):<br>  <span class="hljs-keyword">for</span> head <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_heads):<br>    i += <span class="hljs-number">1</span><br>    plt.subplot(n_layers, n_heads, i)<br><br>    plt.title(<span class="hljs-string">&#x27;Layer:&#123;&#125;, Head:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(layer+<span class="hljs-number">1</span>, head+<span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">if</span> i % n_heads == <span class="hljs-number">0</span>:<br>      cbar=<span class="hljs-literal">True</span><br>    <span class="hljs-keyword">else</span>:<br>      cbar=<span class="hljs-literal">False</span><br>    sns.heatmap(encoder_attns[layer][temp_batch][head].detach().numpy(), cmap=<span class="hljs-string">&#x27;YlGnBu&#x27;</span>, <br>            xticklabels=tokens, yticklabels=tokens, cbar=cbar, vmin=<span class="hljs-number">0</span>, vmax=<span class="hljs-number">1</span>);<br>    plt.xticks([])<br>    plt.yticks([])<br></code></pre></td></tr></table></figure>
<p>æœ€åä¸¤è¡Œ<code>plt.xticks</code>å’Œ<code>plt.yticks</code>çº¯ç²¹æ˜¯ä¸ºäº†<strong>æ–¹ä¾¿æ³¨é‡Šæ‰</strong>, æ‰åˆå†™åœ¨äº†å¤–é¢.</p>
<p><strong>ä¸è¦å¯¹ç»“æœå¤ªåœ¨æ„</strong>, å› ä¸º<strong>è®­ç»ƒæ˜¯æ ¹æœ¬ä¸å®Œæ•´çš„</strong>, æ•°æ®ä¹Ÿæ‰åªæœ‰ä¸¤æ¡. æˆ‘åªæ˜¯æƒ³ç”»å‡ºæ¥çœ‹çœ‹æ¯ä¸ªå¤´éƒ½å¤§è‡´å­¦åˆ°äº†ä»€ä¹ˆ:</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pytorchtransformer1.jpg" srcset="/img/loading.gif" lazyload alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>æœ€å³ä¾§æ˜¯Padding, è¿™ä¸€åˆ—çš„æƒé‡éƒ½è¢«å½“åšæ˜¯0æ¥è®¡ç®—. åœ¨æµ…ä¸€äº›çš„å±‚ç¡®å®å­¦åˆ°äº†ä¸åŒTokenå¯¹ä¸åŒéƒ¨åˆ†çš„æƒé‡. å†æ·±ä¸€äº›çš„å±‚åŸºæœ¬éƒ½æ²¡æœ‰å¾—åˆ°è®­ç»ƒ, å› ä¸ºæ•°æ®å®åœ¨å¤ªå°‘äº†.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">æ·±åº¦å­¦ä¹ </a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86/" class="print-no-link">#ç¬”è®°æ•´ç†</a>
      
        <a href="/tags/transformer/" class="print-no-link">#transformer</a>
      
        <a href="/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" class="print-no-link">#ä»£ç å®ç°</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Transformerçš„ä»£ç å®ç°-åŸºäºPytorch</div>
      <div>https://linxkon.github.io/Transformerçš„ä»£ç å®ç°-åŸºäºPytorch.html</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>linxkon</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2023å¹´1æœˆ11æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/%E5%9F%BA%E4%BA%8EGRU%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%84%E5%BB%BA%E5%B8%A6%E7%BC%96-%E8%A7%A3%E7%A0%81%E5%99%A8%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E8%8B%B1%E8%AF%91%E6%B3%95%E4%BB%BB%E5%8A%A1%E5%AE%9E%E7%8E%B0.html" title="åŸºäºGRUæ¨¡å‹çš„å¸¦ç¼–-è§£ç å™¨å’Œæ³¨æ„åŠ›æœºåˆ¶çš„è‹±è¯‘æ³•ä»»åŠ¡å®ç°">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">åŸºäºGRUæ¨¡å‹çš„å¸¦ç¼–-è§£ç å™¨å’Œæ³¨æ„åŠ›æœºåˆ¶çš„è‹±è¯‘æ³•ä»»åŠ¡å®ç°</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/%E5%9C%A8CentOS%E4%B8%8A%E5%AE%89%E8%A3%85Neo4j%205.21.2%E7%9A%84%E6%AD%A5%E9%AA%A4.html" title="åœ¨CentOSä¸Šå®‰è£…Neo4j 5x">
                        <span class="hidden-mobile">åœ¨CentOSä¸Šå®‰è£…Neo4j 5x</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://lib.baomitu.com/gitalk/1.8.0/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"Ov23licg1p15oAGiQtDC","clientSecret":"d6ca3873752e3a6eb2d21a98b92a3021fd462cbf","repo":"Waline","owner":"linxkon","admin":["linxkon"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},
          {
            id: '653419d286b2415f402f5db352141ccd'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        æ€»è®¿é—®é‡
        <span id="leancloud-site-pv"></span>
        æ¬¡
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        è®¿å®¢é‡
        <span id="leancloud-site-uv"></span>
        æ¬¡
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg-full.js">
</script>
</body>
</html>
